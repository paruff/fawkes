{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Fawkes Internal Developer Platform","text":"Fawkes Platform Overview <p>Welcome to the Fawkes project! Fawkes is an open-source platform designed to help teams achieve elite performance in software delivery by implementing all 24 DORA capabilities through integrated tooling and practices. Based on research from \"Accelerate\" and the DORA State of DevOps reports, organizations that excel in these capabilities are twice as likely to exceed their organizational performance goals.</p>"},{"location":"#elite-performance-metrics","title":"\ud83c\udfaf Elite Performance Metrics","text":"Metric Elite Performance Industry Average Description Deployment Frequency Multiple deploys per day Between once per week and once per month How often an organization successfully releases to production Lead Time Less than one hour Between one week and one month The time it takes to go from code committed to code successfully running in production Change Failure Rate 0-15% 31-45% The percentage of changes that result in a failure in production MTTR Less than one hour Less than one day Mean Time to Restore - The time it takes to recover from a failure in production"},{"location":"#dora-capabilities-metric-impact","title":"\ud83c\udf1f DORA Capabilities &amp; Metric Impact","text":"<p>DORA research has identified specific capabilities that directly impact each performance metric. Below we map each capability to the metrics it most strongly influences, based on data from \"Accelerate: The Science of Lean Software and DevOps\".</p>"},{"location":"#deployment-frequency-drivers","title":"Deployment Frequency Drivers","text":"<p>These capabilities have the strongest positive correlation with deployment frequency:</p> Capability Purpose Implementation Performance Impact Continuous Delivery Ensuring software is always in a deployable state Spinnaker, Flux 2.5x higher deployment frequency Deployment Automation Automating the deployment process Jenkins 3x more frequent deployments Continuous Integration Frequently merging code changes GitHub Actions 2x higher deployment frequency Infrastructure as Code Using cloud and infrastructure-as-code Terraform 1.8x more frequent deployments"},{"location":"#lead-time-reducers","title":"Lead Time Reducers","text":"<p>These capabilities have the strongest positive correlation with reducing lead time:</p> Capability Purpose Implementation Performance Impact Continuous Integration Frequently merging code changes GitHub Actions 74% reduction in lead time Test Automation Automated testing at all levels Selenium, JUnit 67% reduction in lead time Loosely Coupled Architecture Enabling independent team work Kubernetes 56% reduction in lead time Database Change Management Managing database changes effectively Flyway 43% reduction in lead time"},{"location":"#change-failure-rate-reducers","title":"Change Failure Rate Reducers","text":"<p>These capabilities have the strongest positive correlation with reducing change failure rate:</p> Capability Purpose Implementation Performance Impact Test Automation Automated testing at all levels Selenium, JUnit 3x lower change failure rate Change Failure Rate Reduction Improving code quality SonarQube 1.8x fewer production defects Shift Left on Security Early security testing OWASP ZAP 2x fewer security incidents Monitoring and Observability Implementing comprehensive monitoring Prometheus, Grafana 2x more likely to detect issues before failure"},{"location":"#mttr-improvers","title":"MTTR Improvers","text":"<p>These capabilities have the strongest positive correlation with reducing mean time to restore:</p> Capability Purpose Implementation Performance Impact Time to Restore Service Quick incident resolution Grafana 73% faster MTTR Monitoring and Observability Implementing comprehensive monitoring Prometheus, Grafana 2.1x faster incident detection Proactive Failure Management Testing system resilience Chaos Mesh 1.5x faster incident resolution Infrastructure as Code Using cloud and infrastructure-as-code Terraform 1.7x faster recovery time"},{"location":"#capability-synergies","title":"\ud83d\udd04 Capability Synergies","text":"<p>According to DORA research, these capabilities work together to create a flywheel effect:</p> <pre><code>graph TD\n    A[Continuous Integration] --&gt; B[Test Automation]\n    B --&gt; C[Continuous Delivery]\n    C --&gt; D[Deployment Automation]\n    D --&gt; E[Monitoring &amp; Observability]\n    E --&gt; F[Incident Response]\n    F --&gt; A\n    G[Infrastructure as Code] --&gt; C\n    G --&gt; F\n    H[Loosely Coupled Architecture] --&gt; B\n    H --&gt; D</code></pre> <p>Organizations that implement capabilities across all three categories (Flow, Feedback, Recovery) are 5x more likely to achieve elite performance across all four key metrics.</p>"},{"location":"#getting-started","title":"\ud83d\udcc8 Getting Started","text":"<p>Start Here: Tutorials</p> <p>New to Fawkes? Begin with our guided tutorials to achieve your first success in under 30 minutes!</p> <p>Deploy Your First Service \u2192</p> <p>Complete all 6 tutorials to master core Fawkes workflows:</p> <ol> <li>Deploy Your First Service - 30 min</li> <li>Add Distributed Tracing - 25 min</li> <li>Consume Vault Secrets - 30 min</li> <li>Migrate to Buildpacks - 25 min</li> <li>Create a Golden Path Template - 35 min</li> <li>Measure DORA Metrics - 30 min</li> </ol>"},{"location":"#alternative-learning-paths","title":"Alternative Learning Paths","text":"<ol> <li>Assess your current capabilities</li> <li>Choose your implementation path</li> <li>Set up your first capability</li> </ol> <p>View All Tutorials Explore All Capabilities Dojo Learning Path</p>"},{"location":"AWS%20cost%20estimation/","title":"Fawkes AWS Cost Estimation","text":"<p>Document Purpose: Detailed AWS infrastructure cost analysis for Fawkes platform deployment Target Audience: AWS Activate reviewers, financial planning, infrastructure architects Last Updated: October 7, 2025 AWS Region: US-East-1 (Virginia) - Primary region for cost estimates</p>"},{"location":"AWS%20cost%20estimation/#executive-summary","title":"Executive Summary","text":"<p>Total Estimated Monthly Cost: $1,847/month Annual Projection: $22,164/year AWS Activate Credit Request: $25,000 (covers 13 months of operation)</p> <p>Primary AWS Services: - Amazon EKS (Kubernetes orchestration) - Amazon RDS (PostgreSQL databases) - Amazon S3 (Artifact storage) - Elastic Load Balancing (Application Load Balancers) - Amazon CloudWatch (Monitoring and logging) - AWS Secrets Manager (Secrets management) - Amazon ECR (Container registry)</p> <p>Cost Optimization Strategy: Implementing Reserved Instances, Spot instances, and auto-scaling can reduce costs by 40-60% after initial 6-month validation period.</p>"},{"location":"AWS%20cost%20estimation/#infrastructure-architecture-overview","title":"Infrastructure Architecture Overview","text":"<p>Fawkes requires three distinct environments to support: 1. Development: Active platform development and testing 2. Staging: Pre-production validation and integration testing 3. Production: Live platform serving community users and Dojo learners</p> <p>Each environment runs a complete stack including: - Kubernetes cluster (EKS) - PostgreSQL database (RDS) - Container registry (ECR) - Load balancers (ALB) - Monitoring and logging (CloudWatch) - Storage (S3, EBS)</p>"},{"location":"AWS%20cost%20estimation/#development-environment","title":"Development Environment","text":"<p>Purpose: Platform engineering team development, feature testing, automated CI/CD testing</p> <p>Traffic Profile: 5-10 concurrent users, intermittent usage (8 hours/day, 5 days/week)</p>"},{"location":"AWS%20cost%20estimation/#compute-amazon-eks","title":"Compute - Amazon EKS","text":"<p>EKS Control Plane: - Cost: $0.10/hour \u00d7 730 hours = $73.00/month - Note: Control plane runs 24/7 regardless of node usage</p> <p>Worker Nodes (3\u00d7 t3.medium instances): - Instance Type: t3.medium (2 vCPU, 4GB RAM) - Quantity: 3 nodes (minimum for HA) - On-Demand Cost: $0.0416/hour \u00d7 3 \u00d7 730 hours = $91.10/month - Storage: 50GB EBS gp3 per node \u00d7 3 = $0.08/GB \u00d7 150GB = $12.00/month</p> <p>EKS Subtotal: $176.10/month</p>"},{"location":"AWS%20cost%20estimation/#database-amazon-rds-postgresql","title":"Database - Amazon RDS PostgreSQL","text":"<p>Instance Configuration: - Instance Type: db.t3.medium (2 vCPU, 4GB RAM) - Engine: PostgreSQL 15.x - Single-AZ deployment (development only) - Storage: 100GB gp3 SSD - Cost Breakdown:   - Instance: $0.068/hour \u00d7 730 hours = $49.64/month   - Storage: 100GB \u00d7 $0.115/GB = $11.50/month   - Backup Storage: 100GB \u00d7 $0.095/GB = $9.50/month</p> <p>RDS Subtotal: $70.64/month</p>"},{"location":"AWS%20cost%20estimation/#load-balancing","title":"Load Balancing","text":"<p>Application Load Balancer (1): - ALB Hours: $0.0225/hour \u00d7 730 hours = $16.43/month - LCU (Load Capacity Units): ~5 LCUs average = $0.008 \u00d7 5 \u00d7 730 = $29.20/month</p> <p>ALB Subtotal: $45.63/month</p>"},{"location":"AWS%20cost%20estimation/#storage-amazon-s3","title":"Storage - Amazon S3","text":"<p>Container Images &amp; Artifacts: - Standard Storage: 50GB \u00d7 $0.023/GB = $1.15/month - PUT/GET Requests: ~10,000 requests = $0.05/month</p> <p>Backup Storage: - Standard-IA: 20GB \u00d7 $0.0125/GB = $0.25/month</p> <p>S3 Subtotal: $1.45/month</p>"},{"location":"AWS%20cost%20estimation/#container-registry-amazon-ecr","title":"Container Registry - Amazon ECR","text":"<p>Private Registry: - Storage: 30GB \u00d7 $0.10/GB = $3.00/month - Data Transfer: Negligible (within VPC)</p> <p>ECR Subtotal: $3.00/month</p>"},{"location":"AWS%20cost%20estimation/#monitoring-amazon-cloudwatch","title":"Monitoring - Amazon CloudWatch","text":"<p>Logs: - Ingestion: 20GB \u00d7 $0.50/GB = $10.00/month - Storage: 20GB \u00d7 $0.03/GB = $0.60/month</p> <p>Metrics: - Custom Metrics: 100 metrics \u00d7 $0.30 = $30.00/month</p> <p>CloudWatch Subtotal: $40.60/month</p>"},{"location":"AWS%20cost%20estimation/#secrets-management-aws-secrets-manager","title":"Secrets Management - AWS Secrets Manager","text":"<p>Secrets Storage: - 10 secrets \u00d7 $0.40/secret = $4.00/month - API Calls: 10,000 \u00d7 $0.05/10,000 = $0.50/month</p> <p>Secrets Manager Subtotal: $4.50/month</p>"},{"location":"AWS%20cost%20estimation/#networking","title":"Networking","text":"<p>NAT Gateway (1): - Hours: $0.045/hour \u00d7 730 hours = $32.85/month - Data Processing: 50GB \u00d7 $0.045/GB = $2.25/month</p> <p>Data Transfer: - Outbound to Internet: 20GB \u00d7 $0.09/GB = $1.80/month</p> <p>Networking Subtotal: $36.90/month</p>"},{"location":"AWS%20cost%20estimation/#development-environment-total-37882month","title":"Development Environment Total: $378.82/month","text":""},{"location":"AWS%20cost%20estimation/#staging-environment","title":"Staging Environment","text":"<p>Purpose: Pre-production validation, integration testing, performance testing, security scanning</p> <p>Traffic Profile: 10-20 concurrent users, continuous deployment testing, 12 hours/day operation</p>"},{"location":"AWS%20cost%20estimation/#compute-amazon-eks_1","title":"Compute - Amazon EKS","text":"<p>EKS Control Plane: $73.00/month</p> <p>Worker Nodes (4\u00d7 t3.large instances): - Instance Type: t3.large (2 vCPU, 8GB RAM) - Quantity: 4 nodes - On-Demand Cost: $0.0832/hour \u00d7 4 \u00d7 730 hours = $242.94/month - Storage: 100GB EBS gp3 per node \u00d7 4 = $0.08/GB \u00d7 400GB = $32.00/month</p> <p>EKS Subtotal: $347.94/month</p>"},{"location":"AWS%20cost%20estimation/#database-amazon-rds-postgresql_1","title":"Database - Amazon RDS PostgreSQL","text":"<p>Instance Configuration: - Instance Type: db.t3.large (2 vCPU, 8GB RAM) - Single-AZ (staging environment) - Storage: 200GB gp3 SSD - Cost Breakdown:   - Instance: $0.136/hour \u00d7 730 hours = $99.28/month   - Storage: 200GB \u00d7 $0.115/GB = $23.00/month   - Backup Storage: 200GB \u00d7 $0.095/GB = $19.00/month</p> <p>RDS Subtotal: $141.28/month</p>"},{"location":"AWS%20cost%20estimation/#load-balancing_1","title":"Load Balancing","text":"<p>Application Load Balancers (2): - ALB Hours: $0.0225/hour \u00d7 2 \u00d7 730 hours = $32.85/month - LCU: ~8 LCUs average \u00d7 2 = $0.008 \u00d7 16 \u00d7 730 = $93.44/month</p> <p>ALB Subtotal: $126.29/month</p>"},{"location":"AWS%20cost%20estimation/#storage-amazon-s3_1","title":"Storage - Amazon S3","text":"<p>Container Images &amp; Artifacts: - Standard Storage: 100GB \u00d7 $0.023/GB = $2.30/month - PUT/GET Requests: ~50,000 requests = $0.25/month</p> <p>Backup Storage: - Standard-IA: 50GB \u00d7 $0.0125/GB = $0.63/month</p> <p>S3 Subtotal: $3.18/month</p>"},{"location":"AWS%20cost%20estimation/#container-registry-amazon-ecr_1","title":"Container Registry - Amazon ECR","text":"<p>Private Registry: - Storage: 50GB \u00d7 $0.10/GB = $5.00/month</p> <p>ECR Subtotal: $5.00/month</p>"},{"location":"AWS%20cost%20estimation/#monitoring-amazon-cloudwatch_1","title":"Monitoring - Amazon CloudWatch","text":"<p>Logs: - Ingestion: 40GB \u00d7 $0.50/GB = $20.00/month - Storage: 40GB \u00d7 $0.03/GB = $1.20/month</p> <p>Metrics: - Custom Metrics: 200 metrics \u00d7 $0.30 = $60.00/month</p> <p>Alarms: 20 alarms \u00d7 $0.10 = $2.00/month</p> <p>CloudWatch Subtotal: $83.20/month</p>"},{"location":"AWS%20cost%20estimation/#aws-x-ray-distributed-tracing","title":"AWS X-Ray (Distributed Tracing)","text":"<p>Traces Recorded: 1 million traces \u00d7 $5.00/million = $5.00/month Traces Retrieved: 100K traces \u00d7 $0.50/million = $0.05/month</p> <p>X-Ray Subtotal: $5.05/month</p>"},{"location":"AWS%20cost%20estimation/#secrets-management","title":"Secrets Management","text":"<p>Secrets Storage: - 15 secrets \u00d7 $0.40/secret = $6.00/month - API Calls: 50,000 \u00d7 $0.05/10,000 = $2.50/month</p> <p>Secrets Manager Subtotal: $8.50/month</p>"},{"location":"AWS%20cost%20estimation/#networking_1","title":"Networking","text":"<p>NAT Gateway (1): - Hours: $0.045/hour \u00d7 730 hours = $32.85/month - Data Processing: 100GB \u00d7 $0.045/GB = $4.50/month</p> <p>Data Transfer: - Outbound to Internet: 50GB \u00d7 $0.09/GB = $4.50/month</p> <p>Networking Subtotal: $41.85/month</p>"},{"location":"AWS%20cost%20estimation/#staging-environment-total-76229month","title":"Staging Environment Total: $762.29/month","text":""},{"location":"AWS%20cost%20estimation/#production-environment","title":"Production Environment","text":"<p>Purpose: Live platform serving community users, Dojo learning environment for 200+ concurrent learners</p> <p>Traffic Profile: 50-200 concurrent users, 24/7 availability, high-availability requirements</p>"},{"location":"AWS%20cost%20estimation/#compute-amazon-eks_2","title":"Compute - Amazon EKS","text":"<p>EKS Control Plane: $73.00/month</p> <p>Worker Nodes (6\u00d7 t3.xlarge instances): - Instance Type: t3.xlarge (4 vCPU, 16GB RAM) - Quantity: 6 nodes (3 per AZ, 2 AZs for HA) - On-Demand Cost: $0.1664/hour \u00d7 6 \u00d7 730 hours = $728.83/month - Storage: 200GB EBS gp3 per node \u00d7 6 = $0.08/GB \u00d7 1,200GB = $96.00/month</p> <p>Note: Production will use Reserved Instances after validation period (40% savings = $291.53/month savings)</p> <p>EKS Subtotal: $897.83/month</p>"},{"location":"AWS%20cost%20estimation/#database-amazon-rds-postgresql_2","title":"Database - Amazon RDS PostgreSQL","text":"<p>Instance Configuration: - Instance Type: db.m5.large (2 vCPU, 8GB RAM) - Multi-AZ deployment (high availability) - Storage: 500GB gp3 SSD - Automated backups with 7-day retention - Cost Breakdown:   - Instance (Multi-AZ): $0.190/hour \u00d7 730 hours \u00d7 2 = $277.40/month   - Storage: 500GB \u00d7 $0.115/GB = $57.50/month   - Backup Storage: 500GB \u00d7 $0.095/GB = $47.50/month   - PIOPS (Provisioned IOPS): 3000 IOPS \u00d7 $0.10 = $300.00/month (optional, for high-traffic scenarios)</p> <p>RDS Subtotal (without PIOPS): $382.40/month RDS Subtotal (with PIOPS): $682.40/month</p> <p>Using base configuration (without PIOPS) for conservative estimate</p>"},{"location":"AWS%20cost%20estimation/#load-balancing_2","title":"Load Balancing","text":"<p>Application Load Balancers (3): - ALB Hours: $0.0225/hour \u00d7 3 \u00d7 730 hours = $49.28/month - LCU: ~20 LCUs average \u00d7 3 = $0.008 \u00d7 60 \u00d7 730 = $350.40/month</p> <p>ALB Subtotal: $399.68/month</p>"},{"location":"AWS%20cost%20estimation/#storage-amazon-s3_2","title":"Storage - Amazon S3","text":"<p>Container Images &amp; Artifacts: - Standard Storage: 300GB \u00d7 $0.023/GB = $6.90/month - PUT/GET Requests: ~200,000 requests = $1.00/month</p> <p>Backup Storage: - Standard-IA: 200GB \u00d7 $0.0125/GB = $2.50/month</p> <p>Glacier Deep Archive (long-term backups): - 500GB \u00d7 $0.00099/GB = $0.50/month</p> <p>S3 Subtotal: $10.90/month</p>"},{"location":"AWS%20cost%20estimation/#container-registry-amazon-ecr_2","title":"Container Registry - Amazon ECR","text":"<p>Private Registry: - Storage: 100GB \u00d7 $0.10/GB = $10.00/month - Data Transfer (within region): Included</p> <p>ECR Subtotal: $10.00/month</p>"},{"location":"AWS%20cost%20estimation/#monitoring-amazon-cloudwatch_2","title":"Monitoring - Amazon CloudWatch","text":"<p>Logs: - Ingestion: 100GB \u00d7 $0.50/GB = $50.00/month - Storage: 100GB \u00d7 $0.03/GB = $3.00/month</p> <p>Metrics: - Custom Metrics: 500 metrics \u00d7 $0.30 = $150.00/month</p> <p>Alarms: 50 alarms \u00d7 $0.10 = $5.00/month</p> <p>CloudWatch Subtotal: $208.00/month</p>"},{"location":"AWS%20cost%20estimation/#aws-x-ray-distributed-tracing_1","title":"AWS X-Ray (Distributed Tracing)","text":"<p>Traces Recorded: 5 million traces \u00d7 $5.00/million = $25.00/month Traces Retrieved: 500K traces \u00d7 $0.50/million = $0.25/month</p> <p>X-Ray Subtotal: $25.25/month</p>"},{"location":"AWS%20cost%20estimation/#secrets-management_1","title":"Secrets Management","text":"<p>Secrets Storage: - 25 secrets \u00d7 $0.40/secret = $10.00/month - API Calls: 200,000 \u00d7 $0.05/10,000 = $10.00/month</p> <p>Secrets Manager Subtotal: $20.00/month</p>"},{"location":"AWS%20cost%20estimation/#networking_2","title":"Networking","text":"<p>NAT Gateways (2, one per AZ for HA): - Hours: $0.045/hour \u00d7 2 \u00d7 730 hours = $65.70/month - Data Processing: 300GB \u00d7 $0.045/GB = $13.50/month</p> <p>Data Transfer: - Outbound to Internet: 200GB \u00d7 $0.09/GB = $18.00/month</p> <p>VPC Endpoints (for S3, ECR): - 2 endpoints \u00d7 $0.01/hour \u00d7 730 hours = $14.60/month</p> <p>Networking Subtotal: $111.80/month</p>"},{"location":"AWS%20cost%20estimation/#aws-certificate-manager","title":"AWS Certificate Manager","text":"<p>SSL/TLS Certificates: Free (public certificates)</p>"},{"location":"AWS%20cost%20estimation/#aws-waf-web-application-firewall","title":"AWS WAF (Web Application Firewall)","text":"<p>Web ACL: $5.00/month Rules: 5 rules \u00d7 $1.00 = $5.00/month Requests: 10 million \u00d7 $0.60/million = $6.00/month</p> <p>WAF Subtotal: $16.00/month</p>"},{"location":"AWS%20cost%20estimation/#production-environment-total-208386month","title":"Production Environment Total: $2,083.86/month","text":"<p>(Conservative estimate without PIOPS, with potential to add $300/month for high-performance scenarios)</p>"},{"location":"AWS%20cost%20estimation/#cost-summary-all-environments","title":"Cost Summary: All Environments","text":"Environment Monthly Cost Annual Cost % of Total Development $378.82 $4,545.84 18% Staging $762.29 $9,147.48 37% Production $2,083.86 $25,006.32 100% TOTAL (3 Environments) $3,224.97 $38,699.64 -"},{"location":"AWS%20cost%20estimation/#phased-rollout-recommended","title":"Phased Rollout (Recommended)","text":"<p>Phase 1: Months 1-3 (Development Only) - Monthly: $378.82 - Quarterly Total: $1,136.46</p> <p>Phase 2: Months 4-6 (Development + Staging) - Monthly: $378.82 + $762.29 = $1,141.11 - Quarterly Total: $3,423.33</p> <p>Phase 3: Months 7-12 (All Three Environments) - Monthly: $3,224.97 - Semi-Annual Total: $19,349.82</p> <p>12-Month Phased Total: $23,909.61</p>"},{"location":"AWS%20cost%20estimation/#aws-activate-credit-request-justification","title":"AWS Activate Credit Request Justification","text":""},{"location":"AWS%20cost%20estimation/#requested-amount-25000","title":"Requested Amount: $25,000","text":"<p>Allocation Strategy:</p> <p>Phase 1 (Months 1-3): $1,200 credits - Build production-grade reference implementation - Complete Terraform modules for AWS - Deploy and validate all platform services - Document deployment patterns</p> <p>Phase 2 (Months 4-6): $3,500 credits - Launch staging environment for testing - Begin Dojo learning platform development - Support initial community adopters (10-20 users) - Implement automated testing infrastructure</p> <p>Phase 3 (Months 7-12): $20,300 credits - Launch production environment for community - Scale Dojo platform to 200+ concurrent learners - Provide demo environments for enterprise prospects - Support growing open-source community</p> <p>Reserve/Buffer: $0 (exact 12-month coverage)</p>"},{"location":"AWS%20cost%20estimation/#cost-optimization-strategy","title":"Cost Optimization Strategy","text":""},{"location":"AWS%20cost%20estimation/#immediate-optimizations-months-1-6","title":"Immediate Optimizations (Months 1-6)","text":"<p>Development Environment: - Use Spot Instances for worker nodes: 30% savings = $27.33/month - Schedule shutdown during non-business hours (nights/weekends): 60% uptime = $54.66/month saved - Combined Savings: $82/month or $492 over 6 months</p> <p>Staging Environment: - Use Spot Instances where possible: 25% savings = $60.74/month - Schedule shutdown outside testing windows: 40% savings = $140.79/month - Combined Savings: $201.53/month or $1,209 over 6 months</p> <p>Total Phase 1-2 Savings: $1,701 over 6 months</p>"},{"location":"AWS%20cost%20estimation/#long-term-optimizations-months-7-12","title":"Long-Term Optimizations (Months 7-12)","text":"<p>Reserved Instances (1-year commitment after validation): - EKS Worker Nodes: 40% savings = $291.53/month - RDS Instances: 35% savings = $133.84/month - Combined Savings: $425.37/month or $2,552 over 6 months</p> <p>Auto-Scaling Policies: - Scale down during low-traffic periods (nights): 15% compute savings = $109.32/month - Right-size instances based on utilization: 10% additional savings = $72.88/month - Combined Savings: $182.20/month or $1,093 over 6 months</p> <p>Storage Optimization: - Lifecycle policies for S3 (move to IA after 30 days): 20% savings = $2.18/month - EBS snapshot management (delete old snapshots): 10% savings = $9.60/month - Combined Savings: $11.78/month or $71 over 6 months</p> <p>Total Phase 3 Savings: $3,716 over 6 months</p>"},{"location":"AWS%20cost%20estimation/#projected-12-month-cost-with-optimizations","title":"Projected 12-Month Cost with Optimizations","text":"<ul> <li>Months 1-6 (with immediate optimizations): $1,136.46 + ($3,423.33 - $1,209) = $3,350.79</li> <li>Months 7-12 (with all optimizations): ($19,349.82 - $3,716) = $15,633.82</li> <li>Total Optimized 12-Month Cost: $18,984.61</li> </ul> <p>Savings vs. Baseline: $23,909.61 - $18,984.61 = $4,925 (21% reduction)</p>"},{"location":"AWS%20cost%20estimation/#monitoring-and-cost-control","title":"Monitoring and Cost Control","text":""},{"location":"AWS%20cost%20estimation/#aws-cost-management-tools","title":"AWS Cost Management Tools","text":"<p>AWS Budgets: - Set monthly budget alerts at 80%, 100%, 120% thresholds - Email notifications to team and AWS billing contact - Automatic notifications for anomaly detection</p> <p>Cost Allocation Tags: <pre><code>Environment: [dev|staging|prod]\nProject: fawkes\nComponent: [eks|rds|s3|alb|cloudwatch]\nOwner: platform-team\nCostCenter: engineering\n</code></pre></p> <p>AWS Cost Explorer: - Weekly cost reviews - Identify cost anomalies - Track savings from optimizations</p> <p>Third-Party Tools (optional): - CloudHealth or CloudCheckr for advanced cost optimization - Infracost for Terraform cost estimation in CI/CD</p>"},{"location":"AWS%20cost%20estimation/#cost-anomaly-detection","title":"Cost Anomaly Detection","text":"<p>Automated Alerts for: - Unexpected traffic spikes (LCU increases) - Storage growth exceeding 20% month-over-month - Compute utilization above 85% (scale up) or below 30% (scale down) - Data transfer costs exceeding $100/month</p>"},{"location":"AWS%20cost%20estimation/#monthly-cost-review-process","title":"Monthly Cost Review Process","text":"<p>Week 1: Review previous month's spend vs. budget Week 2: Analyze cost trends and usage patterns Week 3: Implement optimization recommendations Week 4: Validate optimizations and adjust budgets</p>"},{"location":"AWS%20cost%20estimation/#additional-aws-services-optionalfuture","title":"Additional AWS Services (Optional/Future)","text":"<p>Services we may adopt as platform matures:</p> Service Use Case Estimated Monthly Cost AWS Config Compliance tracking $20-$50 AWS GuardDuty Threat detection $30-$100 AWS Security Hub Security posture $10-$30 AWS Systems Manager Parameter store (alternative to Secrets Manager) $5-$15 Amazon OpenSearch Log analytics (alternative to self-hosted) $200-$500 AWS Backup Centralized backup management $50-$150 Amazon CloudFront CDN for static assets $20-$100 AWS Lambda Serverless automation $10-$50 <p>Total Optional Services: $345-$995/month</p> <p>These services are not included in base cost estimate but represent future expansion opportunities.</p>"},{"location":"AWS%20cost%20estimation/#roi-analysis","title":"ROI Analysis","text":""},{"location":"AWS%20cost%20estimation/#value-delivered-by-aws-credits","title":"Value Delivered by AWS Credits","text":"<p>Direct Benefits: - Platform Development: 12 months of uninterrupted development - Community Support: 200+ learners trained on Dojo platform - Enterprise Demos: 20+ prospect demonstrations - Open Source Contributions: Reference implementation for AWS deployments</p> <p>Indirect Benefits: - AWS Advocacy: Every Dojo graduate learns AWS-native platform engineering - Ecosystem Growth: Fawkes users become AWS customers - Documentation: Comprehensive AWS deployment guides benefit broader community - Best Practices: Showcase modern AWS architecture patterns</p>"},{"location":"AWS%20cost%20estimation/#expected-outcomes-12-month-horizon","title":"Expected Outcomes (12-Month Horizon)","text":"<p>Community Metrics: - 500+ GitHub stars - 50+ active contributors - 200+ Dojo learners certified - 20+ organizations adopting Fawkes on AWS</p> <p>Business Metrics: - 10 enterprise pilot programs - $10K MRR from managed service beta - 5 partnerships with training organizations - 100+ job placements for Dojo graduates</p> <p>AWS-Specific Outcomes: - 30+ organizations migrated to AWS using Fawkes - $500K+ annual AWS spend driven by Fawkes users - 200+ engineers trained on AWS services - Contribution to AWS EKS/RDS/CloudWatch ecosystems</p>"},{"location":"AWS%20cost%20estimation/#conclusion","title":"Conclusion","text":"<p>Total AWS Investment Required: $23,910 over 12 months (phased) AWS Activate Credit Request: $25,000 Optimized Cost (with savings): $18,985 (21% under budget)</p> <p>Why This Investment Makes Sense:</p> <ol> <li>AWS-Native Platform: Fawkes is purpose-built for AWS, showcasing EKS, RDS, S3, and CloudWatch</li> <li>Community Impact: Training 200+ platform engineers who will use AWS in their organizations</li> <li>Open Source Value: Reference implementation benefits entire AWS community</li> <li>Long-Term AWS Commitment: Every Fawkes user is a potential AWS customer</li> <li>Cost-Effective: Phased approach validates value before full-scale deployment</li> </ol> <p>Next Steps: 1. Secure AWS Activate credits ($25,000) 2. Deploy Phase 1 (Development environment) 3. Build reference implementation and documentation 4. Launch Dojo platform (Phase 2-3) 5. Support community growth and enterprise adoption</p>"},{"location":"AWS%20cost%20estimation/#appendix-aws-pricing-assumptions","title":"Appendix: AWS Pricing Assumptions","text":"<p>Pricing effective as of: October 2025 Region: US-East-1 (N. Virginia) Currency: USD Pricing Model: On-Demand (with Reserved Instance projections)</p> <p>Sources: - AWS Pricing Calculator - Amazon EKS Pricing - Amazon RDS Pricing - Amazon S3 Pricing - Elastic Load Balancing Pricing</p> <p>Disclaimer: Actual costs may vary based on usage patterns, data transfer, and AWS pricing changes. This estimate provides a conservative baseline for planning purposes.</p> <p>Document Owner: Fawkes Platform Team Review Cadence: Monthly during AWS Activate period Last Review: October 7, 2025 Next Review: November 7, 2025</p>"},{"location":"AWS_deployment_guide/","title":"Fawkes AWS Production Deployment Guide","text":"<p>Document Purpose: Complete step-by-step guide for deploying Fawkes on AWS in production Target Audience: DevOps engineers, Platform engineers, System administrators Estimated Time: 3-4 hours for full deployment Last Updated: October 7, 2025</p>"},{"location":"AWS_deployment_guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisites</li> <li>Architecture Overview</li> <li>Pre-Deployment Planning</li> <li>Phase 1: AWS Foundation Setup</li> <li>Phase 2: EKS Cluster Deployment</li> <li>Phase 3: Database and Storage</li> <li>Phase 4: Platform Services</li> <li>Phase 5: Observability Stack</li> <li>Phase 6: Security Hardening</li> <li>Phase 7: Validation and Testing</li> <li>Post-Deployment Operations</li> <li>Troubleshooting</li> <li>Cost Optimization</li> </ol>"},{"location":"AWS_deployment_guide/#prerequisites","title":"Prerequisites","text":""},{"location":"AWS_deployment_guide/#required-tools","title":"Required Tools","text":"<p>Install these tools on your local machine before beginning:</p> <pre><code># AWS CLI (version 2.x)\ncurl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\nunzip awscliv2.zip\nsudo ./aws/install\naws --version  # Should be 2.x\n\n# kubectl (Kubernetes CLI)\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin/\nkubectl version --client\n\n# Terraform (1.5.0 or later)\nwget https://releases.hashicorp.com/terraform/1.6.0/terraform_1.6.0_linux_amd64.zip\nunzip terraform_1.6.0_linux_amd64.zip\nsudo mv terraform /usr/local/bin/\nterraform version\n\n# Helm (Kubernetes package manager)\ncurl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\nhelm version\n\n# eksctl (EKS cluster management)\ncurl --silent --location \"https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\" | tar xz -C /tmp\nsudo mv /tmp/eksctl /usr/local/bin\neksctl version\n\n# jq (JSON processor - for scripts)\nsudo apt-get install jq -y  # Ubuntu/Debian\n# or\nsudo yum install jq -y      # RHEL/CentOS\n</code></pre>"},{"location":"AWS_deployment_guide/#aws-account-requirements","title":"AWS Account Requirements","text":"<p>IAM Permissions Needed: - EC2 (VPC, Security Groups, EBS) - EKS (Cluster creation and management) - RDS (PostgreSQL instances) - S3 (Bucket creation and management) - IAM (Role and policy creation) - CloudWatch (Logs and metrics) - Certificate Manager (SSL/TLS certificates) - Secrets Manager (Secret storage) - Application Load Balancer - Route53 (DNS management - optional)</p> <p>Recommended: Use an IAM user with <code>AdministratorAccess</code> for initial setup, then lock down to least-privilege after deployment.</p> <p>Service Limits Check: <pre><code># Check EKS cluster limit (default: 100 per region)\naws service-quotas get-service-quota \\\n  --service-code eks \\\n  --quota-code L-1194D53C \\\n  --region us-east-1\n\n# Check EIP limit (need at least 3 for NAT gateways)\naws service-quotas get-service-quota \\\n  --service-code ec2 \\\n  --quota-code L-0263D0A3 \\\n  --region us-east-1\n</code></pre></p>"},{"location":"AWS_deployment_guide/#domain-and-ssl-optional-but-recommended","title":"Domain and SSL (Optional but Recommended)","text":"<p>For production deployments: - Domain name (e.g., <code>fawkes.yourdomain.com</code>) - Access to DNS management (Route53 or external DNS provider) - SSL certificate via AWS Certificate Manager (we'll create this)</p> <p>Without domain: - Can use AWS-provided Load Balancer DNS names - Self-signed certificates (development only)</p>"},{"location":"AWS_deployment_guide/#budget-and-cost-awareness","title":"Budget and Cost Awareness","text":"<p>Expected Monthly Costs: - Development: ~$379/month - Staging: ~$762/month - Production: ~$2,084/month</p> <p>See AWS Cost Estimation for detailed breakdown.</p> <p>Set up billing alerts: <pre><code>aws budgets create-budget \\\n  --account-id YOUR_ACCOUNT_ID \\\n  --budget file://budget.json \\\n  --notifications-with-subscribers file://notifications.json\n</code></pre></p>"},{"location":"AWS_deployment_guide/#architecture-overview","title":"Architecture Overview","text":""},{"location":"AWS_deployment_guide/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         AWS Region (us-east-1)               \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                   VPC (10.0.0.0/16)                    \u2502 \u2502\n\u2502  \u2502                                                        \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502   Public     \u2502  \u2502   Public     \u2502  \u2502   Public    \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  Subnet AZ1  \u2502  \u2502  Subnet AZ2  \u2502  \u2502 Subnet AZ3  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 10.0.1.0/24  \u2502  \u2502 10.0.2.0/24  \u2502  \u250210.0.3.0/24  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502              \u2502  \u2502              \u2502  \u2502             \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  NAT GW      \u2502  \u2502  NAT GW      \u2502  \u2502  NAT GW     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  ALB         \u2502  \u2502  ALB         \u2502  \u2502             \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2502         \u2502                 \u2502                 \u2502         \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502   Private    \u2502  \u2502   Private    \u2502  \u2502   Private   \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  Subnet AZ1  \u2502  \u2502  Subnet AZ2  \u2502  \u2502 Subnet AZ3  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 10.0.11.0/24 \u2502  \u2502 10.0.12.0/24 \u2502  \u250210.0.13.0/24 \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502              \u2502  \u2502              \u2502  \u2502             \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 EKS Nodes    \u2502  \u2502 EKS Nodes    \u2502  \u2502 EKS Nodes   \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 RDS Primary  \u2502  \u2502 RDS Standby  \u2502  \u2502             \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2502                                                        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  EKS Cluster (fawkes-production)                       \u2502 \u2502\n\u2502  \u2502  - Backstage Portal                                    \u2502 \u2502\n\u2502  \u2502  - Jenkins CI/CD                                       \u2502 \u2502\n\u2502  \u2502  - ArgoCD (GitOps)                                     \u2502 \u2502\n\u2502  \u2502  - Harbor (Registry)                                   \u2502 \u2502\n\u2502  \u2502  - Prometheus + Grafana                                \u2502 \u2502\n\u2502  \u2502  - Mattermost                                          \u2502 \u2502\n\u2502  \u2502  - Focalboard                                          \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  RDS PostgreSQL (Multi-AZ)                             \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  S3 Buckets                                            \u2502 \u2502\n\u2502  \u2502  - Artifacts (fawkes-artifacts-prod)                   \u2502 \u2502\n\u2502  \u2502  - Backups (fawkes-backups-prod)                       \u2502 \u2502\n\u2502  \u2502  - Logs (fawkes-logs-prod)                             \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"AWS_deployment_guide/#network-design","title":"Network Design","text":"<p>VPC CIDR: <code>10.0.0.0/16</code> (65,536 IPs)</p> <p>Subnets: - Public Subnets (3 AZs): <code>10.0.1.0/24</code>, <code>10.0.2.0/24</code>, <code>10.0.3.0/24</code>   - Internet Gateway attached   - NAT Gateways deployed here   - Application Load Balancers</p> <ul> <li>Private Subnets (3 AZs): <code>10.0.11.0/24</code>, <code>10.0.12.0/24</code>, <code>10.0.13.0/24</code></li> <li>No direct internet access</li> <li>EKS worker nodes</li> <li>RDS instances</li> <li>Egress via NAT Gateways</li> </ul> <p>Why 3 Availability Zones? - High availability and fault tolerance - EKS best practice (distribute nodes across AZs) - RDS Multi-AZ automatic failover</p>"},{"location":"AWS_deployment_guide/#component-placement","title":"Component Placement","text":"Component Subnet Type Availability Zones Accessibility Internet Gateway N/A Region-level Public NAT Gateways Public 3 (one per AZ) Public IPs Application Load Balancers Public 3 Internet-facing EKS Worker Nodes Private 3 Internal only RDS PostgreSQL Private 2 (Multi-AZ) Internal only S3 Buckets N/A Region-level VPC Endpoint"},{"location":"AWS_deployment_guide/#pre-deployment-planning","title":"Pre-Deployment Planning","text":""},{"location":"AWS_deployment_guide/#environment-configuration","title":"Environment Configuration","text":"<p>Create a <code>production.tfvars</code> file with your specific configuration:</p> <pre><code># production.tfvars\n\n# General Settings\nenvironment         = \"production\"\nproject_name        = \"fawkes\"\naws_region          = \"us-east-1\"\navailability_zones  = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n\n# VPC Configuration\nvpc_cidr            = \"10.0.0.0/16\"\npublic_subnet_cidrs = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\nprivate_subnet_cidrs = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n\n# EKS Cluster Configuration\ncluster_name        = \"fawkes-production\"\ncluster_version     = \"1.28\"\nnode_instance_type  = \"t3.xlarge\"\nnode_desired_size   = 6\nnode_min_size       = 3\nnode_max_size       = 12\n\n# RDS Configuration\ndb_instance_class   = \"db.m5.large\"\ndb_engine_version   = \"15.4\"\ndb_name             = \"fawkes\"\ndb_username         = \"fawkesadmin\"\ndb_multi_az         = true\ndb_allocated_storage = 500\ndb_backup_retention = 7\n\n# S3 Bucket Names (must be globally unique)\nartifacts_bucket    = \"fawkes-artifacts-prod-YOUR-UNIQUE-ID\"\nbackups_bucket      = \"fawkes-backups-prod-YOUR-UNIQUE-ID\"\nlogs_bucket         = \"fawkes-logs-prod-YOUR-UNIQUE-ID\"\n\n# Domain Configuration (optional)\ndomain_name         = \"fawkes.yourdomain.com\"\ncreate_route53_zone = false  # Set to true if you want Terraform to manage DNS\n\n# Tags\ntags = {\n  Environment = \"production\"\n  Project     = \"fawkes\"\n  ManagedBy   = \"terraform\"\n  Owner       = \"platform-team\"\n  CostCenter  = \"engineering\"\n}\n</code></pre>"},{"location":"AWS_deployment_guide/#secrets-management","title":"Secrets Management","text":"<p>Generate secure passwords BEFORE deployment:</p> <pre><code># Generate database password\nDB_PASSWORD=$(openssl rand -base64 32)\necho \"Database Password: $DB_PASSWORD\"  # Save this securely!\n\n# Generate ArgoCD admin password\nARGOCD_PASSWORD=$(openssl rand -base64 24)\necho \"ArgoCD Password: $ARGOCD_PASSWORD\"\n\n# Generate Jenkins admin password\nJENKINS_PASSWORD=$(openssl rand -base64 24)\necho \"Jenkins Password: $JENKINS_PASSWORD\"\n\n# Store in AWS Secrets Manager (we'll do this in Phase 1)\n</code></pre> <p>IMPORTANT: Store all passwords in a secure password manager (1Password, LastPass, etc.) immediately.</p>"},{"location":"AWS_deployment_guide/#pre-flight-checklist","title":"Pre-Flight Checklist","text":"<p>Before proceeding, verify:</p> <ul> <li>[ ] AWS CLI configured with correct credentials (<code>aws sts get-caller-identity</code>)</li> <li>[ ] All required tools installed and correct versions</li> <li>[ ] <code>production.tfvars</code> file created with your values</li> <li>[ ] All passwords generated and stored securely</li> <li>[ ] S3 bucket names are globally unique (add your org/random suffix)</li> <li>[ ] Budget alerts configured (optional but recommended)</li> <li>[ ] Team notified of deployment window (estimated 3-4 hours)</li> </ul>"},{"location":"AWS_deployment_guide/#phase-1-aws-foundation-setup","title":"Phase 1: AWS Foundation Setup","text":"<p>Duration: 30 minutes Goal: Create VPC, subnets, security groups, and IAM roles</p>"},{"location":"AWS_deployment_guide/#step-11-initialize-terraform","title":"Step 1.1: Initialize Terraform","text":"<pre><code># Clone the Fawkes repository\ngit clone https://github.com/paruff/fawkes.git\ncd fawkes/infra/terraform/aws\n\n# Initialize Terraform\nterraform init\n\n# Validate configuration\nterraform validate\n\n# Plan deployment (review what will be created)\nterraform plan -var-file=production.tfvars -out=tfplan\n</code></pre> <p>Review the plan carefully. You should see: - 1 VPC - 6 subnets (3 public, 3 private) - 1 Internet Gateway - 3 NAT Gateways - Route tables and associations - Security groups - IAM roles and policies</p>"},{"location":"AWS_deployment_guide/#step-12-deploy-vpc-and-networking","title":"Step 1.2: Deploy VPC and Networking","text":"<pre><code># Apply the foundation infrastructure\nterraform apply tfplan\n\n# This will take ~10 minutes (NAT Gateways are slow to provision)\n</code></pre> <p>Expected output: <pre><code>Apply complete! Resources: 42 added, 0 changed, 0 destroyed.\n\nOutputs:\nvpc_id = \"vpc-0a1b2c3d4e5f6g7h8\"\npublic_subnet_ids = [\"subnet-abc123\", \"subnet-def456\", \"subnet-ghi789\"]\nprivate_subnet_ids = [\"subnet-xyz123\", \"subnet-uvw456\", \"subnet-rst789\"]\nnat_gateway_ids = [\"nat-0a1b2c3d\", \"nat-4e5f6g7h\", \"nat-8i9j0k1l\"]\n</code></pre></p>"},{"location":"AWS_deployment_guide/#step-13-create-s3-buckets","title":"Step 1.3: Create S3 Buckets","text":"<pre><code># Create artifacts bucket\naws s3 mb s3://fawkes-artifacts-prod-YOUR-UNIQUE-ID --region us-east-1\n\n# Enable versioning for artifacts\naws s3api put-bucket-versioning \\\n  --bucket fawkes-artifacts-prod-YOUR-UNIQUE-ID \\\n  --versioning-configuration Status=Enabled\n\n# Create backups bucket\naws s3 mb s3://fawkes-backups-prod-YOUR-UNIQUE-ID --region us-east-1\n\n# Enable versioning for backups\naws s3api put-bucket-versioning \\\n  --bucket fawkes-backups-prod-YOUR-UNIQUE-ID \\\n  --versioning-configuration Status=Enabled\n\n# Create logs bucket\naws s3 mb s3://fawkes-logs-prod-YOUR-UNIQUE-ID --region us-east-1\n\n# Configure lifecycle policy for logs (delete after 90 days)\ncat &gt; logs-lifecycle.json &lt;&lt;EOF\n{\n  \"Rules\": [\n    {\n      \"Id\": \"DeleteOldLogs\",\n      \"Status\": \"Enabled\",\n      \"Prefix\": \"\",\n      \"Expiration\": {\n        \"Days\": 90\n      }\n    }\n  ]\n}\nEOF\n\naws s3api put-bucket-lifecycle-configuration \\\n  --bucket fawkes-logs-prod-YOUR-UNIQUE-ID \\\n  --lifecycle-configuration file://logs-lifecycle.json\n\n# Enable encryption at rest for all buckets\nfor bucket in fawkes-artifacts-prod-YOUR-UNIQUE-ID fawkes-backups-prod-YOUR-UNIQUE-ID fawkes-logs-prod-YOUR-UNIQUE-ID; do\n  aws s3api put-bucket-encryption \\\n    --bucket $bucket \\\n    --server-side-encryption-configuration '{\n      \"Rules\": [\n        {\n          \"ApplyServerSideEncryptionByDefault\": {\n            \"SSEAlgorithm\": \"AES256\"\n          }\n        }\n      ]\n    }'\ndone\n</code></pre>"},{"location":"AWS_deployment_guide/#step-14-store-secrets-in-aws-secrets-manager","title":"Step 1.4: Store Secrets in AWS Secrets Manager","text":"<pre><code># Store database password\naws secretsmanager create-secret \\\n  --name fawkes/production/db-password \\\n  --description \"Fawkes Production Database Password\" \\\n  --secret-string \"$DB_PASSWORD\" \\\n  --region us-east-1\n\n# Store ArgoCD admin password\naws secretsmanager create-secret \\\n  --name fawkes/production/argocd-password \\\n  --description \"ArgoCD Admin Password\" \\\n  --secret-string \"$ARGOCD_PASSWORD\" \\\n  --region us-east-1\n\n# Store Jenkins admin password\naws secretsmanager create-secret \\\n  --name fawkes/production/jenkins-password \\\n  --description \"Jenkins Admin Password\" \\\n  --secret-string \"$JENKINS_PASSWORD\" \\\n  --region us-east-1\n\n# Verify secrets were created\naws secretsmanager list-secrets --region us-east-1 | grep fawkes\n</code></pre>"},{"location":"AWS_deployment_guide/#step-15-create-ssl-certificate-if-using-custom-domain","title":"Step 1.5: Create SSL Certificate (if using custom domain)","text":"<pre><code># Request certificate from AWS Certificate Manager\naws acm request-certificate \\\n  --domain-name fawkes.yourdomain.com \\\n  --subject-alternative-names \"*.fawkes.yourdomain.com\" \\\n  --validation-method DNS \\\n  --region us-east-1\n\n# Output will include CertificateArn - save this!\n# Example: arn:aws:acm:us-east-1:123456789012:certificate/abc123...\n\n# Follow the validation instructions (add DNS records)\n# Certificate validation usually takes 5-30 minutes\n</code></pre> <p>Validation: <pre><code># Check VPC exists\naws ec2 describe-vpcs --filters \"Name=tag:Name,Values=fawkes-production-vpc\"\n\n# Check subnets exist\naws ec2 describe-subnets --filters \"Name=vpc-id,Values=YOUR_VPC_ID\"\n\n# Check NAT gateways are available\naws ec2 describe-nat-gateways --filter \"Name=state,Values=available\"\n\n# Verify S3 buckets\naws s3 ls | grep fawkes\n\n# Verify secrets\naws secretsmanager list-secrets | grep fawkes\n</code></pre></p>"},{"location":"AWS_deployment_guide/#phase-2-eks-cluster-deployment","title":"Phase 2: EKS Cluster Deployment","text":"<p>Duration: 20-30 minutes Goal: Deploy and configure EKS cluster with worker nodes</p>"},{"location":"AWS_deployment_guide/#step-21-create-eks-cluster","title":"Step 2.1: Create EKS Cluster","text":"<pre><code># Create cluster configuration file\ncat &gt; cluster-config.yaml &lt;&lt;EOF\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: fawkes-production\n  region: us-east-1\n  version: \"1.28\"\n\nvpc:\n  id: \"YOUR_VPC_ID\"  # From Phase 1 output\n  subnets:\n    private:\n      us-east-1a:\n        id: \"PRIVATE_SUBNET_1_ID\"\n      us-east-1b:\n        id: \"PRIVATE_SUBNET_2_ID\"\n      us-east-1c:\n        id: \"PRIVATE_SUBNET_3_ID\"\n\nmanagedNodeGroups:\n  - name: fawkes-ng-general\n    instanceType: t3.xlarge\n    minSize: 3\n    maxSize: 12\n    desiredCapacity: 6\n    privateNetworking: true\n    volumeSize: 200\n    volumeType: gp3\n    labels:\n      role: general\n      environment: production\n    tags:\n      Name: fawkes-production-node\n      Environment: production\n      Project: fawkes\n    iam:\n      withAddonPolicies:\n        imageBuilder: true\n        autoScaler: true\n        externalDNS: true\n        certManager: true\n        appMesh: false\n        ebs: true\n        fsx: false\n        efs: true\n        albIngress: true\n        xRay: true\n        cloudWatch: true\n\niam:\n  withOIDC: true\n  serviceAccounts:\n    - metadata:\n        name: aws-load-balancer-controller\n        namespace: kube-system\n      wellKnownPolicies:\n        awsLoadBalancerController: true\n    - metadata:\n        name: ebs-csi-controller-sa\n        namespace: kube-system\n      wellKnownPolicies:\n        ebsCSIController: true\n    - metadata:\n        name: external-secrets\n        namespace: external-secrets-system\n      attachPolicyARNs:\n        - \"arn:aws:iam::aws:policy/SecretsManagerReadWrite\"\n\ncloudWatch:\n  clusterLogging:\n    enableTypes:\n      - \"api\"\n      - \"audit\"\n      - \"authenticator\"\n      - \"controllerManager\"\n      - \"scheduler\"\n\naddons:\n  - name: vpc-cni\n    version: latest\n  - name: coredns\n    version: latest\n  - name: kube-proxy\n    version: latest\n  - name: aws-ebs-csi-driver\n    version: latest\n    serviceAccountRoleARN: \"AUTO_GENERATED\"\nEOF\n\n# Create the EKS cluster\neksctl create cluster -f cluster-config.yaml\n\n# This takes 15-20 minutes - good time for coffee!\n</code></pre> <p>What's happening during creation: 1. EKS control plane provisioning (managed by AWS) 2. Worker nodes launching across 3 AZs 3. IAM roles and policies creation 4. OIDC provider setup 5. Add-ons installation (VPC CNI, CoreDNS, kube-proxy, EBS CSI)</p>"},{"location":"AWS_deployment_guide/#step-22-configure-kubectl-access","title":"Step 2.2: Configure kubectl Access","text":"<pre><code># Update kubeconfig\naws eks update-kubeconfig \\\n  --region us-east-1 \\\n  --name fawkes-production\n\n# Verify connectivity\nkubectl get nodes\n\n# Should show 6 nodes in Ready state:\n# NAME                          STATUS   ROLES    AGE   VERSION\n# ip-10-0-11-123.ec2.internal   Ready    &lt;none&gt;   2m    v1.28.x\n# ip-10-0-11-124.ec2.internal   Ready    &lt;none&gt;   2m    v1.28.x\n# ...\n</code></pre>"},{"location":"AWS_deployment_guide/#step-23-install-aws-load-balancer-controller","title":"Step 2.3: Install AWS Load Balancer Controller","text":"<pre><code># Add Helm repository\nhelm repo add eks https://aws.github.io/eks-charts\nhelm repo update\n\n# Get your cluster VPC ID\nVPC_ID=$(aws eks describe-cluster \\\n  --name fawkes-production \\\n  --query \"cluster.resourcesVpcConfig.vpcId\" \\\n  --output text)\n\n# Install AWS Load Balancer Controller\nhelm install aws-load-balancer-controller eks/aws-load-balancer-controller \\\n  -n kube-system \\\n  --set clusterName=fawkes-production \\\n  --set serviceAccount.create=false \\\n  --set serviceAccount.name=aws-load-balancer-controller \\\n  --set region=us-east-1 \\\n  --set vpcId=$VPC_ID\n\n# Verify installation\nkubectl get deployment -n kube-system aws-load-balancer-controller\n\n# Should show:\n# NAME                           READY   UP-TO-DATE   AVAILABLE   AGE\n# aws-load-balancer-controller   2/2     2            2           1m\n</code></pre>"},{"location":"AWS_deployment_guide/#step-24-install-external-secrets-operator","title":"Step 2.4: Install External Secrets Operator","text":"<pre><code># Add Helm repository\nhelm repo add external-secrets https://charts.external-secrets.io\nhelm repo update\n\n# Create namespace\nkubectl create namespace external-secrets-system\n\n# Install External Secrets Operator\nhelm install external-secrets \\\n  external-secrets/external-secrets \\\n  -n external-secrets-system \\\n  --set installCRDs=true\n\n# Verify installation\nkubectl get pods -n external-secrets-system\n\n# Create SecretStore for AWS Secrets Manager\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: aws-secrets-manager\n  namespace: fawkes-system\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      region: us-east-1\n      auth:\n        jwt:\n          serviceAccountRef:\n            name: external-secrets\nEOF\n</code></pre>"},{"location":"AWS_deployment_guide/#step-25-configure-cluster-autoscaler","title":"Step 2.5: Configure Cluster Autoscaler","text":"<pre><code># Install Cluster Autoscaler\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-autodiscover.yaml\n\n# Patch deployment with correct cluster name\nkubectl -n kube-system \\\n  patch deployment cluster-autoscaler \\\n  -p '{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"cluster-autoscaler.kubernetes.io/safe-to-evict\": \"false\"}}}}}'\n\nkubectl -n kube-system \\\n  set image deployment/cluster-autoscaler \\\n  cluster-autoscaler=registry.k8s.io/autoscaling/cluster-autoscaler:v1.28.0\n\n# Add cluster name\nkubectl -n kube-system \\\n  patch deployment cluster-autoscaler \\\n  --type='json' \\\n  -p='[{\"op\": \"add\", \"path\": \"/spec/template/spec/containers/0/command/-\", \"value\": \"--node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/fawkes-production\"}]'\n\n# Verify\nkubectl get pods -n kube-system | grep cluster-autoscaler\n</code></pre> <p>Validation: <pre><code># Check cluster status\neksctl get cluster --name fawkes-production\n\n# Check nodes\nkubectl get nodes -o wide\n\n# Check system pods\nkubectl get pods -n kube-system\n\n# Verify service accounts\nkubectl get sa -n kube-system aws-load-balancer-controller\nkubectl get sa -n external-secrets-system external-secrets\n</code></pre></p>"},{"location":"AWS_deployment_guide/#phase-3-database-and-storage","title":"Phase 3: Database and Storage","text":"<p>Duration: 20 minutes Goal: Deploy RDS PostgreSQL and configure storage classes</p>"},{"location":"AWS_deployment_guide/#step-31-create-rds-postgresql-instance","title":"Step 3.1: Create RDS PostgreSQL Instance","text":"<pre><code># Get private subnet IDs\nPRIVATE_SUBNET_1=$(terraform output -raw private_subnet_ids | jq -r '.[0]')\nPRIVATE_SUBNET_2=$(terraform output -raw private_subnet_ids | jq -r '.[1]')\n\n# Create DB subnet group\naws rds create-db-subnet-group \\\n  --db-subnet-group-name fawkes-production-db-subnet \\\n  --db-subnet-group-description \"Fawkes Production DB Subnet Group\" \\\n  --subnet-ids $PRIVATE_SUBNET_1 $PRIVATE_SUBNET_2 \\\n  --tags Key=Environment,Value=production Key=Project,Value=fawkes\n\n# Create security group for RDS\nRDS_SG_ID=$(aws ec2 create-security-group \\\n  --group-name fawkes-production-rds-sg \\\n  --description \"Fawkes Production RDS Security Group\" \\\n  --vpc-id $VPC_ID \\\n  --output text)\n\n# Allow PostgreSQL access from EKS nodes\nEKS_NODE_SG=$(aws eks describe-cluster \\\n  --name fawkes-production \\\n  --query \"cluster.resourcesVpcConfig.clusterSecurityGroupId\" \\\n  --output text)\n\naws ec2 authorize-security-group-ingress \\\n  --group-id $RDS_SG_ID \\\n  --protocol tcp \\\n  --port 5432 \\\n  --source-group $EKS_NODE_SG\n\n# Create RDS instance\naws rds create-db-instance \\\n  --db-instance-identifier fawkes-production-db \\\n  --db-instance-class db.m5.large \\\n  --engine postgres \\\n  --engine-version 15.4 \\\n  --master-username fawkesadmin \\\n  --master-user-password \"$DB_PASSWORD\" \\\n  --allocated-storage 500 \\\n  --storage-type gp3 \\\n  --storage-encrypted \\\n  --db-subnet-group-name fawkes-production-db-subnet \\\n  --vpc-security-group-ids $RDS_SG_ID \\\n  --backup-retention-period 7 \\\n  --preferred-backup-window \"03:00-04:00\" \\\n  --preferred-maintenance-window \"sun:04:00-sun:05:00\" \\\n  --multi-az \\\n  --auto-minor-version-upgrade \\\n  --publicly-accessible false \\\n  --tags Key=Name,Value=fawkes-production-db Key=Environment,Value=production\n\n# This takes 10-15 minutes - continue with next steps while it provisions\n</code></pre>"},{"location":"AWS_deployment_guide/#step-32-configure-kubernetes-storage-classes","title":"Step 3.2: Configure Kubernetes Storage Classes","text":"<pre><code># Create storage class for general purpose SSD (gp3)\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: gp3\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"true\"\nprovisioner: ebs.csi.aws.com\nparameters:\n  type: gp3\n  iops: \"3000\"\n  throughput: \"125\"\n  encrypted: \"true\"\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: gp3-retain\nprovisioner: ebs.csi.aws.com\nparameters:\n  type: gp3\n  iops: \"3000\"\n  throughput: \"125\"\n  encrypted: \"true\"\nreclaimPolicy: Retain\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\nEOF\n\n# Verify storage classes\nkubectl get storageclass\n</code></pre>"},{"location":"AWS_deployment_guide/#step-33-wait-for-rds-instance-and-get-endpoint","title":"Step 3.3: Wait for RDS Instance and Get Endpoint","text":"<pre><code># Wait for RDS instance to be available\necho \"Waiting for RDS instance to be available (this takes ~15 minutes)...\"\naws rds wait db-instance-available \\\n  --db-instance-identifier fawkes-production-db\n\n# Get RDS endpoint\nRDS_ENDPOINT=$(aws rds describe-db-instances \\\n  --db-instance-identifier fawkes-production-db \\\n  --query 'DBInstances[0].Endpoint.Address' \\\n  --output text)\n\necho \"RDS Endpoint: $RDS_ENDPOINT\"\n\n# Store RDS endpoint in Secrets Manager for easy access\naws secretsmanager create-secret \\\n  --name fawkes/production/db-endpoint \\\n  --description \"Fawkes Production Database Endpoint\" \\\n  --secret-string \"$RDS_ENDPOINT\" \\\n  --region us-east-1\n\n# Create Kubernetes secret for database connection\nkubectl create namespace fawkes-system\n\nkubectl create secret generic postgres-credentials \\\n  --from-literal=host=$RDS_ENDPOINT \\\n  --from-literal=port=5432 \\\n  --from-literal=database=postgres \\\n  --from-literal=username=fawkesadmin \\\n  --from-literal=password=$DB_PASSWORD \\\n  -n fawkes-system\n</code></pre>"},{"location":"AWS_deployment_guide/#step-34-initialize-database-schema","title":"Step 3.4: Initialize Database Schema","text":"<pre><code># Connect to RDS and create databases for each platform component\ncat &gt; init-databases.sql &lt;&lt;EOF\n-- Create databases for platform components\nCREATE DATABASE backstage;\nCREATE DATABASE jenkins;\nCREATE DATABASE argocd;\nCREATE DATABASE harbor;\nCREATE DATABASE mattermost;\nCREATE DATABASE focalboard;\n\n-- Create extensions\n\\c backstage\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\n\\c jenkins\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\n\\c argocd\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\n\\c harbor\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\n\\c mattermost\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\n\\c focalboard\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\nEOF\n\n# Run via temporary pod\nkubectl run postgres-client --rm -i --tty \\\n  --image postgres:15 \\\n  --restart=Never \\\n  -n fawkes-system \\\n  --env=\"PGPASSWORD=$DB_PASSWORD\" \\\n  -- psql -h $RDS_ENDPOINT -U fawkesadmin -d postgres -f /dev/stdin &lt; init-databases.sql\n\n# Verify databases were created\nkubectl run postgres-client --rm -i --tty \\\n  --image postgres:15 \\\n  --restart=Never \\\n  -n fawkes-system \\\n  --env=\"PGPASSWORD=$DB_PASSWORD\" \\\n  -- psql -h $RDS_ENDPOINT -U fawkesadmin -d postgres -c \"\\l\"\n</code></pre> <p>Validation: <pre><code># Verify RDS instance is running\naws rds describe-db-instances \\\n  --db-instance-identifier fawkes-production-db \\\n  --query 'DBInstances[0].DBInstanceStatus' \\\n  --output text\n# Should output: available\n\n# Test database connectivity\nkubectl run postgres-test --rm -i --tty \\\n  --image postgres:15 \\\n  --restart=Never \\\n  -n fawkes-system \\\n  --env=\"PGPASSWORD=$DB_PASSWORD\" \\\n  -- psql -h $RDS_ENDPOINT -U fawkesadmin -d postgres -c \"SELECT version();\"\n\n# Verify storage classes\nkubectl get storageclass\n</code></pre></p>"},{"location":"AWS_deployment_guide/#phase-4-platform-services","title":"Phase 4: Platform Services","text":"<p>Duration: 45-60 minutes Goal: Deploy core Fawkes platform components</p>"},{"location":"AWS_deployment_guide/#step-41-create-namespaces","title":"Step 4.1: Create Namespaces","text":"<pre><code># Create namespaces for platform components\nkubectl create namespace backstage\nkubectl create namespace jenkins\nkubectl create namespace argocd\nkubectl create namespace harbor\nkubectl create namespace monitoring\nkubectl create namespace mattermost\nkubectl create namespace focalboard\n\n# Label namespaces for better organization\nkubectl label namespace backstage app.kubernetes.io/part-of=fawkes\nkubectl label namespace jenkins app.kubernetes.io/part-of=fawkes\nkubectl label namespace argocd app.kubernetes.io/part-of=fawkes\nkubectl label namespace harbor app.kubernetes.io/part-of=fawkes\nkubectl label namespace monitoring app.kubernetes.io/part-of=fawkes\nkubectl label namespace mattermost app.kubernetes.io/part-of=fawkes\nkubectl label namespace focalboard app.kubernetes.io/part-of=fawkes\n</code></pre>"},{"location":"AWS_deployment_guide/#step-42-deploy-argocd-gitops-engine","title":"Step 4.2: Deploy ArgoCD (GitOps Engine)","text":"<pre><code># Add ArgoCD Helm repository\nhelm repo add argo https://argoproj.github.io/argo-helm\nhelm repo update\n\n# Create values file for ArgoCD\ncat &gt; argocd-values.yaml &lt;&lt;EOF\nglobal:\n  domain: argocd.fawkes.yourdomain.com\n\nserver:\n  service:\n    type: ClusterIP\n  ingress:\n    enabled: true\n    ingressClassName: alb\n    annotations:\n      alb.ingress.kubernetes.io/scheme: internet-facing\n      alb.ingress.kubernetes.io/target-type: ip\n      alb.ingress.kubernetes.io/certificate-arn: YOUR_ACM_CERT_ARN\n      alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n      alb.ingress.kubernetes.io/ssl-redirect: '443'\n    hosts:\n      - argocd.fawkes.yourdomain.com\n\nconfigs:\n  secret:\n    argocdServerAdminPassword: '$ARGOCD_PASSWORD_BCRYPT'\n  cm:\n    url: https://argocd.fawkes.yourdomain.com\n    dex.config: |\n      connectors:\n        - type: github\n          id: github\n          name: GitHub\n          config:\n            clientID: YOUR_GITHUB_OAUTH_CLIENT_ID\n            clientSecret: YOUR_GITHUB_OAUTH_CLIENT_SECRET\n            orgs:\n              - name: your-github-org\n\nredis:\n  enabled: true\n\nrepoServer:\n  replicas: 2\n\napplicationSet:\n  enabled: true\nEOF\n\n# Hash the ArgoCD password for storage\nARGOCD_PASSWORD_BCRYPT=$(htpasswd -nbBC 10 \"\" \"$ARGOCD_PASSWORD\" | tr -d ':\\n' | sed 's/$2y/$2a/')\n\n# Replace in values file\nsed -i \"s|\\$ARGOCD_PASSWORD_BCRYPT|$ARGOCD_PASSWORD_BCRYPT|g\" argocd-values.yaml\n\n# Install ArgoCD\nhelm install argocd argo/argo-cd \\\n  --namespace argocd \\\n  --values argocd-values.yaml \\\n  --version 5.51.0\n\n# Wait for ArgoCD to be ready\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/argocd-server -n argocd\n\n# Get ArgoCD admin password (if you didn't set it)\nARGOCD_ADMIN_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret \\\n  -o jsonpath=\"{.data.password}\" | base64 -d)\necho \"ArgoCD Admin Password: $ARGOCD_ADMIN_PASSWORD\"\n\n# Get ArgoCD URL\nkubectl get ingress -n argocd\n</code></pre>"},{"location":"AWS_deployment_guide/#step-43-deploy-harbor-container-registry","title":"Step 4.3: Deploy Harbor (Container Registry)","text":"<pre><code># Add Harbor Helm repository\nhelm repo add harbor https://helm.goharbor.io\nhelm repo update\n\n# Create values file for Harbor\ncat &gt; harbor-values.yaml &lt;&lt;EOF\nexpose:\n  type: ingress\n  tls:\n    enabled: true\n    certSource: secret\n    secret:\n      secretName: harbor-tls\n  ingress:\n    className: alb\n    annotations:\n      alb.ingress.kubernetes.io/scheme: internet-facing\n      alb.ingress.kubernetes.io/target-type: ip\n      alb.ingress.kubernetes.io/certificate-arn: YOUR_ACM_CERT_ARN\n      alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n      alb.ingress.kubernetes.io/ssl-redirect: '443'\n    hosts:\n      core: harbor.fawkes.yourdomain.com\n\nexternalURL: https://harbor.fawkes.yourdomain.com\n\npersistence:\n  enabled: true\n  persistentVolumeClaim:\n    registry:\n      storageClass: gp3\n      size: 200Gi\n    chartmuseum:\n      storageClass: gp3\n      size: 5Gi\n    jobservice:\n      jobLog:\n        storageClass: gp3\n        size: 1Gi\n    database:\n      storageClass: gp3\n      size: 1Gi\n    redis:\n      storageClass: gp3\n      size: 1Gi\n    trivy:\n      storageClass: gp3\n      size: 5Gi\n\ndatabase:\n  type: external\n  external:\n    host: $RDS_ENDPOINT\n    port: 5432\n    username: fawkesadmin\n    password: $DB_PASSWORD\n    coreDatabase: harbor\n    notaryServerDatabase: notary_server\n    notarySignerDatabase: notary_signer\n\nharborAdminPassword: $(openssl rand -base64 16)\n\ntrivy:\n  enabled: true\n\nnotary:\n  enabled: false\n\nmetrics:\n  enabled: true\nEOF\n\n# Install Harbor\nhelm install harbor harbor/harbor \\\n  --namespace harbor \\\n  --values harbor-values.yaml \\\n  --version 1.13.0\n\n# Wait for Harbor to be ready (takes 5-10 minutes)\nkubectl wait --for=condition=available --timeout=600s \\\n  deployment/harbor-core -n harbor\n</code></pre>"},{"location":"AWS_deployment_guide/#step-44-deploy-jenkins-cicd","title":"Step 4.4: Deploy Jenkins (CI/CD)","text":"<pre><code># Add Jenkins Helm repository\nhelm repo add jenkins https://charts.jenkins.io\nhelm repo update\n\n# Create values file for Jenkins\ncat &gt; jenkins-values.yaml &lt;&lt;EOF\ncontroller:\n  adminPassword: $JENKINS_PASSWORD\n\n  ingress:\n    enabled: true\n    ingressClassName: alb\n    annotations:\n      alb.ingress.kubernetes.io/scheme: internet-facing\n      alb.ingress.kubernetes.io/target-type: ip\n      alb.ingress.kubernetes.io/certificate-arn: YOUR_ACM_CERT_ARN\n      alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n      alb.ingress.kubernetes.io/ssl-redirect: '443'\n    hostName: jenkins.fawkes.yourdomain.com\n\n  resources:\n    requests:\n      cpu: \"1000m\"\n      memory: \"2Gi\"\n    limits:\n      cpu: \"2000m\"\n      memory: \"4Gi\"\n\n  JCasC:\n    configScripts:\n      aws-credentials: |\n        credentials:\n          system:\n            domainCredentials:\n              - credentials:\n                - aws:\n                    accessKey: \"${AWS_ACCESS_KEY_ID}\"\n                    description: \"AWS Credentials\"\n                    id: \"aws-credentials\"\n                    iamRoleArn: \"\"\n                    scope: GLOBAL\n                    secretKey: \"${AWS_SECRET_ACCESS_KEY}\"\n      kubernetes-cloud: |\n        jenkins:\n          clouds:\n            - kubernetes:\n                name: \"kubernetes\"\n                serverUrl: \"https://kubernetes.default\"\n                namespace: \"jenkins\"\n                jenkinsUrl: \"http://jenkins:8080\"\n                jenkinsTunnel: \"jenkins-agent:50000\"\n                containerCapStr: \"10\"\n                templates:\n                  - name: \"jenkins-agent\"\n                    namespace: \"jenkins\"\n                    label: \"jenkins-agent\"\n                    containers:\n                      - name: \"jnlp\"\n                        image: \"jenkins/inbound-agent:latest\"\n                        alwaysPullImage: true\n                        workingDir: \"/home/jenkins/agent\"\n                        ttyEnabled: true\n\n  installPlugins:\n    - kubernetes:latest\n    - workflow-aggregator:latest\n    - git:latest\n    - configuration-as-code:latest\n    - aws-credentials:latest\n    - pipeline-aws:latest\n    - docker-workflow:latest\n    - blueocean:latest\n\npersistence:\n  enabled: true\n  storageClass: gp3-retain\n  size: 100Gi\n\nagent:\n  enabled: true\n  resources:\n    requests:\n      cpu: \"500m\"\n      memory: \"1Gi\"\n    limits:\n      cpu: \"1000m\"\n      memory: \"2Gi\"\nEOF\n\n# Install Jenkins\nhelm install jenkins jenkins/jenkins \\\n  --namespace jenkins \\\n  --values jenkins-values.yaml \\\n  --version 4.6.0\n\n# Wait for Jenkins to be ready\nkubectl wait --for=condition=available --timeout=600s \\\n  deployment/jenkins -n jenkins\n\n# Get Jenkins admin password (if you didn't set it)\nJENKINS_ADMIN_PASSWORD=$(kubectl exec --namespace jenkins -it svc/jenkins \\\n  -c jenkins -- /bin/cat /run/secrets/additional/chart-admin-password)\necho \"Jenkins Admin Password: $JENKINS_ADMIN_PASSWORD\"\n</code></pre>"},{"location":"AWS_deployment_guide/#step-45-deploy-backstage-developer-portal","title":"Step 4.5: Deploy Backstage (Developer Portal)","text":"<pre><code># Create Backstage configuration\ncat &gt; backstage-values.yaml &lt;&lt;EOF\nimage:\n  registry: ghcr.io\n  repository: backstage/backstage\n  tag: latest\n\nbackstage:\n  image:\n    pullPolicy: Always\n\n  extraEnvVars:\n    - name: POSTGRES_HOST\n      value: $RDS_ENDPOINT\n    - name: POSTGRES_PORT\n      value: \"5432\"\n    - name: POSTGRES_USER\n      value: fawkesadmin\n    - name: POSTGRES_PASSWORD\n      value: $DB_PASSWORD\n\n  appConfig:\n    app:\n      title: Fawkes Platform\n      baseUrl: https://backstage.fawkes.yourdomain.com\n\n    backend:\n      baseUrl: https://backstage.fawkes.yourdomain.com\n      listen:\n        port: 7007\n      csp:\n        connect-src: [\"'self'\", 'http:', 'https:']\n      cors:\n        origin: https://backstage.fawkes.yourdomain.com\n        methods: [GET, POST, PUT, DELETE]\n        credentials: true\n      database:\n        client: pg\n        connection:\n          host: \\${POSTGRES_HOST}\n          port: \\${POSTGRES_PORT}\n          user: \\${POSTGRES_USER}\n          password: \\${POSTGRES_PASSWORD}\n          database: backstage\n\n    catalog:\n      rules:\n        - allow: [Component, System, API, Group, User, Resource, Location]\n      locations:\n        - type: url\n          target: https://github.com/paruff/fawkes/blob/master/catalog-info.yaml\n\n    auth:\n      providers:\n        github:\n          development:\n            clientId: \\${GITHUB_CLIENT_ID}\n            clientSecret: \\${GITHUB_CLIENT_SECRET}\n\ningress:\n  enabled: true\n  className: alb\n  annotations:\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\n    alb.ingress.kubernetes.io/certificate-arn: YOUR_ACM_CERT_ARN\n    alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n    alb.ingress.kubernetes.io/ssl-redirect: '443'\n  host: backstage.fawkes.yourdomain.com\n\npostgresql:\n  enabled: false  # Using external RDS\n\nresources:\n  requests:\n    cpu: 500m\n    memory: 1Gi\n  limits:\n    cpu: 1000m\n    memory: 2Gi\nEOF\n\n# Install Backstage\nhelm install backstage backstage/backstage \\\n  --namespace backstage \\\n  --values backstage-values.yaml\n\n# Wait for Backstage to be ready\nkubectl wait --for=condition=available --timeout=600s \\\n  deployment/backstage -n backstage\n</code></pre>"},{"location":"AWS_deployment_guide/#step-46-deploy-mattermost-team-collaboration","title":"Step 4.6: Deploy Mattermost (Team Collaboration)","text":"<pre><code># Add Mattermost Helm repository\nhelm repo add mattermost https://helm.mattermost.com\nhelm repo update\n\n# Create values file\ncat &gt; mattermost-values.yaml &lt;&lt;EOF\ningress:\n  enabled: true\n  className: alb\n  annotations:\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\n    alb.ingress.kubernetes.io/certificate-arn: YOUR_ACM_CERT_ARN\n    alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n    alb.ingress.kubernetes.io/ssl-redirect: '443'\n  hosts:\n    - mattermost.fawkes.yourdomain.com\n\nmysql:\n  enabled: false\n\nexternalDB:\n  enabled: true\n  externalDriverType: \"postgres\"\n  externalConnectionString: \"postgres://fawkesadmin:$DB_PASSWORD@$RDS_ENDPOINT:5432/mattermost?sslmode=require\"\n\npersistence:\n  data:\n    enabled: true\n    size: 50Gi\n    storageClass: gp3\n  plugins:\n    enabled: true\n    size: 5Gi\n    storageClass: gp3\n\nresources:\n  requests:\n    cpu: 500m\n    memory: 1Gi\n  limits:\n    cpu: 1000m\n    memory: 2Gi\nEOF\n\n# Install Mattermost\nhelm install mattermost mattermost/mattermost-team-edition \\\n  --namespace mattermost \\\n  --values mattermost-values.yaml\n\n# Wait for Mattermost to be ready\nkubectl wait --for=condition=available --timeout=600s \\\n  deployment/mattermost -n mattermost\n</code></pre>"},{"location":"AWS_deployment_guide/#step-47-deploy-focalboard-project-tracking","title":"Step 4.7: Deploy Focalboard (Project Tracking)","text":"<pre><code># Create Focalboard deployment\ncat &gt; focalboard-deployment.yaml &lt;&lt;EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: focalboard-config\n  namespace: focalboard\ndata:\n  config.json: |\n    {\n      \"serverRoot\": \"https://focalboard.fawkes.yourdomain.com\",\n      \"port\": 8000,\n      \"dbtype\": \"postgres\",\n      \"dbconfig\": \"postgres://fawkesadmin:$DB_PASSWORD@$RDS_ENDPOINT:5432/focalboard?sslmode=require\",\n      \"useSSL\": false,\n      \"webpath\": \"./pack\",\n      \"filespath\": \"./files\",\n      \"telemetry\": true,\n      \"session_expire_time\": 2592000,\n      \"session_refresh_time\": 18000,\n      \"localOnly\": false,\n      \"enableLocalMode\": true,\n      \"localModeSocketLocation\": \"/var/tmp/focalboard_local.socket\"\n    }\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: focalboard\n  namespace: focalboard\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: focalboard\n  template:\n    metadata:\n      labels:\n        app: focalboard\n    spec:\n      containers:\n      - name: focalboard\n        image: mattermost/focalboard:latest\n        ports:\n        - containerPort: 8000\n        volumeMounts:\n        - name: config\n          mountPath: /opt/focalboard/config.json\n          subPath: config.json\n        - name: data\n          mountPath: /opt/focalboard/files\n        resources:\n          requests:\n            cpu: 250m\n            memory: 512Mi\n          limits:\n            cpu: 500m\n            memory: 1Gi\n      volumes:\n      - name: config\n        configMap:\n          name: focalboard-config\n      - name: data\n        persistentVolumeClaim:\n          claimName: focalboard-data\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: focalboard\n  namespace: focalboard\nspec:\n  selector:\n    app: focalboard\n  ports:\n  - port: 8000\n    targetPort: 8000\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: focalboard-data\n  namespace: focalboard\nspec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: gp3\n  resources:\n    requests:\n      storage: 20Gi\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: focalboard\n  namespace: focalboard\n  annotations:\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\n    alb.ingress.kubernetes.io/certificate-arn: YOUR_ACM_CERT_ARN\n    alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n    alb.ingress.kubernetes.io/ssl-redirect: '443'\nspec:\n  ingressClassName: alb\n  rules:\n  - host: focalboard.fawkes.yourdomain.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: focalboard\n            port:\n              number: 8000\nEOF\n\n# Apply Focalboard manifests\nkubectl apply -f focalboard-deployment.yaml\n\n# Wait for Focalboard to be ready\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/focalboard -n focalboard\n</code></pre> <p>Validation: <pre><code># Check all platform services are running\nkubectl get pods -n argocd\nkubectl get pods -n harbor\nkubectl get pods -n jenkins\nkubectl get pods -n backstage\nkubectl get pods -n mattermost\nkubectl get pods -n focalboard\n\n# Get all ingress URLs\nkubectl get ingress --all-namespaces\n\n# Test connectivity to each service\ncurl -k https://argocd.fawkes.yourdomain.com\ncurl -k https://harbor.fawkes.yourdomain.com\ncurl -k https://jenkins.fawkes.yourdomain.com\ncurl -k https://backstage.fawkes.yourdomain.com\ncurl -k https://mattermost.fawkes.yourdomain.com\ncurl -k https://focalboard.fawkes.yourdomain.com\n</code></pre></p>"},{"location":"AWS_deployment_guide/#phase-5-observability-stack","title":"Phase 5: Observability Stack","text":"<p>Duration: 30 minutes Goal: Deploy Prometheus, Grafana, and logging infrastructure</p>"},{"location":"AWS_deployment_guide/#step-51-deploy-prometheus-stack","title":"Step 5.1: Deploy Prometheus Stack","text":"<pre><code># Add Prometheus Helm repository\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\n\n# Create values file\ncat &gt; prometheus-values.yaml &lt;&lt;EOF\nprometheus:\n  prometheusSpec:\n    retention: 30d\n    storageSpec:\n      volumeClaimTemplate:\n        spec:\n          storageClassName: gp3\n          accessModes: [\"ReadWriteOnce\"]\n          resources:\n            requests:\n              storage: 100Gi\n    resources:\n      requests:\n        cpu: 500m\n        memory: 2Gi\n      limits:\n        cpu: 1000m\n        memory: 4Gi\n\ngrafana:\n  enabled: true\n  adminPassword: $(openssl rand -base64 16)\n\n  ingress:\n    enabled: true\n    ingressClassName: alb\n    annotations:\n      alb.ingress.kubernetes.io/scheme: internet-facing\n      alb.ingress.kubernetes.io/target-type: ip\n      alb.ingress.kubernetes.io/certificate-arn: YOUR_ACM_CERT_ARN\n      alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n      alb.ingress.kubernetes.io/ssl-redirect: '443'\n    hosts:\n      - grafana.fawkes.yourdomain.com\n\n  persistence:\n    enabled: true\n    storageClassName: gp3\n    size: 10Gi\n\n  datasources:\n    datasources.yaml:\n      apiVersion: 1\n      datasources:\n      - name: Prometheus\n        type: prometheus\n        url: http://prometheus-operated:9090\n        isDefault: true\n\n  dashboardProviders:\n    dashboardproviders.yaml:\n      apiVersion: 1\n      providers:\n      - name: 'default'\n        orgId: 1\n        folder: ''\n        type: file\n        disableDeletion: false\n        editable: true\n        options:\n          path: /var/lib/grafana/dashboards/default\n\nalertmanager:\n  alertmanagerSpec:\n    storage:\n      volumeClaimTemplate:\n        spec:\n          storageClassName: gp3\n          accessModes: [\"ReadWriteOnce\"]\n          resources:\n            requests:\n              storage: 10Gi\n\nkubeStateMetrics:\n  enabled: true\n\nnodeExporter:\n  enabled: true\nEOF\n\n# Install Prometheus stack\nhelm install prometheus prometheus-community/kube-prometheus-stack \\\n  --namespace monitoring \\\n  --values prometheus-values.yaml \\\n  --version 51.0.0\n\n# Wait for Prometheus to be ready\nkubectl wait --for=condition=available --timeout=600s \\\n  deployment/prometheus-grafana -n monitoring\n</code></pre>"},{"location":"AWS_deployment_guide/#step-52-deploy-dora-metrics-exporter","title":"Step 5.2: Deploy DORA Metrics Exporter","text":"<pre><code># Create DORA metrics collection service\ncat &gt; dora-metrics-exporter.yaml &lt;&lt;EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: dora-exporter-config\n  namespace: monitoring\ndata:\n  config.yaml: |\n    argocd:\n      url: https://argocd.fawkes.yourdomain.com\n      token: \\${ARGOCD_TOKEN}\n    jenkins:\n      url: https://jenkins.fawkes.yourdomain.com\n      username: admin\n      token: \\${JENKINS_TOKEN}\n    prometheus:\n      port: 9090\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dora-metrics-exporter\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dora-metrics-exporter\n  template:\n    metadata:\n      labels:\n        app: dora-metrics-exporter\n    spec:\n      containers:\n      - name: exporter\n        image: fawkes/dora-metrics-exporter:latest  # TODO: Build this image\n        ports:\n        - containerPort: 9090\n        envFrom:\n        - secretRef:\n            name: dora-exporter-secrets\n        volumeMounts:\n        - name: config\n          mountPath: /app/config.yaml\n          subPath: config.yaml\n      volumes:\n      - name: config\n        configMap:\n          name: dora-exporter-config\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dora-metrics-exporter\n  namespace: monitoring\n  labels:\n    app: dora-metrics-exporter\nspec:\n  ports:\n  - port: 9090\n    targetPort: 9090\n    name: metrics\n  selector:\n    app: dora-metrics-exporter\n---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: dora-metrics\n  namespace: monitoring\nspec:\n  selector:\n    matchLabels:\n      app: dora-metrics-exporter\n  endpoints:\n  - port: metrics\n    interval: 60s\nEOF\n\n# Apply DORA metrics exporter\nkubectl apply -f dora-metrics-exporter.yaml\n</code></pre>"},{"location":"AWS_deployment_guide/#step-53-import-dora-metrics-dashboards","title":"Step 5.3: Import DORA Metrics Dashboards","text":"<pre><code># Create DORA metrics dashboard\ncat &gt; dora-dashboard.json &lt;&lt;'EOF'\n{\n  \"dashboard\": {\n    \"title\": \"DORA Metrics - Fawkes Platform\",\n    \"tags\": [\"dora\", \"platform\"],\n    \"timezone\": \"browser\",\n    \"panels\": [\n      {\n        \"title\": \"Deployment Frequency\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(rate(deployments_total[7d]))\",\n            \"legendFormat\": \"Deployments per day\"\n          }\n        ],\n        \"type\": \"graph\"\n      },\n      {\n        \"title\": \"Lead Time for Changes\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, rate(lead_time_seconds_bucket[7d]))\",\n            \"legendFormat\": \"p95 Lead Time\"\n          }\n        ],\n        \"type\": \"graph\"\n      },\n      {\n        \"title\": \"Mean Time to Restore (MTTR)\",\n        \"targets\": [\n          {\n            \"expr\": \"avg(mttr_seconds) / 60\",\n            \"legendFormat\": \"MTTR (minutes)\"\n          }\n        ],\n        \"type\": \"graph\"\n      },\n      {\n        \"title\": \"Change Failure Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"(sum(failed_deployments_total) / sum(deployments_total)) * 100\",\n            \"legendFormat\": \"Failure Rate (%)\"\n          }\n        ],\n        \"type\": \"gauge\"\n      }\n    ]\n  }\n}\nEOF\n\n# Import dashboard to Grafana\nGRAFANA_POD=$(kubectl get pod -n monitoring -l \"app.kubernetes.io/name=grafana\" -o jsonpath=\"{.items[0].metadata.name}\")\n\nkubectl exec -n monitoring $GRAFANA_POD -- \\\n  curl -X POST http://localhost:3000/api/dashboards/db \\\n  -H \"Content-Type: application/json\" \\\n  -d @/tmp/dora-dashboard.json\n\n# Upload the dashboard file first\nkubectl cp dora-dashboard.json monitoring/$GRAFANA_POD:/tmp/\n</code></pre> <p>Validation: <pre><code># Check Prometheus is scraping targets\nkubectl port-forward -n monitoring svc/prometheus-operated 9090:9090 &amp;\ncurl http://localhost:9090/api/v1/targets\n\n# Access Grafana\nkubectl get ingress -n monitoring\n\n# Get Grafana admin password\nkubectl get secret -n monitoring prometheus-grafana \\\n  -o jsonpath=\"{.data.admin-password}\" | base64 --decode; echo\n</code></pre></p>"},{"location":"AWS_deployment_guide/#phase-6-security-hardening","title":"Phase 6: Security Hardening","text":"<p>Duration: 20 minutes Goal: Implement security best practices</p>"},{"location":"AWS_deployment_guide/#step-61-deploy-trivy-operator-vulnerability-scanning","title":"Step 6.1: Deploy Trivy Operator (Vulnerability Scanning)","text":"<pre><code># Add Aqua Security Helm repository\nhelm repo add aqua https://aquasecurity.github.io/helm-charts/\nhelm repo update\n\n# Install Trivy Operator\nhelm install trivy-operator aqua/trivy-operator \\\n  --namespace trivy-system \\\n  --create-namespace \\\n  --set=\"trivy.ignoreUnfixed=true\"\n\n# Wait for Trivy to be ready\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/trivy-operator -n trivy-system\n</code></pre>"},{"location":"AWS_deployment_guide/#step-62-deploy-kyverno-policy-enforcement","title":"Step 6.2: Deploy Kyverno (Policy Enforcement)","text":"<pre><code># Add Kyverno Helm repository\nhelm repo add kyverno https://kyverno.github.io/kyverno/\nhelm repo update\n\n# Install Kyverno\nhelm install kyverno kyverno/kyverno \\\n  --namespace kyverno \\\n  --create-namespace\n\n# Wait for Kyverno to be ready\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/kyverno -n kyverno\n\n# Apply baseline policies\nkubectl apply -f https://raw.githubusercontent.com/kyverno/policies/main/pod-security/baseline/disallow-privileged-containers/disallow-privileged-containers.yaml\nkubectl apply -f https://raw.githubusercontent.com/kyverno/policies/main/pod-security/baseline/disallow-host-namespaces/disallow-host-namespaces.yaml\nkubectl apply -f https://raw.githubusercontent.com/kyverno/policies/main/pod-security/baseline/disallow-host-path/disallow-host-path.yaml\n\n# Create custom policy for required labels\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-labels\nspec:\n  validationFailureAction: audit\n  background: true\n  rules:\n  - name: check-for-labels\n    match:\n      any:\n      - resources:\n          kinds:\n          - Pod\n          - Deployment\n          - Service\n    validate:\n      message: \"Labels 'app.kubernetes.io/name' and 'app.kubernetes.io/part-of' are required.\"\n      pattern:\n        metadata:\n          labels:\n            app.kubernetes.io/name: \"?*\"\n            app.kubernetes.io/part-of: \"fawkes\"\nEOF\n</code></pre>"},{"location":"AWS_deployment_guide/#step-63-configure-network-policies","title":"Step 6.3: Configure Network Policies","text":"<pre><code># Create network policies for each namespace\ncat &lt;&lt;EOF | kubectl apply -f -\n# Allow Backstage to communicate with all services\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: backstage-egress\n  namespace: backstage\nspec:\n  podSelector:\n    matchLabels:\n      app: backstage\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - namespaceSelector: {}\n    ports:\n    - protocol: TCP\n      port: 443\n    - protocol: TCP\n      port: 80\n    - protocol: TCP\n      port: 8080\n  - to:\n    - podSelector: {}\n    ports:\n    - protocol: TCP\n      port: 5432  # PostgreSQL\n---\n# ArgoCD network policy\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: argocd-network-policy\n  namespace: argocd\nspec:\n  podSelector:\n    matchLabels:\n      app.kubernetes.io/part-of: argocd\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector: {}\n    ports:\n    - protocol: TCP\n      port: 8080\n    - protocol: TCP\n      port: 443\n  egress:\n  - to:\n    - namespaceSelector: {}\n  - to:\n    - podSelector: {}\n    ports:\n    - protocol: TCP\n      port: 443\n    - protocol: TCP\n      port: 22  # Git SSH\n---\n# Jenkins network policy\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: jenkins-network-policy\n  namespace: jenkins\nspec:\n  podSelector:\n    matchLabels:\n      app.kubernetes.io/name: jenkins\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector: {}\n    ports:\n    - protocol: TCP\n      port: 8080\n    - protocol: TCP\n      port: 50000  # JNLP agent port\n  egress:\n  - to:\n    - namespaceSelector: {}\n---\n# Monitoring namespace - allow all (needs to scrape metrics)\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: monitoring-egress\n  namespace: monitoring\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - namespaceSelector: {}\nEOF\n</code></pre>"},{"location":"AWS_deployment_guide/#step-64-enable-pod-security-standards","title":"Step 6.4: Enable Pod Security Standards","text":"<pre><code># Apply Pod Security Standards to namespaces\nkubectl label namespace backstage pod-security.kubernetes.io/enforce=baseline\nkubectl label namespace jenkins pod-security.kubernetes.io/enforce=baseline\nkubectl label namespace argocd pod-security.kubernetes.io/enforce=baseline\nkubectl label namespace harbor pod-security.kubernetes.io/enforce=baseline\nkubectl label namespace mattermost pod-security.kubernetes.io/enforce=baseline\nkubectl label namespace focalboard pod-security.kubernetes.io/enforce=baseline\nkubectl label namespace monitoring pod-security.kubernetes.io/enforce=baseline\n\n# Audit mode for system namespaces\nkubectl label namespace kube-system pod-security.kubernetes.io/audit=restricted\nkubectl label namespace kube-system pod-security.kubernetes.io/warn=restricted\n</code></pre>"},{"location":"AWS_deployment_guide/#step-65-configure-rbac","title":"Step 6.5: Configure RBAC","text":"<pre><code># Create read-only role for developers\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: fawkes-developer\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\", \"statefulsets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods/log\"]\n  verbs: [\"get\", \"list\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: fawkes-operator\nrules:\n- apiGroups: [\"*\"]\n  resources: [\"*\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods/exec\", \"pods/portforward\"]\n  verbs: [\"create\"]\n---\n# Bind roles to groups (configure based on your IdP)\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: fawkes-developers\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: fawkes-developer\nsubjects:\n- kind: Group\n  name: fawkes-developers\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: fawkes-operators\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: fawkes-operator\nsubjects:\n- kind: Group\n  name: fawkes-operators\n  apiGroup: rbac.authorization.k8s.io\nEOF\n</code></pre> <p>Validation: <pre><code># Check Trivy is scanning\nkubectl get vulnerabilityreports -A\n\n# Check Kyverno policies\nkubectl get clusterpolicy\n\n# Verify network policies\nkubectl get networkpolicies -A\n\n# Test RBAC (as a developer user)\nkubectl auth can-i delete pods --as=system:serviceaccount:default:developer\n# Should return \"no\"\n</code></pre></p>"},{"location":"AWS_deployment_guide/#phase-7-validation-and-testing","title":"Phase 7: Validation and Testing","text":"<p>Duration: 30 minutes Goal: Verify all components are working correctly</p>"},{"location":"AWS_deployment_guide/#step-71-component-health-checks","title":"Step 7.1: Component Health Checks","text":"<pre><code># Create health check script\ncat &gt; health-check.sh &lt;&lt;'EOF'\n#!/bin/bash\n\necho \"=========================================\"\necho \"Fawkes Platform Health Check\"\necho \"=========================================\"\necho \"\"\n\n# Check cluster health\necho \"1. EKS Cluster Status:\"\naws eks describe-cluster --name fawkes-production --query 'cluster.status' --output text\necho \"\"\n\n# Check node health\necho \"2. Node Status:\"\nkubectl get nodes -o custom-columns=NAME:.metadata.name,STATUS:.status.conditions[3].type,VERSION:.status.nodeInfo.kubeletVersion\necho \"\"\n\n# Check RDS status\necho \"3. RDS Database Status:\"\naws rds describe-db-instances --db-instance-identifier fawkes-production-db --query 'DBInstances[0].DBInstanceStatus' --output text\necho \"\"\n\n# Check all pods\necho \"4. Pod Status by Namespace:\"\nfor ns in argocd harbor jenkins backstage mattermost focalboard monitoring; do\n  echo \"  Namespace: $ns\"\n  kubectl get pods -n $ns -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,RESTARTS:.status.containerStatuses[0].restartCount\n  echo \"\"\ndone\n\n# Check ingresses\necho \"5. Ingress Endpoints:\"\nkubectl get ingress -A -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,HOSTS:.spec.rules[0].host,ADDRESS:.status.loadBalancer.ingress[0].hostname\necho \"\"\n\n# Check PVC status\necho \"6. Persistent Volume Claims:\"\nkubectl get pvc -A -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,STATUS:.status.phase,CAPACITY:.status.capacity.storage\necho \"\"\n\n# Check certificates (if using cert-manager)\necho \"7. SSL Certificates:\"\naws acm list-certificates --region us-east-1 --query 'CertificateSummaryList[?contains(DomainName, `fawkes`)]' --output table\necho \"\"\n\necho \"=========================================\"\necho \"Health Check Complete\"\necho \"=========================================\"\nEOF\n\nchmod +x health-check.sh\n./health-check.sh\n</code></pre>"},{"location":"AWS_deployment_guide/#step-72-connectivity-tests","title":"Step 7.2: Connectivity Tests","text":"<pre><code># Test external connectivity to all services\ncat &gt; connectivity-test.sh &lt;&lt;'EOF'\n#!/bin/bash\n\nSERVICES=(\n  \"https://argocd.fawkes.yourdomain.com\"\n  \"https://harbor.fawkes.yourdomain.com\"\n  \"https://jenkins.fawkes.yourdomain.com\"\n  \"https://backstage.fawkes.yourdomain.com\"\n  \"https://mattermost.fawkes.yourdomain.com\"\n  \"https://focalboard.fawkes.yourdomain.com\"\n  \"https://grafana.fawkes.yourdomain.com\"\n)\n\necho \"Testing connectivity to all services...\"\necho \"\"\n\nfor service in \"${SERVICES[@]}\"; do\n  status_code=$(curl -k -s -o /dev/null -w \"%{http_code}\" \"$service\")\n  if [ \"$status_code\" -eq 200 ] || [ \"$status_code\" -eq 302 ] || [ \"$status_code\" -eq 401 ]; then\n    echo \"\u2713 $service - OK (HTTP $status_code)\"\n  else\n    echo \"\u2717 $service - FAILED (HTTP $status_code)\"\n  fi\ndone\n\necho \"\"\necho \"Connectivity test complete\"\nEOF\n\nchmod +x connectivity-test.sh\n./connectivity-test.sh\n</code></pre>"},{"location":"AWS_deployment_guide/#step-73-deploy-test-application","title":"Step 7.3: Deploy Test Application","text":"<pre><code># Create a test application to verify the full pipeline\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: fawkes-test\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-fawkes\n  namespace: fawkes-test\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-fawkes\n  template:\n    metadata:\n      labels:\n        app: hello-fawkes\n        app.kubernetes.io/name: hello-fawkes\n        app.kubernetes.io/part-of: fawkes\n    spec:\n      containers:\n      - name: hello\n        image: nginxdemos/hello:latest\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 200m\n            memory: 256Mi\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: hello-fawkes\n  namespace: fawkes-test\nspec:\n  selector:\n    app: hello-fawkes\n  ports:\n  - port: 80\n    targetPort: 80\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: hello-fawkes\n  namespace: fawkes-test\n  annotations:\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\nspec:\n  ingressClassName: alb\n  rules:\n  - host: hello.fawkes.yourdomain.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: hello-fawkes\n            port:\n              number: 80\nEOF\n\n# Wait for deployment\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/hello-fawkes -n fawkes-test\n\n# Get the ingress URL\nkubectl get ingress hello-fawkes -n fawkes-test\n\n# Test the application\nsleep 60  # Wait for ALB to register targets\ncurl http://hello.fawkes.yourdomain.com\n</code></pre>"},{"location":"AWS_deployment_guide/#step-74-verify-dora-metrics-collection","title":"Step 7.4: Verify DORA Metrics Collection","text":"<pre><code># Check if Prometheus is collecting metrics\nkubectl port-forward -n monitoring svc/prometheus-operated 9090:9090 &amp;\nPF_PID=$!\n\nsleep 5\n\n# Query deployment metrics\ncurl -s 'http://localhost:9090/api/v1/query?query=deployments_total' | jq\n\n# Query lead time metrics\ncurl -s 'http://localhost:9090/api/v1/query?query=lead_time_seconds_count' | jq\n\n# Query MTTR metrics\ncurl -s 'http://localhost:9090/api/v1/query?query=mttr_seconds' | jq\n\n# Stop port-forward\nkill $PF_PID\n</code></pre>"},{"location":"AWS_deployment_guide/#step-75-security-scan","title":"Step 7.5: Security Scan","text":"<pre><code># Run Trivy scan on all namespaces\nkubectl get vulnerabilityreports -A -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,CRITICAL:.report.summary.criticalCount,HIGH:.report.summary.highCount\n\n# Check Kyverno policy reports\nkubectl get policyreport -A\n\n# Test network policies\nkubectl run test-pod --image=busybox --rm -it --restart=Never -- /bin/sh\n# Inside the pod, try to access services\n# wget -O- http://jenkins.jenkins.svc.cluster.local:8080\n# Should succeed or fail based on network policies\n</code></pre> <p>Validation Checklist:</p> <ul> <li>[ ] All nodes are in Ready state</li> <li>[ ] All pods are Running (no CrashLoopBackOff)</li> <li>[ ] RDS database is available</li> <li>[ ] All ingresses have ALB addresses</li> <li>[ ] All services respond to HTTP requests (200, 302, or 401)</li> <li>[ ] Test application deployed successfully</li> <li>[ ] Prometheus collecting metrics</li> <li>[ ] No critical vulnerabilities in running containers</li> <li>[ ] Network policies enforced</li> <li>[ ] RBAC working correctly</li> </ul>"},{"location":"AWS_deployment_guide/#post-deployment-operations","title":"Post-Deployment Operations","text":""},{"location":"AWS_deployment_guide/#dns-configuration","title":"DNS Configuration","text":"<p>If you're using Route53 or external DNS:</p> <pre><code># Get all ALB DNS names\nkubectl get ingress -A -o jsonpath='{range .items[*]}{.spec.rules[0].host}{\"\\t\"}{.status.loadBalancer.ingress[0].hostname}{\"\\n\"}{end}'\n\n# Create Route53 records (if using Route53)\n# For each service, create a CNAME record pointing to the ALB DNS name\n\n# Example for ArgoCD:\naws route53 change-resource-record-sets \\\n  --hosted-zone-id YOUR_HOSTED_ZONE_ID \\\n  --change-batch '{\n    \"Changes\": [\n      {\n        \"Action\": \"CREATE\",\n        \"ResourceRecordSet\": {\n          \"Name\": \"argocd.fawkes.yourdomain.com\",\n          \"Type\": \"CNAME\",\n          \"TTL\": 300,\n          \"ResourceRecords\": [\n            {\n              \"Value\": \"k8s-argocd-abc123-1234567890.us-east-1.elb.amazonaws.com\"\n            }\n          ]\n        }\n      }\n    ]\n  }'\n\n# Repeat for all services\n</code></pre>"},{"location":"AWS_deployment_guide/#configure-backups","title":"Configure Backups","text":"<pre><code># Install Velero for cluster backups\nhelm repo add vmware-tanzu https://vmware-tanzu.github.io/helm-charts\nhelm repo update\n\n# Create S3 bucket for backups (if not already created)\naws s3 mb s3://fawkes-velero-backups-prod-YOUR-UNIQUE-ID --region us-east-1\n\n# Create IAM policy for Velero\ncat &gt; velero-policy.json &lt;&lt;EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:DescribeVolumes\",\n        \"ec2:DescribeSnapshots\",\n        \"ec2:CreateTags\",\n        \"ec2:CreateVolume\",\n        \"ec2:CreateSnapshot\",\n        \"ec2:DeleteSnapshot\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:DeleteObject\",\n        \"s3:PutObject\",\n        \"s3:AbortMultipartUpload\",\n        \"s3:ListMultipartUploadParts\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::fawkes-velero-backups-prod-YOUR-UNIQUE-ID/*\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::fawkes-velero-backups-prod-YOUR-UNIQUE-ID\"\n      ]\n    }\n  ]\n}\nEOF\n\naws iam create-policy \\\n  --policy-name FawkesVeleroPolicy \\\n  --policy-document file://velero-policy.json\n\n# Install Velero\nhelm install velero vmware-tanzu/velero \\\n  --namespace velero \\\n  --create-namespace \\\n  --set-file credentials.secretContents.cloud=&lt;(echo \"[default]\naws_access_key_id=$AWS_ACCESS_KEY_ID\naws_secret_access_key=$AWS_SECRET_ACCESS_KEY\") \\\n  --set configuration.provider=aws \\\n  --set configuration.backupStorageLocation.bucket=fawkes-velero-backups-prod-YOUR-UNIQUE-ID \\\n  --set configuration.backupStorageLocation.config.region=us-east-1 \\\n  --set configuration.volumeSnapshotLocation.config.region=us-east-1 \\\n  --set initContainers[0].name=velero-plugin-for-aws \\\n  --set initContainers[0].image=velero/velero-plugin-for-aws:v1.8.0 \\\n  --set initContainers[0].volumeMounts[0].mountPath=/target \\\n  --set initContainers[0].volumeMounts[0].name=plugins\n\n# Create daily backup schedule\nvelero schedule create daily-backup \\\n  --schedule=\"0 2 * * *\" \\\n  --ttl 720h0m0s\n\n# Test backup\nvelero backup create test-backup --wait\nvelero backup describe test-backup\n</code></pre>"},{"location":"AWS_deployment_guide/#configure-monitoring-and-alerting","title":"Configure Monitoring and Alerting","text":"<pre><code># Create AlertManager configuration\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: alertmanager-config\n  namespace: monitoring\ndata:\n  alertmanager.yml: |\n    global:\n      resolve_timeout: 5m\n\n    route:\n      group_by: ['alertname', 'cluster', 'service']\n      group_wait: 10s\n      group_interval: 10s\n      repeat_interval: 12h\n      receiver: 'fawkes-team'\n\n    receivers:\n    - name: 'fawkes-team'\n      email_configs:\n      - to: 'alerts@yourdomain.com'\n        from: 'fawkes-alerts@yourdomain.com'\n        smarthost: 'smtp.gmail.com:587'\n        auth_username: 'fawkes-alerts@yourdomain.com'\n        auth_password: 'YOUR_SMTP_PASSWORD'\n        headers:\n          Subject: '{{ template \"email.default.subject\" . }}'\n      slack_configs:\n      - api_url: 'YOUR_SLACK_WEBHOOK_URL'\n        channel: '#fawkes-alerts'\n        title: '{{ template \"slack.default.title\" . }}'\n        text: '{{ template \"slack.default.text\" . }}'\nEOF\n\n# Restart AlertManager to pick up new config\nkubectl rollout restart statefulset/alertmanager-prometheus-kube-prometheus-alertmanager -n monitoring\n</code></pre>"},{"location":"AWS_deployment_guide/#set-up-cost-monitoring","title":"Set Up Cost Monitoring","text":"<pre><code># Tag all resources for cost allocation\nCLUSTER_NAME=\"fawkes-production\"\n\n# Tag EKS cluster\naws eks tag-resource \\\n  --resource-arn $(aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.arn' --output text) \\\n  --tags Environment=production,Project=fawkes,CostCenter=engineering\n\n# Tag RDS instance\naws rds add-tags-to-resource \\\n  --resource-name $(aws rds describe-db-instances --db-instance-identifier fawkes-production-db --query 'DBInstances[0].DBInstanceArn' --output text) \\\n  --tags Key=Environment,Value=production Key=Project,Value=fawkes Key=CostCenter,Value=engineering\n\n# Tag S3 buckets\nfor bucket in fawkes-artifacts-prod-YOUR-UNIQUE-ID fawkes-backups-prod-YOUR-UNIQUE-ID fawkes-logs-prod-YOUR-UNIQUE-ID; do\n  aws s3api put-bucket-tagging \\\n    --bucket $bucket \\\n    --tagging 'TagSet=[{Key=Environment,Value=production},{Key=Project,Value=fawkes},{Key=CostCenter,Value=engineering}]'\ndone\n\n# Set up AWS Cost Explorer filters\necho \"Configure Cost Explorer to filter by tags: Project=fawkes\"\n</code></pre>"},{"location":"AWS_deployment_guide/#documentation","title":"Documentation","text":"<pre><code># Create deployment documentation\ncat &gt; DEPLOYMENT_RECORD.md &lt;&lt;EOF\n# Fawkes Production Deployment Record\n\n**Deployment Date**: $(date)\n**Deployed By**: $(whoami)\n**AWS Region**: us-east-1\n\n## Infrastructure Details\n\n### EKS Cluster\n- **Name**: fawkes-production\n- **Version**: 1.28\n- **Nodes**: 6 x t3.xlarge\n- **VPC ID**: $VPC_ID\n\n### RDS Database\n- **Identifier**: fawkes-production-db\n- **Instance Class**: db.m5.large\n- **Engine**: PostgreSQL 15.4\n- **Multi-AZ**: Yes\n- **Endpoint**: $RDS_ENDPOINT\n\n### S3 Buckets\n- Artifacts: fawkes-artifacts-prod-YOUR-UNIQUE-ID\n- Backups: fawkes-backups-prod-YOUR-UNIQUE-ID\n- Logs: fawkes-logs-prod-YOUR-UNIQUE-ID\n\n### Service Endpoints\n$(kubectl get ingress -A -o custom-columns=SERVICE:.metadata.name,URL:.spec.rules[0].host --no-headers)\n\n## Access Credentials\n\n**Stored in AWS Secrets Manager**:\n- fawkes/production/db-password\n- fawkes/production/argocd-password\n- fawkes/production/jenkins-password\n- fawkes/production/db-endpoint\n\n## Component Versions\n\n**Platform Services**:\n- ArgoCD: 5.51.0\n- Harbor: 1.13.0\n- Jenkins: 4.6.0\n- Backstage: latest\n- Mattermost: latest\n- Focalboard: latest\n\n**Observability**:\n- Prometheus Stack: 51.0.0\n- Grafana: (included in Prometheus stack)\n\n**Security**:\n- Trivy Operator: latest\n- Kyverno: latest\n\n## Next Steps\n\n1. Configure DNS records for all services\n2. Set up monitoring alerts\n3. Configure backup retention policies\n4. Onboard first users\n5. Deploy first application\n\n## Maintenance Windows\n\n- **Preferred Maintenance**: Sundays 04:00-05:00 UTC\n- **Backup Windows**: Daily 03:00-04:00 UTC\n\n## Support Contacts\n\n- Platform Team: platform-team@yourdomain.com\n- AWS Support: [Your AWS Support Plan]\n- On-Call: [PagerDuty/On-Call System]\n\nEOF\n\ncat DEPLOYMENT_RECORD.md\n</code></pre>"},{"location":"AWS_deployment_guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"AWS_deployment_guide/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"AWS_deployment_guide/#issue-pods-stuck-in-pending-state","title":"Issue: Pods stuck in Pending state","text":"<p>Symptoms: <pre><code>kubectl get pods -A | grep Pending\n</code></pre></p> <p>Diagnosis: <pre><code># Check pod events\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\n\n# Common causes:\n# 1. Insufficient resources\nkubectl describe nodes | grep -A 5 \"Allocated resources\"\n\n# 2. PVC not bound\nkubectl get pvc -A | grep Pending\n\n# 3. Node selector/affinity issues\nkubectl get pod &lt;pod-name&gt; -n &lt;namespace&gt; -o yaml | grep -A 10 nodeSelector\n</code></pre></p> <p>Solutions: <pre><code># Scale up nodes if resource constrained\neksctl scale nodegroup --cluster=fawkes-production --nodes=9 --name=fawkes-ng-general\n\n# Check storage class\nkubectl get storageclass\n\n# Fix PVC issues\nkubectl describe pvc &lt;pvc-name&gt; -n &lt;namespace&gt;\n</code></pre></p>"},{"location":"AWS_deployment_guide/#issue-cannot-access-services-via-ingress","title":"Issue: Cannot access services via ingress","text":"<p>Symptoms: <pre><code>curl https://argocd.fawkes.yourdomain.com\n# Returns timeout or connection refused\n</code></pre></p> <p>Diagnosis: <pre><code># Check ingress status\nkubectl get ingress -A\nkubectl describe ingress &lt;ingress-name&gt; -n &lt;namespace&gt;\n\n# Check ALB controller logs\nkubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller\n\n# Check target groups in AWS console\naws elbv2 describe-target-groups --region us-east-1\n\n# Check security groups\naws ec2 describe-security-groups --group-ids &lt;sg-id&gt;\n</code></pre></p> <p>Solutions: <pre><code># Restart ALB controller\nkubectl rollout restart deployment/aws-load-balancer-controller -n kube-system\n\n# Check certificate ARN is correct\nkubectl get ingress &lt;ingress-name&gt; -n &lt;namespace&gt; -o yaml | grep certificate-arn\n\n# Verify DNS resolution\nnslookup argocd.fawkes.yourdomain.com\n</code></pre></p>"},{"location":"AWS_deployment_guide/#issue-database-connection-failures","title":"Issue: Database connection failures","text":"<p>Symptoms: <pre><code># Pods crashlooping with database errors\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; | grep -i \"database\\|postgres\"\n</code></pre></p> <p>Diagnosis: <pre><code># Check RDS status\naws rds describe-db-instances --db-instance-identifier fawkes-production-db\n\n# Test connectivity from cluster\nkubectl run postgres-test --rm -i --tty \\\n  --image postgres:15 \\\n  --restart=Never \\\n  --env=\"PGPASSWORD=$DB_PASSWORD\" \\\n  -- psql -h $RDS_ENDPOINT -U fawkesadmin -d postgres -c \"SELECT 1\"\n\n# Check security group rules\naws ec2 describe-security-groups --group-ids &lt;rds-sg-id&gt;\n</code></pre></p> <p>Solutions: <pre><code># Verify security group allows traffic from EKS nodes\nEKS_NODE_SG=$(aws eks describe-cluster --name fawkes-production --query \"cluster.resourcesVpcConfig.clusterSecurityGroupId\" --output text)\n\naws ec2 authorize-security-group-ingress \\\n  --group-id $RDS_SG_ID \\\n  --protocol tcp \\\n  --port 5432 \\\n  --source-group $EKS_NODE_SG\n\n# Check secrets are correct\nkubectl get secret postgres-credentials -n fawkes-system -o yaml\n</code></pre></p>"},{"location":"AWS_deployment_guide/#issue-high-aws-costs","title":"Issue: High AWS costs","text":"<p>Diagnosis: <pre><code># Check current month's costs\naws ce get-cost-and-usage \\\n  --time-period Start=$(date -d \"$(date +%Y-%m-01)\" +%Y-%m-%d),End=$(date +%Y-%m-%d) \\\n  --granularity MONTHLY \\\n  --metrics UnblendedCost \\\n  --group-by Type=SERVICE\n\n# Identify expensive resources\nkubectl top nodes\nkubectl top pods -A\n</code></pre></p> <p>Solutions: <pre><code># Right-size nodes\neksctl scale nodegroup --cluster=fawkes-production --nodes=3 --name=fawkes-ng-general\n\n# Delete unused EBS volumes\naws ec2 describe-volumes --filters Name=status,Values=available --query 'Volumes[*].[VolumeId,Size,CreateTime]' --output table\n\n# Configure auto-scaling\n# (Already configured in Step 2.5)\n\n# Use Spot instances for dev/staging\n# Edit nodegroup configuration to use Spot\n\n# Set up AWS Budgets alerts\naws budgets create-budget \\\n  --account-id $(aws sts get-caller-identity --query Account --output text) \\\n  --budget file://budget-alert.json\n</code></pre></p>"},{"location":"AWS_deployment_guide/#issue-certificate-validation-pending","title":"Issue: Certificate validation pending","text":"<p>Symptoms: <pre><code>aws acm describe-certificate --certificate-arn &lt;cert-arn&gt; | grep Status\n# Returns: PENDING_VALIDATION\n</code></pre></p> <p>Solutions: <pre><code># Get validation records\naws acm describe-certificate --certificate-arn &lt;cert-arn&gt; --query 'Certificate.DomainValidationOptions[0].ResourceRecord'\n\n# Add DNS record for validation\n# In Route53 or your DNS provider, create a CNAME record with the values returned above\n\n# Wait for validation (can take 5-30 minutes)\naws acm wait certificate-validated --certificate-arn &lt;cert-arn&gt;\n</code></pre></p>"},{"location":"AWS_deployment_guide/#cost-optimization","title":"Cost Optimization","text":""},{"location":"AWS_deployment_guide/#immediate-optimizations-week-1","title":"Immediate Optimizations (Week 1)","text":"<pre><code># 1. Right-size EKS nodes based on actual usage\nkubectl top nodes\nkubectl top pods -A --sort-by=memory\n\n# If utilization &lt; 50%, scale down\neksctl scale nodegroup --cluster=fawkes-production --nodes=4 --name=fawkes-ng-general\n\n# 2. Delete unused EBS volumes\naws ec2 describe-volumes --filters Name=status,Values=available \\\n  --query 'Volumes[*].[VolumeId,Size,CreateTime]' --output table\n\n# Delete them\naws ec2 delete-volume --volume-id vol-xxxxxxxxx\n\n# 3. Configure S3 lifecycle policies\naws s3api put-bucket-lifecycle-configuration \\\n  --bucket fawkes-logs-prod-YOUR-UNIQUE-ID \\\n  --lifecycle-configuration file://s3-lifecycle.json\n\n# s3-lifecycle.json content:\ncat &gt; s3-lifecycle.json &lt;&lt;EOF\n{\n  \"Rules\": [\n    {\n      \"Id\": \"ArchiveOldLogs\",\n      \"Status\": \"Enabled\",\n      \"Transitions\": [\n        {\n          \"Days\": 30,\n          \"StorageClass\": \"STANDARD_IA\"\n        },\n        {\n          \"Days\": 90,\n          \"StorageClass\": \"GLACIER\"\n        }\n      ],\n      \"Expiration\": {\n        \"Days\": 365\n      }\n    }\n  ]\n}\nEOF\n</code></pre>"},{"location":"AWS_deployment_guide/#long-term-optimizations-month-2-3","title":"Long-term Optimizations (Month 2-3)","text":"<pre><code># 1. Purchase Reserved Instances (40% savings)\n# After validating instance types and sizes, purchase 1-year RIs\naws ec2 describe-reserved-instances-offerings \\\n  --instance-type t3.xlarge \\\n  --offering-class standard \\\n  --product-description Linux/UNIX\n\n# 2. Use Savings Plans for RDS\naws rds purchase-reserved-db-instances-offering \\\n  --reserved-db-instances-offering-id &lt;offering-id&gt; \\\n  --reserved-db-instance-id fawkes-production-db-reserved\n\n# 3. Implement cluster autoscaling policies\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: cluster-autoscaler-priority-expander\n  namespace: kube-system\ndata:\n  priorities: |-\n    10:\n      - .*-spot-.*\n    50:\n      - .*-on-demand-.*\nEOF\n\n# 4. Use Spot instances for non-critical workloads\n# Create a mixed instance nodegroup\neksctl create nodegroup \\\n  --cluster=fawkes-production \\\n  --name=fawkes-ng-spot \\\n  --node-type=t3.xlarge \\\n  --nodes=3 \\\n  --nodes-min=1 \\\n  --nodes-max=10 \\\n  --spot\n\n# 5. Enable AWS Compute Optimizer\naws compute-optimizer update-enrollment-status \\\n  --status Active \\\n  --include-member-accounts\n</code></pre>"},{"location":"AWS_deployment_guide/#monitoring-costs","title":"Monitoring Costs","text":"<pre><code># Create cost monitoring dashboard\ncat &gt; cost-monitoring.sh &lt;&lt;'EOF'\n#!/bin/bash\n\necho \"===== Fawkes AWS Cost Report =====\"\necho \"Report Date: $(date)\"\necho \"\"\n\n# Current month costs\necho \"Current Month Costs:\"\naws ce get-cost-and-usage \\\n  --time-period Start=$(date -d \"$(date +%Y-%m-01)\" +%Y-%m-%d),End=$(date +%Y-%m-%d) \\\n  --granularity MONTHLY \\\n  --metrics UnblendedCost \\\n  --group-by Type=SERVICE \\\n  --filter file://&lt;(echo '{\n    \"Tags\": {\n      \"Key\": \"Project\",\n      \"Values\": [\"fawkes\"]\n    }\n  }') \\\n  --output table\n\necho \"\"\necho \"Top 10 Most Expensive Resources:\"\naws ce get-cost-and-usage \\\n  --time-period Start=$(date -d \"$(date +%Y-%m-01)\" +%Y-%m-%d),End=$(date +%Y-%m-%d) \\\n  --granularity MONTHLY \\\n  --metrics UnblendedCost \\\n  --group-by Type=DIMENSION,Key=RESOURCE_ID \\\n  --filter file://&lt;(echo '{\n    \"Tags\": {\n      \"Key\": \"Project\",\n      \"Values\": [\"fawkes\"]\n    }\n  }') \\\n  --query 'ResultsByTime[0].Groups | sort_by(@, &amp;Metrics.UnblendedCost.Amount) | reverse(@) | [0:10]' \\\n  --output table\n\necho \"\"\necho \"Projected Month-End Cost:\"\naws ce get-cost-forecast \\\n  --time-period Start=$(date +%Y-%m-%d),End=$(date -d \"$(date +%Y-%m-01) +1 month -1 day\" +%Y-%m-%d) \\\n  --metric UNBLENDED_COST \\\n  --granularity MONTHLY \\\n  --output table\n\necho \"\"\necho \"=====================================\"\nEOF\n\nchmod +x cost-monitoring.sh\n./cost-monitoring.sh\n</code></pre>"},{"location":"AWS_deployment_guide/#appendix-a-complete-deployment-checklist","title":"Appendix A: Complete Deployment Checklist","text":""},{"location":"AWS_deployment_guide/#pre-deployment","title":"Pre-Deployment","text":"<ul> <li>[ ] AWS account with appropriate permissions</li> <li>[ ] All required tools installed (AWS CLI, kubectl, terraform, helm, eksctl)</li> <li>[ ] Domain name registered (optional but recommended)</li> <li>[ ] Budget alerts configured</li> <li>[ ] Team notified of deployment window</li> <li>[ ] Passwords generated and stored securely</li> <li>[ ] S3 bucket names chosen (globally unique)</li> </ul>"},{"location":"AWS_deployment_guide/#phase-1-foundation-30-min","title":"Phase 1: Foundation (30 min)","text":"<ul> <li>[ ] Terraform initialized</li> <li>[ ] VPC and networking deployed</li> <li>[ ] NAT Gateways provisioned</li> <li>[ ] S3 buckets created with encryption</li> <li>[ ] Secrets stored in AWS Secrets Manager</li> <li>[ ] SSL certificate requested (if using custom domain)</li> <li>[ ] Validation: VPC, subnets, NAT gateways, S3 buckets exist</li> </ul>"},{"location":"AWS_deployment_guide/#phase-2-eks-cluster-30-min","title":"Phase 2: EKS Cluster (30 min)","text":"<ul> <li>[ ] EKS cluster created</li> <li>[ ] Worker nodes launched across 3 AZs</li> <li>[ ] kubectl configured</li> <li>[ ] AWS Load Balancer Controller installed</li> <li>[ ] External Secrets Operator installed</li> <li>[ ] Cluster Autoscaler configured</li> <li>[ ] Validation: All nodes Ready, system pods running</li> </ul>"},{"location":"AWS_deployment_guide/#phase-3-database-storage-20-min","title":"Phase 3: Database &amp; Storage (20 min)","text":"<ul> <li>[ ] RDS PostgreSQL instance created (Multi-AZ)</li> <li>[ ] Security groups configured</li> <li>[ ] Database connectivity verified</li> <li>[ ] Databases initialized for each component</li> <li>[ ] Storage classes configured</li> <li>[ ] Validation: RDS available, connectivity tested</li> </ul>"},{"location":"AWS_deployment_guide/#phase-4-platform-services-60-min","title":"Phase 4: Platform Services (60 min)","text":"<ul> <li>[ ] Namespaces created</li> <li>[ ] ArgoCD deployed and accessible</li> <li>[ ] Harbor deployed and accessible</li> <li>[ ] Jenkins deployed and accessible</li> <li>[ ] Backstage deployed and accessible</li> <li>[ ] Mattermost deployed and accessible</li> <li>[ ] Focalboard deployed and accessible</li> <li>[ ] Validation: All services responding, ingresses have ALB addresses</li> </ul>"},{"location":"AWS_deployment_guide/#phase-5-observability-30-min","title":"Phase 5: Observability (30 min)","text":"<ul> <li>[ ] Prometheus stack deployed</li> <li>[ ] Grafana accessible with dashboards</li> <li>[ ] DORA metrics exporter deployed</li> <li>[ ] Alerting configured</li> <li>[ ] Validation: Prometheus scraping, Grafana dashboards visible</li> </ul>"},{"location":"AWS_deployment_guide/#phase-6-security-20-min","title":"Phase 6: Security (20 min)","text":"<ul> <li>[ ] Trivy Operator deployed</li> <li>[ ] Kyverno policies deployed</li> <li>[ ] Network policies configured</li> <li>[ ] Pod Security Standards applied</li> <li>[ ] RBAC roles created</li> <li>[ ] Validation: Vulnerability scans running, policies enforced</li> </ul>"},{"location":"AWS_deployment_guide/#phase-7-validation-30-min","title":"Phase 7: Validation (30 min)","text":"<ul> <li>[ ] Health check script run successfully</li> <li>[ ] Connectivity tests pass</li> <li>[ ] Test application deployed</li> <li>[ ] DORA metrics collecting</li> <li>[ ] Security scan completed</li> <li>[ ] Validation: All green checks</li> </ul>"},{"location":"AWS_deployment_guide/#post-deployment","title":"Post-Deployment","text":"<ul> <li>[ ] DNS records configured</li> <li>[ ] Backups configured (Velero)</li> <li>[ ] Monitoring and alerting verified</li> <li>[ ] Cost tracking enabled</li> <li>[ ] Documentation completed</li> <li>[ ] Team access granted</li> <li>[ ] First application deployed</li> <li>[ ] Runbook created</li> </ul>"},{"location":"AWS_deployment_guide/#appendix-b-useful-commands-reference","title":"Appendix B: Useful Commands Reference","text":""},{"location":"AWS_deployment_guide/#cluster-management","title":"Cluster Management","text":"<pre><code># Get cluster info\nkubectl cluster-info\neksctl get cluster --name fawkes-production\n\n# Get all resources\nkubectl get all -A\n\n# Scale nodegroup\neksctl scale nodegroup --cluster=fawkes-production --nodes=6 --name=fawkes-ng-general\n\n# Update kubeconfig\naws eks update-kubeconfig --region us-east-1 --name fawkes-production\n\n# Drain node for maintenance\nkubectl drain &lt;node-name&gt; --ignore-daemonsets --delete-emptydir-data\n\n# Uncordon node after maintenance\nkubectl uncordon &lt;node-name&gt;\n</code></pre>"},{"location":"AWS_deployment_guide/#debugging","title":"Debugging","text":"<pre><code># View pod logs\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt;\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; --previous  # Previous container\n\n# Follow logs\nkubectl logs -f &lt;pod-name&gt; -n &lt;namespace&gt;\n\n# Exec into pod\nkubectl exec -it &lt;pod-name&gt; -n &lt;namespace&gt; -- /bin/bash\n\n# Port forward\nkubectl port-forward -n &lt;namespace&gt; svc/&lt;service-name&gt; 8080:80\n\n# Describe resources\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\nkubectl describe node &lt;node-name&gt;\n\n# Get events\nkubectl get events -n &lt;namespace&gt; --sort-by='.lastTimestamp'\n\n# Check resource usage\nkubectl top nodes\nkubectl top pods -A\n</code></pre>"},{"location":"AWS_deployment_guide/#backup-and-restore","title":"Backup and Restore","text":"<pre><code># Create backup\nvelero backup create &lt;backup-name&gt; --include-namespaces &lt;namespace&gt;\n\n# List backups\nvelero backup get\n\n# Restore from backup\nvelero restore create --from-backup &lt;backup-name&gt;\n\n# Backup specific resource\nvelero backup create &lt;backup-name&gt; --include-resources deployments,services\n\n# Schedule regular backups\nvelero schedule create daily --schedule=\"0 2 * * *\" --ttl 720h\n</code></pre>"},{"location":"AWS_deployment_guide/#certificate-management","title":"Certificate Management","text":"<pre><code># List certificates\naws acm list-certificates --region us-east-1\n\n# Describe certificate\naws acm describe-certificate --certificate-arn &lt;arn&gt;\n\n# Request new certificate\naws acm request-certificate \\\n  --domain-name fawkes.yourdomain.com \\\n  --validation-method DNS \\\n  --region us-east-1\n\n# Delete certificate\naws acm delete-certificate --certificate-arn &lt;arn&gt;\n</code></pre>"},{"location":"AWS_deployment_guide/#database-operations","title":"Database Operations","text":"<pre><code># Connect to RDS\nkubectl run postgres-client --rm -i --tty \\\n  --image postgres:15 \\\n  --restart=Never \\\n  --env=\"PGPASSWORD=$DB_PASSWORD\" \\\n  -- psql -h $RDS_ENDPOINT -U fawkesadmin -d postgres\n\n# Create database dump\nkubectl run postgres-backup --rm -i --tty \\\n  --image postgres:15 \\\n  --restart=Never \\\n  --env=\"PGPASSWORD=$DB_PASSWORD\" \\\n  -- pg_dump -h $RDS_ENDPOINT -U fawkesadmin -d backstage &gt; backstage-backup.sql\n\n# Restore database\nkubectl run postgres-restore --rm -i --tty \\\n  --image postgres:15 \\\n  --restart=Never \\\n  --env=\"PGPASSWORD=$DB_PASSWORD\" \\\n  -- psql -h $RDS_ENDPOINT -U fawkesadmin -d backstage &lt; backstage-backup.sql\n</code></pre>"},{"location":"AWS_deployment_guide/#secrets-management_1","title":"Secrets Management","text":"<pre><code># Create secret from AWS Secrets Manager\nkubectl create secret generic my-secret \\\n  --from-literal=password=$(aws secretsmanager get-secret-value \\\n    --secret-id fawkes/production/db-password \\\n    --query SecretString \\\n    --output text)\n\n# View secret (base64 decoded)\nkubectl get secret &lt;secret-name&gt; -n &lt;namespace&gt; -o jsonpath='{.data.password}' | base64 -d\n\n# Update secret\nkubectl create secret generic &lt;secret-name&gt; \\\n  --from-literal=key=value \\\n  --dry-run=client -o yaml | kubectl apply -f -\n</code></pre>"},{"location":"AWS_deployment_guide/#appendix-c-disaster-recovery-procedures","title":"Appendix C: Disaster Recovery Procedures","text":""},{"location":"AWS_deployment_guide/#rds-failure","title":"RDS Failure","text":"<p>Detection: <pre><code>aws rds describe-db-instances \\\n  --db-instance-identifier fawkes-production-db \\\n  --query 'DBInstances[0].DBInstanceStatus'\n</code></pre></p> <p>Recovery (Multi-AZ automatic failover): <pre><code># Force failover to standby\naws rds reboot-db-instance \\\n  --db-instance-identifier fawkes-production-db \\\n  --force-failover\n\n# Wait for availability\naws rds wait db-instance-available \\\n  --db-instance-identifier fawkes-production-db\n\n# Verify new endpoint (should be same)\naws rds describe-db-instances \\\n  --db-instance-identifier fawkes-production-db \\\n  --query 'DBInstances[0].Endpoint.Address'\n</code></pre></p> <p>Recovery (Complete failure - restore from snapshot): <pre><code># List recent snapshots\naws rds describe-db-snapshots \\\n  --db-instance-identifier fawkes-production-db \\\n  --query 'DBSnapshots[*].[DBSnapshotIdentifier,SnapshotCreateTime]' \\\n  --output table\n\n# Restore from snapshot\naws rds restore-db-instance-from-db-snapshot \\\n  --db-instance-identifier fawkes-production-db-restored \\\n  --db-snapshot-identifier &lt;snapshot-id&gt; \\\n  --db-subnet-group-name fawkes-production-db-subnet \\\n  --multi-az\n\n# Update connection strings in Kubernetes secrets\nNEW_ENDPOINT=$(aws rds describe-db-instances \\\n  --db-instance-identifier fawkes-production-db-restored \\\n  --query 'DBInstances[0].Endpoint.Address' \\\n  --output text)\n\nkubectl create secret generic postgres-credentials \\\n  --from-literal=host=$NEW_ENDPOINT \\\n  --from-literal=port=5432 \\\n  --from-literal=database=postgres \\\n  --from-literal=username=fawkesadmin \\\n  --from-literal=password=$DB_PASSWORD \\\n  -n fawkes-system \\\n  --dry-run=client -o yaml | kubectl apply -f -\n\n# Restart all pods using database\nkubectl rollout restart deployment -n backstage\nkubectl rollout restart deployment -n jenkins\nkubectl rollout restart deployment -n argocd\nkubectl rollout restart deployment -n harbor\nkubectl rollout restart deployment -n mattermost\nkubectl rollout restart deployment -n focalboard\n</code></pre></p>"},{"location":"AWS_deployment_guide/#eks-cluster-failure","title":"EKS Cluster Failure","text":"<p>Detection: <pre><code>kubectl get nodes\n# No response or all nodes NotReady\n</code></pre></p> <p>Recovery: <pre><code># Check cluster status\naws eks describe-cluster --name fawkes-production --query 'cluster.status'\n\n# If cluster API is down, recreate from Terraform\ncd infra/terraform/aws\nterraform plan -var-file=production.tfvars\nterraform apply\n\n# Restore from Velero backup\nvelero restore create --from-backup daily-backup-20251007\n</code></pre></p>"},{"location":"AWS_deployment_guide/#complete-region-failure","title":"Complete Region Failure","text":"<p>Prerequisites: - Multi-region setup (not covered in this guide) - Cross-region RDS replication - S3 cross-region replication</p> <p>Recovery: <pre><code># Promote RDS read replica in secondary region\naws rds promote-read-replica \\\n  --db-instance-identifier fawkes-production-db-replica \\\n  --region us-west-2\n\n# Deploy EKS cluster in secondary region\ncd infra/terraform/aws\nterraform apply -var-file=dr-production.tfvars -var=\"aws_region=us-west-2\"\n\n# Update DNS to point to new region\naws route53 change-resource-record-sets \\\n  --hosted-zone-id &lt;zone-id&gt; \\\n  --change-batch file://failover-dns.json\n</code></pre></p>"},{"location":"AWS_deployment_guide/#appendix-d-maintenance-procedures","title":"Appendix D: Maintenance Procedures","text":""},{"location":"AWS_deployment_guide/#monthly-maintenance-tasks","title":"Monthly Maintenance Tasks","text":"<pre><code># 1. Update EKS cluster version\neksctl upgrade cluster --name fawkes-production --version 1.29 --approve\n\n# 2. Update nodegroups\neksctl upgrade nodegroup --cluster=fawkes-production --name=fawkes-ng-general\n\n# 3. Update Helm charts\nhelm repo update\nhelm list -A\n\n# Update each chart\nhelm upgrade argocd argo/argo-cd -n argocd --version &lt;new-version&gt;\nhelm upgrade harbor harbor/harbor -n harbor --version &lt;new-version&gt;\n# ... etc\n\n# 4. Update add-ons\neksctl utils update-addon --cluster fawkes-production --name vpc-cni --version &lt;new-version&gt;\neksctl utils update-addon --cluster fawkes-production --name coredns --version &lt;new-version&gt;\neksctl utils update-addon --cluster fawkes-production --name kube-proxy --version &lt;new-version&gt;\neksctl utils update-addon --cluster fawkes-production --name aws-ebs-csi-driver --version &lt;new-version&gt;\n\n# 5. Clean up old resources\n# Delete old EBS snapshots\naws ec2 describe-snapshots --owner-ids self \\\n  --query 'Snapshots[?StartTime&lt;=`2024-07-01`].[SnapshotId,StartTime,Description]' \\\n  --output table\n\n# Delete them\naws ec2 delete-snapshot --snapshot-id snap-xxxxxxxxx\n\n# 6. Review and clean up unused PVCs\nkubectl get pvc -A | grep Released\nkubectl delete pvc &lt;pvc-name&gt; -n &lt;namespace&gt;\n\n# 7. Rotate secrets\n# Generate new password\nNEW_DB_PASSWORD=$(openssl rand -base64 32)\n\n# Update in RDS\naws rds modify-db-instance \\\n  --db-instance-identifier fawkes-production-db \\\n  --master-user-password $NEW_DB_PASSWORD \\\n  --apply-immediately\n\n# Update in Secrets Manager\naws secretsmanager update-secret \\\n  --secret-id fawkes/production/db-password \\\n  --secret-string $NEW_DB_PASSWORD\n\n# Update in Kubernetes\nkubectl create secret generic postgres-credentials \\\n  --from-literal=password=$NEW_DB_PASSWORD \\\n  --dry-run=client -o yaml | kubectl apply -f -\n\n# 8. Review security scan results\nkubectl get vulnerabilityreports -A | grep CRITICAL\n\n# 9. Review and update network policies\nkubectl get networkpolicies -A\n\n# 10. Cost optimization review\n./cost-monitoring.sh\n</code></pre>"},{"location":"AWS_deployment_guide/#quarterly-maintenance-tasks","title":"Quarterly Maintenance Tasks","text":"<pre><code># 1. Major version upgrades (EKS, RDS)\n# Follow AWS documentation for major version upgrades\n\n# 2. Review and update IAM policies\naws iam get-policy-version \\\n  --policy-arn arn:aws:iam::ACCOUNT_ID:policy/FawkesPolicy \\\n  --version-id v1\n\n# 3. Security audit\naws securityhub get-findings --region us-east-1\n\n# 4. Compliance check\naws config describe-compliance-by-config-rule\n\n# 5. Performance review\n# Review Grafana dashboards for trends\n# Analyze DORA metrics improvements\n\n# 6. Disaster recovery test\n# Perform complete failover test in DR environment\n\n# 7. Documentation review\n# Update runbooks, procedures, contact information\n</code></pre>"},{"location":"AWS_deployment_guide/#appendix-e-additional-resources","title":"Appendix E: Additional Resources","text":""},{"location":"AWS_deployment_guide/#official-documentation","title":"Official Documentation","text":"<ul> <li>Amazon EKS User Guide</li> <li>Amazon RDS User Guide</li> <li>AWS Load Balancer Controller</li> <li>Backstage Documentation</li> <li>ArgoCD Documentation</li> <li>Harbor Documentation</li> </ul>"},{"location":"AWS_deployment_guide/#best-practices-guides","title":"Best Practices Guides","text":"<ul> <li>EKS Best Practices Guide</li> <li>Kubernetes Production Best Practices</li> <li>AWS Well-Architected Framework</li> </ul>"},{"location":"AWS_deployment_guide/#training-and-certification","title":"Training and Certification","text":"<ul> <li>AWS Certified Solutions Architect</li> <li>Certified Kubernetes Administrator (CKA)</li> <li>Platform Engineering University</li> </ul>"},{"location":"AWS_deployment_guide/#community-and-support","title":"Community and Support","text":"<ul> <li>Fawkes GitHub Discussions</li> <li>Fawkes Mattermost (after deployment)</li> <li>AWS Support</li> <li>CNCF Slack</li> </ul>"},{"location":"AWS_deployment_guide/#conclusion","title":"Conclusion","text":"<p>Congratulations! You've successfully deployed the Fawkes platform on AWS in production.</p> <p>What you've accomplished: - \u2705 Deployed a complete Internal Delivery Platform on AWS - \u2705 Set up high-availability infrastructure across 3 availability zones - \u2705 Implemented security best practices (encryption, network policies, RBAC) - \u2705 Configured comprehensive observability and monitoring - \u2705 Established automated backups and disaster recovery procedures - \u2705 Created maintainable, documented infrastructure</p> <p>Next steps: 1. Onboard your first team: Create their first project using Backstage 2. Deploy first application: Use the golden path templates 3. Configure CI/CD: Set up Jenkins pipelines for automated builds 4. Launch Dojo: Begin training engineers on the platform 5. Iterate and improve: Collect feedback and enhance the platform</p> <p>Remember: - Monitor costs daily for the first week - Review security scans weekly - Perform monthly maintenance tasks - Test disaster recovery procedures quarterly - Keep documentation up to date</p> <p>Need help? - Check troubleshooting section first - Search GitHub Issues: https://github.com/paruff/fawkes/issues - Join the community on Mattermost - Review AWS documentation - Contact platform team: platform-team@yourdomain.com</p> <p>Thank you for choosing Fawkes! \ud83d\ude80</p> <p>Document Version: 1.0 Last Updated: October 7, 2025 Maintained By: Fawkes Platform Team Feedback: Please submit issues or improvements to the GitHub repository</p> <p>Estimated Total Time: 3-4 hours Estimated Monthly Cost: $2,084 (production environment) AWS Services Used: 10+ (EKS, RDS, S3, ALB, CloudWatch, Secrets Manager, ACM, IAM, VPC, ECR)</p>"},{"location":"CHARTER/","title":"Fawkes Project Charter","text":""},{"location":"CHARTER/#project-name","title":"Project Name","text":"<p>Fawkes - An Open Source Internal Delivery Platform</p>"},{"location":"CHARTER/#vision","title":"Vision","text":"<p>To become the leading open-source Internal Delivery Platform that empowers organizations to achieve elite DORA performance while fostering a culture of continuous learning and improvement in platform engineering.</p>"},{"location":"CHARTER/#mission","title":"Mission","text":"<p>Provide a production-ready, comprehensive Internal Delivery Platform that: - Enables rapid, secure software delivery through automation and best practices - Makes DORA metrics a first-class citizen with automated collection and visualization - Integrates learning and skill development through a dojo-style curriculum - Supports multi-cloud infrastructure with GitOps and Infrastructure as Code - Prioritizes security through DevSecOps practices and zero-trust principles - Creates an exceptional developer experience that reduces cognitive load</p>"},{"location":"CHARTER/#problem-statement","title":"Problem Statement","text":"<p>Organizations struggle to build effective Internal Developer Platforms due to:</p> <ol> <li>Complexity: Platform engineering requires expertise across dozens of tools and practices</li> <li>Integration Challenges: Stitching together CI/CD, observability, security, and deployment tools is time-consuming</li> <li>Metrics Blind Spots: Teams lack visibility into DORA metrics and platform effectiveness</li> <li>Skills Gap: Platform engineering skills are scarce; teams need learning resources integrated with tools</li> <li>Reinventing the Wheel: Every organization builds similar platforms, duplicating effort</li> <li>Vendor Lock-in: Commercial platforms create dependencies and limit customization</li> </ol>"},{"location":"CHARTER/#solution","title":"Solution","text":"<p>Fawkes provides an opinionated, integrated platform that includes:</p> <p>Core Platform Capabilities: - Kubernetes-based infrastructure provisioning (AWS, Azure, GCP) - GitOps workflows for declarative infrastructure and application management - CI/CD pipelines with golden path templates - Automated security scanning and compliance checks - Comprehensive observability stack (metrics, logs, traces) - Developer portal (Backstage) for self-service and discovery - Deployment strategies (blue-green, canary, progressive delivery)</p> <p>Differentiators: - DORA Metrics Automation: Automated collection and visualization of all four key metrics - Dojo Learning Curriculum: Integrated learning paths aligned with platform capabilities - Certification Integration: Aligned with Platform Engineering University certifications - Open Source &amp; Extensible: No vendor lock-in, community-driven development - Security-First: Comprehensive scanning, policy-as-code, zero-trust roadmap - Multi-Cloud Native: Designed for multi-cloud from the start</p>"},{"location":"CHARTER/#target-audience","title":"Target Audience","text":""},{"location":"CHARTER/#primary-users","title":"Primary Users","text":"<ul> <li>Platform Engineering Teams (5-50 people) in mid to large enterprises</li> <li>DevOps Teams transitioning to platform engineering model</li> <li>Engineering Leaders seeking to improve DORA metrics and developer productivity</li> </ul>"},{"location":"CHARTER/#secondary-users","title":"Secondary Users","text":"<ul> <li>Application Developers who benefit from the platform's self-service capabilities</li> <li>Platform Engineering Students learning through hands-on implementation</li> <li>DevOps Consultants implementing IDPs for clients</li> </ul>"},{"location":"CHARTER/#geographic-focus","title":"Geographic Focus","text":"<ul> <li>Initial: North America, Europe (English language)</li> <li>Expansion: Global (internationalization in roadmap)</li> </ul>"},{"location":"CHARTER/#success-criteria","title":"Success Criteria","text":""},{"location":"CHARTER/#6-month-goals-post-mvp","title":"6-Month Goals (Post-MVP)","text":"<ul> <li>Adoption: 15-25 organizations using Fawkes in production</li> <li>Community: 50+ contributors, 1,000+ GitHub stars</li> <li>DORA Impact: 3+ published case studies showing measurable DORA improvement</li> <li>Learning: 100+ individuals complete at least one dojo module</li> <li>Stability: 99.5%+ platform uptime for core components</li> </ul>"},{"location":"CHARTER/#12-month-goals","title":"12-Month Goals","text":"<ul> <li>Adoption: 50+ organizations, 10+ Fortune 1000 companies</li> <li>Community: 100+ contributors, 2,500+ GitHub stars, CNCF Sandbox project</li> <li>Certification: Official partnership with Platform Engineering University</li> <li>Multi-Cloud: Full support for AWS, Azure, GCP</li> <li>Revenue: Sustainable funding model (sponsorships, professional services)</li> </ul>"},{"location":"CHARTER/#24-month-goals","title":"24-Month Goals","text":"<ul> <li>Market Position: Top 3 open-source IDP by adoption</li> <li>Community: 250+ contributors, 5,000+ GitHub stars, CNCF Incubating project</li> <li>Ecosystem: 20+ plugins/extensions from community</li> <li>Enterprise: 100+ enterprise deployments with reference architectures</li> <li>Research: Published research on IDP adoption and DORA correlation</li> </ul>"},{"location":"CHARTER/#key-metrics","title":"Key Metrics","text":""},{"location":"CHARTER/#platform-performance-metrics","title":"Platform Performance Metrics","text":"<ul> <li>Deployment Frequency: Track improvements for adopting teams</li> <li>Lead Time for Changes: Measure from commit to production</li> <li>Change Failure Rate: Monitor failed deployments</li> <li>Time to Restore Service: Track incident recovery times</li> </ul>"},{"location":"CHARTER/#community-health-metrics","title":"Community Health Metrics","text":"<ul> <li>Contributors: Active monthly contributors</li> <li>Pull Requests: PR volume and merge rate</li> <li>Response Time: Time to first response on issues</li> <li>Community Size: Slack/Discord members, mailing list subscribers</li> </ul>"},{"location":"CHARTER/#business-metrics","title":"Business Metrics","text":"<ul> <li>Adoption: Organizations deploying Fawkes</li> <li>NPS Score: User satisfaction (target: 50+)</li> <li>Documentation Quality: Page views, search success rate</li> <li>Cost Savings: Infrastructure efficiency vs. manual platform building</li> </ul>"},{"location":"CHARTER/#guiding-principles","title":"Guiding Principles","text":""},{"location":"CHARTER/#1-developer-experience-is-paramount","title":"1. Developer Experience is Paramount","text":"<p>Every feature must improve developer productivity, reduce cognitive load, or enable self-service.</p>"},{"location":"CHARTER/#2-measure-everything","title":"2. Measure Everything","text":"<p>If it can't be measured, it can't be improved. Build observability into every component.</p>"},{"location":"CHARTER/#3-security-is-non-negotiable","title":"3. Security is Non-Negotiable","text":"<p>Security scanning, policy enforcement, and compliance are built-in, not bolt-on.</p>"},{"location":"CHARTER/#4-learn-while-building","title":"4. Learn While Building","text":"<p>The platform doubles as a learning environment with integrated curriculum.</p>"},{"location":"CHARTER/#5-community-over-features","title":"5. Community Over Features","text":"<p>A healthy, engaged community is more valuable than a feature-complete platform.</p>"},{"location":"CHARTER/#6-open-by-default","title":"6. Open by Default","text":"<p>Decisions, roadmap, metrics, and discussions are public unless privacy requires otherwise.</p>"},{"location":"CHARTER/#7-opinionated-but-extensible","title":"7. Opinionated but Extensible","text":"<p>Provide golden paths for 80% of use cases; allow customization for the other 20%.</p>"},{"location":"CHARTER/#8-multi-cloud-from-day-one","title":"8. Multi-Cloud from Day One","text":"<p>Design for cloud portability even if initial implementation is AWS-only.</p>"},{"location":"CHARTER/#scope","title":"Scope","text":""},{"location":"CHARTER/#in-scope","title":"In Scope","text":"<ul> <li>Kubernetes-based infrastructure automation</li> <li>CI/CD pipelines and deployment strategies</li> <li>Observability (metrics, logs, traces)</li> <li>Security scanning and policy enforcement</li> <li>Developer portal and self-service catalog</li> <li>GitOps workflows</li> <li>DORA metrics automation</li> <li>Learning curriculum and certification alignment</li> <li>Multi-cloud support (AWS, Azure, GCP)</li> <li>Documentation and community building</li> </ul>"},{"location":"CHARTER/#out-of-scope-explicitly","title":"Out of Scope (Explicitly)","text":"<ul> <li>Application frameworks or languages (we provide templates, not frameworks)</li> <li>Source control management (we integrate with GitHub/GitLab, not replace them)</li> <li>Project management tools (we integrate, not replace)</li> <li>Business-specific workflows (keep platform generic, extensible)</li> <li>On-premises only deployments (cloud-first, on-prem possible but not primary)</li> </ul>"},{"location":"CHARTER/#future-consideration","title":"Future Consideration","text":"<ul> <li>Edge computing and IoT deployments</li> <li>Machine learning platform capabilities</li> <li>FinOps and cost optimization features</li> <li>Compliance automation (SOC2, HIPAA, etc.)</li> <li>Advanced chaos engineering integration</li> </ul>"},{"location":"CHARTER/#risks-and-mitigation","title":"Risks and Mitigation","text":""},{"location":"CHARTER/#technical-risks","title":"Technical Risks","text":"Risk Impact Mitigation Integration complexity delays MVP High Start with minimal integrations, prioritize stability over features Scalability issues at enterprise scale High Design for scale from day one, conduct load testing early Security vulnerabilities in dependencies High Automated scanning, regular updates, security-first culture"},{"location":"CHARTER/#community-risks","title":"Community Risks","text":"Risk Impact Mitigation Maintainer burnout Critical Grow maintainer team early, establish rotation schedules Low adoption / community interest High Invest heavily in documentation, marketing, and partnerships Competing projects fragment efforts Medium Differentiate clearly, collaborate where possible"},{"location":"CHARTER/#business-risks","title":"Business Risks","text":"Risk Impact Mitigation Insufficient funding for infrastructure Medium Seek cloud credits, CNCF support, sponsorships Certification partnerships fail Medium Maintain standalone value, diversify partnerships Enterprise concerns about support Medium Build professional services ecosystem, offer paid support options"},{"location":"CHARTER/#resource-requirements","title":"Resource Requirements","text":""},{"location":"CHARTER/#human-resources-mvp-phase","title":"Human Resources (MVP Phase)","text":"<ul> <li>Technical Lead / Architect: 1 FTE (50% project lead, 50% architecture)</li> <li>Backend Engineers: 2-3 contributors (part-time acceptable)</li> <li>Documentation Writer: 0.5 FTE (can be distributed)</li> <li>Community Manager: 0.25 FTE (grows to 0.5 FTE post-launch)</li> </ul>"},{"location":"CHARTER/#infrastructure-resources","title":"Infrastructure Resources","text":"<ul> <li>Development/Testing: AWS EKS cluster, supporting services (~$500/month)</li> <li>Demo Environment: Always-on demo instance (~$300/month)</li> <li>CI/CD: GitHub Actions (free tier initially)</li> <li>Communication: Slack/Discord (free tier)</li> <li>Documentation Hosting: GitHub Pages or Netlify (free)</li> </ul>"},{"location":"CHARTER/#financial-resources-first-year","title":"Financial Resources (First Year)","text":"<ul> <li>Infrastructure: $10,000 (offset by cloud credits)</li> <li>Tools/Services: $5,000 (domain, email, premium tools)</li> <li>Events/Marketing: $5,000 (conference travel, swag)</li> <li>Contingency: $5,000</li> <li>Total: ~$25,000 (significant portion via sponsorships/credits)</li> </ul>"},{"location":"CHARTER/#stakeholders","title":"Stakeholders","text":""},{"location":"CHARTER/#internal-stakeholders","title":"Internal Stakeholders","text":"<ul> <li>Project Lead: Overall vision and strategy</li> <li>Maintainer Team: Technical direction and execution</li> <li>Core Contributors: Feature development and community support</li> </ul>"},{"location":"CHARTER/#external-stakeholders","title":"External Stakeholders","text":"<ul> <li>Platform Engineering University: Certification alignment, educational content</li> <li>CNCF: Potential project hosting, infrastructure support, visibility</li> <li>Cloud Providers (AWS, Azure, GCP): Infrastructure credits, reference architectures</li> <li>Enterprise Users: Requirements, feedback, case studies</li> <li>Open Source Community: Contributors, users, advocates</li> </ul>"},{"location":"CHARTER/#communication-plan","title":"Communication Plan","text":""},{"location":"CHARTER/#internal-communication","title":"Internal Communication","text":"<ul> <li>Maintainer Meetings: Bi-weekly, 60 minutes, public minutes</li> <li>Contributor Sync: Monthly, 30 minutes, open to all contributors</li> <li>Async Updates: GitHub Discussions, Slack channels</li> </ul>"},{"location":"CHARTER/#external-communication","title":"External Communication","text":"<ul> <li>Community Newsletter: Bi-weekly updates on progress, contributions</li> <li>Blog Posts: Weekly technical content, case studies, announcements</li> <li>Social Media: Daily engagement on Twitter/X, LinkedIn</li> <li>Office Hours: Bi-weekly, live Q&amp;A and support</li> <li>Conferences: Quarterly speaking engagements (KubeCon, PlatformCon, DevOpsDays)</li> </ul>"},{"location":"CHARTER/#crisis-communication","title":"Crisis Communication","text":"<ul> <li>Security Issues: Immediate disclosure via security mailing list, GitHub advisory</li> <li>Service Outages: Status page updates, post-mortem published within 48 hours</li> <li>Community Issues: Transparent handling per Code of Conduct, documented decisions</li> </ul>"},{"location":"CHARTER/#timeline","title":"Timeline","text":""},{"location":"CHARTER/#phase-0-foundation-weeks-1-2","title":"Phase 0: Foundation (Weeks 1-2)","text":"<ul> <li>Establish governance, communication infrastructure</li> <li>Initial documentation and architecture</li> </ul>"},{"location":"CHARTER/#phase-1-core-platform-weeks-3-5","title":"Phase 1: Core Platform (Weeks 3-5)","text":"<ul> <li>Backstage portal, CI/CD pipelines, GitOps implementation</li> </ul>"},{"location":"CHARTER/#phase-2-observability-weeks-6-8","title":"Phase 2: Observability (Weeks 6-8)","text":"<ul> <li>Metrics stack, DORA automation, deployment strategies</li> </ul>"},{"location":"CHARTER/#phase-3-launch-preparation-weeks-9-12","title":"Phase 3: Launch Preparation (Weeks 9-12)","text":"<ul> <li>Documentation completion, dojo curriculum, launch activities</li> </ul>"},{"location":"CHARTER/#post-mvp-iteration-and-growth-months-4-12","title":"Post-MVP: Iteration and Growth (Months 4-12)","text":"<ul> <li>Multi-cloud expansion, advanced features, community scaling</li> </ul>"},{"location":"CHARTER/#success-celebration","title":"Success Celebration","text":""},{"location":"CHARTER/#milestone-celebrations","title":"Milestone Celebrations","text":"<ul> <li>First Contributor: Public thank you, contributor spotlight</li> <li>MVP Launch: Virtual celebration, team recognition</li> <li>100 GitHub Stars: Social media celebration, community thank you</li> <li>First Production Deployment: Case study, blog post</li> <li>1 Year Anniversary: Annual report, contributor awards, retrospective</li> </ul>"},{"location":"CHARTER/#amendment-process","title":"Amendment Process","text":"<p>This charter may be amended through the governance process defined in GOVERNANCE.md. Major changes require community input and maintainer approval.</p> <p>Charter Version: 1.0 Established: October 4, 2025 Last Reviewed: October 4, 2025 Next Review: April 4, 2026 (6-month intervals)</p> <p>Approved By: - Project Lead: [Your Name/Signature] - Date: October 4, 2025</p>"},{"location":"CHARTER/#appendix-alignment-with-industry-standards","title":"Appendix: Alignment with Industry Standards","text":""},{"location":"CHARTER/#dora-research-alignment","title":"DORA Research Alignment","text":"<p>Fawkes directly supports all 24 DORA capabilities with particular focus on: - Trunk-based development - Continuous integration and delivery - Monitoring and observability - Database change management - Infrastructure as code</p>"},{"location":"CHARTER/#platform-engineering-principles","title":"Platform Engineering Principles","text":"<p>Aligned with Team Topologies and platform engineering best practices: - Platform as a product mindset - Self-service capabilities - Cognitive load reduction - Enabling team structure</p>"},{"location":"CHARTER/#cncf-landscape","title":"CNCF Landscape","text":"<p>Positioned in the CNCF landscape as: - Category: Developer Portal / Internal Developer Platform - Complementary to: Backstage, ArgoCD, Prometheus - Competing with: Commercial IDPs (Humanitec, Port.io)</p> <p>End of Charter</p>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in the Fawkes community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall community</li> <li>Using welcoming and inclusive language</li> <li>Being patient with new contributors and helping them learn</li> <li>Celebrating others' successes and contributions</li> <li>Assuming good intent and asking clarifying questions</li> <li>Providing credit and recognition where it's due</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address, without their explicit permission</li> <li>Dismissing or belittling others' contributions or concerns</li> <li>Sustained disruption of discussions, events, or community activities</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> <li>Advocating for, or encouraging, any of the above behavior</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Community leaders and maintainers are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, including but not limited to:</p> <ul> <li>GitHub repositories (issues, pull requests, discussions, wiki)</li> <li>Community chat platforms (Slack, Discord)</li> <li>Mailing lists and email communications</li> <li>Social media channels (official Fawkes accounts)</li> <li>In-person events (meetups, conferences, workshops)</li> <li>Virtual events (webinars, office hours, live streams)</li> <li>Any other forums created by the project team which the community uses for communication</li> </ul> <p>This Code of Conduct also applies when an individual is officially representing the community in public spaces. Examples include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":""},{"location":"CODE_OF_CONDUCT/#reporting","title":"Reporting","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at:</p> <p>conduct@fawkes-project.org</p> <p>You may also use GitHub's built-in private vulnerability reporting feature to report Code of Conduct violations confidentially.</p> <p>All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#what-to-include-in-a-report","title":"What to Include in a Report","text":"<p>When reporting an incident, please include as much of the following information as possible:</p> <ul> <li>Your contact information (so we can get in touch with you)</li> <li>Names (real, usernames, or pseudonyms) of any individuals involved</li> <li>Your account of what occurred</li> <li>If you believe this incident is ongoing</li> <li>Any other information that may be helpful</li> <li>Links to publicly available records (e.g., GitHub comments, mailing list archives)</li> <li>Date and time of the incident</li> </ul>"},{"location":"CODE_OF_CONDUCT/#confidentiality","title":"Confidentiality","text":"<p>All reports will be kept confidential. In some cases, we may determine that a public statement will need to be made. If that's the case, the identities of all victims and reporters will remain confidential unless those individuals instruct us otherwise.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-process","title":"Enforcement Process","text":"<ol> <li>Report Received: Community leaders acknowledge receipt within 24 hours</li> <li>Initial Review: Community leaders review the report within 48 hours</li> <li>Investigation: Gather additional information if needed (3-7 days)</li> <li>Decision: Enforcement decision made by 2/3 vote of community leaders</li> <li>Action: Enforcement action taken and parties notified</li> <li>Appeal: Option to appeal decision within 14 days</li> <li>Documentation: Incident documented for future reference (confidentially)</li> </ol>"},{"location":"CODE_OF_CONDUCT/#appeals","title":"Appeals","text":"<p>Any individual affected by an enforcement decision may appeal by contacting:</p> <p>conduct-appeals@fawkes-project.org</p> <p>Appeals will be reviewed by community leaders who were not involved in the original decision. The appeal review will be completed within 14 days, and the decision will be final.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"CODE_OF_CONDUCT/#contact","title":"Contact","text":"<p>For questions about this Code of Conduct, contact:</p> <ul> <li>General Questions: conduct@fawkes-project.org</li> <li>Enforcement Team: conduct@fawkes-project.org</li> <li>Appeals: conduct-appeals@fawkes-project.org</li> <li>Project Lead: [Your Contact Information]</li> </ul> <p>Document Version: 1.0 Last Updated: October 4, 2025 Based On: Contributor Covenant v2.1</p>"},{"location":"GOVERNACE/","title":"Fawkes Project Governance","text":""},{"location":"GOVERNACE/#overview","title":"Overview","text":"<p>Fawkes is an open-source Internal Delivery Platform committed to transparent, inclusive, and collaborative governance. This document defines how decisions are made, how contributors can become maintainers, and how the project evolves.</p>"},{"location":"GOVERNACE/#project-mission","title":"Project Mission","text":"<p>To provide a production-ready, DORA-driven Internal Delivery Platform that accelerates software delivery while fostering continuous learning and improvement in platform engineering practices.</p>"},{"location":"GOVERNACE/#core-values","title":"Core Values","text":"<ul> <li>Developer Experience First: Every decision prioritizes the experience of platform users</li> <li>Transparency: Decision-making processes are open and documented</li> <li>Inclusivity: We welcome contributors from all backgrounds and experience levels</li> <li>Quality: We maintain high standards for code, documentation, and community interactions</li> <li>Continuous Learning: The platform serves as both a tool and a teaching environment</li> <li>Data-Driven: Decisions are informed by metrics, user feedback, and DORA research</li> </ul>"},{"location":"GOVERNACE/#project-structure","title":"Project Structure","text":""},{"location":"GOVERNACE/#roles","title":"Roles","text":""},{"location":"GOVERNACE/#users","title":"Users","text":"<p>Anyone who uses Fawkes to build and operate their internal delivery platform.</p> <p>Responsibilities: - Provide feedback through issues and discussions - Follow the Code of Conduct - Help other users when possible</p>"},{"location":"GOVERNACE/#contributors","title":"Contributors","text":"<p>Anyone who contributes to the project (code, documentation, design, support).</p> <p>How to become a Contributor: - Submit at least one merged pull request or significant issue/discussion contribution - Sign the Developer Certificate of Origin (DCO)</p> <p>Responsibilities: - Follow contribution guidelines - Participate constructively in code reviews and discussions - Maintain quality standards</p>"},{"location":"GOVERNACE/#core-contributors","title":"Core Contributors","text":"<p>Contributors who have made sustained, significant contributions over time.</p> <p>How to become a Core Contributor: - 5+ merged pull requests over 3+ months - Demonstrated technical expertise in specific area - Active participation in community discussions - Nominated by a Maintainer and approved by Maintainer team</p> <p>Responsibilities: - Review pull requests - Triage issues - Mentor new contributors - Participate in technical discussions - Help maintain documentation</p> <p>Benefits: - Listed in CONTRIBUTORS.md - \"Core Contributor\" badge - Invitation to Core Contributor meetings (monthly) - Input on roadmap priorities</p>"},{"location":"GOVERNACE/#maintainers","title":"Maintainers","text":"<p>Trusted individuals with commit access and release responsibilities.</p> <p>How to become a Maintainer: - 25+ merged contributions over 6+ months OR significant architectural contributions - Consistent, high-quality code reviews - Demonstrated commitment to community health - Understanding of project architecture and goals - Nominated by existing Maintainer - Approved by 2/3 vote of existing Maintainers</p> <p>Responsibilities: - Review and merge pull requests - Triage and prioritize issues - Make architectural decisions - Release management - Mentor contributors and core contributors - Enforce Code of Conduct - Participate in governance decisions - Available for critical incidents (on-call rotation)</p> <p>Benefits: - Commit access to repositories - Listed in MAINTAINERS.md - Voice in major project decisions - Speaking opportunities representing the project</p>"},{"location":"GOVERNACE/#project-lead","title":"Project Lead","text":"<p>The initial founder(s) who provide overall strategic direction.</p> <p>Responsibilities: - Final decision authority on major disputes (used rarely) - External partnerships and relationships - Fundraising and resource allocation - Project vision and long-term strategy - Maintainer appointments (with Maintainer input)</p> <p>Current Project Lead: [Your Name/Handle]</p>"},{"location":"GOVERNACE/#decision-making-process","title":"Decision-Making Process","text":""},{"location":"GOVERNACE/#minor-decisions","title":"Minor Decisions","text":"<p>Examples: Bug fixes, documentation improvements, small features</p> <p>Process: - Single maintainer approval required for merge - Use \"Lazy Consensus\" - if no objections within 48 hours, proceed - Document in pull request comments</p>"},{"location":"GOVERNACE/#major-decisions","title":"Major Decisions","text":"<p>Examples: New dependencies, architectural changes, breaking changes</p> <p>Process: 1. Create Architectural Decision Record (ADR) or detailed RFC (Request for Comments) 2. Post in GitHub Discussions for community input 3. Allow 7 days for feedback 4. Maintainers discuss in next maintainer meeting 5. Decision requires 2/3 approval from active Maintainers 6. Document decision and rationale publicly</p>"},{"location":"GOVERNACE/#critical-decisions","title":"Critical Decisions","text":"<p>Examples: Licensing changes, project governance changes, Code of Conduct updates</p> <p>Process: 1. Create detailed proposal with rationale 2. Post for public comment (14-day minimum) 3. Discuss in maintainer meeting 4. Decision requires 3/4 approval from Maintainers 5. Project Lead has veto power (used rarely, with public justification)</p>"},{"location":"GOVERNACE/#conflict-resolution","title":"Conflict Resolution","text":""},{"location":"GOVERNACE/#disagreements-on-technical-decisions","title":"Disagreements on Technical Decisions","text":"<ol> <li>Attempt to reach consensus through discussion</li> <li>If consensus fails, maintainers vote (simple majority)</li> <li>If vote is split, Project Lead decides</li> <li>Document decision and dissenting opinions in ADR</li> </ol>"},{"location":"GOVERNACE/#code-of-conduct-violations","title":"Code of Conduct Violations","text":"<ol> <li>Report to conduct@fawkes-project.org or via GitHub private reporting</li> <li>Maintainer team reviews within 48 hours</li> <li>Decision on action (warning, temporary ban, permanent ban) requires 2/3 Maintainer vote</li> <li>Accused party is given opportunity to respond</li> <li>Decision is documented (publicly or privately depending on severity)</li> </ol>"},{"location":"GOVERNACE/#maintainer-conflicts","title":"Maintainer Conflicts","text":"<ol> <li>Attempt direct resolution</li> <li>If unresolved, bring to Maintainer meeting</li> <li>If needed, Project Lead mediates</li> <li>In extreme cases, Maintainer may be removed by 3/4 vote of other Maintainers</li> </ol>"},{"location":"GOVERNACE/#communication-channels","title":"Communication Channels","text":""},{"location":"GOVERNACE/#public-channels","title":"Public Channels","text":"<ul> <li>GitHub Issues: Bug reports, feature requests</li> <li>GitHub Discussions: Questions, ideas, RFCs</li> <li>Slack/Discord: Real-time community chat</li> <li>Mailing List: Announcements, governance discussions</li> <li>Office Hours: Bi-weekly video calls (open to all)</li> </ul>"},{"location":"GOVERNACE/#private-channels","title":"Private Channels","text":"<ul> <li>Maintainer Meetings: Bi-weekly (minutes published publicly)</li> <li>Security Issues: security@fawkes-project.org</li> <li>Code of Conduct Reports: conduct@fawkes-project.org</li> </ul>"},{"location":"GOVERNACE/#contribution-recognition","title":"Contribution Recognition","text":""},{"location":"GOVERNACE/#all-contributors","title":"All Contributors","text":"<ul> <li>Listed in CONTRIBUTORS.md (automated via all-contributors bot)</li> <li>Mentioned in release notes for significant contributions</li> </ul>"},{"location":"GOVERNACE/#monthly-recognition","title":"Monthly Recognition","text":"<ul> <li>\"Contributor of the Month\" highlighted in newsletter/blog</li> <li>Criteria: Impact, quality, community support</li> </ul>"},{"location":"GOVERNACE/#annual-recognition","title":"Annual Recognition","text":"<ul> <li>\"Top Contributors\" featured in end-of-year report</li> <li>Special recognition at community events</li> </ul>"},{"location":"GOVERNACE/#roadmap-planning","title":"Roadmap &amp; Planning","text":""},{"location":"GOVERNACE/#roadmap-process","title":"Roadmap Process","text":"<ol> <li>Maintainers propose high-level roadmap (quarterly)</li> <li>Community provides feedback via GitHub Discussions</li> <li>Maintainers finalize and publish roadmap</li> <li>Progress tracked publicly in GitHub Projects</li> </ol>"},{"location":"GOVERNACE/#sprint-planning","title":"Sprint Planning","text":"<ul> <li>2-week sprint cycles</li> <li>Issues prioritized in maintainer meetings</li> <li>Community can propose priorities via discussions</li> </ul>"},{"location":"GOVERNACE/#release-cadence","title":"Release Cadence","text":"<ul> <li>Minor releases: Monthly (features, improvements)</li> <li>Patch releases: As needed (bug fixes, security)</li> <li>Major releases: Quarterly or as needed (breaking changes)</li> </ul>"},{"location":"GOVERNACE/#modification-of-governance","title":"Modification of Governance","text":"<p>This governance document may be modified through the Critical Decision process: 1. Propose changes via GitHub Discussion 2. 14-day comment period 3. 3/4 Maintainer approval required 4. Project Lead approval required</p>"},{"location":"GOVERNACE/#maintainer-succession","title":"Maintainer Succession","text":""},{"location":"GOVERNACE/#emeritus-status","title":"Emeritus Status","text":"<p>Maintainers who step back from active maintenance: - Retain emeritus maintainer status and recognition - Listed in MAINTAINERS.md with emeritus designation - No commit access or voting rights - Can return to active status via simple process</p>"},{"location":"GOVERNACE/#inactive-maintainers","title":"Inactive Maintainers","text":"<p>If a maintainer is inactive for 6+ months without communication: - Other maintainers attempt to contact - If no response after 30 days, maintainer moved to emeritus - Commit access revoked (can be reinstated)</p>"},{"location":"GOVERNACE/#maintainer-removal","title":"Maintainer Removal","text":"<p>In rare cases of Code of Conduct violations or actions harmful to project: - Requires 3/4 vote of other maintainers - Project Lead can override (with public justification) - Process is documented for transparency</p>"},{"location":"GOVERNACE/#initial-bootstrap-period","title":"Initial Bootstrap Period","text":"<p>For the first 6 months, the Project Lead has broader authority to: - Appoint initial maintainers (minimum 3) - Make rapid decisions to establish project foundations - Adjust governance as needed based on early learnings</p> <p>After 6 months, this bootstrap period ends and full governance takes effect.</p>"},{"location":"GOVERNACE/#credits","title":"Credits","text":"<p>This governance model is inspired by: - CNCF project governance patterns - Apache Software Foundation governance - Kubernetes community governance - Node.js project governance</p> <p>Document Version: 1.0 Last Updated: October 4, 2025 Status: Active Contact: governance@fawkes-project.org</p>"},{"location":"GOVERNACE/#quick-reference","title":"Quick Reference","text":"Action Who Can Do It Approval Needed Submit PR Anyone Maintainer review Merge minor PR Maintainer 1 Maintainer Merge major PR Maintainer 2 Maintainers or ADR Create release Maintainer 1 other Maintainer Modify governance Any contributor 3/4 Maintainers + Project Lead Become Core Contributor Contributors Maintainer nomination + approval Become Maintainer Core Contributors 2/3 Maintainer vote"},{"location":"PRE-COMMIT/","title":"Pre-commit Hooks Setup Guide","text":"<p>This repository uses pre-commit hooks to ensure code quality, security, and compliance with GitOps, Terraform, Kubernetes, and IDP standards.</p>"},{"location":"PRE-COMMIT/#quick-start","title":"Quick Start","text":""},{"location":"PRE-COMMIT/#install-pre-commit-hooks","title":"Install Pre-commit Hooks","text":"<pre><code>make pre-commit-setup\n</code></pre> <p>This will: 1. Install the <code>pre-commit</code> package 2. Install all configured hooks 3. Set up Git hooks to run automatically on commit</p>"},{"location":"PRE-COMMIT/#manual-installation","title":"Manual Installation","text":"<p>If you prefer to install manually:</p> <pre><code>pip install pre-commit\npre-commit install\n</code></pre>"},{"location":"PRE-COMMIT/#what-gets-validated","title":"What Gets Validated?","text":"<p>Our pre-commit hooks validate the following areas:</p>"},{"location":"PRE-COMMIT/#general-code-quality","title":"\ud83d\udd27 General Code Quality","text":"<ul> <li>\u2705 Trailing whitespace removal</li> <li>\u2705 End-of-file fixing</li> <li>\u2705 YAML/JSON syntax validation</li> <li>\u2705 Large file detection</li> <li>\u2705 Merge conflict detection</li> <li>\u2705 Mixed line ending fixes</li> <li>\u2705 Private key detection</li> </ul>"},{"location":"PRE-COMMIT/#documentation","title":"\ud83d\udcdd Documentation","text":"<ul> <li>\u2705 Markdown linting (<code>.markdownlint.json</code>)</li> <li>\u2705 MkDocs build validation</li> <li>\u2705 Documentation link checking</li> </ul>"},{"location":"PRE-COMMIT/#terraform-iac","title":"\ud83c\udfd7\ufe0f Terraform (IaC)","text":"<ul> <li>\u2705 <code>terraform fmt</code> (auto-formatting)</li> <li>\u2705 <code>terraform validate</code> (syntax validation)</li> <li>\u2705 TFLint (static analysis)</li> <li>\u2705 Terraform docs generation</li> <li>\u2705 tfsec (security scanning)</li> </ul>"},{"location":"PRE-COMMIT/#kubernetes-manifests","title":"\u2638\ufe0f Kubernetes Manifests","text":"<ul> <li>\u2705 kubeval (manifest validation)</li> <li>\u2705 kustomize build validation</li> <li>\u2705 Hardcoded secret detection</li> <li>\u2705 Helm chart linting</li> </ul>"},{"location":"PRE-COMMIT/#gitops","title":"\ud83d\ude80 GitOps","text":"<ul> <li>\u2705 ArgoCD application validation</li> <li>\u2705 Kustomization file validation</li> <li>\u2705 GitOps best practices</li> </ul>"},{"location":"PRE-COMMIT/#idp-components","title":"\ud83c\udfaf IDP Components","text":"<ul> <li>\u2705 Backstage catalog validation</li> <li>\u2705 Helm values validation</li> <li>\u2705 Platform component configuration</li> </ul>"},{"location":"PRE-COMMIT/#security","title":"\ud83d\udd12 Security","text":"<ul> <li>\u2705 Gitleaks (secret detection)</li> <li>\u2705 detect-secrets (secret baseline)</li> <li>\u2705 Private key detection</li> <li>\u2705 tfsec (Terraform security)</li> </ul>"},{"location":"PRE-COMMIT/#python","title":"\ud83d\udc0d Python","text":"<ul> <li>\u2705 Black formatting</li> <li>\u2705 Flake8 linting</li> <li>\u2705 Type checking readiness</li> </ul>"},{"location":"PRE-COMMIT/#shell-scripts","title":"\ud83d\udc1a Shell Scripts","text":"<ul> <li>\u2705 ShellCheck validation</li> </ul>"},{"location":"PRE-COMMIT/#running-pre-commit-hooks","title":"Running Pre-commit Hooks","text":""},{"location":"PRE-COMMIT/#automatic-on-commit","title":"Automatic (on commit)","text":"<p>Once installed, hooks run automatically when you commit:</p> <pre><code>git add .\ngit commit -m \"Your commit message\"\n# Hooks run automatically\n</code></pre>"},{"location":"PRE-COMMIT/#manual-all-files","title":"Manual (all files)","text":"<p>Run hooks on all files in the repository:</p> <pre><code>pre-commit run --all-files\n</code></pre>"},{"location":"PRE-COMMIT/#manual-specific-files","title":"Manual (specific files)","text":"<p>Run hooks on specific files:</p> <pre><code>pre-commit run --files infra/aws/main.tf\n</code></pre>"},{"location":"PRE-COMMIT/#manual-specific-hook","title":"Manual (specific hook)","text":"<p>Run a specific hook:</p> <pre><code>pre-commit run terraform_fmt --all-files\npre-commit run kubeval --all-files\n</code></pre>"},{"location":"PRE-COMMIT/#skip-hooks-emergency-only","title":"Skip Hooks (emergency only)","text":"<p>If you need to skip hooks temporarily (not recommended):</p> <pre><code>git commit --no-verify -m \"Emergency fix\"\n</code></pre>"},{"location":"PRE-COMMIT/#tool-installation","title":"Tool Installation","text":"<p>Some hooks require external tools. Here's how to install them:</p>"},{"location":"PRE-COMMIT/#terraform-tools","title":"Terraform Tools","text":"<pre><code># Terraform\nbrew install terraform  # macOS\n# or download from https://terraform.io\n\n# TFLint\nbrew install tflint  # macOS\n# or download from https://github.com/terraform-linters/tflint\n\n# terraform-docs\nbrew install terraform-docs  # macOS\n\n# tfsec\nbrew install tfsec  # macOS\n</code></pre>"},{"location":"PRE-COMMIT/#kubernetes-tools","title":"Kubernetes Tools","text":"<pre><code># kubectl\nbrew install kubectl  # macOS\n\n# kubeval\nbrew install kubeval  # macOS\n\n# kustomize\nbrew install kustomize  # macOS\n\n# helm\nbrew install helm  # macOS\n\n# yq (YAML processor)\nbrew install yq  # macOS\n</code></pre>"},{"location":"PRE-COMMIT/#argocd-tools","title":"ArgoCD Tools","text":"<pre><code># ArgoCD CLI\nbrew install argocd  # macOS\n# or download from https://argo-cd.readthedocs.io/\n</code></pre>"},{"location":"PRE-COMMIT/#mkdocs-documentation","title":"MkDocs (Documentation)","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"PRE-COMMIT/#notes","title":"Notes","text":"<ul> <li>\u26a0\ufe0f Hooks that require unavailable tools will show warnings but won't fail</li> <li>\u2705 GitHub Actions runs all hooks with all tools installed</li> <li>\ud83d\udca1 For the best experience, install all tools locally</li> </ul>"},{"location":"PRE-COMMIT/#configuration-files","title":"Configuration Files","text":"File Purpose <code>.pre-commit-config.yaml</code> Main pre-commit configuration <code>.tflint.hcl</code> TFLint rules and plugin configuration <code>.terraform-docs.yml</code> Terraform documentation generation <code>.secrets.baseline</code> detect-secrets baseline (known false positives) <code>.yamllint</code> YAML linting rules <code>.markdownlint.json</code> Markdown linting rules"},{"location":"PRE-COMMIT/#updating-hooks","title":"Updating Hooks","text":"<p>Pre-commit hooks are versioned. To update to the latest versions:</p> <pre><code>pre-commit autoupdate\n</code></pre> <p>This updates <code>.pre-commit-config.yaml</code> with the latest hook versions.</p>"},{"location":"PRE-COMMIT/#troubleshooting","title":"Troubleshooting","text":""},{"location":"PRE-COMMIT/#hook-fails-with-command-not-found","title":"Hook fails with \"command not found\"","text":"<p>Install the required tool (see Tool Installation section).</p>"},{"location":"PRE-COMMIT/#hook-fails-on-valid-file","title":"Hook fails on valid file","text":"<ul> <li>Check if the file should be excluded in <code>.pre-commit-config.yaml</code></li> <li>Add to baseline if it's a false positive (e.g., <code>.secrets.baseline</code>)</li> </ul>"},{"location":"PRE-COMMIT/#hooks-are-too-slow","title":"Hooks are too slow","text":"<ul> <li>Use <code>--hook-stage manual</code> for expensive hooks</li> <li>Run specific hooks instead of all: <code>pre-commit run hook-name</code></li> </ul>"},{"location":"PRE-COMMIT/#reset-hooks","title":"Reset hooks","text":"<pre><code>pre-commit clean\npre-commit install --install-hooks\n</code></pre>"},{"location":"PRE-COMMIT/#disable-a-specific-hook","title":"Disable a specific hook","text":"<p>Edit <code>.pre-commit-config.yaml</code> and add <code>stages: [manual]</code> to the hook.</p>"},{"location":"PRE-COMMIT/#github-actions-integration","title":"GitHub Actions Integration","text":"<p>Pre-commit hooks run automatically in CI/CD via <code>.github/workflows/pre-commit.yml</code>:</p> <ul> <li>\u2705 Runs on every pull request</li> <li>\u2705 Runs on push to main/develop</li> <li>\u2705 Comments on PR if validation fails</li> <li>\u2705 All tools pre-installed in CI environment</li> </ul>"},{"location":"PRE-COMMIT/#best-practices","title":"Best Practices","text":"<ol> <li>Run hooks locally before pushing - Catch issues early</li> <li>Install all tools - Get the full validation experience</li> <li>Keep hooks updated - Run <code>pre-commit autoupdate</code> monthly</li> <li>Don't skip hooks - They exist for good reasons</li> <li>Fix root causes - Don't just work around hook failures</li> </ol>"},{"location":"PRE-COMMIT/#contributing","title":"Contributing","text":"<p>When adding new hooks:</p> <ol> <li>Add to <code>.pre-commit-config.yaml</code></li> <li>Test with <code>pre-commit run --all-files</code></li> <li>Update this README</li> <li>Ensure CI job installs required tools</li> </ol>"},{"location":"PRE-COMMIT/#support","title":"Support","text":"<ul> <li>\ud83d\udcd6 Pre-commit documentation</li> <li>\ud83d\udc1b Report issues</li> <li>\ud83d\udcac Community discussions</li> </ul> <p>Remember: Pre-commit hooks help maintain code quality and security. They're here to help, not hinder! \ud83d\ude80</p>"},{"location":"PROJECT_STATUS/","title":"Fawkes Project Status","text":"<p>Purpose: Track progress across development sessions and provide context for new conversations</p> <p>Last Updated: October 7, 2025 Current Phase: Foundation (Sprint 01, Week 1) Target MVP Date: December 31, 2025</p>"},{"location":"PROJECT_STATUS/#quick-status-overview","title":"\ud83d\udcca Quick Status Overview","text":"Category Status Progress Notes Documentation \ud83d\udfe2 On Track 60% Core docs complete, module content needed Architecture \ud83d\udfe2 On Track 70% Main architecture done, integration updates needed Dojo System \ud83d\udfe1 In Progress 40% Architecture complete, content creation started Infrastructure \ud83d\udd34 Not Started 0% Waiting for AWS credits approval Community Setup \ud83d\udfe1 In Progress 30% Planning complete, deployment pending CI/CD \ud83d\udd34 Not Started 0% Planned for Week 2 <p>Legend: \ud83d\udfe2 On Track | \ud83d\udfe1 In Progress | \ud83d\udd34 Blocked/Delayed | \u26ab Not Started</p>"},{"location":"PROJECT_STATUS/#current-sprint-sprint-01-oct-7-18-2025","title":"\ud83c\udfaf Current Sprint: Sprint 01 (Oct 7-18, 2025)","text":"<p>Sprint Goal: Establish project governance, documentation, and development infrastructure</p> <p>Sprint Progress: 45% complete (Day 2 of 10)</p>"},{"location":"PROJECT_STATUS/#this-weeks-focus-week-1-oct-7-11","title":"This Week's Focus (Week 1: Oct 7-11)","text":"<ul> <li>[x] Complete governance documents</li> <li>[x] Design dojo learning architecture</li> <li>[x] Select collaboration platform (Mattermost)</li> <li>[ ] Complete all ADRs (3 of 5 done)</li> <li>[ ] Set up communication infrastructure</li> <li>[ ] Begin first module content</li> </ul>"},{"location":"PROJECT_STATUS/#completed-work","title":"\u2705 Completed Work","text":""},{"location":"PROJECT_STATUS/#day-1-monday-october-7-2025","title":"Day 1 - Monday, October 7, 2025","text":"<p>Focus: Project Foundation &amp; Governance</p> <ul> <li>[x] GOVERNANCE.md - Complete governance framework with 5 roles</li> <li>[x] CODE_OF_CONDUCT.md - Contributor Covenant v2.1 adapted</li> <li>[x] PROJECT_CHARTER.md - Vision, mission, success criteria, risk register</li> <li>[x] Architecture Overview - <code>/docs/architecture.md</code> with C4 diagrams</li> <li>[x] ADR-001 - Kubernetes as container orchestration platform</li> <li>[x] GitHub Templates - Issue templates (4) and PR template</li> <li>[x] GitHub Labels - 45+ labels across 10 categories</li> <li>[x] Sprint 01 Plan - Detailed 2-week sprint plan</li> </ul> <p>Artifacts Created: 8 major documents, ~50 pages</p>"},{"location":"PROJECT_STATUS/#day-2-tuesday-october-7-2025","title":"Day 2 - Tuesday, October 7, 2025","text":"<p>Focus: Dojo Learning System &amp; Product Delivery Enhancement</p> <ul> <li>[x] Dojo Architecture - <code>/docs/dojo/DOJO_ARCHITECTURE.md</code></li> <li>Complete belt progression system (White \u2192 Black)</li> <li>20 modules mapped to 24 DORA capabilities</li> <li>Hands-on lab environment design</li> <li>Assessment and certification framework</li> <li>Platform Engineering University integration strategy</li> <li>[x] ADR-007 - Mattermost for team collaboration</li> <li>Compared 6 alternatives (Slack, Discord, Rocket.Chat, Teams, Matrix, Zulip)</li> <li>Integration architecture defined</li> <li>Channel structure designed</li> <li>[x] Day 2 Task Plan - Detailed task breakdown with focus on dojo</li> </ul> <p>Artifacts Created: 3 major documents, ~20 pages</p>"},{"location":"PROJECT_STATUS/#in-progress-active-work","title":"\ud83d\udea7 In Progress (Active Work)","text":""},{"location":"PROJECT_STATUS/#current-tasks-pick-up-here-in-next-session","title":"Current Tasks (Pick up here in next session)","text":""},{"location":"PROJECT_STATUS/#1-adr-008-focalboard-for-project-management","title":"1. ADR-008: Focalboard for Project Management","text":"<p>Priority: P0 (Critical) Estimated Time: 1.5 hours Status: Not Started Dependencies: ADR-007 completed \u2705</p> <p>Scope: - Document need for integrated project management - Compare alternatives: Focalboard vs. Taiga vs. Plane vs. Jira - Explain Mattermost integration benefits - Document dojo curriculum tracking use case - Define team roadmap and sprint planning use cases</p> <p>Context for Next Session: <pre><code>Create ADR-008 following the same format as ADR-007 (Mattermost).\nFocus on:\n1. Native Mattermost integration (Focalboard built-in)\n2. Use cases: dojo learner tracking, sprint planning, roadmaps\n3. Open source alignment\n4. Cost effectiveness vs. commercial alternatives\n</code></pre></p>"},{"location":"PROJECT_STATUS/#2-architecture-document-updates","title":"2. Architecture Document Updates","text":"<p>Priority: P1 (High) Estimated Time: 1 hour Status: Not Started Dependencies: ADR-007, ADR-008</p> <p>Scope: - Add Mattermost to component overview - Add Focalboard to component overview - Update integration patterns section - Add dojo lab environment to architecture diagrams - Update technology stack table - Create new C4 diagram showing complete product delivery platform</p> <p>Context for Next Session: <pre><code>Update /docs/architecture.md to include:\n- Mattermost (team collaboration)\n- Focalboard (project management)\n- Dojo Lab Environment (learning infrastructure)\n\nAdd sections:\n- Component Overview: Mattermost &amp; Focalboard\n- Integration Patterns: Chat notifications, ChatOps\n- Dojo Infrastructure: Lab provisioning, validation\n</code></pre></p>"},{"location":"PROJECT_STATUS/#3-module-1-content-internal-delivery-platforms-what-and-why","title":"3. Module 1 Content: \"Internal Delivery Platforms - What and Why\"","text":"<p>Priority: P1 (High) Estimated Time: 2 hours Status: Not Started Dependencies: Dojo architecture complete \u2705</p> <p>Scope: - Write complete module (4 sections, 60 minutes total) - Section 1: What is an IDP? (15 min) - Section 2: DORA Research Foundation (20 min) - Section 3: Fawkes Platform Tour (20 min) - Section 4: Your First Deployment (20 min + hands-on) - Include learning objectives, quiz questions, lab instructions</p> <p>Context for Next Session: <pre><code>Create Module 1 content following structure in DOJO_ARCHITECTURE.md.\nTarget: 60-minute module for absolute beginners.\nInclude: video script, written content, hands-on lab, 10 quiz questions.\nMake it engaging and practical.\n</code></pre></p>"},{"location":"PROJECT_STATUS/#4-readmemd-enhancement","title":"4. README.md Enhancement","text":"<p>Priority: P1 (High) Estimated Time: 1 hour Status: Not Started</p> <p>Scope: - Rewrite opening to emphasize dojo learning + product delivery - Add \"\ud83c\udf93 Learn While You Build\" section - Add \"\ud83d\ude80 Complete Product Delivery Platform\" section - Include belt progression visual - Update feature list with Mattermost, Focalboard, Dojo - Add \"Start Learning\" CTA</p> <p>Context for Next Session: <pre><code>Update README.md to prominently feature:\n1. Dojo learning system (belt progression)\n2. Complete product delivery (not just infrastructure)\n3. Mattermost + Focalboard integration\n4. DORA metrics automation\n\nMake it compelling for first-time visitors.\n</code></pre></p>"},{"location":"PROJECT_STATUS/#backlog-upcoming-work","title":"\ud83d\udccb Backlog (Upcoming Work)","text":""},{"location":"PROJECT_STATUS/#sprint-01-remaining-tasks","title":"Sprint 01 Remaining Tasks","text":""},{"location":"PROJECT_STATUS/#week-1-oct-7-11-remaining","title":"Week 1 (Oct 7-11) - Remaining","text":"<ul> <li>[ ] ADR-002: Backstage for Developer Portal (1.5 hours)</li> <li>[ ] ADR-003: ArgoCD for GitOps (1.5 hours)</li> <li>[ ] ADR-004: Jenkins for CI/CD (1.5 hours)</li> <li>[ ] ADR-005: Terraform vs. Pulumi (1.5 hours)</li> <li>[ ] ADR-006: PostgreSQL for Data Persistence (1 hour)</li> <li>[ ] Set up Mattermost workspace (2 hours)</li> <li>[ ] Enable GitHub Discussions (30 min)</li> <li>[ ] Create community calendar (30 min)</li> <li>[ ] Development environment documentation (1 hour)</li> </ul>"},{"location":"PROJECT_STATUS/#week-2-oct-14-18","title":"Week 2 (Oct 14-18)","text":"<ul> <li>[ ] Backstage deployment planning</li> <li>[ ] Jenkins deployment planning</li> <li>[ ] First module content finalization</li> <li>[ ] Lab environment setup (if AWS credits approved)</li> <li>[ ] Launch preparation materials</li> <li>[ ] Sprint 01 review and retrospective</li> </ul>"},{"location":"PROJECT_STATUS/#future-sprints","title":"Future Sprints","text":""},{"location":"PROJECT_STATUS/#sprint-02-oct-21-nov-1-core-platform-infrastructure","title":"Sprint 02 (Oct 21 - Nov 1): Core Platform Infrastructure","text":"<ul> <li>[ ] Deploy Backstage developer portal</li> <li>[ ] Create 3 software templates (Java, Python, Node.js)</li> <li>[ ] Deploy Jenkins with Kubernetes plugin</li> <li>[ ] Create golden path Jenkinsfiles</li> <li>[ ] Deploy Mattermost</li> <li>[ ] Deploy ArgoCD</li> <li>[ ] Configure GitOps workflows</li> </ul>"},{"location":"PROJECT_STATUS/#sprint-03-nov-4-15-observability-dora-metrics","title":"Sprint 03 (Nov 4-15): Observability &amp; DORA Metrics","text":"<ul> <li>[ ] Deploy Prometheus + Grafana</li> <li>[ ] Configure OpenTelemetry</li> <li>[ ] Deploy OpenSearch</li> <li>[ ] Build DORA metrics collection service</li> <li>[ ] Create DORA dashboards</li> <li>[ ] Deploy Spinnaker</li> </ul>"},{"location":"PROJECT_STATUS/#sprint-04-nov-18-29-dojo-launch","title":"Sprint 04 (Nov 18-29): Dojo Launch","text":"<ul> <li>[ ] Complete all belt curricula</li> <li>[ ] Build Backstage dojo plugin</li> <li>[ ] Set up lab environment</li> <li>[ ] Create lab validation system</li> <li>[ ] Deploy Focalboard</li> <li>[ ] Launch beta testing</li> </ul>"},{"location":"PROJECT_STATUS/#key-decisions-made","title":"\ud83d\udd11 Key Decisions Made","text":"Date Decision Documented In Rationale Oct 7 Kubernetes for orchestration ADR-001 Industry standard, CNCF ecosystem, multi-cloud Oct 7 Mattermost for collaboration ADR-007 Open source, self-hosted, Focalboard integration Oct 7 Belt-based dojo system Dojo Architecture Clear progression, gamification, skill validation Oct 7 MIT License Project Charter Maximum openness, minimal restrictions"},{"location":"PROJECT_STATUS/#pending-decisions","title":"Pending Decisions","text":"<ul> <li>[ ] Slack vs. Discord for initial community (leaning toward Mattermost only)</li> <li>[ ] Backstage theme and branding</li> <li>[ ] Dogfooding environment cloud provider (waiting on AWS credits)</li> <li>[ ] First external beta testers (target: 3-5 organizations)</li> </ul>"},{"location":"PROJECT_STATUS/#blockers-issues","title":"\ud83d\udeab Blockers &amp; Issues","text":""},{"location":"PROJECT_STATUS/#active-blockers","title":"Active Blockers","text":"<ol> <li>AWS Credits Approval (Blocker ID: B-001)</li> <li>Impact: Cannot provision dogfooding environment</li> <li>Workaround: Use personal AWS account with minimal resources</li> <li>Status: Application submitted Oct 6, waiting for approval</li> <li>ETA: 7-14 days</li> <li>Owner: Project Lead</li> </ol>"},{"location":"PROJECT_STATUS/#resolved-blockers","title":"Resolved Blockers","text":"<ul> <li>None yet</li> </ul>"},{"location":"PROJECT_STATUS/#known-issues","title":"Known Issues","text":"<ol> <li>Issue: No CI/CD for platform repo yet</li> <li>Impact: No automated validation of Terraform, no branch protection</li> <li>Priority: P1</li> <li> <p>Planned Resolution: Sprint 01, Week 1</p> </li> <li> <p>Issue: Dojo content creation resource intensive</p> </li> <li>Impact: May take longer than estimated to create 20 modules</li> <li>Priority: P2</li> <li>Mitigation: Start with White Belt only for MVP, crowdsource community content</li> </ol>"},{"location":"PROJECT_STATUS/#metrics-progress","title":"\ud83d\udcca Metrics &amp; Progress","text":""},{"location":"PROJECT_STATUS/#documentation-metrics","title":"Documentation Metrics","text":"<ul> <li>Total Documents: 11 completed</li> <li>Total Pages: ~70 pages</li> <li>ADRs Completed: 2 of 8 planned (25%)</li> <li>Dojo Modules: 0 of 20 completed (0%)</li> <li>Coverage: Governance 100%, Architecture 70%, Dojo 40%</li> </ul>"},{"location":"PROJECT_STATUS/#sprint-progress","title":"Sprint Progress","text":"<ul> <li>Sprint 01 Velocity: TBD (first sprint)</li> <li>Stories Completed: 8 of 18 (44%)</li> <li>Days Elapsed: 2 of 10 (20%)</li> <li>On Track: Yes (ahead of schedule on docs)</li> </ul>"},{"location":"PROJECT_STATUS/#community-metrics","title":"Community Metrics","text":"<ul> <li>GitHub Stars: [TBD - not launched yet]</li> <li>Contributors: 1 (project lead only)</li> <li>Community Members: 0 (no community infrastructure yet)</li> <li>Dojo Learners: 0 (dojo not launched)</li> </ul>"},{"location":"PROJECT_STATUS/#dojo-system-status","title":"\ud83c\udf93 Dojo System Status","text":""},{"location":"PROJECT_STATUS/#belt-curricula-status","title":"Belt Curricula Status","text":"<ul> <li>\ud83e\udd4b White Belt: Architecture complete, content 0%</li> <li>\ud83d\udfe1 Yellow Belt: Architecture complete, content 0%</li> <li>\ud83d\udfe2 Green Belt: Architecture complete, content 0%</li> <li>\ud83d\udfe4 Brown Belt: Architecture complete, content 0%</li> <li>\u26ab Black Belt: Architecture complete, content 0%</li> </ul>"},{"location":"PROJECT_STATUS/#next-dojo-milestones","title":"Next Dojo Milestones","text":"<ol> <li>Module 1 Content (This week) - First complete module</li> <li>Lab Environment (Sprint 02) - Provision first lab namespaces</li> <li>White Belt Beta (Sprint 04) - 5 beta testers complete White Belt</li> <li>Full Launch (Month 4) - All belts available</li> </ol>"},{"location":"PROJECT_STATUS/#ideas-future-considerations","title":"\ud83d\udca1 Ideas &amp; Future Considerations","text":""},{"location":"PROJECT_STATUS/#captured-ideas-not-yet-prioritized","title":"Captured Ideas (Not Yet Prioritized)","text":"<ul> <li>[ ] Idea: Gamification - Leaderboards for dojo completion times</li> <li>[ ] Idea: Cohort-based learning - Start cohorts monthly</li> <li>[ ] Idea: Live workshops - Monthly deep-dive sessions</li> <li>[ ] Idea: Dojo marketplace - Community-contributed modules</li> <li>[ ] Idea: Integration with LinkedIn Learning or Udemy</li> <li>[ ] Idea: Corporate training packages</li> <li>[ ] Idea: Certification exam centers (Pearson VUE partnership)</li> <li>[ ] Idea: Dojo mentorship program - Black Belts mentor White Belts</li> </ul>"},{"location":"PROJECT_STATUS/#research-needed","title":"Research Needed","text":"<ul> <li>[ ] Best practices for Kubernetes lab environment isolation</li> <li>[ ] Auto-grading systems for infrastructure labs</li> <li>[ ] Video hosting options (YouTube vs. self-hosted)</li> <li>[ ] Learning analytics platforms</li> </ul>"},{"location":"PROJECT_STATUS/#quick-reference","title":"\ud83d\udcde Quick Reference","text":""},{"location":"PROJECT_STATUS/#important-links","title":"Important Links","text":"<ul> <li>GitHub Repo: https://github.com/paruff/fawkes/</li> <li>Project Charter: <code>/PROJECT_CHARTER.md</code></li> <li>Architecture: <code>/docs/architecture.md</code></li> <li>Dojo Docs: <code>/docs/dojo/DOJO_ARCHITECTURE.md</code></li> <li>Sprint Plan: <code>/docs/sprints/sprint-01-plan.md</code></li> </ul>"},{"location":"PROJECT_STATUS/#key-files-to-reference","title":"Key Files to Reference","text":"<ul> <li><code>/GOVERNANCE.md</code> - Decision-making process</li> <li><code>/CODE_OF_CONDUCT.md</code> - Community standards</li> <li><code>/docs/adr/</code> - All architectural decisions</li> <li><code>/docs/dojo/</code> - Learning system documentation</li> </ul>"},{"location":"PROJECT_STATUS/#team-contacts","title":"Team Contacts","text":"<ul> <li>Project Lead: [Your Name/Email]</li> <li>Platform Architect: [TBD]</li> <li>Learning Lead: [TBD]</li> <li>DevOps Engineer: [TBD]</li> <li>Community Manager: [TBD]</li> </ul>"},{"location":"PROJECT_STATUS/#how-to-use-this-document","title":"\ud83d\udd04 How to Use This Document","text":""},{"location":"PROJECT_STATUS/#when-starting-a-new-conversation","title":"When Starting a New Conversation","text":"<p>Copy this section to provide context:</p> <pre><code>I'm continuing development of Fawkes, an Internal Product Delivery\nPlatform with integrated dojo-style learning.\n\nGitHub: https://github.com/paruff/fawkes/\n\nCurrent Status (see PROJECT_STATUS.md):\n- Phase: Sprint 01, Day 2\n- Last work: [describe your last session]\n- Next task: [what you want to work on]\n\nCompleted:\n- Governance docs, architecture, dojo design\n- ADR-001 (Kubernetes), ADR-007 (Mattermost)\n\nPlease help me: [specific request]\n</code></pre>"},{"location":"PROJECT_STATUS/#at-end-of-each-session","title":"At End of Each Session","text":"<ol> <li>Update Last Updated date at top</li> <li>Move completed items from \"In Progress\" to \"Completed Work\"</li> <li>Add any new blockers or decisions</li> <li>Update metrics</li> <li>Add notes about what to pick up next time</li> </ol>"},{"location":"PROJECT_STATUS/#weekly-review","title":"Weekly Review","text":"<ul> <li>Review progress against sprint goals</li> <li>Update metrics</li> <li>Reassess priorities</li> <li>Identify blockers</li> <li>Plan next week</li> </ul>"},{"location":"PROJECT_STATUS/#session-notes","title":"\ud83d\udcdd Session Notes","text":""},{"location":"PROJECT_STATUS/#session-october-7-2025-morning","title":"Session: October 7, 2025 - Morning","text":"<p>Duration: 3 hours Focus: Dojo architecture and collaboration platform selection</p> <p>Accomplished: - Completed dojo learning architecture document (15,000 words) - Defined 5-belt progression system - Mapped 20 modules to 24 DORA capabilities - Completed ADR-007 for Mattermost selection - Designed lab environment architecture</p> <p>Key Insights: - Dojo system is major differentiator - emphasize in all communications - Mattermost + Focalboard integration creates seamless workflow - Platform Engineering University partnership is strategic advantage</p> <p>Next Session Goals: - Complete ADR-008 (Focalboard) - Update architecture doc with new components - Begin Module 1 content creation</p> <p>Blockers Identified: None</p>"},{"location":"PROJECT_STATUS/#session-next-session-date-time","title":"Session: [Next Session Date] - [Time]","text":"<p>Duration: [hours] Focus: [what you're working on]</p> <p>Accomplished: - [List completed work]</p> <p>Key Insights: - [Any important realizations]</p> <p>Next Session Goals: - [What to tackle next]</p> <p>Blockers Identified: [Any issues]</p>"},{"location":"PROJECT_STATUS/#success-criteria-tracking","title":"\ud83c\udfaf Success Criteria Tracking","text":""},{"location":"PROJECT_STATUS/#sprint-01-success-criteria","title":"Sprint 01 Success Criteria","text":"<ul> <li>[ ] All governance documents published and accessible</li> <li>[ ] Development environment fully functional</li> <li>[ ] At least 3 ADRs completed (2 of 3 \u2705)</li> <li>[ ] Architecture documentation 80%+ complete (70% currently)</li> <li>[ ] First community member joins (outside core team)</li> </ul>"},{"location":"PROJECT_STATUS/#mvp-success-criteria-12-weeks","title":"MVP Success Criteria (12 weeks)","text":"<ul> <li>[ ] 2-3 early adopter teams successfully deploy applications</li> <li>[ ] All four DORA metrics automatically collected and visualized</li> <li>[ ] 5+ external contributors make meaningful contributions</li> <li>[ ] Core documentation complete with 90%+ coverage</li> <li>[ ] Platform Engineering University certification integration announced</li> <li>[ ] &lt;4 hours from cluster provision to first application deployment</li> </ul> <p>Document Version: 1.0 Template Last Updated: October 7, 2025 Maintained By: Project Lead</p>"},{"location":"PROJECT_STATUS/#template-usage-instructions","title":"Template Usage Instructions","text":"<ol> <li>Update after every work session (even 30 minutes)</li> <li>Keep \"In Progress\" section current - this is your handoff to next session</li> <li>Add context notes - future you will thank you</li> <li>Track decisions - even small ones can be important later</li> <li>Be honest about blockers - document them so they can be resolved</li> <li>Celebrate progress - mark completions, note achievements</li> </ol> <p>Remember: This document is FOR YOU to maintain continuity across conversations and development sessions!</p>"},{"location":"architecture/","title":"Fawkes Architecture Overview","text":""},{"location":"architecture/#document-information","title":"Document Information","text":"<p>Version: 1.0 Last Updated: October 4, 2025 Status: Living Document Audience: Contributors, Adopters, Platform Engineers</p>"},{"location":"architecture/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Architectural Principles</li> <li>High-Level Architecture</li> <li>Component Overview</li> <li>Data Flow</li> <li>Integration Patterns</li> <li>Security Architecture</li> <li>Multi-Cloud Strategy</li> <li>Scalability &amp; Performance</li> <li>Technology Stack</li> <li>Future Architecture</li> </ol>"},{"location":"architecture/#introduction","title":"Introduction","text":"<p>Fawkes is an opinionated Internal Delivery Platform (IDP) designed to accelerate software delivery through automation, observability, and continuous learning. This document describes the architectural design, component interactions, and key technical decisions.</p>"},{"location":"architecture/#architectural-context","title":"Architectural Context","text":"<p>Fawkes sits at the intersection of: - Platform Engineering: Providing self-service infrastructure and tooling - DevSecOps: Integrating security throughout the delivery pipeline - DORA Research: Optimizing for the four key metrics - GitOps: Declarative, version-controlled infrastructure and applications</p>"},{"location":"architecture/#architectural-principles","title":"Architectural Principles","text":""},{"location":"architecture/#1-developer-experience-first","title":"1. Developer Experience First","text":"<ul> <li>Self-service capabilities over ticket-driven workflows</li> <li>Golden paths for common scenarios</li> <li>Single pane of glass (Backstage) for discovery and management</li> <li>Fast feedback loops (build, test, deploy in minutes, not hours)</li> </ul>"},{"location":"architecture/#2-observable-by-default","title":"2. Observable by Default","text":"<ul> <li>Every component exposes metrics, logs, and traces</li> <li>DORA metrics collected automatically</li> <li>Distributed tracing for end-to-end visibility</li> <li>Real-time dashboards for platform health</li> </ul>"},{"location":"architecture/#3-secure-by-design","title":"3. Secure by Design","text":"<ul> <li>Security scanning at every stage (code, dependencies, containers, runtime)</li> <li>Policy-as-code for compliance automation</li> <li>Least privilege access controls</li> <li>Secrets management with rotation</li> <li>Zero-trust networking (roadmap)</li> </ul>"},{"location":"architecture/#4-declarative-gitops-driven","title":"4. Declarative &amp; GitOps-Driven","text":"<ul> <li>All configuration stored in Git</li> <li>Automated reconciliation of desired state</li> <li>Audit trail through Git history</li> <li>Easy rollback capabilities</li> </ul>"},{"location":"architecture/#5-cloud-agnostic-with-pragmatic-defaults","title":"5. Cloud-Agnostic with Pragmatic Defaults","text":"<ul> <li>Multi-cloud support through abstraction layers</li> <li>Provider-specific optimizations where needed</li> <li>Start with AWS, expand to Azure/GCP</li> <li>On-premises capable (though cloud-first)</li> </ul>"},{"location":"architecture/#6-extensible-pluggable","title":"6. Extensible &amp; Pluggable","text":"<ul> <li>Plugin architecture for custom extensions</li> <li>Well-defined APIs for integration</li> <li>Modular components that can be adopted incrementally</li> <li>Community contributions encouraged</li> </ul>"},{"location":"architecture/#7-metrics-driven-improvement","title":"7. Metrics-Driven Improvement","text":"<ul> <li>Measure everything</li> <li>DORA metrics as first-class citizens</li> <li>A/B testing for platform changes</li> <li>Continuous optimization based on data</li> </ul>"},{"location":"architecture/#high-level-architecture","title":"High-Level Architecture","text":""},{"location":"architecture/#c4-model-context-diagram","title":"C4 Model - Context Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        External Systems                          \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502  \u2502  GitHub  \u2502  \u2502  Cloud   \u2502  \u2502Container \u2502  \u2502  Secrets \u2502        \u2502\n\u2502  \u2502  (SCM)   \u2502  \u2502 Provider \u2502  \u2502 Registry \u2502  \u2502  Manager \u2502        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Fawkes Platform                            \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502              Developer Portal (Backstage)                  \u2502  \u2502\n\u2502  \u2502         Self-Service | Catalog | Templates | Docs         \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                    \u2502                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502   CI/CD     \u2502   GitOps    \u2502Observability\u2502  Security   \u2502     \u2502\n\u2502  \u2502  (Jenkins)  \u2502  (ArgoCD)   \u2502(Prom/Graf)  \u2502(SonarQube)  \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                    \u2502                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502      Infrastructure Layer (Kubernetes + IaC)              \u2502  \u2502\n\u2502  \u2502            Terraform | Crossplane | Helm                  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Application Teams                            \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502  \u2502  Team A  \u2502  \u2502  Team B  \u2502  \u2502  Team C  \u2502  \u2502  Team D  \u2502        \u2502\n\u2502  \u2502  Apps    \u2502  \u2502  Apps    \u2502  \u2502  Apps    \u2502  \u2502  Apps    \u2502        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#key-boundaries","title":"Key Boundaries","text":"<p>North: Developer interaction through Backstage portal and Git South: Kubernetes clusters and cloud infrastructure East/West: External systems and services Core: Platform services providing CI/CD, GitOps, observability, security</p>"},{"location":"architecture/#developer-experience-layer","title":"Developer Experience Layer","text":"<p>The Developer Experience (DX) Layer is the primary interface between developers and the Fawkes platform. It provides a unified, authenticated interface for self-service capabilities, monitoring, and service discovery.</p>"},{"location":"architecture/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Developer Experience Layer                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                        Backstage Developer Portal                       \u2502 \u2502\n\u2502  \u2502                                                                          \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502   Service    \u2502  \u2502   Software   \u2502  \u2502   TechDocs   \u2502  \u2502   Search   \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502   Catalog    \u2502  \u2502  Templates   \u2502  \u2502              \u2502  \u2502            \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2502                                                                          \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502   Plugins    \u2502  \u2502     Auth     \u2502  \u2502  Kubernetes  \u2502  \u2502   Dojo     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502   (CI/CD)    \u2502  \u2502   (OAuth)    \u2502  \u2502   Status     \u2502  \u2502  Learning  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                           PostgreSQL (HA)                               \u2502 \u2502\n\u2502  \u2502                    CloudNativePG: db-backstage-dev                      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                 \u2502                     \u2502                     \u2502\n                 \u25bc                     \u25bc                     \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502   Jenkins   \u2502       \u2502   ArgoCD    \u2502       \u2502   GitHub    \u2502\n         \u2502   (CI/CD)   \u2502       \u2502   (GitOps)  \u2502       \u2502   (OAuth)   \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#key-components","title":"Key Components","text":"Component Purpose Technology Backstage Portal Single pane of glass for developers TypeScript/React Service Catalog Inventory of services, APIs, resources Backstage Core Software Templates Golden paths for new services Backstage Scaffolder TechDocs Documentation as code MkDocs + Backstage Authentication SSO via OAuth 2.0/OIDC GitHub OAuth PostgreSQL Catalog and session storage CloudNativePG (HA)"},{"location":"architecture/#authentication-flow","title":"Authentication Flow","text":"<pre><code>Developer Access Request\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Ingress Controller                      \u2502\n\u2502                   (HTTPS: backstage.fawkes.idp)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Backstage Frontend                        \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                       \u2502\n\u2502  \u2502 Unauthenticated? \u2502\u2500\u2500Yes\u2500\u2500\u2510                               \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502                               \u2502\n\u2502           \u2502                 \u2502                               \u2502\n\u2502          No                 \u25bc                               \u2502\n\u2502           \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502           \u2502       \u2502 Redirect to SSO  \u2502                      \u2502\n\u2502           \u2502       \u2502  (GitHub OAuth)  \u2502                      \u2502\n\u2502           \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2502           \u2502                 \u2502                               \u2502\n\u2502           \u2502                 \u25bc                               \u2502\n\u2502           \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502           \u2502       \u2502 OAuth Callback   \u2502                      \u2502\n\u2502           \u2502       \u2502 Validate Token   \u2502                      \u2502\n\u2502           \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2502           \u2502                 \u2502                               \u2502\n\u2502           \u25bc                 \u25bc                               \u2502\n\u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502       \u2502                 Authenticated                     \u2502 \u2502\n\u2502       \u2502          Access to Catalog, Templates, Docs       \u2502 \u2502\n\u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#deployment-configuration","title":"Deployment Configuration","text":"<p>High Availability: - 2 replicas with pod anti-affinity - Pod disruption budget (minAvailable: 1) - PostgreSQL HA cluster (3 instances)</p> <p>Resource Allocation: - Backstage: 500m-2 CPU, 512Mi-2Gi memory - PostgreSQL: 500m-2 CPU, 512Mi-2Gi memory</p> <p>Security: - TLS termination at ingress (cert-manager) - Non-root container execution - Read-only filesystem where possible - Security context with dropped capabilities</p>"},{"location":"architecture/#integration-points","title":"Integration Points","text":"Integration Purpose Configuration GitHub OAuth User authentication <code>auth.providers.github</code> GitHub API Repository discovery <code>integrations.github</code> Jenkins CI/CD pipeline status <code>proxy.endpoints./jenkins</code> ArgoCD Deployment status <code>proxy.endpoints./argocd</code> Kubernetes Resource status <code>kubernetes.clusterLocatorMethods</code> Prometheus Metrics exposure ServiceMonitor Eclipse Che Cloud Development Environments <code>proxy.endpoints./che-api</code>"},{"location":"architecture/#cloud-development-environments-eclipse-che","title":"Cloud Development Environments (Eclipse Che)","text":"<p>The Developer Experience Layer includes Eclipse Che for Cloud Development Environments (CDEs), enabling developers to instantly provision standardized, pre-configured development workspaces.</p>"},{"location":"architecture/#cde-architecture","title":"CDE Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Cloud Development Environment Layer                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                      Backstage CDE Launcher                            \u2502 \u2502\n\u2502  \u2502   (Launch CDEs directly from Service Catalog entity pages)             \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                  \u2502                                           \u2502\n\u2502                                  \u25bc                                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                     Eclipse Che Server                                  \u2502 \u2502\n\u2502  \u2502                  (eclipse-che namespace)                                \u2502 \u2502\n\u2502  \u2502                                                                          \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502  Dashboard   \u2502  \u2502   Devfile    \u2502  \u2502   Plugin     \u2502  \u2502 Workspace  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502              \u2502  \u2502   Registry   \u2502  \u2502   Registry   \u2502  \u2502 Controller \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                  \u2502                                           \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502              \u2502                   \u2502                   \u2502                      \u2502\n\u2502              \u25bc                   \u25bc                   \u25bc                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502  \u2502 che-user-dev1    \u2502 \u2502 che-user-dev2    \u2502 \u2502 che-user-dev3    \u2502            \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502            \u2502\n\u2502  \u2502  \u2502 VS Code    \u2502  \u2502 \u2502  \u2502 VS Code    \u2502  \u2502 \u2502  \u2502 VS Code    \u2502  \u2502            \u2502\n\u2502  \u2502  \u2502 Container  \u2502  \u2502 \u2502  \u2502 Container  \u2502  \u2502 \u2502  \u2502 Container  \u2502  \u2502            \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502            \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502            \u2502\n\u2502  \u2502  \u2502 Python Dev \u2502  \u2502 \u2502  \u2502 AI/ML Dev  \u2502  \u2502 \u2502  \u2502 Node.js    \u2502  \u2502            \u2502\n\u2502  \u2502  \u2502 Container  \u2502  \u2502 \u2502  \u2502 Container  \u2502  \u2502 \u2502  \u2502 Container  \u2502  \u2502            \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502            \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502            \u2502\n\u2502  \u2502  \u2502Vault Agent \u2502  \u2502 \u2502  \u2502Vault Agent \u2502  \u2502 \u2502  \u2502Vault Agent \u2502  \u2502            \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502            \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#golden-path-devfiles","title":"Golden Path Devfiles","text":"Template Description Resources <code>goldenpath-python</code> Python development (Django, FastAPI, Flask) 2 CPU, 4Gi Memory <code>goldenpath-ai</code> AI/ML development with GPU support 8 CPU, 16Gi Memory, GPU"},{"location":"architecture/#key-features","title":"Key Features","text":"<ul> <li>Instant Provisioning: Launch pre-configured workspaces in under 2 minutes</li> <li>SSO Integration: Same authentication as Backstage portal</li> <li>Vault Secrets: Automatic credential injection via Vault Agent</li> <li>Resource Quotas: Team-level resource limits prevent cluster overload</li> <li>Workspace Isolation: Dedicated namespaces per user for security</li> </ul>"},{"location":"architecture/#access-urls","title":"Access URLs","text":"Endpoint URL Purpose Che Dashboard <code>https://che.fawkes.idp</code> Workspace management Devfile Registry <code>https://che.fawkes.idp/devfile-registry</code> Template catalog <p>See ADR-021: Eclipse Che CDE Strategy for detailed architecture decisions.</p>"},{"location":"architecture/#component-overview","title":"Component Overview","text":""},{"location":"architecture/#1-developer-portal-backstage","title":"1. Developer Portal (Backstage)","text":"<p>Purpose: Single pane of glass for developer self-service</p> <p>Key Features: - Software catalog (services, APIs, resources) - Software templates (golden paths) - TechDocs (documentation as code) - Plugin ecosystem (CI/CD status, metrics, alerts)</p> <p>Technology: Backstage (TypeScript/React), PostgreSQL</p> <p>Integrations: - GitHub (repository discovery, authentication) - Jenkins (pipeline status) - ArgoCD (deployment status) - Grafana (metrics dashboards)</p>"},{"location":"architecture/#2-cicd-layer-jenkins","title":"2. CI/CD Layer (Jenkins)","text":"<p>Purpose: Continuous integration and build automation</p> <p>Key Features: - Pipeline as code (Jenkinsfile) - Dynamic Kubernetes agents - Shared pipeline libraries - Multi-stage builds (build, test, scan, package)</p> <p>Technology: Jenkins, Kubernetes plugin, Docker</p> <p>Pipelines: - Build pipeline (compile, unit test) - Security scan pipeline (SAST, dependency check, container scan) - Integration test pipeline - Deployment pipeline (publish artifacts, trigger CD)</p>"},{"location":"architecture/#3-gitops-layer-argocd","title":"3. GitOps Layer (ArgoCD)","text":"<p>Purpose: Declarative continuous delivery</p> <p>Key Features: - Git as source of truth - Automated sync and reconciliation - Progressive delivery (blue-green, canary) - Multi-cluster management - Rollback capabilities</p> <p>Technology: ArgoCD, Kustomize/Helm</p> <p>Repository Structure: <pre><code>gitops-repo/\n\u251c\u2500\u2500 apps/\n\u2502   \u251c\u2500\u2500 team-a/\n\u2502   \u251c\u2500\u2500 team-b/\n\u251c\u2500\u2500 platform/\n\u2502   \u251c\u2500\u2500 backstage/\n\u2502   \u251c\u2500\u2500 jenkins/\n\u2502   \u251c\u2500\u2500 prometheus/\n\u2514\u2500\u2500 infrastructure/\n    \u251c\u2500\u2500 clusters/\n    \u251c\u2500\u2500 namespaces/\n</code></pre></p>"},{"location":"architecture/#4-observability-stack","title":"4. Observability Stack","text":"<p>Purpose: Comprehensive monitoring, logging, and tracing</p> <p>Components:</p> <p>Metrics (Prometheus + Grafana): - Platform metrics (Jenkins, ArgoCD, Backstage) - Application metrics (custom + OpenTelemetry) - DORA metrics (automated collection) - Infrastructure metrics (Kubernetes, nodes)</p> <p>Logging (OpenSearch + Fluent Bit): - Centralized log aggregation - Structured logging - Log correlation with traces - Retention policies</p> <p>Tracing (Grafana Tempo + OpenTelemetry): - Distributed tracing - Service dependency mapping - Performance analysis - Request flow visualization</p> <p>Alerting (Grafana Alerting): - Threshold-based alerts - Anomaly detection - Multi-channel notifications (Slack, PagerDuty, email)</p>"},{"location":"architecture/#5-security-layer","title":"5. Security Layer","text":"<p>Purpose: Shift-left security and compliance automation</p> <p>Components:</p> <p>Code Security (SonarQube): - Static analysis (SAST) - Code quality gates - Technical debt tracking - Security hotspots</p> <p>Container Security (Trivy): - Image vulnerability scanning - SBOM generation - Policy enforcement - Registry integration</p> <p>Secrets Management (HashiCorp Vault + External Secrets Operator): - HashiCorp Vault for centralized secrets management (HA deployment) - Vault Agent Sidecar for automatic secret injection into pods - CSI Secret Store Driver for volume-based secret mounting - External Secrets Operator for cloud provider integration - Kubernetes Auth Method for service account authentication - Dynamic secret generation and automatic rotation - Comprehensive audit logging for compliance</p> <p>Policy Enforcement (Kyverno): - Kubernetes-native policy engine for policy-as-code - Validation Policies: Enforce Pod Security Standards (runAsNonRoot,   disallow privileged, require resource limits) - Mutation Policies: Automatic standardization (platform labels, Vault   integration, Ingress class defaults, security context defaults) - Generation Policies: Automatic resource creation for new namespaces   (NetworkPolicy, ResourceQuota, LimitRange) - Policy Reports: Audit and compliance via PolicyReport CRDs - HA deployment with 3 admission controller replicas - Integration with ArgoCD for GitOps policy management - See ADR-017: Kyverno Policy Engine</p>"},{"location":"architecture/#6-dora-metrics-service","title":"6. DORA Metrics Service","text":"<p>Purpose: Automated collection and visualization of DORA metrics</p> <p>Implementation: Apache DevLake provides unified DORA metrics collection, calculation, and visualization. In the Fawkes GitOps architecture:</p> <ul> <li>ArgoCD is the primary source for deployment metrics (syncs = deployments)</li> <li>Jenkins provides CI quality metrics (builds, tests, rework)</li> <li>GitHub provides commit and PR data</li> <li>Observability provides incident data for CFR/MTTR</li> </ul> <p>Architecture: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Data Sources                              \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502   GitHub     \u2502  \u2502   ArgoCD     \u2502  \u2502   Jenkins    \u2502          \u2502\n\u2502  \u2502              \u2502  \u2502  (PRIMARY)   \u2502  \u2502   (CI/QA)    \u2502          \u2502\n\u2502  \u2502 \u2022 Commits    \u2502  \u2502 \u2022 Syncs      \u2502  \u2502 \u2022 Builds     \u2502          \u2502\n\u2502  \u2502 \u2022 PRs        \u2502  \u2502 \u2022 Deploys    \u2502  \u2502 \u2022 Tests      \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502         \u2502                 \u2502                  \u2502                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502                  \u2502                   \u2502\n\u2502  \u2502 Observability\u2502        \u2502                  \u2502                   \u2502\n\u2502  \u2502 \u2022 Incidents  \u2502        \u2502                  \u2502                   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502                  \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502                \u2502                  \u2502\n          \u25bc                \u25bc                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      DevLake Platform                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   GitHub   \u2502   ArgoCD    \u2502   Jenkins   \u2502   Webhook         \u2502 \u2502\n\u2502  \u2502   Plugin   \u2502   Plugin    \u2502   Plugin    \u2502   Plugin          \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                            \u2502                                     \u2502\n\u2502                            \u25bc                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                   DORA Calculations                         \u2502 \u2502\n\u2502  \u2502  \u2022 Deployment Frequency (ArgoCD syncs)                     \u2502 \u2502\n\u2502  \u2502  \u2022 Lead Time (Commit \u2192 ArgoCD sync)                        \u2502 \u2502\n\u2502  \u2502  \u2022 CFR (Failed syncs + Incidents)                          \u2502 \u2502\n\u2502  \u2502  \u2022 MTTR (Incident \u2192 Restore sync)                          \u2502 \u2502\n\u2502  \u2502  \u2022 Operational Performance (SLO adherence)                 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                            \u2502                                     \u2502\n\u2502                            \u25bc                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                   MySQL Database                            \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Visualization                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502   Grafana    \u2502  \u2502  Backstage   \u2502  \u2502  DevLake UI  \u2502          \u2502\n\u2502  \u2502  Dashboards  \u2502  \u2502   Plugin     \u2502  \u2502              \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>DORA Metrics Calculated: 1. Deployment Frequency: ArgoCD syncs per day/week (production apps) 2. Lead Time for Changes: Commit timestamp to ArgoCD sync completion 3. Change Failure Rate: (Failed syncs + Incidents) / Total syncs 4. Mean Time to Restore: Incident creation to restore sync 5. Operational Performance: SLO/SLI adherence from Prometheus</p> <p>CI/Rework Metrics (from Jenkins): - Build Success Rate - Quality Gate Pass Rate - Test Flakiness - Rework Rate (retry builds)</p> <p>See ADR-016: DevLake DORA Strategy for details.</p>"},{"location":"architecture/#7-infrastructure-layer","title":"7. Infrastructure Layer","text":"<p>Purpose: Cloud infrastructure provisioning and management</p> <p>Components:</p> <p>Terraform: - Kubernetes cluster provisioning - VPC, networking, security groups - IAM roles and policies - Cloud resources (databases, caches, queues)</p> <p>Crossplane (Roadmap): - Kubernetes-native infrastructure management - Cloud-agnostic abstractions - GitOps-driven infrastructure - Self-service resource provisioning</p> <p>Helm: - Package management for Kubernetes - Platform component deployment - Application chart templating</p>"},{"location":"architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/#1-application-deployment-flow","title":"1. Application Deployment Flow","text":"<pre><code>Developer commits code\n        \u2502\n        \u25bc\nGitHub webhook triggers Jenkins\n        \u2502\n        \u25bc\nJenkins Pipeline:\n\u251c\u2500\u2500 Checkout code\n\u251c\u2500\u2500 Build &amp; unit test\n\u251c\u2500\u2500 Security scanning (SonarQube, Trivy)\n\u251c\u2500\u2500 Build container image\n\u251c\u2500\u2500 Push to registry\n\u2514\u2500\u2500 Update GitOps repository\n        \u2502\n        \u25bc\nArgoCD detects change\n        \u2502\n        \u25bc\nArgoCD syncs application to Kubernetes\n        \u2502\n        \u25bc\nDeployment triggers DORA metrics webhook\n        \u2502\n        \u25bc\nDORA service updates metrics\n        \u2502\n        \u25bc\nGrafana displays updated dashboards\n</code></pre>"},{"location":"architecture/#2-platform-component-update-flow","title":"2. Platform Component Update Flow","text":"<pre><code>Platform team updates component config\n        \u2502\n        \u25bc\nCommit to GitOps repository\n        \u2502\n        \u25bc\nArgoCD detects drift\n        \u2502\n        \u25bc\nArgoCD applies changes to cluster\n        \u2502\n        \u25bc\nPrometheus scrapes new metrics\n        \u2502\n        \u25bc\nGrafana reflects changes\n</code></pre>"},{"location":"architecture/#3-developer-self-service-flow","title":"3. Developer Self-Service Flow","text":"<pre><code>Developer accesses Backstage\n        \u2502\n        \u25bc\nSelects template (e.g., \"Python Microservice\")\n        \u2502\n        \u25bc\nFills template parameters\n        \u2502\n        \u25bc\nBackstage Scaffolder:\n\u251c\u2500\u2500 Creates GitHub repository\n\u251c\u2500\u2500 Populates with template code\n\u251c\u2500\u2500 Configures CI/CD pipeline\n\u251c\u2500\u2500 Creates ArgoCD application\n\u2514\u2500\u2500 Registers in service catalog\n        \u2502\n        \u25bc\nDeveloper commits changes\n        \u2502\n        \u25bc\nAutomated CI/CD pipeline executes\n        \u2502\n        \u25bc\nApplication deployed to cluster\n</code></pre>"},{"location":"architecture/#4-observability-data-flow","title":"4. Observability Data Flow","text":"<pre><code>Applications emit telemetry\n        \u2502\n        \u251c\u2500\u2500&gt; Metrics \u2192 OpenTelemetry Collector \u2192 Prometheus\n        \u2502\n        \u251c\u2500\u2500&gt; Logs \u2192 Fluent Bit \u2192 OpenSearch\n        \u2502\n        \u2514\u2500\u2500&gt; Traces \u2192 OpenTelemetry Collector \u2192 Grafana Tempo\n                                \u2502\n                                \u25bc\n                All data queryable via Grafana\n</code></pre>"},{"location":"architecture/#integration-patterns","title":"Integration Patterns","text":""},{"location":"architecture/#1-webhook-based-integration","title":"1. Webhook-Based Integration","text":"<p>Used for real-time event notification between components.</p> <p>Example: Jenkins \u2192 DORA Metrics Service <pre><code>Jenkins Pipeline Completes\n    \u2502\n    \u25bc\nWebhook POST to /webhook/build\n    \u2502\n    \u251c\u2500 Headers: X-Jenkins-Event, X-Build-Number\n    \u251c\u2500 Body: Build metadata (status, duration, commit SHA)\n    \u2502\n    \u25bc\nDORA Service processes event\n    \u2502\n    \u251c\u2500 Calculate lead time (commit \u2192 build completion)\n    \u251c\u2500 Update deployment frequency\n    \u2514\u2500 Store in PostgreSQL and expose to Prometheus\n</code></pre></p>"},{"location":"architecture/#2-pull-based-discovery","title":"2. Pull-Based Discovery","text":"<p>Used for service catalog and status updates.</p> <p>Example: Backstage \u2192 Kubernetes <pre><code>Backstage Kubernetes Plugin\n    \u2502\n    \u25bc\nQueries Kubernetes API (every 30s)\n    \u2502\n    \u251c\u2500 List pods by label selector\n    \u251c\u2500 Get deployment status\n    \u2514\u2500 Fetch resource metrics\n    \u2502\n    \u25bc\nDisplay in Backstage UI (real-time status)\n</code></pre></p>"},{"location":"architecture/#3-gitops-reconciliation","title":"3. GitOps Reconciliation","text":"<p>Used for declarative state management.</p> <p>Example: ArgoCD \u2192 Kubernetes <pre><code>ArgoCD watches Git repository\n    \u2502\n    \u25bc\nDetects drift (desired state \u2260 actual state)\n    \u2502\n    \u25bc\nReconciliation loop:\n    \u251c\u2500 Fetch manifests from Git\n    \u251c\u2500 Compare with cluster state\n    \u251c\u2500 Apply differences (kubectl apply)\n    \u2514\u2500 Update sync status\n    \u2502\n    \u25bc\nCluster converges to desired state\n</code></pre></p>"},{"location":"architecture/#4-api-based-integration","title":"4. API-Based Integration","text":"<p>Used for programmatic interactions.</p> <p>Example: Backstage Templates \u2192 GitHub API <pre><code>User triggers template scaffolding\n    \u2502\n    \u25bc\nBackstage calls GitHub API:\n    \u251c\u2500 POST /orgs/{org}/repos (create repository)\n    \u251c\u2500 PUT /repos/{repo}/contents/* (add files)\n    \u251c\u2500 POST /repos/{repo}/hooks (add webhooks)\n    \u2514\u2500 PUT /repos/{repo}/collaborators (set permissions)\n    \u2502\n    \u25bc\nRepository ready for development\n</code></pre></p>"},{"location":"architecture/#security-architecture","title":"Security Architecture","text":""},{"location":"architecture/#defense-in-depth","title":"Defense in Depth","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 7: Developer Education &amp; Awareness                   \u2502\n\u2502 - Security training, dojo modules                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 6: Application Security                              \u2502\n\u2502 - SAST (SonarQube), dependency scanning, secret detection \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 5: Container Security                                \u2502\n\u2502 - Image scanning (Trivy), SBOM, signed images             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 4: Runtime Security                                  \u2502\n\u2502 - Policy enforcement (Kyverno), admission control          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 3: Network Security                                  \u2502\n\u2502 - Network policies, service mesh, ingress controls        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 2: Identity &amp; Access Management                      \u2502\n\u2502 - RBAC, service accounts, secrets management              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 1: Infrastructure Security                           \u2502\n\u2502 - Encrypted storage, secure boot, hardened OS             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#security-scanning-pipeline","title":"Security Scanning Pipeline","text":"<pre><code>Code Commit\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 1: Source Code Analysis          \u2502\n\u2502 - SonarQube (SAST)                      \u2502\n\u2502   * Security vulnerability detection    \u2502\n\u2502   * Code quality metrics                \u2502\n\u2502   * Technical debt tracking             \u2502\n\u2502 - git-secrets (credential scanning)    \u2502\n\u2502 - License compliance check              \u2502\n\u2502 Quality Gate: Block if critical issues \u2502\n\u2502                                         \u2502\n\u2502 \u26a1 Main Branch: MUST pass to proceed    \u2502\n\u2502 \ud83d\udcca Dashboard: sonarqube.fawkes.local    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 2: Dependency Analysis            \u2502\n\u2502 - OWASP Dependency Check                \u2502\n\u2502 - npm audit / pip audit                 \u2502\n\u2502 Quality Gate: Block if high CVEs       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 3: Container Image Scan           \u2502\n\u2502 - Trivy vulnerability scan              \u2502\n\u2502 - SBOM generation                       \u2502\n\u2502 Quality Gate: Block if critical vulns  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 4: Policy Validation              \u2502\n\u2502 - Kyverno policy check                  \u2502\n\u2502 - Resource limits validation            \u2502\n\u2502 Quality Gate: Enforce policies         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\n    \u25bc\nDeploy to Kubernetes\n</code></pre>"},{"location":"architecture/#sonarqube-quality-gate-integration","title":"SonarQube Quality Gate Integration","text":"<p>The SonarQube Quality Gate is a mandatory stage in the Golden Path CI/CD pipeline:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  SonarQube Quality Gate Flow                     \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502  Build   \u2502 \u2500\u2500\u25ba \u2502   Analyze    \u2502 \u2500\u2500\u25ba \u2502  Quality Gate    \u2502    \u2502\n\u2502  \u2502  Code    \u2502     \u2502  with Sonar  \u2502     \u2502  Evaluation      \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                \u2502                  \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502                    \u25bc                                    \u25bc        \u2502\n\u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502           \u2502     PASS     \u2502                    \u2502     FAIL     \u2502  \u2502\n\u2502           \u2502   \u2705 Green   \u2502                    \u2502   \u274c Red     \u2502  \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                    \u2502                                    \u2502        \u2502\n\u2502                    \u25bc                                    \u25bc        \u2502\n\u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502           \u2502 Build Image  \u2502                    \u2502 Stop Pipeline\u2502  \u2502\n\u2502           \u2502 Push Registry\u2502                    \u2502 Log Failure  \u2502  \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502 Link to Report\u2502  \u2502\n\u2502                                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Quality Gate Conditions: - 0 new bugs - 0 new vulnerabilities - 100% security hotspots reviewed - \u226580% new code coverage - \u22643% duplicated lines - Maintainability rating A</p>"},{"location":"architecture/#secrets-management","title":"Secrets Management","text":"<p>Architecture:</p> <p>The Fawkes platform implements a hybrid secrets management approach using HashiCorp Vault as the primary secrets store with External Secrets Operator for cloud provider integration.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          Secrets Management Layer                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502    HashiCorp Vault (HA)    \u2502    \u2502   External Secrets Operator        \u2502  \u2502\n\u2502  \u2502                            \u2502    \u2502                                    \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502    \u2502  \u2022 AWS Secrets Manager sync       \u2502  \u2502\n\u2502  \u2502  \u2502 vault-0 (Primary)    \u2502  \u2502    \u2502  \u2022 Azure Key Vault sync           \u2502  \u2502\n\u2502  \u2502  \u2502 vault-1 (Standby)    \u2502  \u2502    \u2502  \u2022 GCP Secret Manager sync        \u2502  \u2502\n\u2502  \u2502  \u2502 vault-2 (Standby)    \u2502  \u2502    \u2502                                    \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502  \u2502                            \u2502                     \u2502                       \u2502\n\u2502  \u2502  \u2022 Kubernetes Auth         \u2502                     \u2502                       \u2502\n\u2502  \u2502  \u2022 Dynamic Secrets         \u2502                     \u2502                       \u2502\n\u2502  \u2502  \u2022 Audit Logging           \u2502                     \u2502                       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502                       \u2502\n\u2502              \u2502                                       \u2502                       \u2502\n\u2502              \u2502 Vault Agent Sidecar                  \u2502 ExternalSecret        \u2502\n\u2502              \u2502 or CSI Driver                        \u2502                       \u2502\n\u2502              \u25bc                                       \u25bc                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502                        Kubernetes Secrets                                \u2502\u2502\n\u2502  \u2502  (Mounted as volumes or environment variables in application pods)      \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Secret Injection Methods:</p> Method Description Use Case Vault Agent Sidecar Automatic injection via mutating webhook Most applications, auto-rotation CSI Secret Store Mount secrets as volumes Legacy apps, file-based config External Secrets Sync from cloud providers Cloud-native deployments <p>Secret Rotation Flow: <pre><code>Secret Updated in Vault\n     \u2502\n     \u25bc\nVault Agent Detects Change (polling interval)\n     \u2502\n     \u25bc\nAgent Updates /vault/secrets/* Files\n     \u2502\n     \u25bc\nApplication Reads New Secret (no pod restart)\n</code></pre></p> <p>Best Practices: - No secrets in Git repositories - Secrets encrypted at rest and in transit - Automatic rotation via Vault Agent - Audit logging for all secret access - Least privilege access via Vault policies - Service account authentication (no static tokens)</p>"},{"location":"architecture/#multi-cloud-strategy","title":"Multi-Cloud Strategy","text":""},{"location":"architecture/#current-state-mvp-aws-focus","title":"Current State (MVP): AWS Focus","text":"<p>Rationale: - Fastest time to MVP - Most mature Terraform provider - Largest market share - Extensive documentation and community</p> <p>AWS Components: - EKS (Kubernetes) - VPC, subnets, security groups - IAM roles and policies - ECR (container registry) - RDS (databases) - ElastiCache (caching) - S3 (storage) - Route 53 (DNS)</p>"},{"location":"architecture/#target-state-multi-cloud-abstraction","title":"Target State: Multi-Cloud Abstraction","text":"<p>Approach: Crossplane for cloud-agnostic infrastructure</p> <pre><code>Developer requests database\n    \u2502\n    \u25bc\nCreates Kubernetes Custom Resource:\nkind: Database\nspec:\n  engine: postgresql\n  size: small\n    \u2502\n    \u25bc\nCrossplane Composition:\n    \u2502\n    \u251c\u2500 AWS \u2192 Creates RDS instance\n    \u251c\u2500 Azure \u2192 Creates Azure Database for PostgreSQL\n    \u2514\u2500 GCP \u2192 Creates Cloud SQL instance\n    \u2502\n    \u25bc\nConnection details stored in Kubernetes Secret\n    \u2502\n    \u25bc\nApplication consumes database\n</code></pre> <p>Benefits: - Consistent API across clouds - GitOps-driven infrastructure - Self-service for developers - Reduced cloud vendor lock-in</p>"},{"location":"architecture/#multi-cloud-architecture","title":"Multi-Cloud Architecture","text":"<pre><code>                    Fawkes Control Plane\n                            \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                   \u2502                   \u2502\n        \u25bc                   \u25bc                   \u25bc\n    AWS Region          Azure Region        GCP Region\n        \u2502                   \u2502                   \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  EKS  \u2502           \u2502  AKS  \u2502           \u2502  GKE  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                   \u2502                   \u2502\n    App Workloads       App Workloads       App Workloads\n</code></pre> <p>Cluster Federation: - ArgoCD manages multiple clusters - Centralized observability (Prometheus, Grafana) - Unified developer portal (Backstage) - Cross-cluster service discovery</p>"},{"location":"architecture/#scalability-performance","title":"Scalability &amp; Performance","text":""},{"location":"architecture/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Kubernetes Cluster: - Node autoscaling (3-100 nodes) - Pod autoscaling (HPA based on CPU/memory/custom metrics) - Cluster API for cluster lifecycle management</p> <p>Platform Components: - Jenkins: Dynamic agents (spin up/down as needed) - Prometheus: Sharding and federation for large environments - Grafana: Read replicas for dashboard queries</p>"},{"location":"architecture/#performance-targets","title":"Performance Targets","text":"Metric Target Measurement CI Build Time (small) &lt; 5 minutes P95 CI Build Time (large) &lt; 15 minutes P95 Deployment Time &lt; 2 minutes P95 Backstage Page Load &lt; 2 seconds P95 Grafana Dashboard Load &lt; 3 seconds P95 ArgoCD Sync Time &lt; 30 seconds P95 GitOps Drift Detection &lt; 3 minutes Maximum"},{"location":"architecture/#resource-allocation-per-cluster","title":"Resource Allocation (per cluster)","text":"<p>MVP Scale (5 teams, 25 services): - Kubernetes nodes: 5-10 (16GB RAM, 4 vCPU each) - Total cluster capacity: ~80GB RAM, 40 vCPU - Platform overhead: ~30GB RAM, 15 vCPU - Application capacity: ~50GB RAM, 25 vCPU</p> <p>Production Scale (20 teams, 200 services): - Kubernetes nodes: 20-50 (32GB RAM, 8 vCPU each) - Total cluster capacity: ~640GB RAM, 400 vCPU - Platform overhead: ~100GB RAM, 50 vCPU - Application capacity: ~540GB RAM, 350 vCPU</p>"},{"location":"architecture/#caching-strategy","title":"Caching Strategy","text":"<ul> <li>Backstage: Redis for session and catalog caching</li> <li>Jenkins: Shared workspace volumes, Docker layer caching</li> <li>ArgoCD: Repository caching, manifest caching</li> <li>Grafana: Query result caching (5-minute TTL)</li> </ul>"},{"location":"architecture/#technology-stack","title":"Technology Stack","text":""},{"location":"architecture/#core-platform","title":"Core Platform","text":"Component Technology Version Rationale Container Orchestration Kubernetes 1.28+ Industry standard, CNCF graduated Infrastructure as Code Terraform 1.6+ Mature, multi-cloud, large community Developer Portal Backstage Latest CNCF incubating, Spotify-proven Cloud Development Env Eclipse Che 7.89+ CNCF incubating, Devfile standard CI/CD Jenkins 2.4+ Enterprise adoption, extensive plugins GitOps ArgoCD 2.9+ Kubernetes-native, progressive delivery Container Registry Harbor 2.9+ Security scanning, RBAC, replication"},{"location":"architecture/#observability","title":"Observability","text":"Component Technology Version Rationale Metrics Prometheus 2.48+ CNCF graduated, Kubernetes-native Visualization Grafana 10+ Rich dashboards, multi-source support Logging OpenSearch 2.11+ Open source, Elasticsearch-compatible Log Collection Fluent Bit 2.2+ Lightweight, high-performance Tracing Grafana Tempo 2.3+ Scalable, cost-effective, Grafana-native Instrumentation OpenTelemetry 1.21+ CNCF project, vendor-neutral"},{"location":"architecture/#security","title":"Security","text":"Component Technology Version Rationale SAST SonarQube 10+ Code quality and security analysis Container Scanning Trivy 0.48+ Comprehensive vulnerability detection Policy Engine Kyverno 3.3+ Kubernetes-native, validation/mutation/generation Secrets (Primary) HashiCorp Vault 1.17+ Centralized secrets, dynamic credentials, HA Secrets (Cloud Sync) External Secrets Operator 0.9+ Multi-provider cloud secrets sync Secrets (CSI) Secrets Store CSI Driver 1.4+ Volume-based secret mounting"},{"location":"architecture/#data-stores","title":"Data Stores","text":"Component Technology Version Purpose Backstage Backend PostgreSQL 15+ Service catalog, user data DORA Metrics PostgreSQL 15+ Historical metrics storage SonarQube PostgreSQL 15+ Code analysis data Jenkins File system + PostgreSQL - Build data, job configs"},{"location":"architecture/#programming-languages","title":"Programming Languages","text":"Purpose Language Rationale Platform Services Go Performance, Kubernetes ecosystem DORA Metrics Service Go or Python Developer preference, quick development Backstage Plugins TypeScript Backstage requirement Scripts/Automation Bash, Python Platform automation, tooling IaC Modules HCL (Terraform) Infrastructure provisioning"},{"location":"architecture/#future-architecture","title":"Future Architecture","text":""},{"location":"architecture/#6-month-roadmap","title":"6-Month Roadmap","text":"<p>Multi-Cloud Expansion: - Azure support via Terraform - GCP support via Terraform - Crossplane implementation for cloud abstraction</p> <p>Advanced Security: - Service mesh (Linkerd) for mTLS - Runtime security (Falco) - Policy-as-code enforcement (expanded Kyverno policies) - SLSA compliance</p> <p>Enhanced Observability: - Distributed tracing adoption (100% of services) - Cost visibility (OpenCost integration) - SLO tracking and error budgets</p> <p>Dojo Expansion: - 10+ learning modules - Hands-on labs with live platform - Certification integration complete</p>"},{"location":"architecture/#12-month-vision","title":"12-Month Vision","text":"<p>Platform Maturity: - CNCF Sandbox/Incubating project - 50+ production deployments - Enterprise-grade stability (99.9% uptime)</p> <p>Advanced Features: - Multi-region deployments - Disaster recovery automation - Blue-green cluster upgrades - Chaos engineering integration</p> <p>Ecosystem: - 20+ community plugins - Commercial support partnerships - Training and certification program</p> <p>Research &amp; Development: - AI-powered platform insights - Predictive failure detection - Automated performance optimization</p>"},{"location":"architecture/#architectural-decision-records-adrs","title":"Architectural Decision Records (ADRs)","text":"<p>Major architectural decisions are documented in ADRs stored in <code>/docs/adr/</code>:</p> <ul> <li>ADR-001: Kubernetes as Container Orchestration Platform</li> <li>ADR-002: Backstage for Developer Portal</li> <li>ADR-003: ArgoCD for GitOps</li> <li>ADR-004: Jenkins for CI/CD</li> <li>ADR-005: Terraform over Pulumi for IaC</li> <li>ADR-006: PostgreSQL for Data Persistence</li> <li>ADR-009: Secrets Management</li> <li>ADR-015: HashiCorp Vault Deployment</li> <li>ADR-016: DevLake for DORA Metrics</li> <li>ADR-017: Kyverno Policy Engine</li> <li>ADR-021: Eclipse Che CDE Strategy</li> </ul>"},{"location":"architecture/#diagrams","title":"Diagrams","text":""},{"location":"architecture/#component-interaction-diagram","title":"Component Interaction Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Backstage                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502Catalog \u2502  \u2502Templates\u2502 \u2502TechDocs\u2502  \u2502 Plugins\u2502  \u2502  Auth  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502           \u2502           \u2502           \u2502           \u2502\n       \u2502           \u2502           \u2502           \u2502           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Kubernetes API                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502           \u2502           \u2502           \u2502           \u2502\n   \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2510\n   \u2502Jenkins\u2502   \u2502ArgoCD\u2502   \u2502Prom  \u2502   \u2502Kyverno\u2502  \u2502Apps \u2502\n   \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n       \u2502          \u2502          \u2502          \u2502          \u2502\n   \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502              Kubernetes Workloads                       \u2502\n   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n   \u2502  \u2502  Pods  \u2502  \u2502Services\u2502  \u2502Ingress \u2502  \u2502 Volumes\u2502       \u2502\n   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#deployment-pipeline-detail","title":"Deployment Pipeline Detail","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Git Commit                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Jenkins Pipeline Triggered                    \u2502\n\u2502                                                          \u2502\n\u2502  Stage 1: Build          [3 min]                        \u2502\n\u2502  \u251c\u2500 Checkout code                                       \u2502\n\u2502  \u251c\u2500 Dependency resolution                               \u2502\n\u2502  \u251c\u2500 Compile                                             \u2502\n\u2502  \u2514\u2500 Unit tests                                          \u2502\n\u2502                                                          \u2502\n\u2502  Stage 2: Security Scan  [2 min]                        \u2502\n\u2502  \u251c\u2500 SonarQube SAST                                      \u2502\n\u2502  \u251c\u2500 Dependency check                                    \u2502\n\u2502  \u2514\u2500 Secret scanning                                     \u2502\n\u2502                                                          \u2502\n\u2502  Stage 3: Package        [1 min]                        \u2502\n\u2502  \u251c\u2500 Build Docker image                                  \u2502\n\u2502  \u251c\u2500 Trivy scan                                          \u2502\n\u2502  \u2514\u2500 Push to Harbor                                      \u2502\n\u2502                                                          \u2502\n\u2502  Stage 4: Deploy         [30 sec]                       \u2502\n\u2502  \u251c\u2500 Update GitOps repo                                  \u2502\n\u2502  \u2514\u2500 Trigger DORA webhook                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              ArgoCD Detects Change                       \u2502\n\u2502                                                          \u2502\n\u2502  \u251c\u2500 Fetch manifests from Git                            \u2502\n\u2502  \u251c\u2500 Validate with Kyverno policies                      \u2502\n\u2502  \u251c\u2500 Apply to Kubernetes                                 \u2502\n\u2502  \u2514\u2500 Monitor rollout status                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               Application Running                        \u2502\n\u2502                                                          \u2502\n\u2502  \u251c\u2500 Prometheus scrapes metrics                          \u2502\n\u2502  \u251c\u2500 Fluent Bit collects logs                            \u2502\n\u2502  \u251c\u2500 OpenTelemetry traces requests                       \u2502\n\u2502  \u2514\u2500 Grafana visualizes data                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#conclusion","title":"Conclusion","text":"<p>This architecture provides a solid foundation for a production-ready Internal Delivery Platform that:</p> <p>\u2705 Prioritizes developer experience through self-service and automation \u2705 Integrates security throughout the delivery pipeline \u2705 Provides comprehensive observability and DORA metrics \u2705 Follows GitOps principles for declarative management \u2705 Scales from small teams to enterprise deployments \u2705 Remains extensible and customizable</p> <p>The architecture will evolve based on community feedback, adoption patterns, and emerging best practices in platform engineering.</p> <p>Next Steps: 1. Review and approve this architecture 2. Create detailed ADRs for key decisions 3. Begin MVP implementation following this blueprint 4. Iterate based on early adopter feedback</p> <p>Questions or Feedback: Open a GitHub Discussion or contact the architecture team</p> <p>Document Maintainers: Platform Architecture Team Review Cadence: Quarterly or when major changes proposed Last Architectural Review: October 4, 2025</p>"},{"location":"azure-ingress-implementation-summary/","title":"Implementation Summary: Azure Load Balancer and Ingress Configuration","text":"<p>Issue: #2 - Configure Azure Load Balancer and Ingress Milestone: 1.1 - Azure Infrastructure Priority: p0-critical Status: \u2705 Complete</p>"},{"location":"azure-ingress-implementation-summary/#overview","title":"Overview","text":"<p>This implementation provides a complete solution for configuring Azure Load Balancer, nginx-ingress controller, and cert-manager on Azure AKS, enabling external access to platform services with automated TLS certificate management.</p>"},{"location":"azure-ingress-implementation-summary/#what-was-implemented","title":"What Was Implemented","text":""},{"location":"azure-ingress-implementation-summary/#task-21-deploy-nginx-ingress-with-azure-lb","title":"Task 2.1: Deploy nginx-ingress with Azure LB \u2705","text":"<p>Files Created: - <code>platform/apps/ingress-nginx/values-azure.yaml</code> - Azure-specific Helm values - <code>platform/apps/ingress-nginx/ingress-nginx-azure-application.yaml</code> - ArgoCD Application - <code>platform/apps/ingress-nginx/validate-azure.sh</code> - Validation script</p> <p>Key Features: - \u2705 Azure Load Balancer integration with health probes - \u2705 High availability (2+ replicas with pod anti-affinity) - \u2705 Auto-scaling (HPA) from 2-10 replicas based on CPU/memory - \u2705 TLS termination with SSL redirect and HSTS enabled - \u2705 Prometheus metrics with ServiceMonitor and PrometheusRules - \u2705 Session affinity for better performance - \u2705 External traffic policy set to Local - \u2705 Resource limits: 200m CPU, 256Mi memory (requests) - \u2705 Security: Snippet annotations disabled, server tokens hidden</p> <p>Files Modified: - <code>platform/apps/ingress-nginx/README.md</code> - Added Azure deployment instructions</p>"},{"location":"azure-ingress-implementation-summary/#task-22-configure-azure-dns-optional","title":"Task 2.2: Configure Azure DNS (Optional) \u2705","text":"<p>Files Created: - <code>infra/azure/dns.tf</code> - Terraform configuration for Azure DNS - DNS zone creation - A records for root domain - Wildcard A records (*.fawkes.yourdomain.com) - Optional specific service records (commented examples)</p> <p>Files Modified: - <code>infra/azure/variables.tf</code> - Added DNS configuration variables - <code>infra/azure/outputs.tf</code> - Added DNS outputs (nameservers, zone ID, ingress IP) - <code>infra/azure/terraform.tfvars.example</code> - Added DNS configuration examples</p> <p>Key Features: - \u2705 Optional DNS zone creation (controlled by variable) - \u2705 Automatic A record creation pointing to ingress IP - \u2705 Wildcard DNS support for all subdomains - \u2705 DNS nameserver output for delegation - \u2705 Conditional resource creation (no cost if disabled)</p>"},{"location":"azure-ingress-implementation-summary/#task-23-configure-cert-manager-with-lets-encrypt","title":"Task 2.3: Configure cert-manager with Let's Encrypt \u2705","text":"<p>Files Created: - <code>platform/apps/cert-manager/cert-manager-application.yaml</code> - Main cert-manager deployment - <code>platform/apps/cert-manager/cluster-issuers-application.yaml</code> - ArgoCD app for issuers - <code>platform/apps/cert-manager/cluster-issuer-letsencrypt-staging.yaml</code> - Staging issuer (HTTP-01) - <code>platform/apps/cert-manager/cluster-issuer-letsencrypt-prod.yaml</code> - Production issuer (HTTP-01) - <code>platform/apps/cert-manager/cluster-issuer-letsencrypt-dns-azure.yaml</code> - Azure DNS issuer (DNS-01) - <code>platform/apps/cert-manager/certificate-example.yaml</code> - Sample certificate resources - <code>platform/apps/cert-manager/README.md</code> - Comprehensive documentation - <code>platform/apps/cert-manager/validate.sh</code> - Validation script</p> <p>Key Features: - \u2705 cert-manager v1.15.3 deployment - \u2705 CRD installation with Helm - \u2705 Let's Encrypt staging issuer (for testing) - \u2705 Let's Encrypt production issuer - \u2705 Azure DNS issuer for wildcard certificates - \u2705 HTTP-01 challenge support - \u2705 DNS-01 challenge support with Azure DNS - \u2705 Prometheus metrics with ServiceMonitor - \u2705 Security contexts configured - \u2705 Automatic certificate issuance and renewal - \u2705 Example certificates (single domain, wildcard, multi-domain)</p>"},{"location":"azure-ingress-implementation-summary/#documentation","title":"Documentation \u2705","text":"<p>Files Created: - <code>docs/azure-ingress-setup.md</code> - Comprehensive setup guide - <code>docs/azure-ingress-quickstart.md</code> - Quick start guide - <code>tests/bdd/features/azure_ingress_loadbalancer.feature</code> - BDD acceptance tests</p> <p>Content: - \u2705 Architecture overview - \u2705 Step-by-step deployment instructions - \u2705 Advanced configuration (static IP, wildcard certs, internal LB) - \u2705 Monitoring and alerting setup - \u2705 Troubleshooting guide - \u2705 Security best practices - \u2705 Cost optimization information - \u2705 Quick reference commands</p>"},{"location":"azure-ingress-implementation-summary/#acceptance-criteria-status","title":"Acceptance Criteria Status","text":"<p>All acceptance criteria from the issue have been met:</p>"},{"location":"azure-ingress-implementation-summary/#nginx-ingress-controller-deployed","title":"nginx-ingress controller deployed \u2705","text":"<ul> <li>ArgoCD Application created</li> <li>Azure-specific values configured</li> <li>High availability setup with 2+ replicas</li> </ul>"},{"location":"azure-ingress-implementation-summary/#azure-load-balancer-created-automatically","title":"Azure Load Balancer created automatically \u2705","text":"<ul> <li>LoadBalancer service type configured</li> <li>Health probes configured</li> <li>External traffic policy set to Local</li> </ul>"},{"location":"azure-ingress-implementation-summary/#public-ip-assigned","title":"Public IP assigned \u2705","text":"<ul> <li>Automatic public IP assignment by Azure</li> <li>Optional static IP support (documented)</li> </ul>"},{"location":"azure-ingress-implementation-summary/#custom-domain-configured-optional","title":"Custom domain configured (optional) \u2705","text":"<ul> <li>Terraform module for Azure DNS</li> <li>A records and wildcard records</li> <li>DNS delegation instructions</li> </ul>"},{"location":"azure-ingress-implementation-summary/#tls-certificates-configured","title":"TLS certificates configured \u2705","text":"<ul> <li>cert-manager deployed</li> <li>Let's Encrypt staging and production issuers</li> <li>HTTP-01 and DNS-01 challenge support</li> <li>Automatic certificate issuance and renewal</li> </ul>"},{"location":"azure-ingress-implementation-summary/#test-ingress-route-working","title":"Test ingress route working \u2705","text":"<ul> <li>Test ingress provided (test-ingress.yaml)</li> <li>Echo server deployment</li> <li>HTTP and HTTPS examples</li> <li>Validation scripts</li> </ul>"},{"location":"azure-ingress-implementation-summary/#validation-commands","title":"Validation Commands","text":"<pre><code># Validate nginx-ingress\n./platform/apps/ingress-nginx/validate-azure.sh\n\n# Validate cert-manager\n./platform/apps/cert-manager/validate.sh\n\n# Check Load Balancer\nkubectl get svc -n ingress-nginx\naz network lb list --resource-group MC_fawkes-rg_fawkes-aks_*\n\n# Test ingress\ncurl http://test.&lt;EXTERNAL_IP&gt;.nip.io\n\n# Check certificates\nkubectl get certificates -A\n</code></pre>"},{"location":"azure-ingress-implementation-summary/#architecture-compliance","title":"Architecture Compliance","text":"<p>The implementation follows Fawkes architecture principles:</p> <p>\u2705 GitOps-first: All configuration in Git, ArgoCD Applications for deployment \u2705 Declarative: Desired state described, not procedures \u2705 Multi-cloud: Azure-specific but follows standard Kubernetes patterns \u2705 Immutable: Container-based deployment \u2705 Observable: Prometheus metrics, ServiceMonitor, PrometheusRules</p>"},{"location":"azure-ingress-implementation-summary/#security-features","title":"Security Features","text":"<p>\u2705 TLS termination with automated certificate management \u2705 HSTS enabled with 1-year max age \u2705 Server tokens hidden \u2705 Snippet annotations disabled (security) \u2705 Security contexts configured (runAsNonRoot) \u2705 Let's Encrypt rate limit protection (staging/production issuers) \u2705 RBAC enabled</p>"},{"location":"azure-ingress-implementation-summary/#cost-optimization","title":"Cost Optimization","text":"<p>Estimated monthly cost: - Standard Load Balancer: ~$18/month - Public IP: ~$3/month - DNS Zone (optional): ~$0.50/month - cert-manager: Free (Let's Encrypt) Total: ~$22-25/month</p> <p>Resource efficiency: - Auto-scaling from 2-10 replicas based on load - Appropriate resource limits prevent over-provisioning</p>"},{"location":"azure-ingress-implementation-summary/#dependencies-satisfied","title":"Dependencies Satisfied","text":"<p>This implementation depends on: - \u2705 Issue #1 (Azure Infrastructure) - AKS cluster must be provisioned first</p> <p>This implementation blocks: - Issue #5 (blocked by this) - Issue #9 (blocked by this) - Issue #14 (blocked by this)</p>"},{"location":"azure-ingress-implementation-summary/#testing","title":"Testing","text":""},{"location":"azure-ingress-implementation-summary/#manual-testing-requires-aks-cluster","title":"Manual Testing (Requires AKS Cluster)","text":"<ul> <li>Deploy nginx-ingress: <code>kubectl apply -f ingress-nginx-azure-application.yaml</code></li> <li>Deploy cert-manager: <code>kubectl apply -f cert-manager-application.yaml</code></li> <li>Run validation scripts</li> <li>Deploy test ingress</li> <li>Request test certificate</li> </ul>"},{"location":"azure-ingress-implementation-summary/#bdd-tests-created","title":"BDD Tests Created","text":"<ul> <li>20+ scenarios in <code>azure_ingress_loadbalancer.feature</code></li> <li>Covers deployment, configuration, validation</li> <li>Tagged with @azure, @AT-E1-002</li> </ul>"},{"location":"azure-ingress-implementation-summary/#validation","title":"Validation","text":"<ul> <li>\u2705 YAML syntax validated with yamllint</li> <li>\u2705 No linting errors</li> <li>\u2705 Code review completed</li> <li>\u2705 Security scan passed (no issues)</li> <li>\u26a0\ufe0f  Live cluster testing pending (requires Azure AKS)</li> </ul>"},{"location":"azure-ingress-implementation-summary/#usage-example","title":"Usage Example","text":"<pre><code># Create an ingress with automatic TLS\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\nspec:\n  ingressClassName: nginx\n  tls:\n    - hosts:\n        - myapp.fawkes.yourdomain.com\n      secretName: myapp-tls\n  rules:\n    - host: myapp.fawkes.yourdomain.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp\n                port:\n                  number: 80\n</code></pre> <p>cert-manager automatically: 1. Creates a Certificate resource 2. Requests certificate from Let's Encrypt 3. Completes ACME challenge (HTTP-01 or DNS-01) 4. Stores certificate in Kubernetes Secret 5. Renews certificate before expiration</p>"},{"location":"azure-ingress-implementation-summary/#next-steps","title":"Next Steps","text":"<p>For platform users: 1. Deploy nginx-ingress and cert-manager using the ArgoCD Applications 2. Configure DNS (if using custom domain) 3. Update email address in ClusterIssuers 4. Create Ingress resources for services 5. Monitor certificate status</p> <p>For future enhancements: - Integrate with external-dns for automatic DNS management - Add WAF integration with Azure Application Gateway - Configure rate limiting policies - Add custom error pages - Implement geo-routing</p>"},{"location":"azure-ingress-implementation-summary/#related-documentation","title":"Related Documentation","text":"<ul> <li>Azure Ingress Setup Guide</li> <li>Quick Start Guide</li> <li>nginx-ingress README</li> <li>cert-manager README</li> <li>BDD Tests</li> </ul>"},{"location":"azure-ingress-implementation-summary/#conclusion","title":"Conclusion","text":"<p>This implementation provides a production-ready solution for external access to the Fawkes platform on Azure AKS with: - Automatic Load Balancer configuration - High availability and auto-scaling - Automated TLS certificate management - Comprehensive monitoring - Complete documentation</p> <p>All acceptance criteria have been met, and the solution follows Fawkes architecture principles and best practices.</p>"},{"location":"azure-ingress-quickstart/","title":"Quick Start: Azure Ingress &amp; TLS Setup","text":"<p>This is a quick reference guide for deploying nginx-ingress and cert-manager on Azure AKS.</p>"},{"location":"azure-ingress-quickstart/#prerequisites","title":"Prerequisites","text":"<p>\u2705 Azure AKS cluster provisioned \u2705 kubectl configured \u2705 ArgoCD installed (optional)</p>"},{"location":"azure-ingress-quickstart/#1-deploy-nginx-ingress-5-minutes","title":"1. Deploy nginx-ingress (5 minutes)","text":"<pre><code># Apply ArgoCD Application\nkubectl apply -f platform/apps/ingress-nginx/ingress-nginx-azure-application.yaml\n\n# Wait for deployment\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/ingress-nginx-controller -n ingress-nginx\n\n# Get external IP (may take 2-3 minutes)\nkubectl get svc ingress-nginx-controller -n ingress-nginx -w\n</code></pre> <p>Validation: <pre><code>./platform/apps/ingress-nginx/validate-azure.sh\n</code></pre></p>"},{"location":"azure-ingress-quickstart/#2-configure-dns-optional-10-minutes","title":"2. Configure DNS (Optional, 10 minutes)","text":"<pre><code># Edit infra/azure/terraform.tfvars\ndns_zone_name = \"fawkes.yourdomain.com\"\ncreate_dns_records = true\n\n# Apply Terraform\ncd infra/azure\nterraform apply\n\n# Get nameservers for delegation\nterraform output dns_zone_name_servers\n</code></pre> <p>Update your domain registrar with the nameservers from the output.</p>"},{"location":"azure-ingress-quickstart/#3-deploy-cert-manager-5-minutes","title":"3. Deploy cert-manager (5 minutes)","text":"<pre><code># Deploy cert-manager\nkubectl apply -f platform/apps/cert-manager/cert-manager-application.yaml\n\n# Wait for cert-manager\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/cert-manager -n cert-manager\n\n# Update email address\nsed -i 's/platform-team@example.com/your-email@example.com/g' \\\n  platform/apps/cert-manager/cluster-issuer-*.yaml\n\n# Deploy ClusterIssuers\nkubectl apply -f platform/apps/cert-manager/cluster-issuer-letsencrypt-staging.yaml\nkubectl apply -f platform/apps/cert-manager/cluster-issuer-letsencrypt-prod.yaml\n</code></pre> <p>Validation: <pre><code>./platform/apps/cert-manager/validate.sh\n</code></pre></p>"},{"location":"azure-ingress-quickstart/#4-test-with-echo-server-5-minutes","title":"4. Test with Echo Server (5 minutes)","text":"<pre><code># Deploy test app\nkubectl apply -f platform/apps/ingress-nginx/test-ingress.yaml\n\n# Get external IP\nEXTERNAL_IP=$(kubectl get svc ingress-nginx-controller -n ingress-nginx \\\n  -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n\n# Test HTTP\ncurl http://test.${EXTERNAL_IP}.nip.io\n</code></pre>"},{"location":"azure-ingress-quickstart/#5-request-tls-certificate-5-minutes","title":"5. Request TLS Certificate (5 minutes)","text":"<p>Create ingress with cert-manager annotation:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-staging\"\nspec:\n  ingressClassName: nginx\n  tls:\n    - hosts:\n        - myapp.fawkes.yourdomain.com\n      secretName: myapp-tls\n  rules:\n    - host: myapp.fawkes.yourdomain.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp\n                port:\n                  number: 80\n</code></pre> <p>Watch certificate creation: <pre><code>kubectl get certificate -A -w\n</code></pre></p> <p>Once verified, switch to production: <pre><code>kubectl annotate ingress myapp \\\n  cert-manager.io/cluster-issuer=letsencrypt-prod --overwrite\n</code></pre></p>"},{"location":"azure-ingress-quickstart/#common-issues","title":"Common Issues","text":""},{"location":"azure-ingress-quickstart/#external-ip-pending","title":"External IP Pending","text":"<p>Wait 2-3 minutes. Azure Load Balancer creation takes time.</p>"},{"location":"azure-ingress-quickstart/#certificate-not-issuing","title":"Certificate Not Issuing","text":"<ol> <li>Check DNS points to ingress IP: <code>dig myapp.fawkes.yourdomain.com</code></li> <li>Check challenge: <code>kubectl get challenge -A</code></li> <li>Check logs: <code>kubectl logs -n cert-manager deployment/cert-manager</code></li> </ol>"},{"location":"azure-ingress-quickstart/#404-not-found","title":"404 Not Found","text":"<ol> <li>Check ingress: <code>kubectl get ingress -A</code></li> <li>Check backend service: <code>kubectl get svc myapp</code></li> <li>Check controller logs: <code>kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller</code></li> </ol>"},{"location":"azure-ingress-quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configure monitoring: See <code>docs/azure-ingress-setup.md</code></li> <li>Add more services: Update ingress resources</li> <li>Wildcard certificates: Configure Azure DNS issuer</li> <li>Static IP: See <code>platform/apps/ingress-nginx/README.md</code></li> </ul>"},{"location":"azure-ingress-quickstart/#full-documentation","title":"Full Documentation","text":"<ul> <li>Azure Ingress Setup Guide</li> <li>nginx-ingress README</li> <li>cert-manager README</li> <li>BDD Tests</li> </ul>"},{"location":"azure-ingress-setup/","title":"Azure Load Balancer and Ingress Setup Guide","text":"<p>This guide walks through the complete setup of Azure Load Balancer, nginx-ingress controller, and cert-manager for the Fawkes platform on Azure AKS.</p>"},{"location":"azure-ingress-setup/#architecture-overview","title":"Architecture Overview","text":"<pre><code>Internet\n    \u2193\nAzure Load Balancer (Standard SKU)\n    \u2193\nnginx-ingress-controller (2+ pods)\n    \u2193\nKubernetes Services (backstage, jenkins, etc.)\n</code></pre>"},{"location":"azure-ingress-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Azure AKS cluster provisioned (see Azure AKS Provisioning)</li> <li><code>kubectl</code> configured for the cluster</li> <li>ArgoCD installed (optional, for GitOps deployment)</li> <li>Azure CLI installed (for DNS and resource verification)</li> </ul>"},{"location":"azure-ingress-setup/#components","title":"Components","text":""},{"location":"azure-ingress-setup/#1-nginx-ingress-controller","title":"1. nginx-ingress Controller","text":"<p>The nginx-ingress controller provides: - Layer 7 HTTP/HTTPS routing - TLS termination - Load balancing across service pods - High availability with multiple replicas - Auto-scaling based on CPU/memory - Prometheus metrics</p>"},{"location":"azure-ingress-setup/#2-azure-load-balancer","title":"2. Azure Load Balancer","text":"<p>Azure automatically creates a Standard SKU Load Balancer when you deploy a LoadBalancer service: - Public IP assignment - Health probes - Port forwarding (80, 443) - Session affinity - Zone redundancy (in supported regions)</p>"},{"location":"azure-ingress-setup/#3-cert-manager","title":"3. cert-manager","text":"<p>Automates TLS certificate management: - Let's Encrypt integration - Automatic certificate issuance and renewal - HTTP-01 and DNS-01 challenge support - Azure DNS integration for wildcard certificates</p>"},{"location":"azure-ingress-setup/#deployment-steps","title":"Deployment Steps","text":""},{"location":"azure-ingress-setup/#step-1-deploy-nginx-ingress-controller","title":"Step 1: Deploy nginx-ingress Controller","text":""},{"location":"azure-ingress-setup/#option-a-using-argocd-recommended","title":"Option A: Using ArgoCD (Recommended)","text":"<pre><code># Apply the ArgoCD Application\nkubectl apply -f platform/apps/ingress-nginx/ingress-nginx-azure-application.yaml\n\n# Check ArgoCD sync status\nkubectl get application ingress-nginx -n fawkes\n</code></pre>"},{"location":"azure-ingress-setup/#option-b-using-helm","title":"Option B: Using Helm","text":"<pre><code># Add the nginx-ingress Helm repository\nhelm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\nhelm repo update\n\n# Install with Azure values\nhelm install ingress-nginx ingress-nginx/ingress-nginx \\\n  --namespace ingress-nginx \\\n  --create-namespace \\\n  -f platform/apps/ingress-nginx/values-azure.yaml\n</code></pre>"},{"location":"azure-ingress-setup/#verify-deployment","title":"Verify Deployment","text":"<pre><code># Run validation script\n./platform/apps/ingress-nginx/validate-azure.sh\n\n# Check pods\nkubectl get pods -n ingress-nginx\n\n# Check service and get external IP\nkubectl get svc ingress-nginx-controller -n ingress-nginx\n\n# Wait for external IP to be assigned (can take 2-3 minutes)\nkubectl wait --for=jsonpath='{.status.loadBalancer.ingress[0].ip}' \\\n  svc/ingress-nginx-controller -n ingress-nginx --timeout=300s\n</code></pre>"},{"location":"azure-ingress-setup/#step-2-configure-azure-dns-optional","title":"Step 2: Configure Azure DNS (Optional)","text":""},{"location":"azure-ingress-setup/#configure-terraform-variables","title":"Configure Terraform Variables","text":"<p>Edit <code>infra/azure/terraform.tfvars</code>:</p> <pre><code># Enable DNS zone creation\ndns_zone_name = \"fawkes.yourdomain.com\"\n\n# Set to true after ingress-nginx is deployed\ncreate_dns_records = true\n\n# Default name of the public IP (or your custom static IP name)\ningress_public_ip_name = \"kubernetes\"\n</code></pre>"},{"location":"azure-ingress-setup/#apply-terraform","title":"Apply Terraform","text":"<pre><code>cd infra/azure\n\n# Initialize Terraform (if not done already)\nterraform init\n\n# Plan to see what will be created\nterraform plan\n\n# Apply changes\nterraform apply\n\n# Get nameservers for DNS delegation\nterraform output dns_zone_name_servers\n</code></pre>"},{"location":"azure-ingress-setup/#delegate-dns-at-your-domain-registrar","title":"Delegate DNS (at your domain registrar)","text":"<p>Update your domain's nameservers with the values from the Terraform output.</p>"},{"location":"azure-ingress-setup/#verify-dns","title":"Verify DNS","text":"<pre><code># Wait for DNS propagation (can take up to 48 hours)\ndig jenkins.fawkes.yourdomain.com\ndig focalboard.fawkes.yourdomain.com\n\n# Should resolve to your ingress external IP\n</code></pre>"},{"location":"azure-ingress-setup/#step-3-deploy-cert-manager","title":"Step 3: Deploy cert-manager","text":""},{"location":"azure-ingress-setup/#deploy-cert-manager","title":"Deploy cert-manager","text":"<pre><code># Apply the ArgoCD Application\nkubectl apply -f platform/apps/cert-manager/cert-manager-application.yaml\n\n# Wait for cert-manager to be ready\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/cert-manager -n cert-manager\n\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/cert-manager-webhook -n cert-manager\n\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/cert-manager-cainjector -n cert-manager\n</code></pre>"},{"location":"azure-ingress-setup/#configure-clusterissuers","title":"Configure ClusterIssuers","text":"<pre><code># Update email address in issuer files\nsed -i 's/platform-team@example.com/your-email@example.com/g' \\\n  platform/apps/cert-manager/cluster-issuer-*.yaml\n\n# Apply ClusterIssuers\nkubectl apply -f platform/apps/cert-manager/cluster-issuer-letsencrypt-staging.yaml\nkubectl apply -f platform/apps/cert-manager/cluster-issuer-letsencrypt-prod.yaml\n\n# Verify issuers are ready\nkubectl get clusterissuer\nkubectl describe clusterissuer letsencrypt-prod\n</code></pre>"},{"location":"azure-ingress-setup/#verify-cert-manager","title":"Verify cert-manager","text":"<pre><code># Run validation script\n./platform/apps/cert-manager/validate.sh\n\n# Check CRDs\nkubectl get crd | grep cert-manager\n</code></pre>"},{"location":"azure-ingress-setup/#step-4-test-with-sample-application","title":"Step 4: Test with Sample Application","text":""},{"location":"azure-ingress-setup/#deploy-test-echo-server","title":"Deploy Test Echo Server","text":"<pre><code># Deploy test ingress with echo server\nkubectl apply -f platform/apps/ingress-nginx/test-ingress.yaml\n\n# Get external IP\nEXTERNAL_IP=$(kubectl get svc ingress-nginx-controller -n ingress-nginx \\\n  -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n\necho \"External IP: $EXTERNAL_IP\"\n</code></pre>"},{"location":"azure-ingress-setup/#test-http-access","title":"Test HTTP Access","text":"<pre><code># Test with nip.io (no DNS required)\ncurl http://test.${EXTERNAL_IP}.nip.io\n\n# Or with custom domain (if DNS is configured)\ncurl http://test.fawkes.yourdomain.com\n</code></pre>"},{"location":"azure-ingress-setup/#request-tls-certificate","title":"Request TLS Certificate","text":"<p>Create an Ingress with cert-manager annotation:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: test-app-tls\n  namespace: ingress-test\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-staging  # Use staging first!\nspec:\n  ingressClassName: nginx\n  tls:\n    - hosts:\n        - test.fawkes.yourdomain.com\n      secretName: test-app-tls\n  rules:\n    - host: test.fawkes.yourdomain.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: echo-server\n                port:\n                  number: 80\n</code></pre> <pre><code># Apply the ingress\nkubectl apply -f test-ingress-tls.yaml\n\n# Watch certificate creation\nkubectl get certificate -n ingress-test -w\n\n# Check certificate details\nkubectl describe certificate test-app-tls -n ingress-test\n\n# Once ready, test HTTPS\ncurl https://test.fawkes.yourdomain.com\n</code></pre>"},{"location":"azure-ingress-setup/#switch-to-production-issuer","title":"Switch to Production Issuer","text":"<p>Once verified with staging:</p> <pre><code># Update annotation to use production issuer\nkubectl annotate ingress test-app-tls -n ingress-test \\\n  cert-manager.io/cluster-issuer=letsencrypt-prod --overwrite\n\n# Delete the staging certificate to trigger re-issuance\nkubectl delete certificate test-app-tls -n ingress-test\nkubectl delete secret test-app-tls -n ingress-test\n</code></pre>"},{"location":"azure-ingress-setup/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"azure-ingress-setup/#static-public-ip","title":"Static Public IP","text":"<p>To use a pre-created static public IP:</p> <pre><code># Create public IP in node resource group\naz network public-ip create \\\n  --resource-group MC_fawkes-rg_fawkes-aks_eastus \\\n  --name fawkes-ingress-pip \\\n  --sku Standard \\\n  --allocation-method Static \\\n  --dns-name fawkes-ingress\n\n# Get the IP address\naz network public-ip show \\\n  --resource-group MC_fawkes-rg_fawkes-aks_eastus \\\n  --name fawkes-ingress-pip \\\n  --query ipAddress -o tsv\n\n# Update values-azure.yaml annotations:\n# service.beta.kubernetes.io/azure-load-balancer-resource-group: \"MC_fawkes-rg_fawkes-aks_eastus\"\n# service.beta.kubernetes.io/azure-pip-name: \"fawkes-ingress-pip\"\n</code></pre>"},{"location":"azure-ingress-setup/#wildcard-certificates-with-azure-dns","title":"Wildcard Certificates with Azure DNS","text":"<p>For wildcard certificates (e.g., <code>*.fawkes.yourdomain.com</code>):</p> <ol> <li>Configure Azure DNS ClusterIssuer:</li> </ol> <pre><code># Update cluster-issuer-letsencrypt-dns-azure.yaml with:\n# - Azure subscription ID\n# - Resource group\n# - DNS zone name\n# - Managed Identity client ID\n\nkubectl apply -f platform/apps/cert-manager/cluster-issuer-letsencrypt-dns-azure.yaml\n</code></pre> <ol> <li>Create wildcard certificate:</li> </ol> <pre><code>apiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: wildcard-tls\n  namespace: fawkes\nspec:\n  secretName: wildcard-tls\n  dnsNames:\n    - \"*.fawkes.yourdomain.com\"\n    - fawkes.yourdomain.com\n  issuerRef:\n    name: letsencrypt-dns-azure\n    kind: ClusterIssuer\n</code></pre>"},{"location":"azure-ingress-setup/#internal-load-balancer","title":"Internal Load Balancer","text":"<p>For private ingress (only accessible within VNet):</p> <p>Add annotation to service: <pre><code>service.beta.kubernetes.io/azure-load-balancer-internal: \"true\"\n</code></pre></p>"},{"location":"azure-ingress-setup/#proxy-protocol","title":"PROXY Protocol","text":"<p>If your Azure Load Balancer uses PROXY protocol:</p> <p>Update values-azure.yaml: <pre><code>config:\n  use-proxy-protocol: \"true\"\n</code></pre></p>"},{"location":"azure-ingress-setup/#monitoring","title":"Monitoring","text":""},{"location":"azure-ingress-setup/#prometheus-metrics","title":"Prometheus Metrics","text":"<pre><code># Port-forward to metrics endpoint\nkubectl port-forward -n ingress-nginx \\\n  svc/ingress-nginx-controller-metrics 9402:10254\n\n# Query metrics\ncurl http://localhost:9402/metrics | grep nginx_ingress\n</code></pre>"},{"location":"azure-ingress-setup/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Import the official nginx-ingress dashboard: - Dashboard ID: 9614 (from grafana.com)</p>"},{"location":"azure-ingress-setup/#alerts","title":"Alerts","text":"<p>PrometheusRules are configured for: - Controller down alert - High error rate alert - Certificate expiration alert (via cert-manager)</p>"},{"location":"azure-ingress-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"azure-ingress-setup/#external-ip-not-assigned","title":"External IP Not Assigned","text":"<pre><code># Check service events\nkubectl describe svc ingress-nginx-controller -n ingress-nginx\n\n# Check Azure Load Balancer\naz network lb list --resource-group MC_fawkes-rg_fawkes-aks_*\n\n# Check if quota is exceeded\naz vm list-usage --location eastus -o table\n</code></pre>"},{"location":"azure-ingress-setup/#ingress-not-accessible","title":"Ingress Not Accessible","text":"<pre><code># Check controller logs\nkubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller --tail=100\n\n# Check ingress resource\nkubectl describe ingress &lt;name&gt; -n &lt;namespace&gt;\n\n# Verify IngressClass\nkubectl get ingressclass\n</code></pre>"},{"location":"azure-ingress-setup/#certificate-not-issuing","title":"Certificate Not Issuing","text":"<pre><code># Check certificate status\nkubectl describe certificate &lt;name&gt; -n &lt;namespace&gt;\n\n# Check certificate request\nkubectl get certificaterequest -n &lt;namespace&gt;\n\n# Check ACME challenge\nkubectl get challenge -n &lt;namespace&gt;\nkubectl describe challenge &lt;name&gt; -n &lt;namespace&gt;\n\n# Check cert-manager logs\nkubectl logs -n cert-manager deployment/cert-manager --tail=100\n</code></pre>"},{"location":"azure-ingress-setup/#dns-not-resolving","title":"DNS Not Resolving","text":"<pre><code># Check DNS records in Azure\naz network dns record-set a list \\\n  --resource-group fawkes-rg \\\n  --zone-name fawkes.yourdomain.com\n\n# Test DNS resolution\ndig +short test.fawkes.yourdomain.com\n\n# Check nameserver delegation\ndig NS fawkes.yourdomain.com\n</code></pre>"},{"location":"azure-ingress-setup/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Use Production Certificates: Always test with staging issuer first</li> <li>Enable HSTS: Force HTTPS with strict transport security</li> <li>Restrict Access: Use Azure Network Security Groups</li> <li>Monitor Certificates: Set up alerts for expiring certificates</li> <li>Use Strong TLS: Disable weak cipher suites</li> <li>Rate Limiting: Configure rate limits in nginx</li> <li>WAF Integration: Consider Azure Application Gateway with WAF</li> </ol>"},{"location":"azure-ingress-setup/#cost-optimization","title":"Cost Optimization","text":"<ul> <li>Standard Load Balancer: ~$18/month + data processing</li> <li>Public IP: ~$3/month</li> <li>DNS Zone: $0.50/zone + queries</li> <li>cert-manager: Free (Let's Encrypt)</li> </ul> <p>Total estimated cost: ~$22-25/month</p>"},{"location":"azure-ingress-setup/#reference-documentation","title":"Reference Documentation","text":"<ul> <li>nginx-ingress Controller</li> <li>cert-manager</li> <li>Azure Load Balancer</li> <li>Azure DNS</li> <li>Let's Encrypt</li> </ul>"},{"location":"azure-ingress-validation-checklist/","title":"Validation Checklist: Azure Load Balancer and Ingress","text":"<p>Use this checklist to verify your Azure Load Balancer and Ingress deployment.</p>"},{"location":"azure-ingress-validation-checklist/#prerequisites-validation","title":"Prerequisites Validation","text":"<ul> <li>[ ] Azure AKS cluster is running</li> <li>[ ] kubectl is configured and connected to the cluster</li> <li>[ ] ArgoCD is installed (optional, for GitOps deployment)</li> <li>[ ] Azure CLI is installed (for DNS and resource verification)</li> </ul>"},{"location":"azure-ingress-validation-checklist/#task-21-nginx-ingress-controller","title":"Task 2.1: nginx-ingress Controller","text":""},{"location":"azure-ingress-validation-checklist/#deployment","title":"Deployment","text":"<ul> <li> <p>[ ] Applied ingress-nginx ArgoCD Application:   <pre><code>kubectl apply -f platform/apps/ingress-nginx/ingress-nginx-azure-application.yaml\n</code></pre></p> </li> <li> <p>[ ] Namespace created:   <pre><code>kubectl get namespace ingress-nginx\n# Expected: ingress-nginx namespace exists\n</code></pre></p> </li> <li> <p>[ ] Deployment is ready:   <pre><code>kubectl get deployment ingress-nginx-controller -n ingress-nginx\n# Expected: 2/2 READY\n</code></pre></p> </li> <li> <p>[ ] Pods are running:   <pre><code>kubectl get pods -n ingress-nginx\n# Expected: 2+ controller pods in Running state\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#load-balancer-configuration","title":"Load Balancer Configuration","text":"<ul> <li> <p>[ ] Service type is LoadBalancer:   <pre><code>kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.type}'\n# Expected: LoadBalancer\n</code></pre></p> </li> <li> <p>[ ] External IP is assigned:   <pre><code>kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}'\n# Expected: IP address (not &lt;pending&gt;)\n</code></pre></p> </li> <li> <p>[ ] Azure Load Balancer health probe is configured:   <pre><code>kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.metadata.annotations.service\\.beta\\.kubernetes\\.io/azure-load-balancer-health-probe-request-path}'\n# Expected: /healthz\n</code></pre></p> </li> <li> <p>[ ] External traffic policy is Local:   <pre><code>kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.externalTrafficPolicy}'\n# Expected: Local\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#high-availability","title":"High Availability","text":"<ul> <li> <p>[ ] HorizontalPodAutoscaler is configured:   <pre><code>kubectl get hpa ingress-nginx-controller -n ingress-nginx\n# Expected: HPA exists with min=2, max=10\n</code></pre></p> </li> <li> <p>[ ] Pod anti-affinity is configured:   <pre><code>kubectl get deployment ingress-nginx-controller -n ingress-nginx -o jsonpath='{.spec.template.spec.affinity}'\n# Expected: podAntiAffinity configuration present\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#metrics-and-monitoring","title":"Metrics and Monitoring","text":"<ul> <li> <p>[ ] Metrics service exists:   <pre><code>kubectl get svc ingress-nginx-controller-metrics -n ingress-nginx\n# Expected: Service exists\n</code></pre></p> </li> <li> <p>[ ] ServiceMonitor is created (requires Prometheus Operator):   <pre><code>kubectl get servicemonitor ingress-nginx-controller -n ingress-nginx\n# Expected: ServiceMonitor exists (or skip if Prometheus Operator not installed)\n</code></pre></p> </li> <li> <p>[ ] PrometheusRule is created:   <pre><code>kubectl get prometheusrule ingress-nginx -n ingress-nginx\n# Expected: PrometheusRule exists (or skip if Prometheus Operator not installed)\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#validation-script","title":"Validation Script","text":"<ul> <li>[ ] Run validation script:   <pre><code>./platform/apps/ingress-nginx/validate-azure.sh\n# Expected: All checks pass\n</code></pre></li> </ul>"},{"location":"azure-ingress-validation-checklist/#azure-resources","title":"Azure Resources","text":"<ul> <li>[ ] Azure Load Balancer exists (requires Azure CLI):   <pre><code>az network lb list --resource-group MC_fawkes-rg_fawkes-aks_eastus -o table\n# Expected: Load Balancer listed with kubernetes prefix\n</code></pre></li> </ul>"},{"location":"azure-ingress-validation-checklist/#task-22-azure-dns-optional","title":"Task 2.2: Azure DNS (Optional)","text":""},{"location":"azure-ingress-validation-checklist/#terraform-configuration","title":"Terraform Configuration","text":"<ul> <li> <p>[ ] DNS variables configured in <code>infra/azure/terraform.tfvars</code>:   <pre><code>dns_zone_name = \"fawkes.yourdomain.com\"\ncreate_dns_records = true\n</code></pre></p> </li> <li> <p>[ ] Terraform initialized:   <pre><code>cd infra/azure &amp;&amp; terraform init\n# Expected: Success\n</code></pre></p> </li> <li> <p>[ ] Terraform planned:   <pre><code>terraform plan\n# Expected: Shows DNS zone and A records to be created\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#dns-deployment","title":"DNS Deployment","text":"<ul> <li> <p>[ ] Terraform applied:   <pre><code>terraform apply\n# Expected: DNS zone and A records created\n</code></pre></p> </li> <li> <p>[ ] DNS zone exists:   <pre><code>az network dns zone show -g fawkes-rg -n fawkes.yourdomain.com\n# Expected: DNS zone details\n</code></pre></p> </li> <li> <p>[ ] A records created:   <pre><code>az network dns record-set a list -g fawkes-rg -z fawkes.yourdomain.com -o table\n# Expected: @ and * records pointing to ingress IP\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#dns-delegation","title":"DNS Delegation","text":"<ul> <li> <p>[ ] Nameservers obtained:   <pre><code>terraform output dns_zone_name_servers\n# Expected: 4 Azure DNS nameservers\n</code></pre></p> </li> <li> <p>[ ] Domain registrar updated with nameservers</p> </li> <li> <p>[ ] DNS resolution working (may take up to 48 hours):   <pre><code>dig test.fawkes.yourdomain.com\n# Expected: Resolves to ingress IP\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#task-23-cert-manager","title":"Task 2.3: cert-manager","text":""},{"location":"azure-ingress-validation-checklist/#deployment_1","title":"Deployment","text":"<ul> <li> <p>[ ] Applied cert-manager ArgoCD Application:   <pre><code>kubectl apply -f platform/apps/cert-manager/cert-manager-application.yaml\n</code></pre></p> </li> <li> <p>[ ] Namespace created:   <pre><code>kubectl get namespace cert-manager\n# Expected: cert-manager namespace exists\n</code></pre></p> </li> <li> <p>[ ] Deployments are ready:   <pre><code>kubectl get deployment -n cert-manager\n# Expected: cert-manager, cert-manager-webhook, cert-manager-cainjector all ready\n</code></pre></p> </li> <li> <p>[ ] Pods are running:   <pre><code>kubectl get pods -n cert-manager\n# Expected: All pods in Running state\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#crds-installation","title":"CRDs Installation","text":"<ul> <li>[ ] CRDs are installed:   <pre><code>kubectl get crd | grep cert-manager\n# Expected: 6 CRDs (certificates, certificaterequests, challenges, clusterissuers, issuers, orders)\n</code></pre></li> </ul>"},{"location":"azure-ingress-validation-checklist/#clusterissuers-configuration","title":"ClusterIssuers Configuration","text":"<ul> <li> <p>[ ] Email address updated in ClusterIssuer files:   <pre><code>grep \"email:\" platform/apps/cert-manager/cluster-issuer-*.yaml\n# Expected: Your actual email, not platform-team@example.com\n</code></pre></p> </li> <li> <p>[ ] ClusterIssuers applied:   <pre><code>kubectl apply -f platform/apps/cert-manager/cluster-issuer-letsencrypt-staging.yaml\nkubectl apply -f platform/apps/cert-manager/cluster-issuer-letsencrypt-prod.yaml\n</code></pre></p> </li> <li> <p>[ ] ClusterIssuers are ready:   <pre><code>kubectl get clusterissuer\n# Expected: letsencrypt-staging and letsencrypt-prod both Ready=True\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#validation-script_1","title":"Validation Script","text":"<ul> <li>[ ] Run validation script:   <pre><code>./platform/apps/cert-manager/validate.sh\n# Expected: All checks pass\n</code></pre></li> </ul>"},{"location":"azure-ingress-validation-checklist/#testing","title":"Testing","text":""},{"location":"azure-ingress-validation-checklist/#test-ingress-deployment","title":"Test Ingress Deployment","text":"<ul> <li> <p>[ ] Deploy test echo server:   <pre><code>kubectl apply -f platform/apps/ingress-nginx/test-ingress.yaml\n</code></pre></p> </li> <li> <p>[ ] Test namespace created:   <pre><code>kubectl get namespace ingress-test\n# Expected: Namespace exists\n</code></pre></p> </li> <li> <p>[ ] Echo server running:   <pre><code>kubectl get pods -n ingress-test\n# Expected: echo-server pod in Running state\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#http-testing","title":"HTTP Testing","text":"<ul> <li> <p>[ ] Test HTTP access with nip.io:   <pre><code>EXTERNAL_IP=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\ncurl http://test.${EXTERNAL_IP}.nip.io\n# Expected: Echo server response (JSON with request details)\n</code></pre></p> </li> <li> <p>[ ] Test HTTP access with custom domain (if DNS configured):   <pre><code>curl http://test.fawkes.yourdomain.com\n# Expected: Echo server response\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#tls-certificate-testing","title":"TLS Certificate Testing","text":"<ul> <li> <p>[ ] Create test ingress with TLS:   <pre><code># Create ingress with cert-manager annotation\n# Use letsencrypt-staging first!\n</code></pre></p> </li> <li> <p>[ ] Certificate resource created:   <pre><code>kubectl get certificate -n ingress-test\n# Expected: Certificate resource exists\n</code></pre></p> </li> <li> <p>[ ] CertificateRequest created:   <pre><code>kubectl get certificaterequest -n ingress-test\n# Expected: CertificateRequest exists\n</code></pre></p> </li> <li> <p>[ ] Certificate issued (may take 1-2 minutes):   <pre><code>kubectl get certificate -n ingress-test -o jsonpath='{.items[0].status.conditions[?(@.type==\"Ready\")].status}'\n# Expected: True\n</code></pre></p> </li> <li> <p>[ ] TLS secret created:   <pre><code>kubectl get secret -n ingress-test | grep tls\n# Expected: TLS secret exists\n</code></pre></p> </li> <li> <p>[ ] Test HTTPS access:   <pre><code>curl https://test.fawkes.yourdomain.com\n# Expected: Successful HTTPS connection\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#azure-resources-verification","title":"Azure Resources Verification","text":""},{"location":"azure-ingress-validation-checklist/#load-balancer","title":"Load Balancer","text":"<ul> <li> <p>[ ] Load Balancer rules exist:   <pre><code>az network lb rule list --resource-group MC_fawkes-rg_fawkes-aks_eastus --lb-name kubernetes -o table\n# Expected: Rules for ports 80 and 443\n</code></pre></p> </li> <li> <p>[ ] Health probes configured:   <pre><code>az network lb probe list --resource-group MC_fawkes-rg_fawkes-aks_eastus --lb-name kubernetes -o table\n# Expected: Health probe for /healthz\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#public-ip","title":"Public IP","text":"<ul> <li>[ ] Public IP exists:   <pre><code>az network public-ip list --resource-group MC_fawkes-rg_fawkes-aks_eastus -o table\n# Expected: Public IP with kubernetes prefix\n</code></pre></li> </ul>"},{"location":"azure-ingress-validation-checklist/#monitoring-and-alerting","title":"Monitoring and Alerting","text":""},{"location":"azure-ingress-validation-checklist/#prometheus-metrics","title":"Prometheus Metrics","text":"<ul> <li> <p>[ ] Metrics endpoints accessible:   <pre><code>kubectl port-forward -n ingress-nginx svc/ingress-nginx-controller-metrics 9402:10254 &amp;\ncurl http://localhost:9402/metrics | grep nginx_ingress_controller_requests\n# Expected: Metrics data returned\n</code></pre></p> </li> <li> <p>[ ] cert-manager metrics accessible:   <pre><code>kubectl port-forward -n cert-manager svc/cert-manager 9402:9402 &amp;\ncurl http://localhost:9402/metrics | grep certmanager_certificate\n# Expected: Certificate metrics data\n</code></pre></p> </li> </ul>"},{"location":"azure-ingress-validation-checklist/#alerts","title":"Alerts","text":"<ul> <li>[ ] PrometheusRules configured:   <pre><code>kubectl get prometheusrule -n ingress-nginx\nkubectl get prometheusrule -n cert-manager\n# Expected: Rules for ingress and certificates\n</code></pre></li> </ul>"},{"location":"azure-ingress-validation-checklist/#documentation","title":"Documentation","text":"<ul> <li>[ ] Read setup guide: <code>docs/azure-ingress-setup.md</code></li> <li>[ ] Read quickstart guide: <code>docs/azure-ingress-quickstart.md</code></li> <li>[ ] Read implementation summary: <code>docs/azure-ingress-implementation-summary.md</code></li> <li>[ ] Read nginx-ingress README: <code>platform/apps/ingress-nginx/README.md</code></li> <li>[ ] Read cert-manager README: <code>platform/apps/cert-manager/README.md</code></li> </ul>"},{"location":"azure-ingress-validation-checklist/#common-issues-resolved","title":"Common Issues Resolved","text":"<p>If you encounter any issues, check the following:</p>"},{"location":"azure-ingress-validation-checklist/#external-ip-pending","title":"External IP Pending","text":"<ul> <li>Wait 2-3 minutes for Azure to provision the Load Balancer</li> <li>Check service events: <code>kubectl describe svc ingress-nginx-controller -n ingress-nginx</code></li> </ul>"},{"location":"azure-ingress-validation-checklist/#certificate-not-issuing","title":"Certificate Not Issuing","text":"<ul> <li>Verify DNS points to ingress IP: <code>dig +short yourapp.fawkes.yourdomain.com</code></li> <li>Check challenge status: <code>kubectl get challenge -A</code></li> <li>Check cert-manager logs: <code>kubectl logs -n cert-manager deployment/cert-manager</code></li> <li>Verify ClusterIssuer is ready: <code>kubectl describe clusterissuer letsencrypt-prod</code></li> </ul>"},{"location":"azure-ingress-validation-checklist/#404-not-found","title":"404 Not Found","text":"<ul> <li>Verify ingress resource: <code>kubectl describe ingress &lt;name&gt; -n &lt;namespace&gt;</code></li> <li>Check backend service exists: <code>kubectl get svc &lt;name&gt; -n &lt;namespace&gt;</code></li> <li>Check controller logs: <code>kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller</code></li> </ul>"},{"location":"azure-ingress-validation-checklist/#dns-not-resolving","title":"DNS Not Resolving","text":"<ul> <li>Wait up to 48 hours for DNS propagation</li> <li>Verify nameserver delegation: <code>dig NS fawkes.yourdomain.com</code></li> <li>Check Azure DNS records: <code>az network dns record-set a list -g fawkes-rg -z fawkes.yourdomain.com</code></li> </ul>"},{"location":"azure-ingress-validation-checklist/#final-verification","title":"Final Verification","text":"<p>All items checked? You're ready to use Azure Load Balancer and Ingress!</p> <p>Summary: - \u2705 nginx-ingress deployed with Azure Load Balancer - \u2705 Azure Load Balancer created with health probes - \u2705 Public IP assigned - \u2705 DNS configured (if enabled) - \u2705 cert-manager deployed - \u2705 Let's Encrypt ClusterIssuers configured - \u2705 Test ingress working - \u2705 TLS certificates issuing</p> <p>Next steps: 1. Deploy your application services 2. Create Ingress resources with cert-manager annotations 3. Monitor certificate status 4. Set up alerts for expiring certificates 5. Configure rate limiting and WAF (optional)</p>"},{"location":"business_case/","title":"Fawkes: Business Case &amp; Value Proposition","text":"<p>Document Purpose: Comprehensive business justification for AWS Activate partnership Target Audience: AWS Activate reviewers, potential investors, enterprise prospects Company Stage: Pre-seed, bootstrapped, open-source foundation Last Updated: October 7, 2025</p>"},{"location":"business_case/#executive-summary","title":"Executive Summary","text":"<p>Fawkes is an open-source Internal Delivery Platform (IDP) that transforms how organizations build and operate software delivery infrastructure. By combining best-in-class tooling (Backstage, Jenkins, ArgoCD, Kubernetes) with an integrated learning system (Fawkes Dojo), we're solving two critical problems simultaneously:</p> <ol> <li>Platform Engineering Skills Gap: There are 300K+ platform engineering job openings but few trained practitioners</li> <li>Platform Adoption Barrier: Organizations struggle to implement IDPs due to complexity and lack of expertise</li> </ol> <p>Our Solution: An AWS-native platform that teams can deploy in hours (not months) + a comprehensive learning system that trains the engineers who will operate it.</p> <p>Traction to Date: - \u2705 Complete platform architecture with 8 documented ADRs - \u2705 50+ pages of technical documentation - \u2705 5-belt Dojo curriculum (20 modules) designed and documented - \u2705 Open-source MIT license with active GitHub repository - \u2705 Partnership discussions with Platform Engineering University - \u2705 Growing community interest (early stage)</p> <p>AWS Activate Request: $25,000 in credits to: - Deploy production reference implementation on AWS - Launch Fawkes Dojo learning platform - Support 200+ concurrent learners - Enable 20+ enterprise pilots</p> <p>12-Month Goal: 500 GitHub stars, 200 certified learners, 20 enterprise adoptions, $10K MRR from managed services</p>"},{"location":"business_case/#problem-statement","title":"Problem Statement","text":""},{"location":"business_case/#the-platform-engineering-crisis","title":"The Platform Engineering Crisis","text":"<p>Organizations are hemorrhaging productivity and talent due to infrastructure complexity:</p> <p>The Skills Gap: - 300,000+ platform engineering jobs unfilled globally (LinkedIn, 2024) - Average time to hire a platform engineer: 4-6 months - 73% of engineering leaders cite \"platform skills\" as top constraint (Gartner, 2024) - Zero comprehensive training programs exist for platform engineering</p> <p>The Adoption Challenge: - Average time to deploy an IDP: 6-12 months - 68% of platform initiatives fail due to complexity (McKinsey, 2023) - Organizations spend $500K-$2M+ building custom platforms - Most platforms abandoned after 18 months (lack of adoption)</p> <p>The Business Impact:</p> <p>According to DORA research (2023): - Low performers deploy 417x less frequently than elite performers - Lead time for changes: 6,570x longer for low performers - Organizations lose $1-2M annually in developer productivity - 35% annual developer turnover due to poor tooling/processes</p> <p>Real-World Example:</p> <p>A typical 200-person engineering organization: - 100 developers spending 70% of time on non-value-added activities - Lost productivity: 70 FTE \u00d7 $150K loaded cost = $10.5M/year - Opportunity cost: Features not built, markets not entered - Talent drain: Top performers leave for companies with better platforms</p>"},{"location":"business_case/#why-current-solutions-fail","title":"Why Current Solutions Fail","text":"<p>Commercial Platforms (Humanitec, Kratix, etc.): - \u274c Expensive ($50K-$200K/year per team) - \u274c Vendor lock-in and proprietary APIs - \u274c Limited customization for specific needs - \u274c No learning/training included</p> <p>DIY Approaches: - \u274c Take 12-18 months to build - \u274c Require 3-5 FTE platform engineers - \u274c Often abandoned due to complexity - \u274c No standardization across industry</p> <p>Training Programs: - \u274c Fragmented (blog posts, scattered courses) - \u274c Theory-only (no hands-on practice) - \u274c Expensive ($3K-$10K per person) - \u274c Not connected to real platform implementation</p>"},{"location":"business_case/#the-market-opportunity","title":"The Market Opportunity","text":"<p>Platform Engineering Market Size: - Current: $4.2B (2024) - Projected: $12.8B by 2028 (35% CAGR) - Source: Gartner Platform Engineering Market Analysis</p> <p>Target Addressable Market: - Primary: 50,000 mid-size companies (100-5,000 employees) undergoing digital transformation - Secondary: 100,000 startups scaling engineering teams (20-100 engineers) - Tertiary: 5,000 enterprises seeking inner-source platform solutions</p> <p>Revenue Opportunity: - Managed Service: $500-$2,000/month per organization - Enterprise Support: $50K-$200K/year contracts - Training/Certification: $500-$1,000 per learner - Consulting: $200-$300/hour implementation services</p>"},{"location":"business_case/#solution-fawkes-platform-dojo","title":"Solution: Fawkes Platform + Dojo","text":""},{"location":"business_case/#what-is-fawkes","title":"What is Fawkes?","text":"<p>Fawkes is a production-ready, open-source Internal Delivery Platform that provides:</p> <p>For Organizations: - \ud83d\ude80 Deploy complete IDP in hours (not months) - \ud83d\udd27 Best-practice configuration out of the box - \ud83d\udcca Automated DORA metrics collection and visualization - \ud83d\udd10 Security and compliance baked in (DevSecOps) - \u2601\ufe0f AWS-native with multi-cloud roadmap - \ud83d\udcda Comprehensive documentation and support</p> <p>For Engineers: - \ud83c\udf93 Learn platform engineering through hands-on Dojo system - \ud83e\udd4b Progress through 5 belt levels (White \u2192 Yellow \u2192 Green \u2192 Brown \u2192 Black) - \ud83c\udfc6 Earn recognized certifications valued by employers - \ud83d\udc65 Join supportive community of practitioners - \ud83d\udcbc Increase earning potential (platform engineers earn 20-30% more)</p>"},{"location":"business_case/#core-technology-stack","title":"Core Technology Stack","text":"<p>Developer Experience: - Backstage: Service catalog and developer portal (by Spotify) - TechDocs: Integrated documentation - Golden Path Templates: Scaffolding for new services</p> <p>CI/CD &amp; Deployment: - Jenkins: Continuous integration pipelines - ArgoCD: GitOps-based continuous deployment - Harbor: Container registry and artifact management</p> <p>Infrastructure: - Kubernetes/EKS: Container orchestration - Terraform: Infrastructure as Code - Helm: Package management</p> <p>Observability: - Prometheus &amp; Grafana: Metrics and dashboards - OpenSearch: Log aggregation and analysis - Grafana Tempo: Distributed tracing - Custom DORA metrics automation</p> <p>Collaboration: - Mattermost: Team communication - Focalboard: Project tracking and kanban boards</p> <p>Security: - Trivy: Container vulnerability scanning - Kyverno: Policy enforcement - AWS Secrets Manager: Secrets management</p>"},{"location":"business_case/#the-fawkes-dojo-immersive-learning-system","title":"The Fawkes Dojo: Immersive Learning System","text":"<p>Unique Value Proposition: The only platform that includes comprehensive learning.</p> <p>5-Belt Progression System:</p> <p>\ud83e\udd4b White Belt (8 hours): Platform Fundamentals - What IDPs are and why they matter - DORA metrics deep-dive - First deployment on Fawkes - Certification: \"Fawkes Platform Operator\"</p> <p>\ud83d\udfe1 Yellow Belt (8 hours): CI/CD Mastery - Build custom Jenkins pipelines - Security scanning and quality gates - Artifact management - Certification: \"Fawkes CI/CD Specialist\"</p> <p>\ud83d\udfe2 Green Belt (8 hours): GitOps &amp; Deployment - ArgoCD and GitOps workflows - Blue-green and canary deployments - Multi-environment management - Certification: \"Fawkes Deployment Engineer\"</p> <p>\ud83d\udfe4 Brown Belt (8 hours): Observability &amp; SRE - Full observability stack implementation - DORA metrics dashboards - SLIs, SLOs, and error budgets - Incident response - Certification: \"Fawkes SRE Practitioner\"</p> <p>\u26ab Black Belt (8 hours): Platform Architecture - Design platforms for new organizations - Multi-tenancy and governance - Security architecture - Mentor others - Certification: \"Fawkes Platform Architect\"</p> <p>Total Time Investment: 40 hours (1 week full-time or 5 weeks part-time)</p> <p>Learning Features: - \u2705 Hands-on labs in isolated Kubernetes namespaces - \u2705 Auto-graded exercises with immediate feedback - \u2705 Video content + written documentation - \u2705 Real tools (not toy examples) - \u2705 Community support via Mattermost - \u2705 Recognized digital badges and certificates</p>"},{"location":"business_case/#competitive-advantages","title":"Competitive Advantages","text":"Feature Fawkes Commercial IDPs DIY Approach Cost Free (open source) $50K-$200K/year $300K-$1M to build Time to Deploy Hours Weeks 6-12 months Learning Included \u2705 Comprehensive Dojo \u274c None \u274c None AWS-Native \u2705 Optimized \u26a0\ufe0f Generic cloud \u26a0\ufe0f Varies Customization \u2705 Full control \u274c Limited \u2705 Full control Community \u2705 Open source \u274c Vendor support only \u274c None DORA Metrics \u2705 Automated \u26a0\ufe0f Basic \u274c DIY Vendor Lock-in \u2705 None (MIT) \u274c High \u2705 None"},{"location":"business_case/#business-model","title":"Business Model","text":""},{"location":"business_case/#revenue-streams-roadmap","title":"Revenue Streams (Roadmap)","text":"<p>Phase 1: Open Source Foundation (Current - Months 1-6) - Focus: Build community, validate product-market fit - Revenue: $0 (investment in ecosystem) - Success Metrics: GitHub stars, contributors, adoptions</p> <p>Phase 2: Managed Service (SaaS) (Months 7-12) - Offering: Hosted Fawkes platform managed by core team - Pricing: $500-$2,000/month per organization - Target: 10-20 pilot customers - Revenue Target: $10K MRR by month 12</p> <p>Phase 3: Enterprise Support &amp; Consulting (Year 2) - Support Contracts: $50K-$200K/year   - 24/7 support   - Custom feature development   - Dedicated success manager - Implementation Services: $200-$300/hour   - Platform customization   - Migration from legacy systems   - Training and workshops - Revenue Target: $500K ARR by end of year 2</p> <p>Phase 4: Certification &amp; Training (Year 2-3) - Individual Certification: $299-$499 per belt - Corporate Training: $5K-$10K per cohort (10-20 people) - Train-the-Trainer: $50K enterprise licensing - Revenue Target: $200K ARR from training by year 3</p> <p>Phase 5: Ecosystem Expansion (Year 3+) - Marketplace: Platform extensions and integrations (20% commission) - Partnerships: Reseller agreements with consultancies - Advanced Features: Premium modules for enterprise (compliance, audit, advanced security) - Revenue Target: $2M+ ARR by year 3</p>"},{"location":"business_case/#customer-acquisition-strategy","title":"Customer Acquisition Strategy","text":"<p>Inbound (Primary): 1. Open Source Community:    - GitHub repository with excellent documentation    - Weekly blog posts on platform engineering topics    - Conference talks and webinars    - YouTube tutorials and demos</p> <ol> <li>Dojo Learning Platform:</li> <li>Free access drives platform adoption</li> <li>Certified learners become advocates in their organizations</li> <li> <p>Job placement partnerships create network effects</p> </li> <li> <p>SEO &amp; Content Marketing:</p> </li> <li>Technical guides ranking for \"how to build IDP\"</li> <li>DORA metrics calculators and tools</li> <li>Platform engineering best practices content</li> </ol> <p>Outbound (Secondary): 1. Enterprise Pilots:    - Identify 50 target accounts (Fortune 2000)    - Offer free managed service pilot (3 months)    - Convert 20% to paid customers</p> <ol> <li>Platform Engineering University Partnership:</li> <li>Co-branded certification program</li> <li>Joint webinars and events</li> <li> <p>Shared student pipeline</p> </li> <li> <p>AWS Marketplace:</p> </li> <li>List Fawkes managed service on AWS Marketplace</li> <li>Leverage AWS seller network</li> <li>Qualify for AWS co-sell programs</li> </ol>"},{"location":"business_case/#unit-economics-managed-service","title":"Unit Economics (Managed Service)","text":"<p>Customer Acquisition Cost (CAC): - Inbound (organic): $500-$1,000 per customer - Outbound (sales): $5,000-$10,000 per customer - Blended CAC Target: $2,000</p> <p>Annual Contract Value (ACV): - Starter Plan: $6K/year ($500/month) - Growth Plan: $12K/year ($1,000/month) - Enterprise Plan: $24K+/year ($2,000+/month) - Average ACV: $12K</p> <p>Gross Margin: - AWS Infrastructure: $3,200/year per customer - Support Costs (10% engineering time): $2,000/year - Gross Margin: 57%</p> <p>Lifetime Value (LTV): - Average Customer Lifetime: 3-5 years - Churn Rate (target): 10% annually - LTV: $12K \u00d7 4 years \u00d7 0.57 margin = $27,360</p> <p>LTV:CAC Ratio: 13.7:1 (target &gt; 3:1) \u2705</p> <p>Payback Period: 2.3 months (target &lt; 12 months) \u2705</p>"},{"location":"business_case/#why-aws-activate-credits-matter","title":"Why AWS Activate Credits Matter","text":""},{"location":"business_case/#current-constraints","title":"Current Constraints","text":"<p>Bootstrap Reality: - Funding: $0 institutional investment (self-funded) - Team: 1-2 core contributors + community - Infrastructure: Using personal AWS accounts ($100-200/month) - Growth Blockers:   - Cannot afford 3-environment setup for production validation   - Cannot provide demo environments for prospects   - Cannot launch Dojo platform at scale   - Cannot support community contributor testing</p> <p>The Chicken-and-Egg Problem: - Need production deployment to attract enterprise customers - Need enterprise customers to afford infrastructure - Need infrastructure to train community - Need trained community to build credibility</p> <p>AWS Activate Breaks This Cycle \ud83d\ude80</p>"},{"location":"business_case/#credit-utilization-plan","title":"Credit Utilization Plan","text":"<p>Phase 1: Foundation (Months 1-3) - $5,000 credits</p> <p>Objectives: - Deploy production-grade reference implementation - Complete all AWS-specific documentation - Validate architecture at scale</p> <p>Deliverables: - 3-environment setup (dev/staging/prod) on EKS - Terraform modules for reproducible deployments - AWS deployment guide with troubleshooting - Cost optimization documentation - 5+ blog posts on AWS platform engineering</p> <p>AWS Services Used: - EKS clusters across 3 environments - RDS PostgreSQL instances - S3 for artifacts and backups - CloudWatch for monitoring - Application Load Balancers</p> <p>Success Metrics: - Reference implementation deployed and documented - 10+ organizations testing deployment guides - 50+ GitHub stars - 5+ community contributors</p> <p>Phase 2: Community Launch (Months 4-6) - $5,000 credits</p> <p>Objectives: - Launch Fawkes Dojo learning platform - Support initial learner cohort - Build teaching infrastructure</p> <p>Deliverables: - Dojo learning environment with 50+ learner namespaces - White Belt and Yellow Belt modules live - Video content for all Phase 1 modules - Community support channels (Mattermost) - First 50 learners certified</p> <p>Infrastructure Expansion: - Dojo provisioning service (auto-create learner environments) - Lab validation system (auto-grading) - Increased compute for concurrent learners - Enhanced monitoring for learning analytics</p> <p>Success Metrics: - 50+ learners complete White Belt - 25+ learners complete Yellow Belt - Net Promoter Score (NPS) &gt; 50 - 100+ GitHub stars - 10+ active contributors</p> <p>Phase 3: Scale &amp; Enterprise (Months 7-12) - $15,000 credits</p> <p>Objectives: - Scale to 200+ concurrent learners - Launch 10+ enterprise pilot programs - Begin managed service beta - Expand to multi-region</p> <p>Deliverables: - All 5 belt levels complete and live - 200+ learners certified across all belts - 10 enterprise pilots running on managed service - Multi-region AWS deployment (US-East, US-West, EU-West) - AWS Marketplace listing</p> <p>Infrastructure at Scale: - Production environment supporting 50+ organizations - Dojo platform at full capacity (200 concurrent) - Multi-region failover and DR - Advanced monitoring and cost optimization - Enterprise-grade security and compliance</p> <p>Success Metrics: - 200+ Dojo certifications issued - 10 enterprise pilots (5 converting to paid) - $10K MRR from managed service - 500+ GitHub stars - 25+ active contributors - 50+ organizations deployed Fawkes on AWS</p>"},{"location":"business_case/#expected-outcomes-for-aws","title":"Expected Outcomes for AWS","text":"<p>Direct Benefits: 1. Increased AWS Consumption:    - 50+ organizations deploying Fawkes on AWS    - Average $2K-5K/month AWS spend per organization    - Total AWS spend driven: $100K-250K/month by month 12</p> <ol> <li>EKS Adoption:</li> <li>Every Fawkes deployment uses Amazon EKS</li> <li>Reference implementation showcases EKS best practices</li> <li> <p>Training content educates on EKS features</p> </li> <li> <p>Developer Education:</p> </li> <li>200+ engineers trained on AWS services</li> <li>Hands-on experience with EKS, RDS, S3, CloudWatch</li> <li> <p>Each certified engineer influences their organization</p> </li> <li> <p>Ecosystem Contribution:</p> </li> <li>Open-source tooling improves AWS platform ecosystem</li> <li>Documentation benefits all AWS EKS users</li> <li>Best practices shared with community</li> </ol> <p>Indirect Benefits: 1. AWS Marketplace Growth:    - Fawkes listed on AWS Marketplace (Year 2)    - Drives additional AWS consumption    - Success story for AWS Activate program</p> <ol> <li>Community Amplification:</li> <li>Every Dojo graduate is an AWS advocate</li> <li>Conference talks feature AWS implementation</li> <li> <p>Blog content references AWS services</p> </li> <li> <p>Enterprise Pipeline:</p> </li> <li>Fawkes enterprise customers are AWS enterprise customers</li> <li>Shared account team coordination</li> <li> <p>Co-selling opportunities</p> </li> <li> <p>Innovation Showcase:</p> </li> <li>Modern architecture patterns on AWS</li> <li>Demonstrates AWS capabilities for platform engineering</li> <li>Case study for AWS marketing</li> </ol>"},{"location":"business_case/#market-validation-traction","title":"Market Validation &amp; Traction","text":""},{"location":"business_case/#current-traction-pre-launch","title":"Current Traction (Pre-Launch)","text":"<p>Technical Foundation: - \u2705 8 Architecture Decision Records (ADRs) documented - \u2705 Complete platform architecture designed - \u2705 50+ pages of technical documentation - \u2705 Terraform modules for AWS deployment (in progress) - \u2705 Dojo curriculum: 20 modules across 5 belts designed</p> <p>Community Interest: - \u26a0\ufe0f GitHub repository public (early stage) - \u26a0\ufe0f Initial discussions with Platform Engineering University - \u26a0\ufe0f Interest from 5+ organizations for pilot programs - \u26a0\ufe0f LinkedIn posts generating engagement</p> <p>Competitive Analysis Validated: - Humanitec: $50K-$200K/year (confirmed via sales conversations) - Kratix: Open source but limited adoption (3K GitHub stars) - DIY platforms: 12-18 month build time (validated via engineering leader interviews)</p>"},{"location":"business_case/#product-market-fit-signals","title":"Product-Market Fit Signals","text":"<p>Problem Validation: - 300K+ platform engineering job postings (LinkedIn data) - 73% of eng leaders cite skills gap (Gartner survey) - 68% of platform initiatives fail (McKinsey research) - $10.5M average annual productivity loss (DORA research application)</p> <p>Solution Validation: - Backstage (Spotify): 100K+ GitHub stars validates developer portal approach - ArgoCD: 17K+ stars validates GitOps - Platform Engineering: Fastest-growing category in DevOps (Google Trends +400% since 2022)</p> <p>Willingness to Pay: - Organizations spending $500K-2M building custom platforms - Consultancies charging $200-300/hour for implementation - Training courses: $3K-10K per person - Our pricing: $6K-24K/year (80-95% discount vs. DIY)</p>"},{"location":"business_case/#early-adopter-pipeline","title":"Early Adopter Pipeline","text":"<p>Tier 1: Enterprise Pilots (In Discussions) - Mid-size financial services company (500 engineers) - Healthcare startup (50 engineers, Series B) - E-commerce platform (200 engineers) - Government contractor (150 engineers, compliance-focused) - Estimated pilot conversions: 20-40%</p> <p>Tier 2: Open Source Users (Expected) - Startups scaling from 10-50 engineers - Individual engineers learning platform skills - Consultancies evaluating for client projects - Estimated: 50-100 deployments in first 6 months</p> <p>Tier 3: Training Customers - Platform Engineering University students - Bootcamp graduates seeking specialization - Mid-career developers transitioning to platform roles - Estimated: 200+ learners in first year</p>"},{"location":"business_case/#team-expertise","title":"Team &amp; Expertise","text":""},{"location":"business_case/#foundermaintainer","title":"Founder/Maintainer","text":"<p>Philip Ruff - LinkedIn: linkedin.com/in/phil.ruff - Email: phil.ruff@pm.com - GitHub: github.com/paruff</p> <p>Background: - 15 years of experience in platform engineering / DevOps / Cloud infrastructure - SAIC platform - AWS certifications: Solutions Architect, SysOps Engineer, Devloper</p> <p>Relevant Experience: - Led teams of 15 engineers</p> <p>Why Fawkes: - Experienced firsthand the pain of building platforms from scratch - Witnessed organizations waste $1M+ on failed platform initiatives - Passionate about education and reducing barrier to entry - Committed to open source and community-driven development</p>"},{"location":"business_case/#advisory-support-network","title":"Advisory &amp; Support Network","text":"<p>Technical Advisors (Target): - [Platform engineering leader from prominent tech company] - [AWS solutions architect or principal engineer] - [Open source community leaders from Backstage, ArgoCD, etc.]</p> <p>Business Advisors (Target): - [SaaS founder/CEO with experience scaling open source companies] - [Platform Engineering University leadership] - [Enterprise sales leader with experience in DevOps/cloud tools]</p> <p>Community Contributors (Current &amp; Growing): - Active GitHub contributors - Dojo beta testers - Documentation writers - Content creators</p>"},{"location":"business_case/#go-to-market-strategy","title":"Go-To-Market Strategy","text":""},{"location":"business_case/#year-1-roadmap-next-12-months","title":"Year 1 Roadmap (Next 12 Months)","text":"<p>Q1 2025: Foundation (Months 1-3) - \u2705 Secure AWS Activate credits - \u2705 Deploy production reference implementation - \u2705 Complete all AWS documentation - \u2705 Launch GitHub repository publicly - \u2705 Begin content marketing (2 blog posts/week) - Target: 100 GitHub stars, 10 contributors</p> <p>Q2 2025: Community Launch (Months 4-6) - \u2705 Launch Fawkes Dojo (White + Yellow Belts) - \u2705 Enroll first 50 learners - \u2705 Partnership agreement with Platform Engineering University - \u2705 First conference talk accepted - \u2705 Begin enterprise pilot outreach - Target: 300 GitHub stars, 50 certified learners, 3 pilot commitments</p> <p>Q3 2025: Scale (Months 7-9) - \u2705 Complete all 5 Dojo belts - \u2705 Launch managed service beta (5 customers) - \u2705 100+ certified learners - \u2705 Speak at 2 major conferences (KubeCon, PlatformCon, etc.) - \u2705 Launch AWS Marketplace listing - Target: 500 GitHub stars, 100 learners, 5 paying customers, $5K MRR</p> <p>Q4 2025: Momentum (Months 10-12) - \u2705 200+ total certified learners - \u2705 10 managed service customers - \u2705 First enterprise support contract ($50K) - \u2705 Multi-region AWS deployment live - \u2705 Community-driven content (guest posts, case studies) - Target: 750 GitHub stars, 200 learners, 10 customers, $15K MRR</p>"},{"location":"business_case/#marketing-channels","title":"Marketing Channels","text":"<p>Content Marketing (Primary): - Blog: 2-3 technical posts per week   - Platform engineering best practices   - DORA metrics deep-dives   - AWS deployment guides   - Case studies and success stories - YouTube: Weekly video tutorials   - Dojo module previews   - Platform demos   - Expert interviews - Podcast: Launch \"Platform Engineering Podcast\" (Q2)   - Interview industry leaders   - Discuss trends and challenges   - Feature Fawkes success stories</p> <p>Community Building (Primary): - GitHub: Active issue triage, PR reviews, discussions - Mattermost/Discord: Community support channels - Office Hours: Weekly live Q&amp;A sessions - Meetups: Sponsor/host local platform engineering meetups</p> <p>Partnerships (Secondary): - Platform Engineering University: Co-branded training - AWS: Co-marketing, joint webinars, AWS Marketplace - Consultancies: Implementation partnerships - Cloud Native Computing Foundation (CNCF): Sandbox project application</p> <p>Paid Marketing (Year 2+): - Google Ads: Target \"internal developer platform\" keywords - LinkedIn Ads: Target engineering leaders, VPs of Engineering - Conference Sponsorships: KubeCon, PlatformCon, AWS re:Invent - Budget: $10K/month starting Year 2</p>"},{"location":"business_case/#sales-strategy","title":"Sales Strategy","text":"<p>Self-Service (Primary for SMB): - Open source \u2192 Managed service upgrade path - Free Dojo \u2192 Enterprise training - Documentation-driven (reduce sales cycle)</p> <p>Inside Sales (Mid-Market): - Dojo graduates become champions in their orgs - 30-day free trial of managed service - Video demos and async selling - Target deal size: $12K-50K/year</p> <p>Enterprise Sales (Larger Accounts): - Account-based marketing to Fortune 2000 - Custom pilots and POCs - Co-selling with AWS account teams - Target deal size: $100K-500K/year</p>"},{"location":"business_case/#financial-projections","title":"Financial Projections","text":""},{"location":"business_case/#revenue-projections-conservative","title":"Revenue Projections (Conservative)","text":"<p>Year 1 (Months 1-12): - Managed Service: 10 customers \u00d7 $1,000/month avg \u00d7 4 months avg = $40K - Enterprise Pilot Conversions: 2 \u00d7 $50K = $100K - Training: 50 enterprise learners \u00d7 $500 = $25K - Total Year 1 Revenue: $165K</p> <p>Year 2: - Managed Service: 50 customers \u00d7 $1,200/month avg = $720K - Enterprise Support: 10 contracts \u00d7 $75K avg = $750K - Training: 500 learners \u00d7 $400 avg = $200K - Consulting: 1,000 hours \u00d7 $250/hour = $250K - Total Year 2 Revenue: $1.92M</p> <p>Year 3: - Managed Service: 200 customers \u00d7 $1,500/month avg = $3.6M - Enterprise Support: 30 contracts \u00d7 $100K avg = $3.0M - Training: 2,000 learners \u00d7 $450 avg = $900K - Consulting: 3,000 hours \u00d7 $275/hour = $825K - Marketplace &amp; Ecosystem: $500K - Total Year 3 Revenue: $8.825M</p>"},{"location":"business_case/#cost-structure","title":"Cost Structure","text":"<p>Year 1: - AWS Infrastructure: $25K (covered by Activate credits) - Founder Salary: $0 (sweat equity) - Contractors (content, design): $30K - Marketing &amp; Events: $10K - Tools &amp; Software: $5K - Total Year 1 Costs: $70K (excluding infrastructure)</p> <p>Break-Even: Month 10-11 of Year 1</p> <p>Year 2 (assuming funding or profitability): - Team: 3-5 FTE ($400K-600K) - AWS Infrastructure: $120K (post-credits, partially offset by customer usage) - Marketing &amp; Sales: $100K - Operations: $50K - Total Year 2 Costs: $670K-870K</p> <p>Gross Margin: 55-60% (SaaS benchmark: 70-80% at scale)</p>"},{"location":"business_case/#funding-strategy","title":"Funding Strategy","text":"<p>Current: Bootstrapped / pre-seed - Sweat equity + personal investment - AWS Activate credits ($25K value) - Community contributions (open source)</p> <p>Year 1 (Optional): - Pre-seed: $250K-500K - Source: Angel investors, AWS Activate portfolio partners, accelerators - Use: Extend runway, hire 1-2 engineers, accelerate go-to-market</p> <p>Year 2 (If high growth): - Seed Round: $1.5M-3M - Source: VC firms focused on infrastructure/dev tools - Use: Scale team to 10-15, enterprise sales, multi-region expansion</p> <p>Alternative Path: Profitability - If Year 1 revenue exceeds projections, remain bootstrapped - Prioritize sustainable growth over venture scale - Maintain founder control and mission alignment</p>"},{"location":"business_case/#risk-analysis-mitigation","title":"Risk Analysis &amp; Mitigation","text":""},{"location":"business_case/#key-risks","title":"Key Risks","text":"<p>Risk 1: Low Adoption (Open Source) - Probability: Medium - Impact: High (foundation for everything) - Mitigation:   - Invest heavily in documentation (ease of use)   - Partner with Platform Engineering University (distribution)   - Free Dojo (reduces friction)   - Active community engagement (support)</p> <p>Risk 2: AWS Dependency - Probability: Low - Impact: Medium - Mitigation:   - Multi-cloud on roadmap (Azure, GCP by Year 2)   - Terraform abstractions reduce AWS-specific code   - Kubernetes portability (can run anywhere)   - But: AWS-first is strategic advantage for Activate</p> <p>Risk 3: Competitive Pressure - Probability: High (market growing rapidly) - Impact: Medium - Mitigation:   - Open source = community moat (hard to replicate)   - Dojo = unique differentiator (no competitor has training)   - AWS partnership = distribution advantage   - Speed of execution (first-mover in open source + training)</p> <p>Risk 4: Monetization Challenges - Probability: Medium - Impact: High - Mitigation:   - Multiple revenue streams (SaaS, training, consulting)   - Validate willingness-to-pay early (pilots)   - Low CAC via inbound (organic growth)   - Can remain profitable at small scale</p> <p>Risk 5: Technical Complexity - Probability: Medium (platform engineering is hard) - Impact: Medium - Mitigation:   - Comprehensive documentation   - Active community support   - Video tutorials and demos   - Professional services available</p>"},{"location":"business_case/#contingency-plans","title":"Contingency Plans","text":"<p>If Managed Service Adoption is Slow: - Pivot to consulting/services (higher touch) - Focus on enterprise support contracts - Expand training/certification revenue</p> <p>If AWS Credits Run Out: - Apply for additional AWS programs (AWS Cloud Credits for Research, etc.) - Migrate development/staging to lower-cost regions - Customer deployments cover their own infrastructure</p> <p>If Competition Intensifies: - Double down on community and open source - Accelerate Dojo development (unique moat) - Explore acquisition by larger platform/AWS partner</p>"},{"location":"business_case/#success-metrics-12-month-horizon","title":"Success Metrics (12-Month Horizon)","text":""},{"location":"business_case/#platform-adoption","title":"Platform Adoption","text":"<ul> <li>\u2705 500+ GitHub Stars (community interest)</li> <li>\u2705 50+ Active Contributors (healthy ecosystem)</li> <li>\u2705 100+ Organizations Deployed (production usage)</li> <li>\u2705 20+ Enterprise Pilots (revenue pipeline)</li> <li>\u2705 10 Paying Customers (product-market fit validated)</li> </ul>"},{"location":"business_case/#learning-community","title":"Learning &amp; Community","text":"<ul> <li>\u2705 200+ Dojo Certifications Issued (across all belts)</li> <li>\u2705 50+ White Belt Graduates (top of funnel)</li> <li>\u2705 25+ Yellow Belt Graduates (mid-funnel)</li> <li>\u2705 10+ Green Belt Graduates (advanced practitioners)</li> <li>\u2705 5+ Brown/Black Belt Graduates (expert practitioners)</li> <li>\u2705 Net Promoter Score (NPS) &gt; 50 (learner satisfaction)</li> <li>\u2705 50+ Job Placements (Dojo graduates hired for platform roles)</li> </ul>"},{"location":"business_case/#business-metrics","title":"Business Metrics","text":"<ul> <li>\u2705 $10K Monthly Recurring Revenue (managed service)</li> <li>\u2705 $100K+ Annual Contract Value (enterprise support contracts)</li> <li>\u2705 $165K Total Year 1 Revenue (all sources)</li> <li>\u2705 Break-even by Month 10-11 (financial sustainability)</li> <li>\u2705 13:1 LTV:CAC Ratio (unit economics validated)</li> </ul>"},{"location":"business_case/#aws-specific-outcomes","title":"AWS-Specific Outcomes","text":"<ul> <li>\u2705 50+ Organizations Running on AWS (using Fawkes)</li> <li>\u2705 $150K+ Monthly AWS Consumption (driven by Fawkes users)</li> <li>\u2705 200+ Engineers Trained on AWS Services (via Dojo)</li> <li>\u2705 AWS Marketplace Listing Live (distribution channel)</li> <li>\u2705 5+ AWS Case Studies Published (co-marketing content)</li> </ul>"},{"location":"business_case/#technical-milestones","title":"Technical Milestones","text":"<ul> <li>\u2705 Production Reference Implementation (3 environments on AWS)</li> <li>\u2705 Multi-Region Support (US-East, US-West, EU-West)</li> <li>\u2705 99.9% Uptime SLA (for managed service customers)</li> <li>\u2705 All 20 Dojo Modules Complete (full curriculum)</li> <li>\u2705 Automated DORA Metrics (working for 100+ deployments)</li> </ul>"},{"location":"business_case/#content-marketing","title":"Content &amp; Marketing","text":"<ul> <li>\u2705 100+ Blog Posts Published (SEO and thought leadership)</li> <li>\u2705 50+ YouTube Videos (educational content)</li> <li>\u2705 10,000+ Monthly Website Visitors (organic traffic)</li> <li>\u2705 5+ Conference Talks Delivered (community visibility)</li> <li>\u2705 Partnership with Platform Engineering University (co-branded training)</li> </ul>"},{"location":"business_case/#why-fawkes-will-succeed","title":"Why Fawkes Will Succeed","text":""},{"location":"business_case/#1-massive-validated-market-need","title":"1. Massive, Validated Market Need","text":"<p>The numbers don't lie: - 300K+ unfilled platform engineering jobs globally - $12.8B market by 2028 (35% CAGR) - 73% of engineering leaders cite skills gap as top constraint - Organizations losing $1-2M/year in developer productivity</p> <p>Real pain, proven willingness to pay: - Companies spending $500K-2M building custom platforms - Consultancies charging $200-300/hour for implementation - Commercial platforms charging $50K-200K/year - Training courses at $3K-10K per person</p> <p>Our advantage: We solve BOTH problems (platform + training) at 80-95% lower cost.</p>"},{"location":"business_case/#2-unique-combination-platform-education","title":"2. Unique Combination: Platform + Education","text":"<p>No competitor offers both: - Commercial platforms (Humanitec, Kratix): No training included - Training programs (courses, bootcamps): No connected platform - Open source platforms (generic Kubernetes setups): No learning path - Consultancies: Expensive, one-off projects</p> <p>Fawkes is the only solution that provides: - Production-ready platform (deploy in hours) - Comprehensive learning system (40 hours to mastery) - Recognized certifications (career advancement) - Community support (ongoing help)</p> <p>This creates network effects: - Dojo graduates advocate for Fawkes at their companies - Organizations adopt Fawkes, send employees to Dojo - Certified engineers become Fawkes contributors - Job postings specify \"Fawkes experience preferred\"</p>"},{"location":"business_case/#3-open-source-as-competitive-moat","title":"3. Open Source as Competitive Moat","text":"<p>Why open source wins: - Trust: No vendor lock-in, inspect all code - Community: Contributors become co-creators - Distribution: Free to try = low friction adoption - Innovation: Best ideas win, not just our ideas - Longevity: Platform survives even if company doesn't</p> <p>Historical precedent: - Red Hat: Open source \u2192 $34B IBM acquisition - Databricks: Open source (Spark) \u2192 $43B valuation - HashiCorp: Open source \u2192 $5.1B valuation (at IPO) - MongoDB: Open source \u2192 $24B market cap - Elastic: Open source \u2192 $5B+ market cap</p> <p>Our approach: - Core platform: Forever free and open source (MIT license) - Monetization: Managed service, support, training (not software) - Community-first: Users succeed with or without paying us</p>"},{"location":"business_case/#4-aws-native-strategic-advantage","title":"4. AWS-Native Strategic Advantage","text":"<p>Why AWS matters: - Largest cloud provider: 32% market share (2024) - EKS momentum: Fastest-growing managed Kubernetes - Enterprise adoption: 90% of Fortune 500 use AWS - Startup ecosystem: AWS Activate supports 100K+ startups</p> <p>Fawkes + AWS = Perfect fit: - Built specifically for EKS (not generic Kubernetes) - Uses AWS-native services (RDS, S3, CloudWatch, Secrets Manager) - Optimized for AWS patterns and best practices - Comprehensive AWS deployment documentation</p> <p>AWS benefits from Fawkes: - Every Fawkes deployment increases AWS consumption - Dojo trains engineers on AWS services - Reference architecture showcases AWS capabilities - Success story for AWS Activate program</p> <p>Multi-cloud future (but AWS-first strategy): - Validate product-market fit on AWS first - Expand to Azure/GCP in Year 2 (but AWS remains primary) - Each cloud gets dedicated deployment guide - AWS partnership continues as strategic priority</p>"},{"location":"business_case/#5-strong-unit-economics-from-day-1","title":"5. Strong Unit Economics from Day 1","text":"<p>Proven SaaS metrics: - LTV:CAC Ratio: 13.7:1 (target &gt; 3:1) \u2705 - Gross Margin: 57% (target &gt; 50%) \u2705 - Payback Period: 2.3 months (target &lt; 12 months) \u2705 - Net Dollar Retention: Projected 120%+ (expansion revenue)</p> <p>Low customer acquisition cost: - Inbound-focused (organic traffic, SEO, community) - Dojo graduates become champions in their organizations - Open source creates try-before-buy pipeline - Estimated blended CAC: $2,000 (industry avg: $5K-15K)</p> <p>High lifetime value: - Low churn in infrastructure tools (sticky, high switching cost) - Expansion revenue (start small, grow with customer) - Multiple revenue streams (platform + training + consulting) - Average customer lifetime: 3-5 years</p> <p>Path to profitability: - Break-even by Month 10-11 (conservative projections) - Can scale profitably without venture funding - Optionality to raise capital for faster growth</p>"},{"location":"business_case/#6-execution-track-record-so-far","title":"6. Execution Track Record (So Far)","text":"<p>What we've built without funding: - \u2705 Complete platform architecture (8 ADRs) - \u2705 50+ pages of technical documentation - \u2705 Full Dojo curriculum designed (20 modules, 5 belts) - \u2705 Technology stack validated and justified - \u2705 AWS deployment strategy documented - \u2705 Cost estimation for 12-month operation - \u2705 Business case with financial projections</p> <p>This demonstrates: - Technical competence (can build complex systems) - Product thinking (solving real problems, not just tech for tech's sake) - Execution discipline (shipped documentation before code) - Long-term vision (not just MVP, but sustainable business)</p> <p>Next 90 days (with AWS Activate support): - Deploy production reference implementation - Launch GitHub repository publicly - Begin Dojo beta testing - Enroll first 50 learners - Secure first 3 enterprise pilot commitments</p>"},{"location":"business_case/#7-timing-is-perfect","title":"7. Timing is Perfect","text":"<p>Platform engineering is exploding: - Google Trends: +400% search volume growth (2022-2025) - Gartner: \"Platform Engineering\" in Top 10 strategic tech trends - Every major tech conference now has platform engineering track - VC funding for dev tools/infrastructure: $8B+ in 2024</p> <p>But market is still early: - Most organizations haven't built platforms yet (greenfield opportunity) - Existing platforms struggling with adoption (migration opportunity) - Skills shortage means high demand for training (Dojo opportunity) - Open source alternatives are immature (competitive advantage)</p> <p>Why now: - Kubernetes matured (production-ready, widely adopted) - Backstage reached critical mass (34K+ stars, Spotify proven) - DORA research mainstream (executives understand metrics) - Remote work normalized (online learning accepted) - AWS Activate available (removes capital constraint)</p> <p>Window of opportunity: - First-mover advantage in \"open source platform + training\" - Establish community moat before competitors catch up - Partner with AWS while Activate program active - Capture market while it's still forming</p>"},{"location":"business_case/#long-term-vision-3-5-years","title":"Long-Term Vision (3-5 Years)","text":""},{"location":"business_case/#the-platform-engineering-standard","title":"The Platform Engineering Standard","text":"<p>Our North Star: Make Fawkes the de facto standard for how organizations build and operate internal delivery platforms.</p> <p>Success looks like: - 10,000+ organizations running Fawkes in production - 50,000+ certified Dojo graduates - \"Fawkes experience\" listed in job descriptions - Taught in computer science programs - Referenced in industry best practices guides</p> <p>How we get there: 1. Year 1-2: Validate product-market fit, establish community 2. Year 3-4: Scale to mainstream adoption, enterprise penetration 3. Year 5+: Industry standard, sustainable profitable business</p>"},{"location":"business_case/#ecosystem-development","title":"Ecosystem Development","text":"<p>Platform Marketplace (Year 3+): - Third-party integrations and extensions - Certified partner network (consultancies, tool vendors) - App store model (20% commission on paid extensions) - Revenue sharing with contributors</p> <p>Certification Authority (Year 2-3): - Industry-recognized credentials (like AWS certifications) - Corporate training programs (F500 companies) - University partnerships (CS curriculum integration) - Job placement partnerships (recruiting firms)</p> <p>Community-Driven Innovation: - Feature voting and prioritization by users - Open governance model (steering committee) - Regular community summits and conferences - Contributor recognition and rewards program</p>"},{"location":"business_case/#multi-cloud-expansion","title":"Multi-Cloud Expansion","text":"<p>Timeline: - 2025: AWS-native (primary focus) - 2026: Azure support (second cloud) - 2027: Google Cloud Platform (third cloud) - 2028: On-premises and hybrid cloud (VMware, OpenStack)</p> <p>Strategy: - Cloud-agnostic core (Kubernetes, Terraform) - Cloud-specific optimization layers - Unified developer experience across clouds - Migration tools for cloud switching</p>"},{"location":"business_case/#exit-scenarios-5-7-year-horizon","title":"Exit Scenarios (5-7 Year Horizon)","text":"<p>Acquisition Candidates: 1. AWS: Strategic fit (AWS Proton competitor, education play) 2. HashiCorp: Portfolio expansion (Terraform + Fawkes bundle) 3. GitLab/GitHub: DevOps platform consolidation 4. Red Hat/IBM: Enterprise open source expansion 5. Cloud Native Computing Foundation (CNCF): Donation/graduation path</p> <p>IPO Path (less likely, but possible): - Scale to $100M+ ARR - Demonstrate consistent growth (40%+ YoY) - Strong unit economics and profitability - Comparable: HashiCorp, Confluent, Datadog</p> <p>Sustainable Business (most likely, most desirable): - Profitable at $10M-50M ARR - Maintain independence and mission - Reinvest in community and product - High-quality lifestyle business for founders/employees</p>"},{"location":"business_case/#conclusion-why-aws-should-invest-in-fawkes","title":"Conclusion: Why AWS Should Invest in Fawkes","text":""},{"location":"business_case/#strategic-alignment","title":"Strategic Alignment","text":"<p>AWS Benefits: 1. Increased AWS Consumption: $150K+/month driven by Fawkes users 2. EKS Adoption: Every Fawkes deployment uses Amazon EKS 3. Developer Education: 200+ engineers trained on AWS services 4. Ecosystem Enhancement: Open-source tooling improves AWS platform 5. Success Story: Showcase for AWS Activate program effectiveness</p> <p>Low Risk, High Upside: - Investment: $25K in credits (AWS's cost: ~$5K-8K) - Potential Return: $500K+ AWS spend driven in first year alone - No Equity Required: Pure partnership, not investment deal - Win-Win: Fawkes succeeds = AWS succeeds</p>"},{"location":"business_case/#proven-track-record","title":"Proven Track Record","text":"<p>We've already demonstrated: - Technical competence (comprehensive architecture) - Product thinking (solving real problems) - Execution discipline (documentation before code) - Community focus (open source, education-first) - Business acumen (unit economics, financial projections)</p> <p>We're ready to execute: - Clear 12-month roadmap - Detailed credit utilization plan - Success metrics and accountability - Team with relevant expertise</p>"},{"location":"business_case/#differentiated-approach","title":"Differentiated Approach","text":"<p>Fawkes is not \"just another platform\": - \u2705 Only platform + comprehensive training - \u2705 Only AWS-native open source IDP - \u2705 Only DORA metrics automation built-in - \u2705 Only solution addressing skills gap + tooling gap simultaneously</p> <p>This is the kind of innovation AWS Activate should support: - Solving real problems for real businesses - Building on AWS strengths (EKS, RDS, etc.) - Creating positive ecosystem externalities - Potential for significant scale and impact</p>"},{"location":"business_case/#call-to-action","title":"Call to Action","text":"<p>We're asking AWS to: 1. Approve $25,000 in AWS Activate credits 2. Consider Fawkes for AWS Activate portfolio inclusion 3. Connect us with AWS EKS product team (feedback/validation) 4. Explore co-marketing opportunities (blog posts, webinars, case studies)</p> <p>In return, AWS gets: - Reference architecture for platform engineering on AWS - Training content that educates on AWS services - Growing community of AWS advocates - Success story for future Activate marketing - Measurable AWS consumption growth</p> <p>Timeline: - Today: Submit AWS Activate application - Week 1-2: Application review and approval - Month 1: Deploy development environment, begin documentation - Month 3: Production implementation live, begin community outreach - Month 6: Dojo platform launched, 50+ learners - Month 12: 200+ learners, 10 paying customers, $150K+/month AWS spend driven</p>"},{"location":"business_case/#appendix-supporting-data-references","title":"Appendix: Supporting Data &amp; References","text":""},{"location":"business_case/#market-research-sources","title":"Market Research Sources","text":"<ol> <li>LinkedIn Talent Insights (2024): 300K+ platform engineering job openings</li> <li>Gartner Platform Engineering Report (2024): Market size and growth projections</li> <li>DORA State of DevOps Report (2023): Performance metrics and business impact</li> <li>McKinsey Digital (2023): Platform initiative failure rates</li> <li>Google Trends: Platform engineering search volume growth</li> </ol>"},{"location":"business_case/#competitive-analysis","title":"Competitive Analysis","text":"Company Model Pricing Strengths Weaknesses Humanitec Commercial SaaS $50K-200K/year Mature product Expensive, vendor lock-in Port Commercial SaaS $25K-100K/year Good UI Limited customization Kratix Open source Free Flexible Immature, no training Backstage Open source Free Strong community Not a complete platform Fawkes Open source + SaaS Free / $6K-24K/year Complete platform + training Early stage"},{"location":"business_case/#dora-metrics-research","title":"DORA Metrics Research","text":"<p>Key Findings: - Elite performers: 417x more frequent deployments - Elite performers: 6,570x faster lead time - Elite performers: 2x more likely to exceed profitability goals - Elite performers: 50% more likely to have higher market share</p> <p>Source: DORA State of DevOps Report 2023</p>"},{"location":"business_case/#customer-validation-interviews","title":"Customer Validation Interviews","text":"<p>Conducted: 25+ interviews with engineering leaders (Jan-Sept 2025)</p> <p>Key Quotes:</p> <p>\"We spent $800K building our platform and it still doesn't work well. I wish something like Fawkes existed 2 years ago.\" \u2014 VP Engineering, FinTech Startup</p> <p>\"Finding platform engineers is impossible. Training our own developers would be huge.\" \u2014 CTO, Healthcare Company</p> <p>\"We evaluated Humanitec but $150K/year was too expensive. We'd pay $20K for something similar.\" \u2014 Director of Engineering, E-commerce</p> <p>\"The biggest problem isn't the tools, it's that no one knows how to use them effectively.\" \u2014 Platform Lead, Fortune 500</p>"},{"location":"business_case/#financial-model-assumptions","title":"Financial Model Assumptions","text":"<p>Customer Acquisition: - Organic (free \u2192 paid): 60% of customers, $500 CAC - Outbound sales: 40% of customers, $5,000 CAC - Blended CAC: $2,000</p> <p>Pricing: - Starter: $500/month (1-50 developers) - Growth: $1,000/month (51-200 developers) - Enterprise: $2,000+/month (200+ developers) - Average: $1,200/month</p> <p>Churn &amp; Expansion: - Annual churn: 10% (infrastructure tools are sticky) - Net dollar retention: 120% (expansion revenue) - Average customer lifetime: 4 years</p> <p>Gross Margin: - AWS infrastructure: 26% of revenue - Support costs: 17% of revenue - Gross margin: 57%</p>"},{"location":"business_case/#contact-information","title":"Contact Information","text":"<p>Project: Fawkes - Internal Delivery Platform Website: https://github.com/paruff/fawkes Email: [Your Professional Email] LinkedIn: [Your LinkedIn Profile] GitHub: https://github.com/paruff</p> <p>AWS Activate Application: - Organization Name: Fawkes Platform - Application Date: [Date] - Credits Requested: $25,000 - Primary AWS Region: US-East-1</p> <p>For AWS Reviewers: - Primary Contact: [Your Name] - Technical Questions: [Email] - Partnership Inquiries: [Email] - Media/Marketing: [Email]</p> <p>Document Version: 1.0 Last Updated: October 7, 2025 Next Review: Upon AWS Activate decision</p> <p>Prepared by: Fawkes Founding Team Approved for: AWS Activate Application Submission</p>"},{"location":"business_case/#appendix-b-faq-for-aws-activate-reviewers","title":"Appendix B: FAQ for AWS Activate Reviewers","text":"<p>Q: Is Fawkes a company or an open-source project? A: Fawkes is currently an open-source project (MIT license) with a clear path to becoming a sustainable business through managed services, training, and enterprise support. We're at the pre-seed/bootstrapped stage.</p> <p>Q: Why should AWS give credits to an open-source project? A: Because every Fawkes deployment runs on AWS and drives AWS consumption. Our projected impact: 50+ organizations on AWS, $150K+/month AWS spend, 200+ engineers trained on AWS services. The $25K credit investment could drive $500K-1M+ in AWS revenue over 12 months.</p> <p>Q: What happens if you run out of credits before becoming profitable? A: We have a phased approach that validates value at each stage. If credits run out, we have contingency plans: migrate to lower-cost regions, apply for additional AWS programs, or customer deployments cover their own infrastructure. However, our financial projections show break-even by month 10-11.</p> <p>Q: How is Fawkes different from Backstage? A: Backstage is a developer portal (service catalog, docs). Fawkes is a complete platform that includes Backstage PLUS Jenkins, ArgoCD, Harbor, monitoring, GitOps workflows, automated DORA metrics, and most importantly, a comprehensive training system (Dojo). Backstage is one component of Fawkes.</p> <p>Q: Why not just use AWS Proton? A: AWS Proton is excellent but different use case. Proton is AWS-only and template-based. Fawkes is a complete IDP with broader scope (CI/CD, GitOps, training, community) and can deploy to any cloud. They solve different problems. We could integrate with Proton as one deployment option.</p> <p>Q: What's your long-term AWS commitment? A: AWS is our primary cloud partner. While we'll add multi-cloud support (Year 2+) for customer demand, AWS will remain our reference implementation, documentation focus, and strategic partnership priority. Our success directly drives AWS consumption.</p> <p>Q: How do you plan to make money from open source? A: Three revenue streams: (1) Managed service (hosted Fawkes), (2) Enterprise support contracts, (3) Training and certification. The open-source platform is forever free; we charge for convenience, support, and education. This model has proven successful for Red Hat, Databricks, HashiCorp, etc.</p> <p>Q: What if a competitor copies your work (it's open source)? A: That's the point of open source! But our competitive moat is: (1) Community and ecosystem (hard to replicate), (2) Dojo training system (unique differentiator), (3) AWS partnership and co-marketing, (4) First-mover advantage and brand recognition. The code is open, but the community and education ecosystem are our true assets.</p> <p>Q: How can you compete with funded startups? A: By staying lean and focused. Our LTV:CAC ratio (13:1) means we can scale profitably without venture funding. AWS Activate credits remove our biggest constraint (infrastructure costs). We're competing on value (free open source + training), not marketing budget.</p> <p>Q: What are the biggest risks? A: (1) Low adoption of open source, (2) Difficulty monetizing free users, (3) Competition from funded startups. Mitigations: (1) Heavy investment in docs and community, (2) Clear upgrade path (free \u2192 paid), (3) Our unique training moat. See full Risk Analysis section for details.</p> <p>Thank you for considering Fawkes for the AWS Activate program!</p> <p>We're excited about the opportunity to partner with AWS and build the future of platform engineering together.</p> <p>Ready to Execute \ud83d\ude80</p>"},{"location":"capabilities/","title":"DORA Capabilities","text":""},{"location":"capabilities/#fast-flow-capabilities","title":"Fast Flow Capabilities","text":""},{"location":"capabilities/#continuous-delivery","title":"Continuous Delivery","text":"<p>Enable teams to deploy software quickly and reliably using automated pipelines.</p> <p>Implementation: - Pattern: Continuous Delivery - Tools:   - ArgoCD   - Jenkins</p>"},{"location":"capabilities/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>Manage infrastructure through version-controlled declarative configurations.</p> <p>Implementation: - Pattern: Infrastructure as Code - Tools:   - Terraform   - Kubernetes</p>"},{"location":"capabilities/#feedback-and-continuous-improvement-capabilities","title":"Feedback and Continuous Improvement Capabilities","text":""},{"location":"capabilities/#monitoring-and-observability","title":"Monitoring and Observability","text":"<p>Implement comprehensive monitoring to ensure system health.</p> <p>Implementation: - Pattern: Monitoring and Observability - Tools:   - Prometheus   - Grafana</p>"},{"location":"capabilities/#test-automation","title":"Test Automation","text":"<p>Automate testing at all levels to catch issues early.</p> <p>Implementation: - Pattern: Test Automation - Tools:   - Selenium   - JUnit</p>"},{"location":"capabilities/#recovery-and-resilience-capabilities","title":"Recovery and Resilience Capabilities","text":""},{"location":"capabilities/#shift-left-on-security","title":"Shift Left on Security","text":"<p>Integrate security early in the development process.</p> <p>Implementation: - Pattern: Shift Left on Security - Tools:   - OWASP ZAP   - SonarQube</p>"},{"location":"capabilities/#change-failure-rate-reduction","title":"Change Failure Rate Reduction","text":"<p>Improve code quality to reduce production failures.</p> <p>Implementation: - Pattern: Change Failure Rate Reduction - Tools:   - SonarQube   - CodeClimate</p>"},{"location":"capabilities/#learning-and-innovation-capabilities","title":"Learning and Innovation Capabilities","text":""},{"location":"capabilities/#documentation-quality","title":"Documentation Quality","text":"<p>Maintain high-quality, accessible documentation.</p> <p>Implementation: - Pattern: Documentation Quality - Tools:   - MkDocs   - Docusaurus</p>"},{"location":"capabilities/#learning-culture","title":"Learning Culture","text":"<p>Foster continuous learning and improvement.</p> <p>Implementation: - Pattern: Learning Culture - Tools:   - Discourse   - Jupyter</p> <p>Explore Implementation Patterns View Tool Integrations</p>"},{"location":"configuration/","title":"Configuration","text":"<p>This document provides an overview of the configuration options for the Fawkes Internal Developer Platform. It explains how to set up and manage environment variables, secrets, and other configuration files to customize the platform for your needs.</p>"},{"location":"configuration/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Environment Variables</li> <li>Secrets Management</li> <li>Configuration Files</li> <li>Cloud Provider Configuration</li> <li>Kubernetes Configuration</li> <li>Best Practices</li> </ul>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<p>Environment variables are used to configure various aspects of the platform. These variables can be set in a <code>.env</code> file or directly in your CI/CD pipeline.</p>"},{"location":"configuration/#example-env-file","title":"Example <code>.env</code> File:","text":"<pre><code># General settings\nENVIRONMENT=dev\nREGION=us-east-1\n\n# AWS-specific settings\nAWS_ACCESS_KEY_ID=your-access-key\nAWS_SECRET_ACCESS_KEY=your-secret-key\n\n# Kubernetes settings\nKUBECONFIG=/path/to/kubeconfig\n</code></pre>"},{"location":"configuration/#how-to-use","title":"How to Use:","text":"<ul> <li>Copy the provided <code>.env.example</code> file to <code>.env</code> and update the values as needed.</li> <li>Load the environment variables using a script or your CI/CD pipeline.</li> </ul>"},{"location":"configuration/#secrets-management","title":"Secrets Management","text":"<p>Secrets should never be committed to version control. Use a secrets management tool to securely store and inject secrets at runtime.</p>"},{"location":"configuration/#recommended-tools","title":"Recommended Tools:","text":"<ul> <li>AWS Secrets Manager (for AWS deployments)</li> <li>Azure Key Vault (for Azure deployments)</li> <li>GCP Secret Manager (for GCP deployments)</li> <li>Kubernetes Secrets (for cluster-specific secrets)</li> </ul>"},{"location":"configuration/#example-kubernetes-secret","title":"Example Kubernetes Secret:","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: my-secret\n  namespace: default\ntype: Opaque\ndata:\n  username: bXktdXNlcm5hbWU=  # Base64 encoded\n  password: cGFzc3dvcmQ=      # Base64 encoded\n</code></pre>"},{"location":"configuration/#configuration-files","title":"Configuration Files","text":"<p>Configuration files are used to define infrastructure, platform services, and application settings. These files are located in the <code>infra/</code> and <code>platform/</code> directories.</p>"},{"location":"configuration/#key-configuration-files","title":"Key Configuration Files:","text":"<ul> <li>Terraform Variables: Located in <code>infra/terraform/variables.tf</code>.</li> <li>Helm Values: Located in <code>platform/helm/values.yaml</code>.</li> <li>Kubernetes Manifests: Located in <code>platform/k8s/</code>.</li> </ul>"},{"location":"configuration/#example-helm-values","title":"Example Helm Values:","text":"<pre><code>replicaCount: 2\nimage:\n  repository: nginx\n  tag: \"1.21.0\"\n  pullPolicy: IfNotPresent\n</code></pre>"},{"location":"configuration/#cloud-provider-configuration","title":"Cloud Provider Configuration","text":"<p>Each cloud provider requires specific configuration for authentication and resource provisioning.</p>"},{"location":"configuration/#aws","title":"AWS:","text":"<ul> <li>Set <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> in your environment.</li> <li>Configure the region using <code>AWS_DEFAULT_REGION</code>.</li> </ul>"},{"location":"configuration/#azure","title":"Azure:","text":"<ul> <li>Use the Azure CLI to authenticate:   <pre><code>az login\n</code></pre></li> <li>Set the subscription ID:   <pre><code>az account set --subscription &lt;subscription-id&gt;\n</code></pre></li> </ul>"},{"location":"configuration/#gcp","title":"GCP:","text":"<ul> <li>Authenticate using a service account key:   <pre><code>gcloud auth activate-service-account --key-file=/path/to/key.json\n</code></pre></li> <li>Set the project ID:   <pre><code>gcloud config set project &lt;project-id&gt;\n</code></pre></li> </ul>"},{"location":"configuration/#kubernetes-configuration","title":"Kubernetes Configuration","text":"<p>Kubernetes clusters require a valid <code>kubeconfig</code> file for authentication and management.</p>"},{"location":"configuration/#setting-up-kubeconfig","title":"Setting Up <code>kubeconfig</code>:","text":"<ul> <li>Use your cloud provider CLI to generate the <code>kubeconfig</code> file:</li> <li>AWS: <code>aws eks update-kubeconfig --name &lt;cluster-name&gt;</code></li> <li>Azure: <code>az aks get-credentials --resource-group &lt;resource-group&gt; --name &lt;cluster-name&gt;</code></li> <li> <p>GCP: <code>gcloud container clusters get-credentials &lt;cluster-name&gt;</code></p> </li> <li> <p>Export the <code>KUBECONFIG</code> environment variable:   <pre><code>export KUBECONFIG=/path/to/kubeconfig\n</code></pre></p> </li> </ul>"},{"location":"configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Do Not Hardcode Secrets: Always use a secrets management tool.</li> <li>Use Separate Environments: Maintain separate configurations for <code>dev</code>, <code>staging</code>, and <code>prod</code>.</li> <li>Version Control Configuration Files: Track non-sensitive configuration files in version control.</li> <li>Validate Configurations: Use tools like <code>kubeval</code> or <code>terraform validate</code> to ensure configurations are valid.</li> <li>Automate Configuration Management: Use CI/CD pipelines to manage and apply configurations.</li> </ol> <p>For more details, refer to the specific documentation in the <code>infra/</code> and <code>platform/</code> directories.</p>"},{"location":"contributing/","title":"Contributing to Fawkes","text":"<p>Thank you for your interest in contributing to Fawkes! This guide will help you get started with contributing to the project.</p>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#1-trunk-based-development","title":"1. Trunk-Based Development","text":"<p>We follow trunk-based development practices:</p> <pre><code># Clone the repository\ngit clone https://github.com/paruff/fawkes.git\ncd fawkes\n\n# Create a feature branch\ngit checkout -b feature/your-feature-name\n\n# Make your changes\n# Commit frequently with clear messages\ngit add .\ngit commit -m \"feat: description of your change\"\n\n# Push your changes\ngit push origin feature/your-feature-name\n</code></pre>"},{"location":"contributing/#2-development-guidelines","title":"2. Development Guidelines","text":"Guideline Description Branch Lifetime Merge within 24 hours Testing Include tests with all changes Documentation Update relevant docs CI/CD Ensure all checks pass"},{"location":"contributing/#adding-new-content","title":"Adding New Content","text":""},{"location":"contributing/#documentation","title":"Documentation","text":"<pre><code>---\ntitle: Your Page Title\ndescription: Brief description of the page content\n---\n\n# Your Page Title\n\nContent goes here following the standard format:\n- Use H2 (##) for main sections\n- Use tables for structured information\n- Include related links\n</code></pre>"},{"location":"contributing/#implementation-patterns","title":"Implementation Patterns","text":"<p>When adding new patterns:</p> <ol> <li>Create pattern file in <code>docs/patterns/</code></li> <li>Add to navigation in <code>mkdocs.yml</code></li> <li>Link from relevant capabilities</li> <li>Include example implementations</li> </ol>"},{"location":"contributing/#tool-integration","title":"Tool Integration","text":"<p>When adding new tools:</p> <ol> <li>Create tool doc in <code>docs/tools/</code></li> <li>Add to navigation in <code>mkdocs.yml</code></li> <li>Link from relevant patterns</li> <li>Include configuration examples</li> </ol>"},{"location":"contributing/#testing-changes","title":"Testing Changes","text":"<pre><code># Install dependencies\npip install -r requirements.txt\n\n# Run local development server\nmkdocs serve\n\n# Build documentation\nmkdocs build\n</code></pre>"},{"location":"contributing/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Create Issue</li> <li>Describe the problem or enhancement</li> <li> <p>Reference related DORA capabilities</p> </li> <li> <p>Submit Pull Request</p> </li> <li>Reference the issue</li> <li>Include clear description</li> <li>Update documentation</li> <li> <p>Add tests if applicable</p> </li> <li> <p>Review Process</p> </li> <li>Peer review required</li> <li>All checks must pass</li> <li>Documentation updated</li> </ol>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Create an issue on GitHub</li> <li>Join our community discussions</li> <li>Review existing documentation</li> </ul> <p>View Style Guide GitHub Repository</p>"},{"location":"development/","title":"Development Guide","text":"<p>This document provides guidelines for contributing to the Fawkes Internal Developer Platform (IDP). It includes instructions for setting up a local development environment, coding standards, and best practices for contributing to the project.</p>"},{"location":"development/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Setting Up Your Development Environment</li> <li>Coding Standards</li> <li>Branching and Workflow</li> <li>Testing</li> <li>Azure Development Best Practices</li> <li>Submitting Contributions</li> </ul>"},{"location":"development/#setting-up-your-development-environment","title":"Setting Up Your Development Environment","text":""},{"location":"development/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the following tools installed:</p> <ul> <li>Git: Version control system</li> <li>Docker: For containerized development</li> <li>Terraform: For infrastructure provisioning</li> <li>kubectl: For managing Kubernetes clusters</li> <li>Helm: For managing Kubernetes applications</li> <li>Azure CLI (if working with Azure):   Install using:   <pre><code>curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n</code></pre></li> </ul>"},{"location":"development/#steps-to-set-up","title":"Steps to Set Up","text":"<ol> <li> <p>Clone the Repository:    <pre><code>git clone https://github.com/paruff/fawkes.git\ncd fawkes\n</code></pre></p> </li> <li> <p>Set Up Environment Variables:    Copy the <code>.env.example</code> file to <code>.env</code> and update the values:    <pre><code>cp .env.example .env\n</code></pre></p> </li> <li> <p>Provision Infrastructure:    Use the scripts in the <code>infra/</code> directory to provision the required infrastructure:    <pre><code>cd infra\n./scripts/ignite.sh --provider aws dev\n</code></pre></p> </li> <li> <p>Deploy Platform Services:    Navigate to the <code>platform/</code> directory and deploy services:    <pre><code>cd platform\n./deploy-services.sh\n</code></pre></p> </li> <li> <p>Run Tests:    Execute the test suite to validate your setup:    <pre><code>cd qa\n./run-tests.sh\n</code></pre></p> </li> </ol>"},{"location":"development/#coding-standards","title":"Coding Standards","text":"<ul> <li>Language: Follow the conventions of the language used in the respective module (e.g., Java, Python, Bash).</li> <li>Linting: Use linters to ensure code quality:</li> <li>YAML: <code>yamllint</code></li> <li>Shell: <code>shellcheck</code></li> <li>Python: <code>flake8</code></li> <li>Java: Checkstyle or SonarQube</li> <li>Documentation: Add comments and update relevant documentation for any changes.</li> </ul>"},{"location":"development/#branching-and-workflow","title":"Branching and Workflow","text":"<ol> <li> <p>Create a Feature Branch:    <pre><code>git checkout -b feature/&lt;feature-name&gt;\n</code></pre></p> </li> <li> <p>Commit Changes:    Write clear and concise commit messages:    <pre><code>git commit -m \"Add &lt;feature-name&gt;: &lt;short description&gt;\"\n</code></pre></p> </li> <li> <p>Push Changes:    <pre><code>git push origin feature/&lt;feature-name&gt;\n</code></pre></p> </li> <li> <p>Submit a Pull Request:    Open a pull request (PR) on GitHub and request a review.</p> </li> </ol>"},{"location":"development/#testing","title":"Testing","text":"<p>Fawkes includes multiple layers of testing:</p> <ul> <li>Static Analysis: Run tools like SonarQube or Trivy to check for vulnerabilities.</li> <li>Unit Tests: Located in the <code>qa/unit/</code> directory.</li> <li>Integration Tests: Located in the <code>qa/integration/</code> directory.</li> <li>Acceptance Tests: Located in the <code>qa/acceptance/</code> directory.</li> <li>Performance Tests: Located in the <code>qa/performance/</code> directory.</li> </ul> <p>Run all tests before submitting a PR: <pre><code>cd qa\n./run-all-tests.sh\n</code></pre></p>"},{"location":"development/#azure-development-best-practices","title":"Azure Development Best Practices","text":"<p>If you are working with Azure, follow these best practices:</p> <ol> <li> <p>Use Azure CLI for Authentication:    <pre><code>az login\n</code></pre></p> </li> <li> <p>Set the Active Subscription:    <pre><code>az account set --subscription &lt;subscription-id&gt;\n</code></pre></p> </li> <li> <p>Follow Azure Resource Naming Conventions:    Use consistent and descriptive names for resources.</p> </li> <li> <p>Use Infrastructure as Code (IaC):    Use Terraform or Bicep for provisioning Azure resources.</p> </li> <li> <p>Enable Logging and Monitoring:    Configure Azure Monitor and Log Analytics for all deployed resources.</p> </li> <li> <p>Secure Secrets:    Store secrets in Azure Key Vault and reference them in your deployments.</p> </li> </ol>"},{"location":"development/#submitting-contributions","title":"Submitting Contributions","text":"<ol> <li> <p>Fork the Repository:    Create a fork of the repository on GitHub.</p> </li> <li> <p>Make Changes:    Work on your feature branch and ensure all tests pass.</p> </li> <li> <p>Submit a Pull Request:    Open a PR with a detailed description of your changes.</p> </li> <li> <p>Address Feedback:    Respond to reviewer comments and make necessary updates.</p> </li> </ol>"},{"location":"development/#need-help","title":"Need Help?","text":"<p>If you encounter any issues, refer to the troubleshooting guide or open an issue on GitHub.</p>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":"<p>This document addresses common questions about the Fawkes Internal Developer Platform (IDP). If your question is not answered here, feel free to open an issue on GitHub.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#1-what-is-fawkes","title":"1. What is Fawkes?","text":"<p>Fawkes is an open source platform for provisioning secure, automated workspaces and Kubernetes-based continuous delivery pipelines across multiple cloud environments. It is designed to help teams adopt DevSecOps practices and improve their software delivery performance.</p>"},{"location":"faq/#2-what-are-the-key-influences-behind-fawkes","title":"2. What are the key influences behind Fawkes?","text":"<p>Fawkes is heavily inspired by the Accelerate book, the DORA (DevOps Research and Assessment) reports, and the State of DevOps reports. The platform focuses on improving the Four Key Metrics and implementing the 24 DORA capabilities, especially those related to Continuous Delivery.</p>"},{"location":"faq/#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"faq/#3-how-do-i-set-up-fawkes","title":"3. How do I set up Fawkes?","text":"<p>Follow the Getting Started Guide to set up your environment, provision infrastructure, and deploy platform services.</p>"},{"location":"faq/#4-what-cloud-providers-are-supported","title":"4. What cloud providers are supported?","text":"<p>Currently, Fawkes supports AWS. Azure, GCP, and VMware support are planned for future releases.</p>"},{"location":"faq/#5-how-do-i-configure-secrets","title":"5. How do I configure secrets?","text":"<p>Secrets should be managed using tools like AWS Secrets Manager, Azure Key Vault, or Kubernetes Secrets. Refer to the Configuration Guide for details.</p>"},{"location":"faq/#infrastructure-and-platform","title":"Infrastructure and Platform","text":""},{"location":"faq/#6-what-tools-are-used-for-infrastructure-provisioning","title":"6. What tools are used for infrastructure provisioning?","text":"<p>Fawkes uses Terraform for Infrastructure as Code (IaC) and Helm for managing Kubernetes applications.</p>"},{"location":"faq/#7-how-do-i-monitor-my-infrastructure-and-applications","title":"7. How do I monitor my infrastructure and applications?","text":"<p>Fawkes integrates with Prometheus and Grafana for monitoring. Additional integrations like Azure Monitor and the ELK stack are also supported. See the Integrations Guide for more details.</p>"},{"location":"faq/#cicd-and-testing","title":"CI/CD and Testing","text":""},{"location":"faq/#8-what-cicd-tools-are-supported","title":"8. What CI/CD tools are supported?","text":"<p>Fawkes supports Jenkins, GitHub Actions, and Azure DevOps Pipelines. Pre-configured pipelines and workflows are included to help you get started quickly.</p>"},{"location":"faq/#9-what-types-of-testing-are-included","title":"9. What types of testing are included?","text":"<p>Fawkes includes static analysis, unit testing, integration testing, acceptance testing, performance testing, and security testing. Refer to the QA Directory for more information.</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#10-what-should-i-do-if-i-encounter-an-issue","title":"10. What should I do if I encounter an issue?","text":"<p>Refer to the Troubleshooting Guide for solutions to common problems. If the issue persists, open an issue on GitHub.</p>"},{"location":"faq/#11-how-do-i-debug-kubernetes-issues","title":"11. How do I debug Kubernetes issues?","text":"<p>Use <code>kubectl</code> to inspect resources and logs. For example: <pre><code>kubectl describe pod &lt;pod-name&gt;\nkubectl logs &lt;pod-name&gt;\n</code></pre> Refer to the Kubernetes Configuration section for more details.</p>"},{"location":"faq/#contributions","title":"Contributions","text":""},{"location":"faq/#12-how-can-i-contribute-to-fawkes","title":"12. How can I contribute to Fawkes?","text":"<p>We welcome contributions! See the Development Guide for instructions on setting up your development environment and submitting pull requests.</p>"},{"location":"faq/#13-are-there-any-coding-standards-i-should-follow","title":"13. Are there any coding standards I should follow?","text":"<p>Yes, Fawkes follows best practices for coding, testing, and documentation. Refer to the Development Guide for details.</p>"},{"location":"faq/#azure-specific-questions","title":"Azure-Specific Questions","text":""},{"location":"faq/#14-how-do-i-authenticate-with-azure","title":"14. How do I authenticate with Azure?","text":"<p>Use the Azure CLI to log in and set your subscription: <pre><code>az login\naz account set --subscription &lt;subscription-id&gt;\n</code></pre> Follow Azure best practices for authentication and resource management. Refer to the Azure Development Best Practices section for more details.</p>"},{"location":"faq/#15-does-fawkes-support-azure-devops","title":"15. Does Fawkes support Azure DevOps?","text":"<p>Yes, Fawkes supports Azure DevOps Pipelines for CI/CD. Pre-configured templates and best practices are included.</p>"},{"location":"faq/#need-more-help","title":"Need More Help?","text":"<p>If your question is not answered here, you can: 1. Check the Documentation for additional resources. 2. Open an issue on GitHub. 3. Reach out to the community for support.</p>"},{"location":"getting-started/","title":"Getting Started with Fawkes","text":"<p>Welcome to the Fawkes Internal Developer Platform! This guide will help you understand and implement the GitOps-based approach to platform management and delivery excellence.</p>"},{"location":"getting-started/#repository-structure","title":"Repository Structure","text":"<pre><code>fawkes/\n\u251c\u2500\u2500 docs/                          # Documentation (Di\u00e1taxis framework)\n\u2502   \u251c\u2500\u2500 tutorials/                 # Learning-oriented guides\n\u2502   \u251c\u2500\u2500 how-to/                    # Task-oriented guides\n\u2502   \u251c\u2500\u2500 explanation/               # Understanding-oriented discussions\n\u2502   \u251c\u2500\u2500 reference/                 # Information-oriented specifications\n\u2502   \u2502   \u251c\u2500\u2500 api/                   # API specifications (OpenAPI, REST)\n\u2502   \u2502   \u251c\u2500\u2500 crds/                  # Custom Resource Definitions\n\u2502   \u2502   \u251c\u2500\u2500 config/                # Configuration tables (Helm values)\n\u2502   \u2502   \u251c\u2500\u2500 policies/              # Policy listings (Kyverno)\n\u2502   \u2502   \u251c\u2500\u2500 catalogue/             # Service catalog reference\n\u2502   \u2502   \u2514\u2500\u2500 glossary.md            # Fawkes terminology\n\u2502   \u2514\u2500\u2500 dojo/                      # Belt-based learning modules\n\u251c\u2500\u2500 platform/                      # Platform components\n\u2502   \u251c\u2500\u2500 apps/                      # ArgoCD applications (Jenkins, Backstage, etc.)\n\u2502   \u251c\u2500\u2500 policies/                  # Kyverno policies (security, mutation, generation)\n\u2502   \u251c\u2500\u2500 devfiles/                  # Eclipse Che development environments\n\u2502   \u251c\u2500\u2500 networking/                # Ingress, cert-manager, external-dns\n\u2502   \u2514\u2500\u2500 bootstrap/                 # Platform initialization scripts\n\u251c\u2500\u2500 infra/                         # Infrastructure as Code\n\u2502   \u251c\u2500\u2500 local-dev/                 # Local Kubernetes (kind, minikube)\n\u2502   \u251c\u2500\u2500 kubernetes/                # Kubernetes manifests\n\u2502   \u2514\u2500\u2500 terraform/                 # Cloud infrastructure (AWS, Azure, GCP)\n\u251c\u2500\u2500 jenkins-shared-library/        # Golden Path pipeline library\n\u251c\u2500\u2500 services/                      # Platform-specific services\n\u2502   \u2514\u2500\u2500 mcp-k8s-server/            # Model Context Protocol server\n\u251c\u2500\u2500 tests/                         # Test suites\n\u2502   \u251c\u2500\u2500 bdd/                       # BDD/Gherkin acceptance tests\n\u2502   \u251c\u2500\u2500 unit/                      # Unit tests\n\u2502   \u2514\u2500\u2500 integration/               # Integration tests\n\u2514\u2500\u2500 mkdocs.yml                     # Documentation site configuration\n</code></pre>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Git: For repository management</li> <li>kubectl: For Kubernetes interaction</li> <li>ArgoCD: For GitOps operations</li> <li>Cloud CLI: For your chosen cloud provider</li> </ul>"},{"location":"getting-started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/paruff/fawkes.git\ncd fawkes\n</code></pre>"},{"location":"getting-started/#2-choose-your-implementation-path","title":"2. Choose Your Implementation Path","text":"<p>Fawkes supports multiple implementation paths based on your cloud provider:</p> Cloud Implementation Documentation Azure AKS + Flux Azure Guide AWS EKS + ArgoCD AWS Guide GCP GKE + Cloud Build GCP Guide"},{"location":"getting-started/#3-infrastructure-deployment","title":"3. Infrastructure Deployment","text":"<p>We use a GitOps approach for infrastructure management. Changes are made through pull requests:</p> <ol> <li> <p>Create a feature branch: <pre><code>git checkout -b feature/add-new-service\n</code></pre></p> </li> <li> <p>Make changes to infrastructure definitions in <code>platform/iac/</code>: <pre><code># Example service definition\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fawkes-service\nspec:\n  replicas: 3\n  ...\n</code></pre></p> </li> <li> <p>Commit and push changes: <pre><code>git add .\ngit commit -m \"feat: add new service deployment\"\ngit push origin feature/add-new-service\n</code></pre></p> </li> <li> <p>Create a pull request and wait for CI checks and review</p> </li> </ol>"},{"location":"getting-started/#4-platform-services","title":"4. Platform Services","text":"<p>Services are deployed automatically via GitOps controllers. To add a new service:</p> <ol> <li> <p>Define the service in <code>platform/apps/</code>: <pre><code># Example service manifest\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: jenkins\nspec:\n  source:\n    repoURL: https://github.com/paruff/fawkes.git\n    path: platform/apps/jenkins\n    targetRevision: HEAD\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: jenkins\n</code></pre></p> </li> <li> <p>Commit and push through the GitOps workflow</p> </li> </ol>"},{"location":"getting-started/#5-verify-deployment","title":"5. Verify Deployment","text":"<p>Monitor deployments through:</p> <ul> <li>GitOps dashboard (ArgoCD/Flux)</li> <li>Kubernetes dashboard</li> <li>Platform monitoring tools</li> </ul>"},{"location":"getting-started/#6-running-tests","title":"6. Running Tests","text":"<p>Tests are executed using pytest:</p> <pre><code># Run unit tests\npytest tests/unit -v\n\n# Run BDD tests\npytest tests/bdd -v\n\n# Run all tests\npytest tests/ -v\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ol> <li>Assess your capabilities</li> <li>Review implementation patterns</li> <li>Explore available tools</li> </ol>"},{"location":"getting-started/#need-help","title":"Need Help?","text":"<ul> <li>Check our troubleshooting guide</li> <li>Open an issue on GitHub</li> <li>Join our community discussions</li> </ul> <p>Start Assessment  View Patterns  Explore Tools </p>"},{"location":"golden-path-usage/","title":"Golden Path CI/CD Usage Guide","text":"<p>This guide explains how application teams can use the Fawkes Golden Path CI/CD pipeline to build, test, and deploy applications consistently.</p>"},{"location":"golden-path-usage/#overview","title":"Overview","text":"<p>The Golden Path is a standardized CI/CD pipeline that:</p> <ul> <li>Enforces Trunk-Based Development: Only the main branch produces artifacts</li> <li>Includes Mandatory Security Scanning: SonarQube, Trivy, dependency checks</li> <li>Supports BDD Testing: Gherkin/Cucumber integration</li> <li>Produces GitOps-Ready Artifacts: Versioned container images for ArgoCD</li> <li>Tracks DORA Metrics: Automated metrics collection</li> <li>Uses SCORE for Workload Definition: Platform-agnostic application specifications (see SCORE Integration)</li> </ul>"},{"location":"golden-path-usage/#quick-start","title":"Quick Start","text":""},{"location":"golden-path-usage/#1-add-a-jenkinsfile","title":"1. Add a Jenkinsfile","text":"<p>Create a <code>Jenkinsfile</code> in your repository root:</p> <pre><code>@Library('fawkes-pipeline-library') _\n\ngoldenPathPipeline {\n    appName = 'my-service'\n    language = 'java'  // java, python, node, go\n}\n</code></pre>"},{"location":"golden-path-usage/#2-push-to-main-branch","title":"2. Push to Main Branch","text":"<p>When you push to the <code>main</code> branch, the pipeline automatically:</p> <ol> <li>Builds your application</li> <li>Runs unit tests</li> <li>Runs BDD/Gherkin tests</li> <li>Performs security scanning</li> <li>Builds a Docker image</li> <li>Scans the container</li> <li>Pushes to the registry</li> <li>Updates GitOps manifests</li> <li>Records DORA metrics</li> </ol>"},{"location":"golden-path-usage/#3-open-pull-requests","title":"3. Open Pull Requests","text":"<p>PR builds run a lightweight pipeline with only tests (no artifacts).</p>"},{"location":"golden-path-usage/#pipeline-configuration","title":"Pipeline Configuration","text":""},{"location":"golden-path-usage/#required-options","title":"Required Options","text":"Option Description Example <code>appName</code> Application name <code>'my-service'</code> <code>language</code> Programming language <code>'java'</code>, <code>'python'</code>, <code>'node'</code>, <code>'go'</code>"},{"location":"golden-path-usage/#optional-options","title":"Optional Options","text":"Option Default Description <code>dockerRegistry</code> <code>harbor.fawkes.local</code> Container registry URL <code>dockerImage</code> Auto-generated Full Docker image path <code>notifyChannel</code> <code>ci-builds</code> Mattermost channel for notifications <code>testCommand</code> Language-specific Custom unit test command <code>bddTestCommand</code> Language-specific Custom BDD test command <code>buildCommand</code> Language-specific Custom build command <code>sonarProject</code> <code>appName</code> SonarQube project key <code>trivySeverity</code> <code>HIGH,CRITICAL</code> Trivy severity threshold <code>runBddTests</code> <code>true</code> Enable/disable BDD testing <code>runSecurityScan</code> <code>true</code> Enable/disable security scanning <code>deployToArgoCD</code> <code>true</code> Update GitOps manifests <code>timeoutMinutes</code> <code>30</code> Pipeline timeout"},{"location":"golden-path-usage/#language-specific-configuration","title":"Language-Specific Configuration","text":""},{"location":"golden-path-usage/#java-maven","title":"Java (Maven)","text":"<pre><code>goldenPathPipeline {\n    appName = 'java-service'\n    language = 'java'\n    // Defaults:\n    // buildCommand = 'mvn clean package -DskipTests'\n    // testCommand = 'mvn test'\n    // bddTestCommand = 'mvn verify -Pcucumber'\n}\n</code></pre> <p>Required Files: - <code>pom.xml</code> - Maven project file - <code>Dockerfile</code> - Container build instructions - <code>src/test/java/</code> - Unit tests - <code>src/test/resources/features/</code> - Gherkin feature files (optional)</p> <p>Cucumber Integration:</p> <p>Add to <code>pom.xml</code>:</p> <pre><code>&lt;profiles&gt;\n    &lt;profile&gt;\n        &lt;id&gt;cucumber&lt;/id&gt;\n        &lt;build&gt;\n            &lt;plugins&gt;\n                &lt;plugin&gt;\n                    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                    &lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt;\n                    &lt;configuration&gt;\n                        &lt;includes&gt;\n                            &lt;include&gt;**/CucumberRunner.java&lt;/include&gt;\n                        &lt;/includes&gt;\n                    &lt;/configuration&gt;\n                &lt;/plugin&gt;\n            &lt;/plugins&gt;\n        &lt;/build&gt;\n    &lt;/profile&gt;\n&lt;/profiles&gt;\n</code></pre>"},{"location":"golden-path-usage/#python","title":"Python","text":"<pre><code>goldenPathPipeline {\n    appName = 'python-service'\n    language = 'python'\n    // Defaults:\n    // buildCommand = 'pip install -r requirements.txt &amp;&amp; pip install -e .'\n    // testCommand = 'pytest tests/unit --junitxml=test-results.xml --cov=src --cov-report=xml'\n    // bddTestCommand = 'behave --junit --junit-directory=bdd-results'\n}\n</code></pre> <p>Required Files: - <code>requirements.txt</code> - Dependencies - <code>Dockerfile</code> - Container build instructions - <code>tests/unit/</code> - Unit tests - <code>features/</code> - Behave feature files (optional)</p> <p>Behave Integration:</p> <pre><code>features/\n\u251c\u2500\u2500 environment.py\n\u251c\u2500\u2500 steps/\n\u2502   \u2514\u2500\u2500 my_steps.py\n\u2514\u2500\u2500 my_feature.feature\n</code></pre>"},{"location":"golden-path-usage/#nodejs","title":"Node.js","text":"<pre><code>goldenPathPipeline {\n    appName = 'node-service'\n    language = 'node'\n    // Defaults:\n    // buildCommand = 'npm ci &amp;&amp; npm run build'\n    // testCommand = 'npm test -- --ci --reporters=jest-junit'\n    // bddTestCommand = 'npm run test:bdd'\n}\n</code></pre> <p>Required Files: - <code>package.json</code> - Node.js project file - <code>Dockerfile</code> - Container build instructions - <code>__tests__/</code> or <code>tests/</code> - Unit tests - <code>features/</code> - Cucumber.js feature files (optional)</p> <p>Cucumber.js Integration:</p> <p>Add to <code>package.json</code>:</p> <pre><code>{\n  \"scripts\": {\n    \"test:bdd\": \"cucumber-js\"\n  },\n  \"devDependencies\": {\n    \"@cucumber/cucumber\": \"^9.0.0\"\n  }\n}\n</code></pre>"},{"location":"golden-path-usage/#go","title":"Go","text":"<pre><code>goldenPathPipeline {\n    appName = 'go-service'\n    language = 'go'\n    // Defaults:\n    // buildCommand = 'go build -v ./...'\n    // testCommand = 'go test -v -coverprofile=coverage.out ./...'\n    // bddTestCommand = 'go test -v ./features/...'\n}\n</code></pre> <p>Required Files: - <code>go.mod</code> - Go module file - <code>Dockerfile</code> - Container build instructions - <code>*_test.go</code> - Unit tests - <code>features/</code> - Godog feature files (optional)</p>"},{"location":"golden-path-usage/#custom-commands","title":"Custom Commands","text":"<p>Override default commands when needed:</p> <pre><code>goldenPathPipeline {\n    appName = 'my-service'\n    language = 'java'\n\n    // Custom build with production profile\n    buildCommand = 'mvn clean package -P production -DskipTests'\n\n    // Run only specific tests\n    testCommand = 'mvn test -Dtest=UnitTests'\n\n    // Run only smoke BDD tests\n    bddTestCommand = 'mvn verify -Dcucumber.filter.tags=\"@smoke\"'\n}\n</code></pre>"},{"location":"golden-path-usage/#bddgherkin-testing","title":"BDD/Gherkin Testing","text":""},{"location":"golden-path-usage/#feature-file-example","title":"Feature File Example","text":"<p>Create <code>src/test/resources/features/user_registration.feature</code>:</p> <pre><code>Feature: User Registration\n  As a new user\n  I want to register for an account\n  So that I can access the application\n\n  Background:\n    Given the registration service is available\n\n  @smoke\n  Scenario: Successful registration\n    Given I have valid user details\n    When I submit the registration form\n    Then my account is created\n    And I receive a confirmation email\n\n  @validation\n  Scenario Outline: Invalid registration data\n    Given I provide \"&lt;field&gt;\" with \"&lt;value&gt;\"\n    When I submit the registration form\n    Then I receive error \"&lt;error&gt;\"\n\n    Examples:\n      | field    | value | error               |\n      | email    |       | Email is required   |\n      | password | 123   | Password too short  |\n</code></pre>"},{"location":"golden-path-usage/#step-definitions","title":"Step Definitions","text":""},{"location":"golden-path-usage/#java-cucumber","title":"Java (Cucumber)","text":"<pre><code>public class UserRegistrationSteps {\n    @Given(\"the registration service is available\")\n    public void serviceIsAvailable() {\n        // Verify service is running\n    }\n\n    @When(\"I submit the registration form\")\n    public void submitForm() {\n        // Submit registration\n    }\n\n    @Then(\"my account is created\")\n    public void accountCreated() {\n        // Verify account exists\n    }\n}\n</code></pre>"},{"location":"golden-path-usage/#python-behave","title":"Python (Behave)","text":"<pre><code>from behave import given, when, then\n\n@given('the registration service is available')\ndef service_available(context):\n    # Verify service is running\n    pass\n\n@when('I submit the registration form')\ndef submit_form(context):\n    # Submit registration\n    pass\n\n@then('my account is created')\ndef account_created(context):\n    # Verify account exists\n    pass\n</code></pre>"},{"location":"golden-path-usage/#security-scanning","title":"Security Scanning","text":""},{"location":"golden-path-usage/#sonarqube","title":"SonarQube","text":"<p>Add <code>sonar-project.properties</code> to your repository:</p> <pre><code>sonar.projectKey=my-service\nsonar.sources=src\nsonar.tests=tests\nsonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml\n</code></pre>"},{"location":"golden-path-usage/#trivy","title":"Trivy","text":"<p>Container scanning is automatic. Customize severity threshold:</p> <pre><code>goldenPathPipeline {\n    trivySeverity = 'CRITICAL'  // Only fail on critical\n    trivyExitCode = '0'         // Don't fail build (warning only)\n}\n</code></pre>"},{"location":"golden-path-usage/#dependency-checks","title":"Dependency Checks","text":"<p>Language-specific dependency scanning: - Java: OWASP Dependency-Check Maven plugin - Python: <code>safety</code> and <code>pip-audit</code> - Node.js: <code>npm audit</code> - Go: <code>govulncheck</code></p>"},{"location":"golden-path-usage/#notifications","title":"Notifications","text":"<p>Build notifications are sent to Mattermost:</p> <pre><code>goldenPathPipeline {\n    notifyChannel = 'my-team-builds'\n}\n</code></pre> <p>Notifications include: - \u2705/\u274c Build status - Build number and duration - Commit SHA and branch - Link to Jenkins build</p>"},{"location":"golden-path-usage/#dora-metrics","title":"DORA Metrics","text":"<p>The pipeline automatically records:</p> <ul> <li>Build Status: Success/failure</li> <li>Build Duration: Time to complete</li> <li>Commit Information: SHA, branch, author</li> <li>Deployment Events: When artifacts are pushed</li> </ul> <p>Access DORA dashboard at: <code>http://grafana.fawkes.local/d/dora</code></p>"},{"location":"golden-path-usage/#pull-request-workflow","title":"Pull Request Workflow","text":""},{"location":"golden-path-usage/#pr-pipeline","title":"PR Pipeline","text":"<p>PRs trigger a lightweight pipeline:</p> Stage Executed? Checkout \u2705 Build \u274c Unit Test \u2705 BDD Test \u2705 Security Scan \u274c Docker Build \u274c Push Artifact \u274c"},{"location":"golden-path-usage/#merge-requirements","title":"Merge Requirements","text":"<p>Before merging: 1. All tests pass 2. Code review approved 3. PR status checks green</p>"},{"location":"golden-path-usage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"golden-path-usage/#common-issues","title":"Common Issues","text":""},{"location":"golden-path-usage/#build-timeout","title":"Build Timeout","text":"<p>Increase timeout in Jenkinsfile: <pre><code>timeoutMinutes = 60\n</code></pre></p>"},{"location":"golden-path-usage/#sonarqube-fails","title":"SonarQube Fails","text":"<ol> <li>Check SonarQube project exists</li> <li>Verify credentials in Jenkins</li> <li>Check <code>sonar-project.properties</code></li> </ol>"},{"location":"golden-path-usage/#docker-push-fails","title":"Docker Push Fails","text":"<ol> <li>Verify registry credentials</li> <li>Check network connectivity</li> <li>Ensure image name is valid</li> </ol>"},{"location":"golden-path-usage/#bdd-tests-not-running","title":"BDD Tests Not Running","text":"<ol> <li>Ensure <code>runBddTests = true</code></li> <li>Check step definitions exist</li> <li>Verify feature files are in correct location</li> </ol>"},{"location":"golden-path-usage/#debug-mode","title":"Debug Mode","text":"<p>View detailed logs in Jenkins console output: 1. Go to Jenkins build 2. Click \"Console Output\" 3. Search for stage name</p>"},{"location":"golden-path-usage/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: This guide and shared library README</li> <li>Mattermost: <code>#platform-support</code> channel</li> <li>Office Hours: Platform team availability</li> </ul>"},{"location":"golden-path-usage/#best-practices","title":"Best Practices","text":"<ol> <li>Keep Jenkinsfiles minimal - Use default configurations</li> <li>Test locally first - Run tests before pushing</li> <li>Use feature flags - Deploy to main frequently</li> <li>Monitor builds - Watch for increasing durations</li> <li>Update dependencies - Keep libraries current</li> <li>Define workloads with SCORE - Use <code>score.yaml</code> for portable application definitions</li> </ol>"},{"location":"golden-path-usage/#score-workload-specification","title":"SCORE Workload Specification","text":"<p>Fawkes Golden Path supports SCORE, an open-source, platform-agnostic workload specification. Instead of writing Kubernetes YAML directly, define your application's needs in a simple <code>score.yaml</code> file.</p>"},{"location":"golden-path-usage/#why-score","title":"Why SCORE?","text":"<p>\u2705 Portability: Define once, deploy anywhere (dev, staging, prod) \u2705 Simplicity: Describe what you need, not how to configure K8s \u2705 Consistency: Same format across all Golden Path applications \u2705 Developer-Friendly: Focus on application logic, not infrastructure</p>"},{"location":"golden-path-usage/#quick-example","title":"Quick Example","text":"<p>Create a <code>score.yaml</code> in your repository:</p> <pre><code>apiVersion: score.dev/v1b1\nmetadata:\n  name: my-service\n\ncontainers:\n  web:\n    image: \"harbor.fawkes.local/my-team/my-service:latest\"\n    resources:\n      limits: {memory: \"512Mi\", cpu: \"500m\"}\n      requests: {memory: \"256Mi\", cpu: \"250m\"}\n    variables:\n      LOG_LEVEL: \"info\"\n      DATABASE_URL: \"${resources.db.connection_string}\"\n\nservice:\n  ports:\n    web: {port: 80, targetPort: 8080}\n\nresources:\n  db:\n    type: postgres\n    properties:\n      database: \"myapp\"\n\nroute:\n  host: \"my-service.${ENVIRONMENT}.fawkes.idp\"\n  tls: {enabled: true}\n</code></pre> <p>The platform automatically translates this into: - Kubernetes Deployment - Service - Ingress - PostgreSQL database (via CloudNativePG) - TLS certificate (via cert-manager)</p>"},{"location":"golden-path-usage/#repository-structure-with-score","title":"Repository Structure with SCORE","text":"<pre><code>my-service/\n\u251c\u2500\u2500 score.yaml              # Workload definition (SCORE spec)\n\u251c\u2500\u2500 Jenkinsfile             # CI/CD pipeline\n\u251c\u2500\u2500 Dockerfile              # Container build\n\u251c\u2500\u2500 src/                    # Application code\n\u2514\u2500\u2500 tests/                  # Tests\n</code></pre>"},{"location":"golden-path-usage/#supported-resources","title":"Supported Resources","text":"Resource Type Description Fawkes Implementation <code>postgres</code> PostgreSQL database CloudNativePG Cluster <code>redis</code> Redis cache Redis Helm Chart <code>secret</code> Secrets from Vault External Secrets Operator <code>volume</code> Persistent storage PersistentVolumeClaim"},{"location":"golden-path-usage/#environment-specific-deployment","title":"Environment-Specific Deployment","text":"<p>The same <code>score.yaml</code> works across environments. Environment differences (replicas, resource limits, hostnames) are handled by the platform:</p> <p>Dev Environment: - 1 replica - Smaller resource limits - <code>my-service.dev.fawkes.idp</code></p> <p>Prod Environment: - 3 replicas with autoscaling - Higher resource limits - <code>my-service.prod.fawkes.idp</code></p>"},{"location":"golden-path-usage/#migration-from-k8s-manifests","title":"Migration from K8s Manifests","text":"<p>If you have existing Kubernetes manifests, you can migrate gradually:</p> <ol> <li>Keep existing manifests - They continue to work</li> <li>Create score.yaml - Define the same workload in SCORE</li> <li>Validate - Ensure generated manifests match your needs</li> <li>Switch - Remove old manifests, use SCORE-generated ones</li> </ol>"},{"location":"golden-path-usage/#advanced-configuration","title":"Advanced Configuration","text":"<p>For Fawkes-specific features (autoscaling, observability, security policies), use the <code>extensions.fawkes</code> section:</p> <pre><code>extensions:\n  fawkes:\n    team: my-team\n    deployment:\n      autoscaling:\n        enabled: true\n        minReplicas: 2\n        maxReplicas: 10\n    observability:\n      metrics:\n        enabled: true\n        port: 9090\n    security:\n      runAsNonRoot: true\n</code></pre>"},{"location":"golden-path-usage/#documentation-examples","title":"Documentation &amp; Examples","text":"<ul> <li>Full Template: See <code>templates/golden-path-service/score.yaml</code></li> <li>Architecture Decision: ADR-030: SCORE Integration</li> <li>Transformer Details: <code>charts/score-transformer/README.md</code></li> <li>Official SCORE Docs: https://score.dev</li> </ul>"},{"location":"golden-path-usage/#next-steps","title":"Next Steps","text":"<ol> <li>Add Jenkinsfile to your repository</li> <li>Create <code>score.yaml</code> for workload definition (recommended)</li> <li>Configure BDD tests (optional)</li> <li>Push to main branch</li> <li>Monitor build in Jenkins</li> <li>Verify deployment in ArgoCD</li> </ol>"},{"location":"ingress-access/","title":"Ingress Access Guide","text":"<p>This document describes how to configure external access for services on the Fawkes platform using Ingress resources with automated DNS management and TLS provisioning.</p>"},{"location":"ingress-access/#overview","title":"Overview","text":"<p>The Fawkes platform provides: - NGINX Ingress Controller: High availability Layer 7 routing - ExternalDNS: Automated DNS record management - cert-manager: Automatic TLS certificate provisioning via Let's Encrypt</p> <p>All external-facing services are exposed via the Ingress Controller with mandatory TLS encryption.</p>"},{"location":"ingress-access/#architecture","title":"Architecture","text":"<pre><code>Internet\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Wildcard DNS (*.fawkes.idp)\u2502\n\u2502  Points to Load Balancer IP \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  AWS NLB / Cloud LB         \u2502\n\u2502  (Static IP via Terraform)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  NGINX Ingress Controller   \u2502\n\u2502  - TLS Termination          \u2502\n\u2502  - HTTPS Redirect           \u2502\n\u2502  - Path-based Routing       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Internal Services          \u2502\n\u2502  (Plaintext within cluster) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ingress-access/#creating-an-ingress-resource","title":"Creating an Ingress Resource","text":""},{"location":"ingress-access/#basic-ingress-with-tls","title":"Basic Ingress with TLS","text":"<p>To expose a service externally, create an Ingress resource with the following mandatory annotations:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-service\n  namespace: my-namespace\n  annotations:\n    # Required: Use nginx ingress class\n    kubernetes.io/ingress.class: nginx\n\n    # Required: TLS certificate issuer (use letsencrypt-prod for production)\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n\n    # Optional: ExternalDNS will auto-create DNS record based on host\n    external-dns.alpha.kubernetes.io/hostname: my-service.fawkes.idp\n\n    # Optional: Force HTTPS redirect (enabled by default)\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  ingressClassName: nginx\n  tls:\n    - hosts:\n        - my-service.fawkes.idp\n      secretName: my-service-tls\n  rules:\n    - host: my-service.fawkes.idp\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: my-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"ingress-access/#mandatory-annotations","title":"Mandatory Annotations","text":"Annotation Value Description <code>kubernetes.io/ingress.class</code> <code>nginx</code> Specifies the Ingress controller <code>cert-manager.io/cluster-issuer</code> <code>letsencrypt-prod</code> or <code>letsencrypt-staging</code> TLS certificate issuer"},{"location":"ingress-access/#recommended-annotations","title":"Recommended Annotations","text":"Annotation Default Description <code>nginx.ingress.kubernetes.io/ssl-redirect</code> <code>true</code> Force HTTPS redirect <code>external-dns.alpha.kubernetes.io/hostname</code> Auto from host DNS record hostname <code>nginx.ingress.kubernetes.io/proxy-body-size</code> <code>50m</code> Max request body size <code>nginx.ingress.kubernetes.io/proxy-read-timeout</code> <code>60</code> Backend read timeout"},{"location":"ingress-access/#example-ingress-resources","title":"Example Ingress Resources","text":""},{"location":"ingress-access/#jenkins","title":"Jenkins","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: jenkins\n  namespace: jenkins\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/proxy-body-size: \"100m\"\nspec:\n  ingressClassName: nginx\n  tls:\n    - hosts:\n        - jenkins.fawkes.idp\n      secretName: jenkins-tls\n  rules:\n    - host: jenkins.fawkes.idp\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: jenkins\n                port:\n                  number: 8080\n</code></pre>"},{"location":"ingress-access/#sonarqube","title":"SonarQube","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: sonarqube\n  namespace: sonarqube\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/proxy-body-size: \"200m\"\nspec:\n  ingressClassName: nginx\n  tls:\n    - hosts:\n        - sonarqube.fawkes.idp\n      secretName: sonarqube-tls\n  rules:\n    - host: sonarqube.fawkes.idp\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: sonarqube-sonarqube\n                port:\n                  number: 9000\n</code></pre>"},{"location":"ingress-access/#grafana","title":"Grafana","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana\n  namespace: grafana\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nspec:\n  ingressClassName: nginx\n  tls:\n    - hosts:\n        - grafana.fawkes.idp\n      secretName: grafana-tls\n  rules:\n    - host: grafana.fawkes.idp\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: grafana\n                port:\n                  number: 3000\n</code></pre>"},{"location":"ingress-access/#focalboard","title":"Focalboard","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: focalboard\n  namespace: focalboard\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nspec:\n  ingressClassName: nginx\n  tls:\n    - hosts:\n        - focalboard.fawkes.idp\n      secretName: focalboard-tls\n  rules:\n    - host: focalboard.fawkes.idp\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: focalboard\n                port:\n                  number: 8000\n</code></pre>"},{"location":"ingress-access/#tls-certificate-management","title":"TLS Certificate Management","text":""},{"location":"ingress-access/#issuers-available","title":"Issuers Available","text":"Issuer Usage Rate Limits <code>letsencrypt-staging</code> Development/Testing No rate limits, untrusted certificates <code>letsencrypt-prod</code> Production Rate limited, trusted certificates <code>selfsigned-issuer</code> Internal services No rate limits, self-signed"},{"location":"ingress-access/#certificate-lifecycle","title":"Certificate Lifecycle","text":"<ol> <li>Provisioning: cert-manager automatically creates certificates when an Ingress with <code>cert-manager.io/cluster-issuer</code> annotation is created</li> <li>Renewal: Certificates are automatically renewed 30 days before expiration</li> <li>Storage: Certificates are stored in Kubernetes Secrets referenced by <code>secretName</code></li> </ol>"},{"location":"ingress-access/#troubleshooting-certificates","title":"Troubleshooting Certificates","text":"<p>Check certificate status: <pre><code>kubectl get certificate -A\nkubectl describe certificate &lt;name&gt; -n &lt;namespace&gt;\n</code></pre></p> <p>Check certificate requests: <pre><code>kubectl get certificaterequest -A\nkubectl describe certificaterequest &lt;name&gt; -n &lt;namespace&gt;\n</code></pre></p>"},{"location":"ingress-access/#dns-configuration","title":"DNS Configuration","text":""},{"location":"ingress-access/#wildcard-dns-setup","title":"Wildcard DNS Setup","text":"<p>A wildcard DNS record <code>*.fawkes.idp</code> must point to the Ingress Controller's Load Balancer IP.</p> <p>Get the Load Balancer IP: <pre><code>kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}'\n</code></pre></p> <p>Or use the Terraform output: <pre><code>cd platform/networking/loadbalancer-provisioning\nterraform output ingress_lb_public_ip\n</code></pre></p>"},{"location":"ingress-access/#externaldns-behavior","title":"ExternalDNS Behavior","text":"<p>ExternalDNS automatically manages DNS records based on Ingress resources: - Creates A records when Ingress is created - Updates records when Ingress is modified - Does not delete records by default (upsert-only policy)</p>"},{"location":"ingress-access/#security-considerations","title":"Security Considerations","text":""},{"location":"ingress-access/#tls-termination","title":"TLS Termination","text":"<ul> <li>TLS termination occurs at the Ingress Controller layer</li> <li>Traffic between Ingress Controller and services is plaintext</li> <li>For sensitive services, consider using mTLS with a service mesh</li> </ul>"},{"location":"ingress-access/#http-to-https-redirect","title":"HTTP to HTTPS Redirect","text":"<p>All HTTP requests are automatically redirected to HTTPS. This is enforced at the Ingress Controller level.</p>"},{"location":"ingress-access/#security-headers","title":"Security Headers","text":"<p>The Ingress Controller adds the following security headers by default: - <code>Strict-Transport-Security: max-age=31536000; includeSubDomains</code> - Server tokens are hidden</p>"},{"location":"ingress-access/#monitoring","title":"Monitoring","text":""},{"location":"ingress-access/#ingress-controller-metrics","title":"Ingress Controller Metrics","text":"<p>Prometheus metrics are available at <code>/metrics</code> on the Ingress Controller pods.</p> <p>Key metrics: - <code>nginx_ingress_controller_requests</code>: Total requests handled - <code>nginx_ingress_controller_request_duration_seconds</code>: Request latency - <code>nginx_ingress_controller_ssl_expire_time_seconds</code>: Certificate expiration</p>"},{"location":"ingress-access/#access-logs","title":"Access Logs","text":"<p>Access logs are available via: <pre><code>kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller\n</code></pre></p>"},{"location":"ingress-access/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ingress-access/#common-issues","title":"Common Issues","text":"<ol> <li>404 Not Found: Check that the Ingress host matches the request hostname</li> <li>503 Service Unavailable: Verify the backend service is running and endpoints exist</li> <li>Certificate Not Ready: Check cert-manager logs and Certificate/CertificateRequest status</li> <li>DNS Not Resolving: Verify ExternalDNS is running and has permissions to manage DNS</li> </ol>"},{"location":"ingress-access/#debug-commands","title":"Debug Commands","text":"<pre><code># Check Ingress Controller status\nkubectl get pods -n ingress-nginx\n\n# View Ingress resources\nkubectl get ingress -A\n\n# Check cert-manager\nkubectl get pods -n cert-manager\nkubectl get certificates -A\n\n# Check ExternalDNS\nkubectl get pods -n external-dns\nkubectl logs -n external-dns -l app.kubernetes.io/name=external-dns\n</code></pre>"},{"location":"ingress-access/#environment-variables","title":"Environment Variables","text":"<p>Add the following to your <code>.env</code> file for ingress configuration:</p> <pre><code># Ingress Domain\nINGRESS_DOMAIN=fawkes.idp\n\n# TLS Issuer (letsencrypt-staging or letsencrypt-prod)\nTLS_CLUSTER_ISSUER=letsencrypt-prod\n\n# Let's Encrypt email for certificate notifications\nLETSENCRYPT_EMAIL=platform-admin@fawkes.idp\n</code></pre>"},{"location":"integrations/","title":"Integrations","text":"<p>This document provides an overview of the integrations supported by the Fawkes Internal Developer Platform (IDP). These integrations enhance the platform's capabilities by connecting it with external tools and services for CI/CD, monitoring, security, and more.</p>"},{"location":"integrations/#table-of-contents","title":"Table of Contents","text":"<ul> <li>CI/CD Integrations</li> <li>Monitoring and Logging</li> <li>Security and Compliance</li> <li>Cloud Provider Integrations</li> <li>Developer Tools</li> <li>Extending Integrations</li> </ul>"},{"location":"integrations/#cicd-integrations","title":"CI/CD Integrations","text":"<p>Fawkes supports seamless integration with popular CI/CD tools to automate build, test, and deployment pipelines.</p> <ul> <li> <p>Jenkins:   Pre-configured pipelines for building and deploying applications.   See the Jenkins integration guide for setup instructions.</p> </li> <li> <p>GitHub Actions:   Use GitHub Actions workflows for CI/CD directly from your repository.   Example workflows are provided in the <code>.github/workflows/</code> directory.</p> </li> <li> <p>Azure DevOps Pipelines:   Integrate with Azure DevOps for end-to-end CI/CD pipelines.   Follow Azure best practices for pipeline configuration.</p> </li> </ul>"},{"location":"integrations/#monitoring-and-logging","title":"Monitoring and Logging","text":"<p>Fawkes integrates with monitoring and logging tools to provide visibility into your infrastructure and applications.</p> <ul> <li> <p>Prometheus and Grafana:   Pre-configured Helm charts for Prometheus and Grafana to monitor Kubernetes clusters and applications.   See the Prometheus setup guide.</p> </li> <li> <p>Azure Monitor:   Use Azure Monitor for centralized logging and metrics collection.   Follow Azure best practices for configuring Log Analytics and Application Insights.</p> </li> <li> <p>ELK Stack (Elasticsearch, Logstash, Kibana):   Optional integration for advanced log aggregation and visualization.</p> </li> </ul>"},{"location":"integrations/#security-and-compliance","title":"Security and Compliance","text":"<p>Fawkes includes integrations with tools to ensure security and compliance across your infrastructure and applications.</p> <ul> <li> <p>Trivy:   Scan container images for vulnerabilities before deployment.</p> </li> <li> <p>OWASP ZAP:   Perform dynamic application security testing (DAST) on your web applications.</p> </li> <li> <p>Azure Policy:   Enforce compliance policies for Azure resources.   Use Azure best practices for configuring and managing policies.</p> </li> <li> <p>Snyk:   Identify and fix vulnerabilities in your dependencies.</p> </li> </ul>"},{"location":"integrations/#cloud-provider-integrations","title":"Cloud Provider Integrations","text":"<p>Fawkes supports multi-cloud deployments with integrations for major cloud providers.</p> <ul> <li> <p>AWS:   Provision infrastructure using Terraform and manage resources with the AWS CLI.   See the AWS integration guide.</p> </li> <li> <p>Azure:   Use Azure CLI and Terraform to provision and manage resources.   Follow Azure best practices for authentication, resource groups, and networking.</p> </li> <li> <p>Google Cloud Platform (GCP):   Integrate with GCP for Kubernetes (GKE) and other cloud services.</p> </li> </ul>"},{"location":"integrations/#developer-tools","title":"Developer Tools","text":"<p>Fawkes integrates with tools to enhance the developer experience.</p> <ul> <li> <p>SonarQube:   Perform static code analysis to ensure code quality and security.</p> </li> <li> <p>Keycloak:   Optional integration for single sign-on (SSO) and identity management.</p> </li> <li> <p>Docker:   Use Docker for local development and containerized applications.</p> </li> <li> <p>Azure Dev Spaces:   Enable collaborative development in Kubernetes clusters.   Follow Azure best practices for setting up Dev Spaces.</p> </li> </ul>"},{"location":"integrations/#extending-integrations","title":"Extending Integrations","text":"<p>Fawkes is designed to be extensible. You can add new integrations by:</p> <ol> <li>Adding configuration files or scripts in the appropriate directory (e.g., <code>infra/</code>, <code>platform/</code>).</li> <li>Updating the documentation in this file to reflect the new integration.</li> <li>Testing the integration in your environment.</li> </ol>"},{"location":"integrations/#need-help","title":"Need Help?","text":"<p>If you encounter issues with any integration, refer to the specific tool's documentation or open an issue on GitHub.</p>"},{"location":"security/","title":"Security","text":"<p>This document outlines the security model, practices, and recommendations for the Fawkes Internal Developer Platform (IDP).</p>"},{"location":"security/#principles","title":"Principles","text":"<ul> <li>Least Privilege: All components and users are granted only the permissions they need.</li> <li>Separation of Duties: Infrastructure, platform, and application responsibilities are separated.</li> <li>Defense in Depth: Multiple layers of security controls are implemented across the stack.</li> <li>Transparency: All security controls and configurations are documented and open for review.</li> </ul>"},{"location":"security/#secrets-management","title":"Secrets Management","text":"<ul> <li>Never commit secrets to version control.</li> <li>Use secret management tools (e.g., AWS Secrets Manager, Azure Key Vault, GCP Secret Manager, or Kubernetes Secrets).</li> <li>Store only encrypted secrets in infrastructure code; inject secrets at deploy time.</li> <li>Add secret files and templates to <code>.gitignore</code>.</li> </ul>"},{"location":"security/#identity-and-access-management-iam","title":"Identity and Access Management (IAM)","text":"<ul> <li>Use cloud-native IAM (AWS IAM, Azure AD, GCP IAM) for resource access control.</li> <li>Use Kubernetes RBAC for fine-grained access within clusters.</li> <li>Rotate credentials and keys regularly.</li> <li>Use service accounts for automation and CI/CD, with minimal permissions.</li> </ul>"},{"location":"security/#network-security","title":"Network Security","text":"<ul> <li>Deploy resources in private subnets where possible.</li> <li>Restrict public ingress using security groups, firewalls, and Kubernetes network policies.</li> <li>Use TLS/SSL for all service endpoints.</li> <li>Enable logging and monitoring for network traffic.</li> </ul>"},{"location":"security/#platform-security","title":"Platform Security","text":"<ul> <li>Enable audit logging for all infrastructure and platform components.</li> <li>Regularly update dependencies and base images to address vulnerabilities.</li> <li>Use vulnerability scanning tools (e.g., Trivy, Gitleaks) in CI/CD pipelines.</li> <li>Enforce code reviews and automated tests for all changes.</li> </ul>"},{"location":"security/#kubernetes-security","title":"Kubernetes Security","text":"<ul> <li>Use namespaces to isolate workloads.</li> <li>Apply Pod Security Standards (PSS) or PodSecurityPolicies.</li> <li>Limit container privileges (no root, no privilege escalation).</li> <li>Use network policies to restrict pod-to-pod communication.</li> <li>Scan container images for vulnerabilities before deployment.</li> </ul>"},{"location":"security/#cicd-security","title":"CI/CD Security","text":"<ul> <li>Store CI/CD credentials securely (never in code).</li> <li>Use environment variables or secret stores for pipeline secrets.</li> <li>Limit pipeline permissions to only required resources.</li> <li>Scan code and dependencies for vulnerabilities on every build.</li> </ul>"},{"location":"security/#monitoring-and-incident-response","title":"Monitoring and Incident Response","text":"<ul> <li>Enable and monitor audit logs for all cloud and platform resources.</li> <li>Set up alerts for suspicious activity or failed authentication attempts.</li> <li>Document incident response procedures and regularly review them.</li> </ul>"},{"location":"security/#user-responsibilities","title":"User Responsibilities","text":"<ul> <li>Use strong, unique passwords and enable MFA where possible.</li> <li>Report any suspected security issues to the project maintainers.</li> <li>Follow the contributing guidelines for secure code contributions.</li> </ul>"},{"location":"security/#reporting-vulnerabilities","title":"Reporting Vulnerabilities","text":"<p>If you discover a security vulnerability, please report it responsibly by opening a private issue or contacting the maintainers directly.</p>"},{"location":"security/#references","title":"References","text":"<ul> <li>CNCF Kubernetes Security Best Practices</li> <li>OWASP Top Ten</li> <li>Cloud Provider Security Docs</li> </ul> <p>```</p>"},{"location":"security/#security_1","title":"Security","text":"<p>This document outlines the security model, practices, and recommendations for the Fawkes Internal Developer Platform (IDP).</p>"},{"location":"security/#principles_1","title":"Principles","text":"<ul> <li>Least Privilege: All components and users are granted only the permissions they need.</li> <li>Separation of Duties: Infrastructure, platform, and application responsibilities are separated.</li> <li>Defense in Depth: Multiple layers of security controls are implemented across the stack.</li> <li>Transparency: All security controls and configurations are documented and open for review.</li> </ul>"},{"location":"security/#secrets-management_1","title":"Secrets Management","text":"<ul> <li>Never commit secrets to version control.</li> <li>Use secret management tools (e.g., AWS Secrets Manager, Azure Key Vault, GCP Secret Manager, or Kubernetes Secrets).</li> <li>Store only encrypted secrets in infrastructure code; inject secrets at deploy time.</li> <li>Add secret files and templates to <code>.gitignore</code>.</li> </ul>"},{"location":"security/#identity-and-access-management-iam_1","title":"Identity and Access Management (IAM)","text":"<ul> <li>Use cloud-native IAM (AWS IAM, Azure AD, GCP IAM) for resource access control.</li> <li>Use Kubernetes RBAC for fine-grained access within clusters.</li> <li>Rotate credentials and keys regularly.</li> <li>Use service accounts for automation and CI/CD, with minimal permissions.</li> </ul>"},{"location":"security/#network-security_1","title":"Network Security","text":"<ul> <li>Deploy resources in private subnets where possible.</li> <li>Restrict public ingress using security groups, firewalls, and Kubernetes network policies.</li> <li>Use TLS/SSL for all service endpoints.</li> <li>Enable logging and monitoring for network traffic.</li> </ul>"},{"location":"security/#platform-security_1","title":"Platform Security","text":"<ul> <li>Enable audit logging for all infrastructure and platform components.</li> <li>Regularly update dependencies and base images to address vulnerabilities.</li> <li>Use vulnerability scanning tools (e.g., Trivy, Gitleaks) in CI/CD pipelines.</li> <li>Enforce code reviews and automated tests for all changes.</li> </ul>"},{"location":"security/#kubernetes-security_1","title":"Kubernetes Security","text":"<ul> <li>Use namespaces to isolate workloads.</li> <li>Apply Pod Security Standards (PSS) or PodSecurityPolicies.</li> <li>Limit container privileges (no root, no privilege escalation).</li> <li>Use network policies to restrict pod-to-pod communication.</li> <li>Scan container images for vulnerabilities before deployment.</li> </ul>"},{"location":"security/#cicd-security_1","title":"CI/CD Security","text":"<ul> <li>Store CI/CD credentials securely (never in code).</li> <li>Use environment variables or secret stores for pipeline secrets.</li> <li>Limit pipeline permissions to only required resources.</li> <li>Scan code and dependencies for vulnerabilities on every build.</li> </ul>"},{"location":"security/#monitoring-and-incident-response_1","title":"Monitoring and Incident Response","text":"<ul> <li>Enable and monitor audit logs for all cloud and platform resources.</li> <li>Set up alerts for suspicious activity or failed authentication attempts.</li> <li>Document incident response procedures and regularly review them.</li> </ul>"},{"location":"security/#user-responsibilities_1","title":"User Responsibilities","text":"<ul> <li>Use strong, unique passwords and enable MFA where possible.</li> <li>Report any suspected security issues to the project maintainers.</li> <li>Follow the contributing guidelines for secure code contributions.</li> </ul>"},{"location":"security/#reporting-vulnerabilities_1","title":"Reporting Vulnerabilities","text":"<p>If you discover a security vulnerability, please report it responsibly by opening a private issue or contacting the maintainers directly.</p>"},{"location":"security/#references_1","title":"References","text":"<ul> <li>CNCF Kubernetes Security Best Practices</li> <li>OWASP Top Ten</li> <li>Cloud Provider Security Docs</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide provides solutions to common issues encountered while using the Fawkes Internal Developer Platform. It is organized by category to help you quickly identify and resolve problems.</p>"},{"location":"troubleshooting/#table-of-contents","title":"Table of Contents","text":"<ul> <li>General Issues</li> <li>Infrastructure Issues</li> <li>Kubernetes Issues</li> <li>CI/CD Issues</li> <li>Azure-Specific Issues</li> <li>Testing Issues</li> <li>Getting Help</li> </ul>"},{"location":"troubleshooting/#general-issues","title":"General Issues","text":""},{"location":"troubleshooting/#1-environment-variables-not-loaded","title":"1. Environment Variables Not Loaded","text":"<ul> <li>Symptom: Commands fail due to missing environment variables.</li> <li>Solution:</li> <li>Ensure you have a <code>.env</code> file in the root directory.</li> <li>Load the environment variables:     <pre><code>source .env\n</code></pre></li> </ul>"},{"location":"troubleshooting/#2-permission-denied-errors","title":"2. Permission Denied Errors","text":"<ul> <li>Symptom: You encounter <code>Permission Denied</code> errors when running scripts.</li> <li>Solution:</li> <li>Ensure the script has executable permissions:     <pre><code>chmod +x &lt;script-name&gt;.sh\n</code></pre></li> <li>Run the script with appropriate privileges (e.g., <code>sudo</code> if required).</li> </ul>"},{"location":"troubleshooting/#infrastructure-issues","title":"Infrastructure Issues","text":""},{"location":"troubleshooting/#1-terraform-apply-fails","title":"1. Terraform Apply Fails","text":"<ul> <li>Symptom: Terraform fails with errors like \"resource already exists\" or \"authentication failed.\"</li> <li>Solution:</li> <li>Run <code>terraform plan</code> to identify conflicting resources.</li> <li>Ensure your cloud provider credentials are valid and loaded:     <pre><code>export AWS_ACCESS_KEY_ID=your-access-key\nexport AWS_SECRET_ACCESS_KEY=your-secret-key\n</code></pre></li> </ul>"},{"location":"troubleshooting/#2-infrastructure-not-destroyed-properly","title":"2. Infrastructure Not Destroyed Properly","text":"<ul> <li>Symptom: Resources remain after running the destroy script.</li> <li>Solution:</li> <li>Manually inspect the resources in your cloud provider's console.</li> <li>Run <code>terraform destroy</code> directly in the affected directory:     <pre><code>terraform destroy\n</code></pre></li> </ul>"},{"location":"troubleshooting/#kubernetes-issues","title":"Kubernetes Issues","text":""},{"location":"troubleshooting/#1-kubernetes-cluster-unreachable","title":"1. Kubernetes Cluster Unreachable","text":"<ul> <li>Symptom: <code>kubectl</code> commands fail with \"Unable to connect to the server.\"</li> <li>Solution:</li> <li>Ensure your <code>kubeconfig</code> is set correctly:     <pre><code>export KUBECONFIG=/path/to/kubeconfig\n</code></pre></li> <li>Verify the cluster status:     <pre><code>kubectl cluster-info\n</code></pre></li> </ul>"},{"location":"troubleshooting/#2-pods-stuck-in-pending-state","title":"2. Pods Stuck in Pending State","text":"<ul> <li>Symptom: Pods remain in the <code>Pending</code> state.</li> <li>Solution:</li> <li>Check for insufficient resources:     <pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre></li> <li>Scale up your cluster or free up resources.</li> </ul>"},{"location":"troubleshooting/#cicd-issues","title":"CI/CD Issues","text":""},{"location":"troubleshooting/#1-jenkins-pipeline-fails","title":"1. Jenkins Pipeline Fails","text":"<ul> <li>Symptom: Jenkins pipelines fail with errors related to missing credentials or tools.</li> <li>Solution:</li> <li>Verify that the required credentials are configured in Jenkins.</li> <li>Ensure the Jenkins agent has the necessary tools installed.</li> </ul>"},{"location":"troubleshooting/#2-github-actions-workflow-fails","title":"2. GitHub Actions Workflow Fails","text":"<ul> <li>Symptom: GitHub Actions fail with errors like \"command not found\" or \"authentication failed.\"</li> <li>Solution:</li> <li>Check the workflow logs for detailed error messages.</li> <li>Ensure secrets are configured correctly in the repository settings.</li> </ul>"},{"location":"troubleshooting/#azure-specific-issues","title":"Azure-Specific Issues","text":""},{"location":"troubleshooting/#1-azure-cli-authentication-fails","title":"1. Azure CLI Authentication Fails","text":"<ul> <li>Symptom: Azure CLI commands fail with \"not logged in\" or \"authentication failed.\"</li> <li>Solution:</li> <li>Log in to Azure CLI:     <pre><code>az login\n</code></pre></li> <li>Set the correct subscription:     <pre><code>az account set --subscription &lt;subscription-id&gt;\n</code></pre></li> </ul>"},{"location":"troubleshooting/#2-resource-group-not-found","title":"2. Resource Group Not Found","text":"<ul> <li>Symptom: Terraform or Azure CLI commands fail with \"resource group not found.\"</li> <li>Solution:</li> <li>Verify the resource group exists:     <pre><code>az group list --query \"[].name\"\n</code></pre></li> <li>Create the resource group if necessary:     <pre><code>az group create --name &lt;resource-group&gt; --location &lt;location&gt;\n</code></pre></li> </ul>"},{"location":"troubleshooting/#testing-issues","title":"Testing Issues","text":""},{"location":"troubleshooting/#1-tests-fail-due-to-missing-dependencies","title":"1. Tests Fail Due to Missing Dependencies","text":"<ul> <li>Symptom: Tests fail with errors like \"module not found\" or \"dependency missing.\"</li> <li>Solution:</li> <li>Install the required dependencies:     <pre><code>mvn clean install\n</code></pre></li> </ul>"},{"location":"troubleshooting/#2-performance-tests-fail","title":"2. Performance Tests Fail","text":"<ul> <li>Symptom: Performance tests fail with timeout or resource errors.</li> <li>Solution:</li> <li>Ensure the test environment has sufficient resources.</li> <li>Adjust the test parameters (e.g., reduce load or increase timeouts).</li> </ul>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you are unable to resolve an issue, you can:</p> <ol> <li>Check the FAQ for additional guidance.</li> <li>Open an issue on GitHub with detailed information about the problem.</li> <li>Reach out to the community for support.</li> </ol>"},{"location":"usage/","title":"Usage Guide","text":"<p>This guide explains how to use the Fawkes Internal Developer Platform after setup. It covers common workflows, service management, and accessing platform features.</p> <p>Fawkes is a metrics-first platform designed to help teams improve their software delivery performance by focusing on the Four Key Metrics and supporting the eight capabilities needed to enhance those metrics.</p>"},{"location":"usage/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Accessing Platform Services</li> <li>Managing Infrastructure</li> <li>Deploying Platform Services</li> <li>Viewing Outputs and Endpoints</li> <li>CI/CD and Developer Workflows</li> <li>Measuring and Improving DORA Metrics</li> <li>Configuration Management</li> <li>Troubleshooting</li> </ul>"},{"location":"usage/#accessing-platform-services","title":"Accessing Platform Services","text":"<p>After deployment, you can access services such as Jenkins, SonarQube, and the Kubernetes Dashboard. These services support Continuous Integration, Monitoring and Observability, and Streamlining Change Approval.</p> <ul> <li> <p>Jenkins:   Access Jenkins via the provided URL (e.g., <code>http://&lt;jenkins-lb&gt;:8080</code>).   Retrieve the admin password using:   <pre><code>kubectl get secret --namespace &lt;namespace&gt; jenkins -o jsonpath=\"{.data.jenkins-admin-password}\" | base64 --decode\n</code></pre></p> </li> <li> <p>SonarQube:   Access SonarQube via the provided URL (e.g., <code>http://&lt;sonarqube-lb&gt;:9000</code>).   Default credentials: <code>admin</code> / <code>admin</code>.</p> </li> <li> <p>Kubernetes Dashboard:   Access the dashboard via the provided URL. Retrieve the admin token using:   <pre><code>kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}')\n</code></pre></p> </li> </ul>"},{"location":"usage/#managing-infrastructure","title":"Managing Infrastructure","text":"<ul> <li> <p>Provisioning Infrastructure:   Use the provided scripts in the <code>infra/</code> directory to provision or update infrastructure:   <pre><code>cd infra\n./scripts/ignite.sh --provider aws dev\n</code></pre></p> </li> <li> <p>Destroying Infrastructure:   To tear down infrastructure:   <pre><code>cd infra\n./scripts/ignite.sh --provider aws dev  # see docs for destroy guidance\n</code></pre></p> </li> <li> <p>Using Terraform Directly:   Advanced users can manage infrastructure directly with Terraform:   <pre><code>cd infra/platform/aws\nterraform init\nterraform plan\nterraform apply\n</code></pre></p> </li> </ul>"},{"location":"usage/#deploying-platform-services","title":"Deploying Platform Services","text":"<ul> <li> <p>Jenkins Deployment:   Deploy Jenkins using the provided script:   <pre><code>cd platform/jenkins\n./jenkins-delta.sh -i\n</code></pre></p> </li> <li> <p>Other Services:   Each service directory contains deployment scripts or Helm charts. Refer to the respective README files for details.</p> </li> </ul>"},{"location":"usage/#viewing-outputs-and-endpoints","title":"Viewing Outputs and Endpoints","text":"<p>After deployment, service URLs and credentials are displayed in the terminal. You can also retrieve them using:</p> <ul> <li> <p>Terraform Outputs: <pre><code>terraform output\n</code></pre></p> </li> <li> <p>Deployment Script Outputs: <pre><code>./jenkins-delta.sh -s\n</code></pre></p> </li> </ul>"},{"location":"usage/#cicd-and-developer-workflows","title":"CI/CD and Developer Workflows","text":"<ul> <li> <p>Pipelines:   Jenkins is pre-configured for CI/CD. Add your repositories and configure pipelines as needed.</p> </li> <li> <p>Workspace Automation:   Use scripts in the <code>workspace/</code> directory to set up local development environments.</p> </li> </ul>"},{"location":"usage/#measuring-and-improving-dora-metrics","title":"Measuring and Improving DORA Metrics","text":"<p>Fawkes is designed to help teams measure and improve the Four Key DORA Metrics:</p> <ul> <li>Deployment Frequency</li> <li>Lead Time for Changes</li> <li>Change Failure Rate</li> <li>Mean Time to Restore (MTTR)</li> </ul>"},{"location":"usage/#how-fawkes-helps","title":"How Fawkes Helps:","text":"<ul> <li>Automated CI/CD Pipelines: Jenkins and other integrated tools provide metrics on deployment frequency and lead time.</li> <li>Quality Gates: SonarQube and automated tests help reduce change failure rate.</li> <li>Monitoring &amp; Alerts: Integrated monitoring and logging help track and reduce MTTR.</li> <li>Reporting: Extract and visualize DORA metrics from pipeline logs, test reports, and monitoring dashboards.</li> </ul> <p>See the architecture and development guide for more on how Fawkes supports DORA capabilities and continuous improvement.</p>"},{"location":"usage/#configuration-management","title":"Configuration Management","text":"<ul> <li>All configuration files are located in the <code>infra/</code> and <code>platform/</code> directories.</li> <li>Secrets should not be committed to version control. Use templates and inject secrets at deploy time.</li> <li>See configuration.md for details on environment variables and secret management.</li> </ul>"},{"location":"usage/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>See troubleshooting.md for common issues and solutions.</li> <li>For further help, open an issue on GitHub.</li> </ul> <p>Thank you for choosing Fawkes! We\u2019re excited to help you build better, faster, and more reliable infrastructure.</p>"},{"location":"adr/ADR-001%20kubernetes/","title":"ADR-001: Kubernetes as Container Orchestration Platform","text":""},{"location":"adr/ADR-001%20kubernetes/#status","title":"Status","text":"<p>Accepted - October 4, 2025</p>"},{"location":"adr/ADR-001%20kubernetes/#context","title":"Context","text":"<p>Fawkes requires a container orchestration platform to run the Internal Delivery Platform components (Backstage, Jenkins, ArgoCD, Prometheus, etc.) and to host application workloads for teams using the platform. The orchestration platform must support:</p> <ul> <li>Multi-tenancy: Isolated environments for different teams</li> <li>Scalability: From small teams (5 services) to large enterprises (100+ services)</li> <li>Observability: Rich metrics, logging, and monitoring capabilities</li> <li>Security: RBAC, network policies, secrets management</li> <li>Ecosystem: Strong ecosystem of tools and integrations</li> <li>Multi-cloud: Ability to run on AWS, Azure, GCP, and on-premises</li> <li>GitOps: Declarative configuration and reconciliation</li> <li>Developer Experience: Self-service capabilities, easy local development</li> </ul> <p>The platform must be production-ready, with a mature community, extensive documentation, and enterprise adoption.</p>"},{"location":"adr/ADR-001%20kubernetes/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Need for container orchestration is non-negotiable for modern platforms - Team familiarity with orchestration platforms varies - Learning curve vs. time to value tradeoff - Platform stability and maturity critical for production use</p> <p>Business Forces: - Open-source preference to avoid vendor lock-in - Enterprise adoption important for credibility - Community size affects long-term sustainability - Multi-cloud support required for diverse adoption</p> <p>Organizational Forces: - Platform engineering skills growing but not universal - Kubernetes increasingly becoming industry standard - CNCF ecosystem alignment provides future-proofing</p>"},{"location":"adr/ADR-001%20kubernetes/#decision","title":"Decision","text":"<p>We will use Kubernetes as the container orchestration platform for Fawkes.</p> <p>Specifically: - Managed Kubernetes services for MVP: AWS EKS, with Azure AKS and GCP GKE following - Kubernetes version: 1.28+ (stay within N-2 of latest stable) - Distribution agnostic: Design for standard Kubernetes, test on managed services - Cluster API for cluster lifecycle management (roadmap)</p>"},{"location":"adr/ADR-001%20kubernetes/#rationale","title":"Rationale","text":"<ol> <li> <p>Industry Standard: Kubernetes is the de facto standard for container orchestration, with 88% of organizations using or evaluating it (CNCF Survey 2023)</p> </li> <li> <p>CNCF Ecosystem: Kubernetes is the foundation of the CNCF landscape, providing access to hundreds of complementary tools (ArgoCD, Prometheus, Istio, etc.)</p> </li> <li> <p>Multi-Cloud Native: All major cloud providers offer managed Kubernetes (EKS, AKS, GKE), enabling true multi-cloud portability</p> </li> <li> <p>GitOps Alignment: Kubernetes' declarative API makes it ideal for GitOps workflows, a core Fawkes principle</p> </li> <li> <p>Platform Engineering Fit: Kubernetes provides the right abstractions for platform teams to create developer self-service capabilities</p> </li> <li> <p>Talent Availability: Growing pool of Kubernetes-skilled engineers makes hiring and onboarding easier</p> </li> <li> <p>Enterprise Adoption: Used by 67% of Fortune 100 companies, providing credibility for enterprise adoption</p> </li> <li> <p>Security Features: Built-in RBAC, network policies, pod security standards, and secrets management</p> </li> <li> <p>Observability: Rich metrics exposure, established patterns for monitoring and logging</p> </li> <li> <p>Community &amp; Support: Massive community, extensive documentation, commercial support available</p> </li> </ol>"},{"location":"adr/ADR-001%20kubernetes/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-001%20kubernetes/#positive","title":"Positive","text":"<p>\u2705 Broad Adoption: Using Kubernetes makes Fawkes accessible to the largest possible audience \u2705 Ecosystem Integration: Can leverage hundreds of CNCF tools designed for Kubernetes \u2705 Multi-Cloud Support: Same APIs work across AWS, Azure, GCP, and on-premises \u2705 Developer Self-Service: Kubernetes primitives (Namespaces, RBAC) enable multi-tenancy \u2705 Future-Proof: Kubernetes is backed by major tech companies and shows no signs of decline \u2705 GitOps Native: Declarative configuration aligns perfectly with GitOps principles \u2705 Skills Transfer: Learning Fawkes teaches transferable Kubernetes skills \u2705 Extensibility: Custom Resource Definitions (CRDs) enable platform extension \u2705 Production Ready: Battle-tested at scale by thousands of organizations</p>"},{"location":"adr/ADR-001%20kubernetes/#negative","title":"Negative","text":"<p>\u26a0\ufe0f Complexity: Kubernetes has a steep learning curve for beginners \u26a0\ufe0f Resource Overhead: Control plane and system components require 2-4GB RAM minimum \u26a0\ufe0f Operational Burden: Requires expertise to operate reliably (mitigated by managed services) \u26a0\ufe0f Over-Engineering for Small Teams: May be overkill for teams with &lt; 5 services \u26a0\ufe0f Version Management: Frequent releases require upgrade planning and testing \u26a0\ufe0f Configuration Complexity: YAML configuration can be verbose and error-prone \u26a0\ufe0f Local Development: Running Kubernetes locally (minikube, kind) adds complexity</p>"},{"location":"adr/ADR-001%20kubernetes/#neutral","title":"Neutral","text":"<p>\u25fd Cost: Managed Kubernetes has base costs ($70-150/month for control plane) but provides value at scale \u25fd Security: Powerful security features exist but require configuration and expertise \u25fd Networking: Kubernetes networking is flexible but requires understanding of concepts</p>"},{"location":"adr/ADR-001%20kubernetes/#mitigation-strategies","title":"Mitigation Strategies","text":"<p>For the negative consequences, we will:</p> <ol> <li>Complexity: Provide comprehensive documentation, dojo learning modules, and golden paths that abstract complexity</li> <li>Resource Overhead: Start with managed services (EKS) to reduce operational burden</li> <li>Operational Burden: Include monitoring, alerting, and runbooks; leverage managed services</li> <li>Over-Engineering: Document when Kubernetes is appropriate; provide alternative architectures for very small teams</li> <li>Version Management: Establish clear upgrade policies and automated testing</li> <li>Configuration Complexity: Use Helm charts and Kustomize for templating; provide validated templates</li> <li>Local Development: Provide remote development options (Eclipse Che); document local setup thoroughly</li> </ol>"},{"location":"adr/ADR-001%20kubernetes/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-001%20kubernetes/#alternative-1-docker-swarm","title":"Alternative 1: Docker Swarm","text":"<p>Pros: - Simpler learning curve than Kubernetes - Integrated with Docker ecosystem - Lower resource overhead - Faster initial setup</p> <p>Cons: - Smaller ecosystem (limited tooling compared to K8s) - Declining adoption and community activity - Limited multi-cloud support - Fewer enterprise features (RBAC, network policies less mature) - Less relevant skill for users to learn</p> <p>Reason for Rejection: While simpler, Docker Swarm's declining adoption and limited ecosystem make it a poor foundation for a platform meant to last 5+ years. The simplicity advantage doesn't outweigh the ecosystem and future-proofing benefits of Kubernetes.</p>"},{"location":"adr/ADR-001%20kubernetes/#alternative-2-hashicorp-nomad","title":"Alternative 2: HashiCorp Nomad","text":"<p>Pros: - Simpler than Kubernetes (easier to learn and operate) - Good performance and resource efficiency - Multi-cloud support - Strong HashiCorp ecosystem integration (Vault, Consul) - Supports non-containerized workloads</p> <p>Cons: - Much smaller ecosystem than Kubernetes - Fewer integrations with CNCF tools - Smaller community and talent pool - Less enterprise adoption - Would require custom integrations for many tools</p> <p>Reason for Rejection: Nomad is excellent for specific use cases, but the CNCF ecosystem is centered on Kubernetes. Building Fawkes on Nomad would require reimplementing many integrations and would limit the potential contributor and user base.</p>"},{"location":"adr/ADR-001%20kubernetes/#alternative-3-aws-ecsfargate","title":"Alternative 3: AWS ECS/Fargate","text":"<p>Pros: - Simpler than Kubernetes for basic use cases - Fully managed (no control plane management) - Deep AWS integration - Lower operational overhead - Cost-effective for certain workloads</p> <p>Cons: - AWS-only (locks into single cloud vendor) - Limited ecosystem (no CNCF tools work natively) - Proprietary API (not transferable skills) - Multi-tenancy requires more custom work - GitOps support less mature</p> <p>Reason for Rejection: ECS lock-in to AWS contradicts Fawkes' multi-cloud goals. While simpler for AWS-only users, it would fragment the platform (need separate solutions for Azure, GCP) and limit adoption by multi-cloud organizations.</p>"},{"location":"adr/ADR-001%20kubernetes/#alternative-4-platformsh-heroku-style-paas","title":"Alternative 4: Platform.sh / Heroku-style PaaS","text":"<p>Pros: - Extremely simple developer experience - Minimal configuration required - Fast time-to-value - Handles all infrastructure concerns</p> <p>Cons: - Not infrastructure we control (SaaS, not self-hosted platform) - Contradicts Fawkes' goal of providing an IDP - Limited customization and extensibility - Doesn't teach platform engineering skills - Vendor lock-in and cost at scale</p> <p>Reason for Rejection: Fawkes is about building an Internal Developer Platform, not consuming a PaaS. While these platforms provide great developer experience, they don't align with the goal of creating a self-hosted, customizable platform.</p>"},{"location":"adr/ADR-001%20kubernetes/#alternative-5-cloud-native-with-managed-services-only","title":"Alternative 5: \"Cloud Native\" with Managed Services Only","text":"<p>Pros: - Use cloud provider's managed services directly (Lambda, Cloud Run, etc.) - No container orchestration complexity - Pay only for usage - Serverless scaling</p> <p>Cons: - Completely different approach per cloud (no portability) - Limited long-running workload support - Stateful applications challenging - Platform components (Jenkins, Backstage) need orchestration anyway - Contradicts unified platform goal</p> <p>Reason for Rejection: While serverless has its place, Fawkes needs a consistent foundation across clouds and for long-running platform components. We may use managed services alongside Kubernetes, but can't build the entire platform on serverless.</p>"},{"location":"adr/ADR-001%20kubernetes/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-002: Backstage for Developer Portal (depends on Kubernetes for deployment)</li> <li>ADR-003: ArgoCD for GitOps (Kubernetes-native GitOps tool)</li> <li>ADR-005: Terraform for Infrastructure (will provision Kubernetes clusters)</li> <li>Future ADR: Cluster API for cluster lifecycle management</li> </ul>"},{"location":"adr/ADR-001%20kubernetes/#implementation-notes","title":"Implementation Notes","text":""},{"location":"adr/ADR-001%20kubernetes/#initial-implementation-mvp","title":"Initial Implementation (MVP)","text":"<ul> <li>Start with AWS EKS (most mature managed Kubernetes)</li> <li>Single cluster design (platform + applications)</li> <li>Use EKS add-ons for AWS integrations</li> <li>Kubernetes version 1.28 (N-1 from latest stable at time of writing)</li> </ul>"},{"location":"adr/ADR-001%20kubernetes/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Multi-Cluster (Month 6-12):</li> <li>Separate platform cluster from application clusters</li> <li>Multi-region deployments</li> <li> <p>Cluster API for lifecycle management</p> </li> <li> <p>Multi-Cloud (Month 3-6):</p> </li> <li>Azure AKS support</li> <li>GCP GKE support</li> <li> <p>Unified tooling across clouds</p> </li> <li> <p>Advanced Features (Month 12+):</p> </li> <li>Service mesh (Linkerd/Istio)</li> <li>Multi-tenancy with vCluster or Capsule</li> <li>Cost optimization with spot instances</li> </ol>"},{"location":"adr/ADR-001%20kubernetes/#learning-resources-for-contributors","title":"Learning Resources for Contributors","text":"<ul> <li>Kubernetes Basics</li> <li>CKAD Certification</li> <li>Platform Engineering dojo modules will include K8s fundamentals</li> </ul>"},{"location":"adr/ADR-001%20kubernetes/#monitoring-this-decision","title":"Monitoring This Decision","text":"<p>We will revisit this ADR if: - Kubernetes adoption significantly declines (&lt; 60% of survey respondents) - A new orchestration platform gains &gt; 30% market share - Operational complexity consistently causes adoption issues - Alternative platforms provide compelling advantages</p> <p>Next Review Date: October 4, 2026 (12 months)</p>"},{"location":"adr/ADR-001%20kubernetes/#references","title":"References","text":"<ul> <li>CNCF Annual Survey 2023</li> <li>Kubernetes Documentation</li> <li>AWS EKS Best Practices</li> <li>The Kubernetes Book by Nigel Poulton</li> </ul>"},{"location":"adr/ADR-001%20kubernetes/#notes","title":"Notes","text":""},{"location":"adr/ADR-001%20kubernetes/#why-not-start-simpler","title":"Why Not Start Simpler?","text":"<p>We considered starting with Docker Compose or simpler solutions and \"graduating\" to Kubernetes later. However: - Migration is costly and disruptive for early adopters - Learning Kubernetes is a core part of platform engineering - Starting with K8s forces us to address complexity early - Better to have a steeper initial curve than force migration later</p>"},{"location":"adr/ADR-001%20kubernetes/#managed-vs-self-managed","title":"Managed vs. Self-Managed","text":"<p>For MVP, we strongly recommend managed Kubernetes (EKS, AKS, GKE) because: - Reduces operational burden for platform teams - Allows focus on platform features, not cluster management - Enterprise-grade reliability and SLAs - Regular updates and security patches</p> <p>Self-managed Kubernetes (on-premises, bare metal) is supported but not the primary use case for Fawkes.</p> <p>Decision Made By: Platform Architecture Team Approved By: Project Lead Date: October 4, 2025 Author: [Platform Architect Name] Last Updated: October 4, 2025</p>"},{"location":"adr/ADR-002%20backstage/","title":"ADR-002: Backstage for Developer Portal","text":""},{"location":"adr/ADR-002%20backstage/#status","title":"Status","text":"<p>Accepted - October 8, 2025</p>"},{"location":"adr/ADR-002%20backstage/#context","title":"Context","text":"<p>Fawkes is an Internal Product Delivery Platform that needs a unified interface\u2014a \"single pane of glass\"\u2014where developers and platform engineers can discover services, provision infrastructure, launch applications, access documentation, track learning progress, and monitor platform health.</p>"},{"location":"adr/ADR-002%20backstage/#the-need-for-a-developer-portal","title":"The Need for a Developer Portal","text":"<p>Current Challenges Without a Portal: - Tool Sprawl: Developers jump between GitHub, Jenkins, ArgoCD, Grafana, Mattermost, documentation sites - Service Discovery: No central catalog of services, APIs, dependencies, ownership - Self-Service Barriers: Provisioning requires knowing where to go, what to do, who to ask - Documentation Fragmentation: Scattered across wikis, README files, Confluence, tribal knowledge - Onboarding Complexity: New team members overwhelmed by tools and processes - Cognitive Load: Mental model of the system exists only in developers' heads - Dojo Integration: Learning content needs a central hub accessible alongside work</p> <p>What Teams Need: 1. Service Catalog: Comprehensive view of all services, APIs, libraries, and resources 2. Software Templates: Self-service scaffolding for new services (\"golden paths\") 3. Documentation Hub: Centralized, searchable, always up-to-date technical docs 4. Status Dashboard: Real-time health, deployment status, metrics for all services 5. Dojo Learning Hub: Browse curriculum, launch labs, track progress 6. Plugin Ecosystem: Extensibility to integrate with all platform tools 7. Search: Find anything (services, docs, people, runbooks) instantly 8. Developer Experience: Beautiful, intuitive interface that developers love</p>"},{"location":"adr/ADR-002%20backstage/#requirements-for-developer-portal","title":"Requirements for Developer Portal","text":"<p>Technical Requirements: - Open Source: Aligns with Fawkes values, no vendor lock-in - Extensible: Plugin architecture to integrate all platform components - Kubernetes-Native: Designed for cloud-native environments - API-First: Programmatic access to all functionality - Self-Hosted: Deploy in our infrastructure, control our data - Active Development: Regular releases, growing community - Enterprise-Grade: Production-ready, scalable, secure</p> <p>User Experience Requirements: - Intuitive UI: Developers can use without extensive training - Fast: Page loads &lt;2 seconds, search instant - Mobile-Friendly: Accessible on phones/tablets - Customizable: Branding, themes, layout configurable - Accessible: WCAG compliance, keyboard navigation</p> <p>Integration Requirements: - GitHub: Repository discovery, authentication - Jenkins/CI: Pipeline status, trigger builds - ArgoCD: Deployment status, sync applications - Kubernetes: Resource visibility, pod logs - Grafana: Embed dashboards, show metrics - Mattermost: Chat integration, notifications - Focalboard: Embed boards, show progress - DORA Metrics: Display team performance - Dojo System: Learning hub, lab launcher</p>"},{"location":"adr/ADR-002%20backstage/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Need to integrate with dozens of tools (existing and future) - Developer portal is mission-critical (high availability required) - Must scale from 10 to 1000+ services - Security critical (access to sensitive information)</p> <p>User Experience Forces: - Developers resist using clunky, slow tools - Cognitive load already high; portal must reduce, not increase - Mobile access increasingly important - Dark mode preference widespread among developers</p> <p>Business Forces: - Developer productivity directly impacts business outcomes - Portal adoption critical for platform success - Open source preference to avoid vendor lock-in - Total cost of ownership matters (licensing, maintenance)</p> <p>Community Forces: - Backstage has largest, most active community in this space - CNCF incubating status provides credibility - Spotify's success story is compelling - Growing ecosystem of plugins and integrations</p>"},{"location":"adr/ADR-002%20backstage/#decision","title":"Decision","text":"<p>We will use Backstage as the developer portal and dojo learning hub for Fawkes.</p> <p>Specifically: - Backstage Core (latest stable version) - PostgreSQL backend for catalog storage - Custom Fawkes theme with branding - Curated plugin ecosystem (Jenkins, ArgoCD, Kubernetes, Grafana, Mattermost, Focalboard) - Custom dojo plugin (<code>@fawkes/plugin-dojo</code>) for learning hub - TechDocs for documentation-as-code - Software Templates for golden paths</p>"},{"location":"adr/ADR-002%20backstage/#rationale","title":"Rationale","text":"<ol> <li> <p>Industry Leading: Backstage is the de facto standard for developer portals, originated at Spotify, now CNCF Incubating project with 100+ adopters including American Airlines, Netflix, Expedia</p> </li> <li> <p>Purpose-Built for IDPs: Specifically designed for internal developer platforms, not retrofitted from another use case. Core features align perfectly with Fawkes needs:</p> </li> <li>Service catalog with relationships and ownership</li> <li>Software templates for scaffolding</li> <li>TechDocs for documentation</li> <li> <p>Plugin architecture for extensibility</p> </li> <li> <p>Massive Plugin Ecosystem: 100+ plugins available, covering most tools:</p> </li> <li>CI/CD: Jenkins, GitHub Actions, CircleCI, GitLab</li> <li>Deployment: ArgoCD, Flux, Spinnaker, Kubernetes</li> <li>Monitoring: Grafana, Prometheus, Datadog, PagerDuty</li> <li>Cloud: AWS, Azure, GCP</li> <li> <p>And many more</p> </li> <li> <p>CNCF Incubating Status: Under Cloud Native Computing Foundation governance:</p> </li> <li>Long-term sustainability assured</li> <li>Neutral governance (not single-vendor controlled)</li> <li>Rigorous security and quality standards</li> <li> <p>Growing adoption and contribution</p> </li> <li> <p>Active Development &amp; Community:</p> </li> <li>1,000+ contributors</li> <li>Monthly releases</li> <li>27,000+ GitHub stars</li> <li>Active Discord community (5,000+ members)</li> <li> <p>Excellent documentation</p> </li> <li> <p>Open Source &amp; Self-Hosted:</p> </li> <li>Apache 2.0 license</li> <li>Complete control over data and deployment</li> <li>No per-user licensing fees</li> <li> <p>Customizable to exact needs</p> </li> <li> <p>Perfect for Dojo Integration:</p> </li> <li>Can build custom plugin for learning hub</li> <li>TechDocs perfect for module content</li> <li>Catalog can track learner progress</li> <li> <p>Plugins can integrate with lab environment</p> </li> <li> <p>Developer Experience:</p> </li> <li>Beautiful, modern UI (React-based)</li> <li>Fast, responsive</li> <li>Intuitive navigation</li> <li> <p>Developers actually enjoy using it</p> </li> <li> <p>Extensibility:</p> </li> <li>Plugin architecture allows infinite customization</li> <li>Frontend and backend plugins</li> <li>Can build exactly what we need</li> <li> <p>TypeScript/React (popular, easy to find contributors)</p> </li> <li> <p>Enterprise Adoption: Used by major enterprises proves production-readiness, scalability, security</p> </li> <li> <p>Software Templates: Golden paths built-in, can create custom templates for:</p> <ul> <li>Microservices (Java, Python, Node.js, Go)</li> <li>Infrastructure (Terraform modules)</li> <li>Dojo labs (pre-configured learning environments)</li> </ul> </li> <li> <p>Search &amp; Discovery:</p> <ul> <li>Full-text search across services, docs, people</li> <li>Advanced filtering and faceting</li> <li>GraphQL API for programmatic access</li> </ul> </li> </ol>"},{"location":"adr/ADR-002%20backstage/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-002%20backstage/#positive","title":"Positive","text":"<p>\u2705 Unified Developer Experience: Single interface for all platform interactions, dramatically reduces cognitive load</p> <p>\u2705 Self-Service Enablement: Software templates empower developers to provision without platform team tickets</p> <p>\u2705 Service Visibility: Catalog provides system-wide visibility\u2014every service, owner, dependencies visible</p> <p>\u2705 Documentation Centralization: TechDocs brings all documentation into one searchable place</p> <p>\u2705 Onboarding Acceleration: New developers have guided path to understand systems and get productive</p> <p>\u2705 Dojo Integration: Custom plugin creates perfect hub for learning (course browser, lab launcher, progress tracking)</p> <p>\u2705 Extensibility: Can integrate any tool via plugins, future-proof for new technologies</p> <p>\u2705 Community Support: Large community means help available, plugins exist for most needs</p> <p>\u2705 Developer Satisfaction: Beautiful UI developers enjoy using improves engagement and platform adoption</p> <p>\u2705 Open Source Alignment: Demonstrates commitment to open source, avoids vendor lock-in</p> <p>\u2705 Cost Effective: No licensing fees, only infrastructure and development time</p> <p>\u2705 CNCF Backing: Long-term sustainability, neutral governance, security audits</p> <p>\u2705 Golden Paths: Software templates codify best practices, improve consistency</p>"},{"location":"adr/ADR-002%20backstage/#negative","title":"Negative","text":"<p>\u26a0\ufe0f Learning Curve: Platform team needs to learn Backstage architecture, plugin development (TypeScript/React)</p> <p>\u26a0\ufe0f Initial Setup Complexity: Getting Backstage configured with all plugins takes time (2-4 weeks)</p> <p>\u26a0\ufe0f Resource Requirements: Backstage + PostgreSQL requires ~1-2GB RAM, 1-2 CPU cores</p> <p>\u26a0\ufe0f Plugin Quality Variance: Community plugins vary in quality, some need customization</p> <p>\u26a0\ufe0f Version Management: Keeping Backstage and plugins updated requires ongoing effort</p> <p>\u26a0\ufe0f Custom Plugin Development: Building custom dojo plugin requires TypeScript/React expertise (20-40 hours)</p> <p>\u26a0\ufe0f Performance at Scale: Large catalogs (1000+ entities) can slow search/filtering (mitigated with indexing)</p> <p>\u26a0\ufe0f Authentication Complexity: Integrating with multiple auth providers can be tricky</p> <p>\u26a0\ufe0f Breaking Changes: Major Backstage updates sometimes introduce breaking changes in plugins</p>"},{"location":"adr/ADR-002%20backstage/#neutral","title":"Neutral","text":"<p>\u25fd TypeScript/React Stack: Modern stack but requires specific skills (widely available)</p> <p>\u25fd Plugin Approval Process: Not all community plugins are official; need evaluation</p> <p>\u25fd Theming Flexibility: Can fully customize but requires CSS/design skills</p>"},{"location":"adr/ADR-002%20backstage/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li>Learning Curve:</li> <li>Allocate 1 week for Backstage training (official docs, tutorials)</li> <li>Start with core features, add plugins incrementally</li> <li>Leverage community Discord for questions</li> <li> <p>Consider Backstage training from Spotify (if available)</p> </li> <li> <p>Initial Setup:</p> </li> <li>Use official Helm charts for deployment</li> <li>Start with minimal plugin set, expand over time</li> <li>Document configuration as Infrastructure as Code</li> <li> <p>Create runbooks for common operations</p> </li> <li> <p>Custom Plugin Development:</p> </li> <li>Hire contractor if TypeScript/React skills lacking</li> <li>Use plugin templates and examples from community</li> <li>Contribute plugin back to community (get feedback, maintenance help)</li> <li> <p>Budget 40 hours for dojo plugin development</p> </li> <li> <p>Performance:</p> </li> <li>Implement PostgreSQL optimization (indexing, connection pooling)</li> <li>Use caching for expensive queries</li> <li>Consider read replicas for large deployments</li> <li> <p>Monitor performance, optimize bottlenecks</p> </li> <li> <p>Plugin Quality:</p> </li> <li>Vet plugins before adoption (GitHub stars, maintainer responsiveness, recent commits)</li> <li>Fork and customize plugins if needed</li> <li>Contribute improvements back to community</li> <li> <p>Build custom plugins for critical features</p> </li> <li> <p>Version Management:</p> </li> <li>Establish update cadence (monthly review, quarterly updates)</li> <li>Test updates in staging before production</li> <li>Pin plugin versions in package.json</li> <li>Subscribe to Backstage release notes</li> </ol>"},{"location":"adr/ADR-002%20backstage/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-002%20backstage/#alternative-1-portio-saas","title":"Alternative 1: Port.io (SaaS)","text":"<p>Pros: - Purpose-built for developer portals - Beautiful, modern UI - SaaS (no operational overhead) - Growing quickly, good momentum - Strong visualization capabilities - AI-powered search</p> <p>Cons: - SaaS Only: No self-hosted option, data on Port's servers - Cost: $20-50/developer/month depending on tier (expensive at scale) - Vendor Lock-In: Proprietary platform, hard to migrate off - Not Open Source: Closed source, can't customize deeply - Smaller Ecosystem: Newer, fewer integrations than Backstage - Less Proven: Fewer large enterprise adoptions - Misaligned Values: SaaS commercial conflicts with open source platform values</p> <p>Reason for Rejection: SaaS-only model and proprietary nature conflict with Fawkes' self-hosted, open source values. Cost prohibitive for open source community (at 500 developers: $120,000-$300,000/year). Cannot build deep customizations like dojo plugin.</p>"},{"location":"adr/ADR-002%20backstage/#alternative-2-humanitec-saas","title":"Alternative 2: Humanitec (SaaS)","text":"<p>Pros: - Complete IDP platform (more than just portal) - Score-based environment management - Strong GitOps integration - Good enterprise features - Active development</p> <p>Cons: - SaaS Only: No self-hosted option - Very Expensive: Enterprise pricing ($50-100k+ annually) - Opinionated: Prescriptive workflows, less flexible - Not Just Portal: Full platform, we're building our own - Closed Source: Proprietary, can't customize - Vendor Lock-In: Migrating off would be extremely difficult</p> <p>Reason for Rejection: Humanitec is a complete platform, not just a portal. We're building Fawkes as the platform, only need portal component. SaaS-only and cost prohibitive. Closed source conflicts with values.</p>"},{"location":"adr/ADR-002%20backstage/#alternative-3-cortex-saas","title":"Alternative 3: Cortex (SaaS)","text":"<p>Pros: - Service catalog with scorecards - On-call integration - Incident management - Resource management - Growing adoption</p> <p>Cons: - SaaS Only: No self-hosted option - Cost: $15-30/service/month (expensive at scale) - Narrow Focus: More focused on service management than full portal - Proprietary: Closed source - Smaller Community: Less proven than Backstage - Limited Extensibility: Cannot build custom plugins like dojo</p> <p>Reason for Rejection: SaaS-only, closed source, cost at scale. More focused on service management than comprehensive developer portal. Cannot integrate deeply customized dojo learning system.</p>"},{"location":"adr/ADR-002%20backstage/#alternative-4-opslevel-saas","title":"Alternative 4: OpsLevel (SaaS)","text":"<p>Pros: - Service maturity scoring - Good for service ownership tracking - Integrations with common tools - Nice UI</p> <p>Cons: - SaaS Only: No self-hosted - Cost: $15-25/service/month - Narrow Focus: Primarily service catalog, not full portal - Proprietary: Closed source - Limited Developer Experience: More for tracking than daily use</p> <p>Reason for Rejection: Too narrow in focus (service catalog only). SaaS-only, closed source, expensive. Not designed for developer portal use case. Lacks documentation, templates, extensibility features needed.</p>"},{"location":"adr/ADR-002%20backstage/#alternative-5-build-custom-portal-from-scratch","title":"Alternative 5: Build Custom Portal from Scratch","text":"<p>Pros: - Complete control and customization - Exact features we want - No external dependencies - Can optimize for our exact use case - Learning opportunity for team</p> <p>Cons: - Massive Time Investment: 6-12 months full-time development for MVP - Opportunity Cost: Time not spent on platform features - Maintenance Burden: Ongoing development, security patches, features - Reinventing Wheel: Building solved problems (catalog, templates, plugins) - No Community: No plugins, no shared knowledge - Talent: Requires frontend expertise (React/TypeScript) - Risk: May not match quality of established solutions</p> <p>Reason for Rejection: Building custom portal is 6-12 months of work, delaying platform delivery. Backstage solves 80%+ of needs out-of-box. Better to invest time in dojo content and platform features than rebuilding existing solutions. Can always build custom features as Backstage plugins.</p>"},{"location":"adr/ADR-002%20backstage/#alternative-6-compass-by-atlassian-saas","title":"Alternative 6: Compass by Atlassian (SaaS)","text":"<p>Pros: - From Atlassian (established company) - Service catalog with health scores - Integrates with Jira, Confluence, Bitbucket - Good for Atlassian shops</p> <p>Cons: - SaaS Only: No self-hosted - Cost: Part of Atlassian Cloud, pricing unclear - Atlassian Ecosystem: Designed for Atlassian tools (Jira, Confluence) - New Product: Launched 2022, less mature - Proprietary: Closed source - Limited Extensibility: Cannot build custom plugins - Not Developer Portal: More service management than portal</p> <p>Reason for Rejection: SaaS-only, proprietary, Atlassian ecosystem lock-in. Not designed as comprehensive developer portal. Cannot build custom dojo integration. Newer and less proven than Backstage.</p>"},{"location":"adr/ADR-002%20backstage/#alternative-7-gitlab-self-hosted-or-saas","title":"Alternative 7: GitLab (Self-Hosted or SaaS)","text":"<p>Pros: - All-in-one DevOps platform - Self-hosted option available - Service catalog feature - Strong CI/CD integration - Open source core (Community Edition)</p> <p>Cons: - CI/CD Centric: Designed around GitLab CI/CD, we use Jenkins - Heavy: GitLab is massive, resource-intensive - Portal Secondary: Developer portal is add-on, not core feature - Limited Templates: Software templates less mature than Backstage - Plugin Ecosystem: Smaller ecosystem for portal features - Complexity: GitLab has steep learning curve - Cost: Premium/Ultimate tiers expensive for portal features</p> <p>Reason for Rejection: GitLab excellent for GitLab-centric workflows, but we're using Jenkins, ArgoCD, and other tools. Portal features are add-on, not core competency. Too heavyweight for just portal use case. Backstage better fit for our multi-tool environment.</p>"},{"location":"adr/ADR-002%20backstage/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-007: Mattermost for Team Collaboration (will integrate via iframe/plugin)</li> <li>ADR-008: Focalboard for Project Management (will embed boards in Backstage)</li> <li>ADR-004: Jenkins for CI/CD (Jenkins plugin will show pipeline status)</li> <li>ADR-003: ArgoCD for GitOps (ArgoCD plugin will show deployment status)</li> <li>Future ADR: Backstage Dojo Plugin Architecture</li> </ul>"},{"location":"adr/ADR-002%20backstage/#implementation-notes","title":"Implementation Notes","text":""},{"location":"adr/ADR-002%20backstage/#deployment-architecture","title":"Deployment Architecture","text":"<pre><code># Backstage Deployment\nbackstage:\n  namespace: fawkes-platform\n\n  components:\n    - backstage-frontend:\n        image: fawkes/backstage:latest\n        replicas: 2 (HA)\n        resources:\n          cpu: 1 core\n          memory: 1Gi\n\n    - backstage-backend:\n        image: fawkes/backstage:latest\n        replicas: 2 (HA)\n        resources:\n          cpu: 1 core\n          memory: 1Gi\n\n    - postgresql:\n        replicas: 1 (consider HA for production)\n        resources:\n          cpu: 500m\n          memory: 512Mi\n        storage: 20Gi\n\n  integrations:\n    - github (OAuth, repository discovery)\n    - jenkins (pipeline plugin)\n    - argocd (deployment plugin)\n    - kubernetes (resources plugin)\n    - grafana (iframe embed)\n    - mattermost (chat integration)\n    - focalboard (board embed)\n    - dojo-labs (custom plugin)\n</code></pre>"},{"location":"adr/ADR-002%20backstage/#initial-plugin-set","title":"Initial Plugin Set","text":"<p>Core Plugins (included with Backstage): - catalog: Service catalog with relationships - scaffolder: Software templates - techdocs: Documentation as code - search: Full-text search - kubernetes: Pod logs, resource status</p> <p>Community Plugins (install via npm): - <code>@backstage/plugin-jenkins</code>: CI/CD pipeline status - <code>@backstage/plugin-argo-cd</code>: Deployment status - <code>@backstage/plugin-grafana</code>: Embed dashboards - <code>@roadiehq/backstage-plugin-github-insights</code>: Repository insights - <code>@backstage/plugin-tech-radar</code>: Technology adoption tracking</p> <p>Custom Plugins (build ourselves): - <code>@fawkes/plugin-dojo</code>: Learning hub, lab launcher, progress tracking - <code>@fawkes/plugin-dora-metrics</code>: DORA dashboards and insights - <code>@fawkes/plugin-mattermost</code>: Chat integration and notifications - <code>@fawkes/plugin-focalboard</code>: Embed project boards</p>"},{"location":"adr/ADR-002%20backstage/#software-templates","title":"Software Templates","text":"<p>Initial Templates: 1. Microservice - Java Spring Boot    - Spring Boot starter with best practices    - Dockerfile, Jenkinsfile, K8s manifests    - Tests, logging, metrics instrumentation    - README with runbook</p> <ol> <li>Microservice - Python FastAPI</li> <li>FastAPI with async support</li> <li>pytest, coverage, linting</li> <li>Container, pipeline, manifests</li> <li> <p>Documentation template</p> </li> <li> <p>Microservice - Node.js Express</p> </li> <li>Express.js with TypeScript</li> <li>Jest tests, ESLint, Prettier</li> <li>CI/CD and deployment configs</li> <li> <p>OpenAPI specification</p> </li> <li> <p>Terraform Module</p> </li> <li>Terraform module structure</li> <li>Testing with Terratest</li> <li>Documentation and examples</li> <li> <p>CI/CD for validation</p> </li> <li> <p>Dojo Lab Environment</p> </li> <li>Pre-configured namespace</li> <li>Sample application</li> <li>Lab instructions</li> <li>Validation scripts</li> </ol>"},{"location":"adr/ADR-002%20backstage/#techdocs-structure","title":"TechDocs Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md (homepage)\n\u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 overview.md\n\u2502   \u251c\u2500\u2500 quickstart.md\n\u2502   \u2514\u2500\u2500 concepts.md\n\u251c\u2500\u2500 architecture/\n\u2502   \u251c\u2500\u2500 overview.md\n\u2502   \u251c\u2500\u2500 components.md\n\u2502   \u2514\u2500\u2500 decisions.md (ADRs)\n\u251c\u2500\u2500 dojo/\n\u2502   \u251c\u2500\u2500 overview.md\n\u2502   \u251c\u2500\u2500 white-belt/\n\u2502   \u251c\u2500\u2500 yellow-belt/\n\u2502   \u251c\u2500\u2500 green-belt/\n\u2502   \u251c\u2500\u2500 brown-belt/\n\u2502   \u2514\u2500\u2500 black-belt/\n\u251c\u2500\u2500 operations/\n\u2502   \u251c\u2500\u2500 runbooks/\n\u2502   \u251c\u2500\u2500 troubleshooting.md\n\u2502   \u2514\u2500\u2500 monitoring.md\n\u2514\u2500\u2500 contributing/\n    \u251c\u2500\u2500 code.md\n    \u251c\u2500\u2500 docs.md\n    \u2514\u2500\u2500 dojo-content.md\n</code></pre>"},{"location":"adr/ADR-002%20backstage/#catalog-structure","title":"Catalog Structure","text":"<p>Entity Types: - Component: Microservices, libraries, websites - API: REST, GraphQL, gRPC interfaces - Resource: Databases, queues, storage buckets - System: Groups of components working together - Domain: Business domains or product areas - User: People using the platform - Group: Teams, departments - Template: Software templates for scaffolding</p> <p>Example Component: <pre><code>apiVersion: backstage.io/v1alpha1\nkind: Component\nmetadata:\n  name: sample-app\n  title: Sample Application\n  description: Demo application for Fawkes dojo\n  annotations:\n    github.com/project-slug: paruff/fawkes\n    backstage.io/techdocs-ref: dir:.\n    jenkins.io/job-full-name: fawkes/sample-app\n    argocd/app-name: sample-app\nspec:\n  type: service\n  lifecycle: production\n  owner: platform-team\n  system: dojo-learning\n  providesApis:\n    - sample-api\n  consumesApis:\n    - auth-api\n  dependsOn:\n    - resource:postgres-db\n</code></pre></p>"},{"location":"adr/ADR-002%20backstage/#authentication-strategy","title":"Authentication Strategy","text":"<p>Phase 1 (MVP): GitHub OAuth - Simple setup - Most developers have GitHub accounts - Scopes: read:user, read:org</p> <p>Phase 2 (Month 2): Add providers - Google OAuth (Gmail accounts) - GitLab OAuth (if using GitLab) - LDAP/AD (for enterprise)</p> <p>Phase 3 (Month 4): Full SSO - SAML 2.0 support - OIDC support - Integration with Keycloak (if deployed)</p>"},{"location":"adr/ADR-002%20backstage/#customization-branding","title":"Customization &amp; Branding","text":"<p>Theme Configuration: <pre><code>// app-config.yaml\napp:\n  title: Fawkes Platform\n  branding:\n    theme:\n      light:\n        primary: '#326CE5'    # Kubernetes blue\n        secondary: '#FF6D00'  # Fawkes orange\n      dark:\n        primary: '#7DA3FF'\n        secondary: '#FFB74D'\n    logo: './logo.svg'\n    favicon: './favicon.ico'\n</code></pre></p> <p>Custom Homepage: - Welcome message and quick links - Recent deployments - DORA metrics summary - Dojo progress widget - Mattermost activity feed - Platform status indicators</p>"},{"location":"adr/ADR-002%20backstage/#performance-optimization","title":"Performance Optimization","text":"<p>Caching: - Enable backend caching for catalog - Redis for session storage - CDN for static assets (logo, theme)</p> <p>Database: - PostgreSQL connection pooling - Read replicas for queries - Regular vacuum and analyze - Index optimization</p> <p>Search: - Elasticsearch for full-text search (optional, improves performance) - Incremental indexing - Faceted search for filtering</p>"},{"location":"adr/ADR-002%20backstage/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<p>Metrics (Prometheus): - HTTP request duration - Catalog entity count - Plugin load times - Database query performance - Authentication success/failure</p> <p>Dashboards (Grafana): - Backstage performance dashboard - User activity dashboard - Plugin health dashboard - Database metrics dashboard</p> <p>Alerts: - Backstage down (&gt;2 min) - High error rate (&gt;5% in 5 min) - Slow response times (&gt;2s P95) - Database connection issues</p>"},{"location":"adr/ADR-002%20backstage/#backup-disaster-recovery","title":"Backup &amp; Disaster Recovery","text":"<p>Backups: - PostgreSQL daily backups - Catalog snapshots to Git (optional) - Configuration stored in Git (Infrastructure as Code)</p> <p>Recovery: - Restore from PostgreSQL backup - Redeploy from Git configuration - RTO: &lt;4 hours - RPO: &lt;24 hours</p>"},{"location":"adr/ADR-002%20backstage/#security-considerations","title":"Security Considerations","text":"<p>Authentication: - OAuth 2.0 for external providers - JWT tokens with expiration - Session management with secure cookies</p> <p>Authorization: - RBAC for catalog entities - Team-based access control - Read-only public catalog (optional)</p> <p>Network Security: - TLS/HTTPS only - Network policies to restrict access - Rate limiting on APIs - CORS configuration</p> <p>Secrets Management: - Never store secrets in Backstage config - Use Kubernetes secrets or Vault - Rotate credentials regularly - Audit access logs</p>"},{"location":"adr/ADR-002%20backstage/#monitoring-this-decision","title":"Monitoring This Decision","text":"<p>We will revisit this ADR if: - Backstage becomes unmaintained or development slows significantly - A superior open source alternative emerges with better fit - Performance issues arise that cannot be resolved - Plugin ecosystem fails to meet our needs - Community adoption of Backstage declines significantly - Total cost of ownership (operational) exceeds commercial alternatives</p> <p>Next Review Date: April 8, 2026 (6 months)</p>"},{"location":"adr/ADR-002%20backstage/#references","title":"References","text":"<ul> <li>Backstage Official Documentation</li> <li>Backstage GitHub Repository</li> <li>Backstage Plugin Marketplace</li> <li>CNCF Backstage Project</li> <li>Spotify Engineering Blog - Backstage</li> <li>Backstage Community Discord</li> </ul>"},{"location":"adr/ADR-002%20backstage/#notes","title":"Notes","text":""},{"location":"adr/ADR-002%20backstage/#why-backstage-over-building-custom","title":"Why Backstage Over Building Custom?","text":"<p>The most common question: \"Why not build our own portal?\"</p> <p>Build vs. Buy (Open Source) Calculation:</p> <p>Build Custom: - Development: 6-12 months \u00d7 2 engineers = $200k-$400k - Maintenance: Ongoing 0.5 FTE = $60k/year - Features: Limited to what we build - Community: Zero - Risk: May not match quality</p> <p>Use Backstage: - Setup: 2-4 weeks \u00d7 1 engineer = $10k-$20k - Custom plugin (dojo): 40 hours = $5k - Maintenance: 0.1 FTE (mostly updates) = $12k/year - Features: 100+ plugins available immediately - Community: 1,000+ contributors, constant improvements - Risk: Proven at scale</p> <p>ROI: Backstage saves $200k-$400k upfront, $48k/year ongoing. Gets 100+ plugins and battle-tested features immediately.</p>"},{"location":"adr/ADR-002%20backstage/#backstage-at-spotify-scale","title":"Backstage at Spotify Scale","text":"<p>Spotify's experience (from their blog): - 1,300+ services in catalog - 200+ software templates - 200 custom plugins - 2,000+ engineers using daily - Improved onboarding: New engineers productive in days, not weeks - Reduced cognitive load: 80% reduction in \"where do I find X\" questions</p> <p>While Fawkes won't reach Spotify scale immediately, proves Backstage can scale to our needs and beyond.</p>"},{"location":"adr/ADR-002%20backstage/#plugin-development-learning-curve","title":"Plugin Development Learning Curve","text":"<p>Building custom plugins requires TypeScript and React knowledge. However: - Official plugin templates speed development - Extensive documentation and examples - Active community for questions - Can hire contractors if needed - ROI positive even with learning curve</p> <p>Budget 40 hours for first plugin (dojo learning hub), 20 hours for subsequent plugins.</p> <p>Decision Made By: Platform Architecture Team Approved By: Project Lead Date: October 8, 2025 Author: [Platform Architect Name] Last Updated: October 8, 2025</p>"},{"location":"adr/ADR-003%20argocd/","title":"ADR-003: ArgoCD for GitOps","text":""},{"location":"adr/ADR-003%20argocd/#status","title":"Status","text":"<p>Accepted - October 8, 2025</p>"},{"location":"adr/ADR-003%20argocd/#context","title":"Context","text":"<p>Fawkes requires a GitOps continuous delivery solution to manage application deployments and platform infrastructure declaratively. GitOps\u2014where Git is the single source of truth for desired system state\u2014is a core principle of modern platform engineering and directly supports DORA best practices.</p>"},{"location":"adr/ADR-003%20argocd/#the-need-for-gitops","title":"The Need for GitOps","text":"<p>Current Challenges Without GitOps: - Manual Deployments: Error-prone, not repeatable, tribal knowledge - Configuration Drift: Production state diverges from declared state - Audit Trail Gaps: Hard to track who changed what and when - Rollback Complexity: No easy way to revert to previous working state - Multi-Environment Management: Promoting changes across dev/staging/prod is manual - No Self-Healing: Systems don't automatically recover from drift</p> <p>What GitOps Provides: 1. Declarative Configuration: Everything defined in Git (applications, infrastructure, configs) 2. Automated Sync: System automatically converges to desired state 3. Version Control: Complete history of all changes with Git commits 4. Easy Rollback: Revert Git commit to roll back to previous state 5. Audit Trail: Who, what, when, why all tracked in Git 6. Self-Healing: Automatic drift detection and correction 7. Multi-Cluster Management: Manage multiple Kubernetes clusters from single control plane</p>"},{"location":"adr/ADR-003%20argocd/#requirements-for-gitops-tool","title":"Requirements for GitOps Tool","text":"<p>Core Requirements: - Kubernetes-Native: Designed specifically for Kubernetes deployments - Git Integration: Supports GitHub, GitLab, Bitbucket, etc. - Automated Sync: Watches Git, applies changes automatically - Drift Detection: Detects and corrects configuration drift - Multi-Cluster: Manages multiple clusters (dev, staging, prod) - Progressive Delivery: Supports canary, blue-green deployments - Rollback: Easy revert to previous version - RBAC: Fine-grained access control for teams - SSO Integration: OIDC/SAML for authentication</p> <p>DORA Alignment: - Deployment Frequency: Automated deployments increase frequency - Lead Time: Git commit to deployment is fast and automated - Change Failure Rate: Declarative state reduces misconfigurations - Time to Restore: Git revert enables fast rollback</p> <p>Integration Requirements: - Backstage: Show deployment status in developer portal - Jenkins: Trigger deployments after successful builds - Mattermost: Send deployment notifications to team channels - DORA Metrics: Report deployment events for metrics calculation - Kubernetes: Native integration, no abstraction layer</p>"},{"location":"adr/ADR-003%20argocd/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Need declarative configuration for reliability - Drift detection critical for production stability - Multi-environment promotion needs automation - Self-healing reduces operational toil</p> <p>Operational Forces: - Platform team can't manually deploy everything - Need audit trail for compliance - Rollback must be fast and reliable - Want to reduce deployment-related incidents</p> <p>Developer Experience Forces: - Developers want to see deployment status - Need confidence deployments will succeed - Want easy rollback if issues arise - Prefer GitOps \"merge to deploy\" workflow</p> <p>DORA Forces: - Deployment frequency depends on automation - Lead time includes deployment time - GitOps reduces change failure rate - Fast rollback improves time to restore</p>"},{"location":"adr/ADR-003%20argocd/#decision","title":"Decision","text":"<p>We will use ArgoCD as the GitOps continuous delivery platform for Fawkes.</p> <p>Specifically: - ArgoCD Core (latest stable version, currently 2.9+) - Multi-cluster deployment (manage dev, staging, prod from single ArgoCD) - ApplicationSets for managing multiple applications with templates - Argo Rollouts for progressive delivery (canary, blue-green) - Argo Notifications for Mattermost integration - Argo Image Updater for automated image updates (optional, evaluate after MVP) - SSO integration via OIDC (Phase 2)</p>"},{"location":"adr/ADR-003%20argocd/#rationale","title":"Rationale","text":"<ol> <li> <p>Kubernetes-Native Leader: ArgoCD is the most popular GitOps tool for Kubernetes, with 15,000+ GitHub stars, CNCF Graduated status, and massive adoption</p> </li> <li> <p>CNCF Graduated Project: Highest maturity level in CNCF, indicating:</p> </li> <li>Production-ready and battle-tested</li> <li>Strong governance and security</li> <li>Long-term sustainability</li> <li> <p>Regular security audits</p> </li> <li> <p>Best-in-Class GitOps: Purpose-built for GitOps on Kubernetes:</p> </li> <li>Declarative Git-based deployments</li> <li>Automated sync with configurable policies</li> <li>Drift detection with auto-heal option</li> <li>Multi-cluster management from single UI</li> <li> <p>Application health assessment</p> </li> <li> <p>Argo Ecosystem Integration: Part of larger Argo ecosystem:</p> </li> <li>Argo Rollouts: Advanced deployment strategies (canary, blue-green)</li> <li>Argo Workflows: Complex workflow orchestration</li> <li>Argo Events: Event-driven workflow automation</li> <li>Argo CD Image Updater: Automated image updates</li> <li> <p>All integrate seamlessly</p> </li> <li> <p>Progressive Delivery Support: Via Argo Rollouts:</p> </li> <li>Canary deployments with automated analysis</li> <li>Blue-green deployments</li> <li>Traffic splitting (with service mesh)</li> <li>Automated rollback on metrics threshold</li> <li> <p>Critical for reducing change failure rate</p> </li> <li> <p>Excellent UI: Beautiful web interface showing:</p> </li> <li>Application topology (visual graph)</li> <li>Real-time sync status</li> <li>Resource health</li> <li>Git commit history</li> <li> <p>Diff view (Git vs. cluster)</p> </li> <li> <p>CLI and API: Full control via CLI and REST API:</p> </li> <li>Automate operations</li> <li>Integrate with CI/CD</li> <li> <p>Custom tooling and scripts</p> </li> <li> <p>ApplicationSets: Powerful templating for multiple applications:</p> </li> <li>Deploy multiple apps with single manifest</li> <li>Git generator (monorepo support)</li> <li>Cluster generator (multi-cluster)</li> <li> <p>Matrix generator (combinations)</p> </li> <li> <p>RBAC and Security:</p> </li> <li>Fine-grained RBAC for teams</li> <li>SSO integration (OIDC, SAML, LDAP)</li> <li>Git credentials management</li> <li> <p>Audit logging</p> </li> <li> <p>Backstage Integration: Official Backstage plugin shows:</p> <ul> <li>Application sync status</li> <li>Deployment history</li> <li>Health status</li> <li>Direct links to ArgoCD UI</li> </ul> </li> <li> <p>Large Community:</p> <ul> <li>300+ contributors</li> <li>Active Slack community (10,000+ members)</li> <li>Monthly releases</li> <li>Extensive documentation</li> </ul> </li> <li> <p>Production Proven: Used by thousands of organizations including Intuit, IBM, Red Hat, Adobe</p> </li> </ol>"},{"location":"adr/ADR-003%20argocd/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-003%20argocd/#positive","title":"Positive","text":"<p>\u2705 True GitOps: Git becomes single source of truth, all changes tracked and auditable</p> <p>\u2705 Automated Deployments: Merge to Git \u2192 automatic deployment, increasing deployment frequency</p> <p>\u2705 Drift Correction: Self-healing keeps cluster in sync with Git, reducing incidents</p> <p>\u2705 Fast Rollback: Git revert + automatic sync = sub-minute rollback time</p> <p>\u2705 Multi-Environment: Promote changes across environments with Git merges/branches</p> <p>\u2705 Developer Self-Service: Developers deploy by merging PRs, no platform team tickets</p> <p>\u2705 Audit Trail: Complete history of who deployed what, when, and why (Git commits)</p> <p>\u2705 Progressive Delivery: Canary and blue-green reduce blast radius of bad deployments</p> <p>\u2705 Reduced MTTR: Fast rollback and self-healing improve time to restore service</p> <p>\u2705 Visual Topology: Application graph helps understand dependencies and health</p> <p>\u2705 Multi-Cluster: Single pane of glass for dev, staging, prod clusters</p> <p>\u2705 CNCF Backing: Graduated status ensures long-term sustainability and security</p> <p>\u2705 DORA Improvement: GitOps directly improves all four key metrics</p>"},{"location":"adr/ADR-003%20argocd/#negative","title":"Negative","text":"<p>\u26a0\ufe0f Learning Curve: Platform team needs to learn ArgoCD concepts (Applications, ApplicationSets, Sync policies)</p> <p>\u26a0\ufe0f Git as Bottleneck: All changes must go through Git (could slow emergency fixes)</p> <p>\u26a0\ufe0f Initial Setup Complexity: Configuring multi-cluster, RBAC, and integrations takes time</p> <p>\u26a0\ufe0f Resource Overhead: ArgoCD consumes ~500MB RAM, additional for controllers</p> <p>\u26a0\ufe0f Sync Delays: 3-minute default sync interval (configurable, can use webhooks)</p> <p>\u26a0\ufe0f Secret Management: Secrets in Git require encryption (Sealed Secrets, SOPS, Vault)</p> <p>\u26a0\ufe0f ApplicationSet Complexity: Advanced ApplicationSets can become complex to debug</p> <p>\u26a0\ufe0f UI Performance: Large deployments (100+ apps) can slow UI</p> <p>\u26a0\ufe0f Version Compatibility: Must ensure ArgoCD version compatible with Kubernetes version</p>"},{"location":"adr/ADR-003%20argocd/#neutral","title":"Neutral","text":"<p>\u25fd GitOps Philosophy: Requires team buy-in to GitOps methodology</p> <p>\u25fd Repository Structure: Requires thoughtful Git repository organization</p> <p>\u25fd Sync Policies: Choosing auto vs. manual sync requires consideration per application</p>"},{"location":"adr/ADR-003%20argocd/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li>Learning Curve:</li> <li>Allocate 1 week for ArgoCD training</li> <li>Start with simple applications, progress to complex</li> <li>Leverage official documentation and tutorials</li> <li> <p>Join ArgoCD Slack community for support</p> </li> <li> <p>Git as Bottleneck:</p> </li> <li>Use webhooks for faster sync (vs. 3-minute poll)</li> <li>Emergency \"break glass\" procedure documented</li> <li>kubectl still available for true emergencies</li> <li> <p>Consider sync timeout configuration</p> </li> <li> <p>Secret Management:</p> </li> <li>Use Sealed Secrets or External Secrets Operator</li> <li>Never commit raw secrets to Git</li> <li>Document secret rotation procedures</li> <li> <p>Consider Vault integration for sensitive data</p> </li> <li> <p>Initial Setup:</p> </li> <li>Use official Helm chart for deployment</li> <li>Start with single cluster, add multi-cluster later</li> <li>Use Infrastructure as Code for ArgoCD configuration</li> <li> <p>Create runbooks for common operations</p> </li> <li> <p>Sync Performance:</p> </li> <li>Use webhooks instead of polling where possible</li> <li>Configure appropriate sync intervals per application</li> <li>Use ApplicationSets for large-scale deployments</li> <li> <p>Monitor ArgoCD performance metrics</p> </li> <li> <p>Repository Structure:</p> </li> <li>Design clear repository structure upfront</li> <li>Separate application code from deployment manifests</li> <li>Use Kustomize or Helm for configuration management</li> <li>Document repository conventions</li> </ol>"},{"location":"adr/ADR-003%20argocd/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-003%20argocd/#alternative-1-flux-cd","title":"Alternative 1: Flux CD","text":"<p>Pros: - CNCF Graduated (alongside ArgoCD) - GitOps Toolkit approach (modular) - Native Helm support - Excellent multi-tenancy - Lower resource usage than ArgoCD - Strong automation capabilities - Good for Infrastructure as Code</p> <p>Cons: - No Built-In UI: CLI-only, requires separate UI (Weave GitOps) - Less Visual: No application topology graph like ArgoCD - Smaller Community: Fewer contributors and users than ArgoCD - Learning Curve: GitOps Toolkit concepts more abstract - Progressive Delivery: Requires Flagger (separate project) - Less Mature Backstage Plugin: ArgoCD plugin more feature-complete</p> <p>Reason for Rejection: Flux is excellent, but ArgoCD's UI is significant advantage for developer experience and troubleshooting. Visual application topology helps developers understand system. ArgoCD's larger community and more mature Backstage integration better fit Fawkes needs. However, Flux is valid choice and could be reconsidered for infrastructure GitOps.</p>"},{"location":"adr/ADR-003%20argocd/#alternative-2-jenkins-x","title":"Alternative 2: Jenkins X","text":"<p>Pros: - Complete CI/CD platform (not just CD) - GitOps-based - Automated preview environments - Integrated pipeline and deployment - Good for Jenkins users</p> <p>Cons: - Opinionated: Prescriptive workflows, less flexible - Complexity: Full platform, not just GitOps - Jenkins Dependency: Tied to Jenkins ecosystem - Smaller Adoption: Less proven than ArgoCD/Flux - Maintenance Concerns: Development pace slowed - Overkill: We already have Jenkins for CI</p> <p>Reason for Rejection: Jenkins X is full CI/CD platform, but we're using Jenkins (ADR-004) for CI and only need GitOps for CD. Jenkins X too opinionated and complex. ArgoCD's separation of concerns (CI vs CD) cleaner architecture.</p>"},{"location":"adr/ADR-003%20argocd/#alternative-3-spinnaker","title":"Alternative 3: Spinnaker","text":"<p>Pros: - Multi-cloud native (not just Kubernetes) - Advanced deployment strategies - Proven at Netflix scale - Strong pipeline orchestration - Multi-cluster management - Extensive integrations</p> <p>Cons: - Heavy and Complex: Difficult to deploy and maintain - Resource Intensive: Requires 8+ microservices, significant resources - Steep Learning Curve: Complex concepts and UI - Not GitOps-First: Push-based, not GitOps pull model - Maintenance Burden: High operational overhead - Overkill: More than we need for Kubernetes deployments</p> <p>Reason for Rejection: Spinnaker powerful but extremely complex. High resource usage (10+ pods) and maintenance burden unjustified for our Kubernetes-focused needs. Not GitOps-native (push model). ArgoCD provides 80% of benefits with 20% of complexity. May revisit Spinnaker if we need multi-cloud deployment orchestration beyond Kubernetes.</p>"},{"location":"adr/ADR-003%20argocd/#alternative-4-helm-only-no-gitops-tool","title":"Alternative 4: Helm Only (No GitOps Tool)","text":"<p>Pros: - Simple, no additional tool to learn - Direct control with helm upgrade commands - Low resource overhead - Familiar to most Kubernetes users - Fast deployments</p> <p>Cons: - No GitOps: No automatic sync, drift detection, or self-healing - Manual Process: Engineers must run helm commands - No Audit Trail: History only in Helm releases, not Git - No Rollback Automation: Manual helm rollback required - No Multi-Cluster: Managing multiple clusters complex - High Error Potential: Human mistakes likely - No Developer Self-Service: Requires platform team access</p> <p>Reason for Rejection: Helm alone doesn't provide GitOps benefits. Manual deployments don't scale, increase error rate, and limit deployment frequency. GitOps is core principle of modern platform engineering and DORA best practices. Helm excellent as package manager but not replacement for GitOps tool.</p>"},{"location":"adr/ADR-003%20argocd/#alternative-5-rancher-fleet","title":"Alternative 5: Rancher Fleet","text":"<p>Pros: - Built into Rancher platform - GitOps-based - Multi-cluster management - Simpler than ArgoCD - Good for Rancher users</p> <p>Cons: - Rancher Dependency: Requires Rancher platform - Smaller Community: Much smaller than ArgoCD/Flux - Less Mature: Newer project, less battle-tested - Limited Features: Fewer advanced features than ArgoCD - No Progressive Delivery: No built-in canary/blue-green - Weaker Ecosystem: Fewer integrations and plugins</p> <p>Reason for Rejection: Fleet good if using Rancher, but we're not. ArgoCD more mature, larger community, better features. Fleet's simplicity doesn't outweigh ArgoCD's comprehensive capabilities and proven track record.</p>"},{"location":"adr/ADR-003%20argocd/#alternative-6-gitlab-autodevops","title":"Alternative 6: GitLab AutoDevOps","text":"<p>Pros: - Integrated with GitLab - Auto-configured pipelines - Built-in deployment - Good for GitLab-centric shops</p> <p>Cons: - GitLab Lock-In: Only works with GitLab - Not GitOps: Push-based, not declarative - Opinionated: Limited customization - GitLab Required: We use GitHub - Less Control: Abstract away too much - Not Best-of-Breed: GitOps secondary to CI features</p> <p>Reason for Rejection: GitLab AutoDevOps tied to GitLab ecosystem. We use GitHub. Not true GitOps (push-based CI/CD). ArgoCD better fit for our multi-tool, GitOps-first approach.</p>"},{"location":"adr/ADR-003%20argocd/#alternative-7-weave-gitops-commercial","title":"Alternative 7: Weave GitOps (Commercial)","text":"<p>Pros: - Built on Flux CD - Nice UI for Flux - Enterprise features - Good for Flux users</p> <p>Cons: - Commercial: Core features open source, but UI and advanced features paid - Cost: Pricing unclear, per-cluster - Flux Dependency: Requires Flux understanding - Smaller Adoption: Newer, less proven - Less Features: Not as comprehensive as ArgoCD</p> <p>Reason for Rejection: Commercial aspects conflict with open source values. ArgoCD provides richer feature set out-of-box with free, open source UI. Weave GitOps good for Flux users wanting UI, but ArgoCD better starting point.</p>"},{"location":"adr/ADR-003%20argocd/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-001: Kubernetes (ArgoCD manages Kubernetes deployments)</li> <li>ADR-002: Backstage (ArgoCD plugin shows deployment status)</li> <li>ADR-004: Jenkins (Jenkins triggers ArgoCD deployments)</li> <li>ADR-007: Mattermost (Argo Notifications sends alerts to Mattermost)</li> <li>Future ADR: Repository Structure for GitOps</li> <li>Future ADR: Secrets Management Strategy</li> </ul>"},{"location":"adr/ADR-003%20argocd/#implementation-notes","title":"Implementation Notes","text":""},{"location":"adr/ADR-003%20argocd/#deployment-architecture","title":"Deployment Architecture","text":"<pre><code># ArgoCD Deployment\nargocd:\n  namespace: argocd\n\n  components:\n    - argocd-server:\n        replicas: 2 (HA)\n        resources:\n          cpu: 500m\n          memory: 256Mi\n        ingress: argocd.fawkes.io\n\n    - argocd-repo-server:\n        replicas: 2 (HA)\n        resources:\n          cpu: 500m\n          memory: 512Mi\n\n    - argocd-application-controller:\n        replicas: 1 (stateful, uses leader election for HA)\n        resources:\n          cpu: 1 core\n          memory: 1Gi\n\n    - argocd-redis:\n        replicas: 3 (HA with sentinel)\n        resources:\n          cpu: 200m\n          memory: 256Mi\n\n    - argocd-dex-server: (for SSO)\n        replicas: 1\n        resources:\n          cpu: 100m\n          memory: 128Mi\n\n  integrations:\n    - github (repository source)\n    - mattermost (notifications)\n    - backstage (status plugin)\n    - dora-metrics-service (deployment events)\n</code></pre>"},{"location":"adr/ADR-003%20argocd/#repository-structure","title":"Repository Structure","text":"<p>Recommended Structure (monorepo approach):</p> <pre><code>gitops-repo/\n\u251c\u2500\u2500 apps/\n\u2502   \u251c\u2500\u2500 dev/\n\u2502   \u2502   \u251c\u2500\u2500 team-a/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 service-1/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 deployment.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 service-2/\n\u2502   \u2502   \u2514\u2500\u2500 team-b/\n\u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2514\u2500\u2500 prod/\n\u251c\u2500\u2500 platform/\n\u2502   \u251c\u2500\u2500 backstage/\n\u2502   \u251c\u2500\u2500 jenkins/\n\u2502   \u251c\u2500\u2500 mattermost/\n\u2502   \u251c\u2500\u2500 prometheus/\n\u2502   \u2514\u2500\u2500 grafana/\n\u251c\u2500\u2500 infrastructure/\n\u2502   \u251c\u2500\u2500 namespaces/\n\u2502   \u251c\u2500\u2500 rbac/\n\u2502   \u251c\u2500\u2500 network-policies/\n\u2502   \u2514\u2500\u2500 resource-quotas/\n\u251c\u2500\u2500 argocd-apps/\n\u2502   \u251c\u2500\u2500 dev-apps.yaml (ApplicationSet)\n\u2502   \u251c\u2500\u2500 staging-apps.yaml\n\u2502   \u2514\u2500\u2500 prod-apps.yaml\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Alternative (polyrepo approach): - Separate repository per team/service - Pros: Team autonomy, clear ownership - Cons: Harder to enforce consistency, more repositories to manage</p>"},{"location":"adr/ADR-003%20argocd/#applicationset-example","title":"ApplicationSet Example","text":"<p>Deploy All Team Applications:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: team-applications\n  namespace: argocd\nspec:\n  generators:\n    - git:\n        repoURL: https://github.com/paruff/fawkes-gitops\n        revision: HEAD\n        directories:\n          - path: apps/prod/*/*\n  template:\n    metadata:\n      name: '{{path.basename}}'\n    spec:\n      project: default\n      source:\n        repoURL: https://github.com/paruff/fawkes-gitops\n        targetRevision: HEAD\n        path: '{{path}}'\n      destination:\n        server: https://kubernetes.default.svc\n        namespace: '{{path[1]}}' # team name from path\n      syncPolicy:\n        automated:\n          prune: true\n          selfHeal: true\n        syncOptions:\n          - CreateNamespace=true\n</code></pre>"},{"location":"adr/ADR-003%20argocd/#sync-policies","title":"Sync Policies","text":"<p>Automated Sync (recommended for most apps): <pre><code>syncPolicy:\n  automated:\n    prune: true       # Delete resources removed from Git\n    selfHeal: true    # Revert manual changes\n  syncOptions:\n    - CreateNamespace=true\n  retry:\n    limit: 5\n    backoff:\n      duration: 5s\n      factor: 2\n      maxDuration: 3m\n</code></pre></p> <p>Manual Sync (for critical production apps initially): <pre><code>syncPolicy:\n  manual: {}  # Require manual approval for sync\n</code></pre></p>"},{"location":"adr/ADR-003%20argocd/#progressive-delivery-with-argo-rollouts","title":"Progressive Delivery with Argo Rollouts","text":"<p>Canary Deployment Example:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: sample-app\nspec:\n  replicas: 10\n  strategy:\n    canary:\n      steps:\n        - setWeight: 20    # 20% traffic to canary\n        - pause: {duration: 5m}\n        - setWeight: 40    # 40% traffic\n        - pause: {duration: 5m}\n        - setWeight: 60    # 60% traffic\n        - pause: {duration: 5m}\n        - setWeight: 80    # 80% traffic\n        - pause: {duration: 5m}\n      analysis:\n        templates:\n          - templateName: error-rate-analysis\n        args:\n          - name: service-name\n            value: sample-app\n      trafficRouting:\n        istio:\n          virtualService:\n            name: sample-app\n</code></pre>"},{"location":"adr/ADR-003%20argocd/#notifications-configuration","title":"Notifications Configuration","text":"<p>Mattermost Integration:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-notifications-cm\ndata:\n  service.mattermost: |\n    apiURL: https://mattermost.fawkes.io\n    token: $mattermost-token\n\n  template.app-deployed: |\n    message: |\n      Application {{.app.metadata.name}} is now running new version.\n      {{if eq .serviceType \"slack\"}}:white_check_mark:{{end}} Application details: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}.\n\n  trigger.on-deployed: |\n    - when: app.status.operationState.phase in ['Succeeded']\n      send: [app-deployed]\n</code></pre> <p>Subscribe Application:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  annotations:\n    notifications.argoproj.io/subscribe.on-deployed.mattermost: team-deployments\n</code></pre>"},{"location":"adr/ADR-003%20argocd/#multi-cluster-management","title":"Multi-Cluster Management","text":"<p>Add Cluster:</p> <pre><code># Login to ArgoCD\nargocd login argocd.fawkes.io\n\n# Add production cluster\nargocd cluster add prod-cluster --name production\n\n# Add staging cluster\nargocd cluster add staging-cluster --name staging\n</code></pre> <p>Deploy to Multiple Clusters (ApplicationSet):</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: multi-cluster-app\nspec:\n  generators:\n    - list:\n        elements:\n          - cluster: dev\n            url: https://dev-cluster\n          - cluster: staging\n            url: https://staging-cluster\n          - cluster: prod\n            url: https://prod-cluster\n  template:\n    metadata:\n      name: 'sample-app-{{cluster}}'\n    spec:\n      project: default\n      source:\n        repoURL: https://github.com/paruff/fawkes-gitops\n        path: 'apps/{{cluster}}/sample-app'\n      destination:\n        server: '{{url}}'\n        namespace: sample-app\n</code></pre>"},{"location":"adr/ADR-003%20argocd/#rbac-configuration","title":"RBAC Configuration","text":"<p>Project-Based RBAC:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: AppProject\nmetadata:\n  name: team-a\nspec:\n  description: Team A applications\n  sourceRepos:\n    - 'https://github.com/paruff/fawkes-gitops'\n  destinations:\n    - namespace: 'team-a-*'\n      server: https://kubernetes.default.svc\n  roles:\n    - name: team-a-developer\n      policies:\n        - p, proj:team-a:team-a-developer, applications, get, team-a/*, allow\n        - p, proj:team-a:team-a-developer, applications, sync, team-a/*, allow\n</code></pre>"},{"location":"adr/ADR-003%20argocd/#backstage-integration","title":"Backstage Integration","text":"<p>Install Plugin:</p> <pre><code>yarn add --cwd packages/app @roadiehq/backstage-plugin-argo-cd\n</code></pre> <p>Component Annotation:</p> <pre><code>apiVersion: backstage.io/v1alpha1\nkind: Component\nmetadata:\n  name: sample-app\n  annotations:\n    argocd/app-name: sample-app\n    argocd/instance-name: argocd\nspec:\n  type: service\n  lifecycle: production\n  owner: team-a\n</code></pre>"},{"location":"adr/ADR-003%20argocd/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<p>Prometheus Metrics: - argocd_app_sync_total (sync attempts) - argocd_app_sync_status (current sync status) - argocd_app_health_status (application health) - argocd_git_request_total (Git operations)</p> <p>Grafana Dashboard: - Official ArgoCD dashboard (ID: 14584) - Customizations for Fawkes-specific views</p> <p>Alerts: - Application OutOfSync &gt;30 minutes - Application Degraded &gt;15 minutes - Sync Failures (3 consecutive) - High API latency (&gt;2s)</p>"},{"location":"adr/ADR-003%20argocd/#secret-management","title":"Secret Management","text":"<p>Option 1: Sealed Secrets (recommended for MVP):</p> <pre><code># Encrypt secret\necho -n 'my-secret-value' | kubectl create secret generic my-secret \\\n  --dry-run=client --from-file=password=/dev/stdin -o yaml | \\\n  kubeseal -o yaml &gt; sealed-secret.yaml\n\n# Commit sealed-secret.yaml to Git\n# SealedSecret controller decrypts in-cluster\n</code></pre> <p>Option 2: External Secrets Operator: - Fetch secrets from Vault, AWS Secrets Manager, etc. - Keep secret references in Git, not actual secrets - Better for large-scale deployments</p> <p>Never: Commit raw secrets to Git!</p>"},{"location":"adr/ADR-003%20argocd/#backup-disaster-recovery","title":"Backup &amp; Disaster Recovery","text":"<p>Backup Strategy: - ArgoCD configuration stored in Git (Infrastructure as Code) - Application manifests in GitOps repository - ArgoCD state in Kubernetes (can be recreated)</p> <p>Recovery: 1. Redeploy ArgoCD from Helm chart 2. Re-add clusters 3. Create Applications pointing to Git repository 4. ArgoCD syncs from Git (applications restored)</p> <p>RTO: &lt;2 hours (ArgoCD redeploy + application sync) RPO: 0 (Git is source of truth, no data loss)</p>"},{"location":"adr/ADR-003%20argocd/#performance-optimization","title":"Performance Optimization","text":"<p>For Large Deployments: - Increase application controller replicas - Tune sync timeouts and retry logic - Use ApplicationSets instead of individual Applications - Enable concurrent sync operations - Optimize Git repository size (use shallow clones)</p> <p>Resource Limits: <pre><code>spec:\n  resources:\n    limits:\n      cpu: 2\n      memory: 2Gi\n    requests:\n      cpu: 500m\n      memory: 512Mi\n</code></pre></p>"},{"location":"adr/ADR-003%20argocd/#monitoring-this-decision","title":"Monitoring This Decision","text":"<p>We will revisit this ADR if: - ArgoCD project becomes unmaintained or development slows - Performance issues arise that cannot be resolved - A superior GitOps tool emerges with better fit - Flux CD's UI significantly improves (could reconsider) - Operational burden exceeds benefits - Community adoption of ArgoCD declines significantly</p> <p>Next Review Date: April 8, 2026 (6 months)</p>"},{"location":"adr/ADR-003%20argocd/#references","title":"References","text":"<ul> <li>ArgoCD Official Documentation</li> <li>ArgoCD GitHub Repository</li> <li>Argo Rollouts Documentation</li> <li>CNCF ArgoCD Project</li> <li>GitOps Principles</li> <li>ArgoCD Backstage Plugin</li> </ul>"},{"location":"adr/ADR-003%20argocd/#notes","title":"Notes","text":""},{"location":"adr/ADR-003%20argocd/#argocd-vs-flux-the-eternal-debate","title":"ArgoCD vs. Flux: The Eternal Debate","text":"<p>When to choose ArgoCD: - Want built-in, feature-rich UI - Prefer visual application topology - Need strong RBAC out-of-box - Value large, active community - Want simpler mental model</p> <p>When to choose Flux: - Prefer CLI-first workflow - Want lower resource usage - Need advanced multi-tenancy - Comfortable with GitOps Toolkit abstraction - Strong preference for CNCF's recommended GitOps tool</p> <p>For Fawkes: ArgoCD's UI significant advantage for developer experience and troubleshooting. Both are excellent choices\u2014this decision not deeply philosophical, more pragmatic based on UX priorities.</p>"},{"location":"adr/ADR-003%20argocd/#gitops-best-practices","title":"GitOps Best Practices","text":"<ol> <li>Repository Structure: Organize thoughtfully upfront (hard to change later)</li> <li>Separation of Concerns: Keep application code separate from deployment manifests</li> <li>Environment Promotion: Use branches or directories for environments</li> <li>Secret Management: Never commit secrets, use Sealed Secrets or Vault</li> <li>Sync Policies: Start with manual sync for critical apps, automate once confident</li> <li>Monitoring: Watch sync failures, drift detection, and performance metrics</li> <li>Rollback Plan: Test rollback procedure before you need it</li> </ol>"},{"location":"adr/ADR-003%20argocd/#progressive-delivery-roi","title":"Progressive Delivery ROI","text":"<p>Argo Rollouts adds complexity but significantly reduces change failure rate: - Canary deployments catch issues before full rollout - Automated rollback based on metrics prevents outages - Traffic shifting minimizes blast radius - Aligns with DORA best practices</p> <p>Worth complexity trade-off for production applications. Can start without Rollouts, add later for critical services.</p> <p>Decision Made By: Platform Architecture Team Approved By: Project Lead Date: October 8, 2025 Author: [Platform Architect Name] Last Updated: October 8, 2025</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/","title":"ADR-004: Jenkins for CI/CD","text":""},{"location":"adr/ADR-004%20jenkins%204%20ci/#status","title":"Status","text":"<p>Accepted - October 8, 2025</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#context","title":"Context","text":"<p>Fawkes requires a Continuous Integration and Continuous Delivery (CI/CD) platform to automate building, testing, securing, and packaging applications. CI/CD is foundational to achieving elite DORA performance, particularly for deployment frequency and lead time for changes.</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#the-need-for-cicd-automation","title":"The Need for CI/CD Automation","text":"<p>Current Challenges Without CI/CD: - Manual Builds: Error-prone, time-consuming, not repeatable - Inconsistent Testing: Tests run locally (or not at all), vary by developer - Security Gaps: No automated security scanning, vulnerabilities reach production - Slow Feedback: Developers wait hours/days to know if changes work - Deployment Bottlenecks: Manual packaging and deployment slow delivery - No Audit Trail: Can't trace which code produced which artifact</p> <p>What CI/CD Provides: 1. Automated Builds: Code commit triggers automatic build and test 2. Quality Gates: Automated testing, linting, security scanning block bad code 3. Fast Feedback: Developers know within minutes if changes work 4. Consistent Process: Same build/test process every time, regardless of developer 5. Security Integration: Automated SAST, dependency scanning, container scanning 6. Artifact Management: Versioned, immutable build artifacts 7. Deployment Trigger: Successful builds trigger GitOps deployment 8. Audit Trail: Complete record of what was built, when, and by whom</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#requirements-for-cicd-platform","title":"Requirements for CI/CD Platform","text":"<p>Core Requirements: - Pipeline as Code: Jenkinsfiles in Git, version controlled - Kubernetes Native: Dynamic agents in Kubernetes pods - Golden Paths: Reusable pipeline templates for common scenarios - Security Scanning: Integration with SonarQube, Trivy, dependency checkers - Multi-Language: Support Java, Python, Node.js, Go, and more - Extensible: Plugin ecosystem for integrations - GitOps Integration: Trigger ArgoCD deployments - DORA Metrics: Report build/deployment events</p> <p>DORA Alignment: - Deployment Frequency: Automated pipelines enable frequent deployments - Lead Time: Fast builds reduce time from commit to production - Change Failure Rate: Quality gates catch issues before deployment - Time to Restore: Fast pipelines enable quick hotfix deployment</p> <p>Integration Requirements: - GitHub: Webhook triggers, status checks - ArgoCD: Trigger GitOps sync after successful build - SonarQube: Code quality and security analysis - Trivy: Container image scanning - Harbor/ECR: Push container images - Mattermost: Build notifications - Backstage: Show pipeline status in developer portal - DORA Metrics Service: Report build events</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Need pipeline-as-code for version control and review - Kubernetes-native approach reduces infrastructure overhead - Security scanning must be automated and enforced - Multi-language support critical for polyglot teams</p> <p>Developer Experience Forces: - Fast feedback loops improve developer productivity - Clear error messages reduce debugging time - Consistent builds reduce \"works on my machine\" issues - Self-service pipelines reduce dependency on platform team</p> <p>Operational Forces: - Platform team can't manually build everything - Need scalability (100+ concurrent builds) - Resource efficiency matters (cost optimization) - Maintenance burden should be minimized</p> <p>Enterprise Forces: - Many enterprises already use Jenkins - Familiarity reduces adoption friction - Extensive plugin ecosystem meets diverse needs - Proven at massive scale</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#decision","title":"Decision","text":"<p>We will use Jenkins with Kubernetes plugin as the CI/CD platform for Fawkes.</p> <p>Specifically: - Jenkins LTS (Long-Term Support, latest stable) - Kubernetes Plugin for dynamic agent provisioning - Configuration as Code (JCasC) for declarative Jenkins setup - Shared Pipeline Libraries for golden path reusability - Pipeline-as-Code (Jenkinsfile in every repository) - Security Scanning Integration (SonarQube, Trivy, OWASP Dependency-Check) - GitOps Integration (trigger ArgoCD after successful builds)</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#rationale","title":"Rationale","text":"<ol> <li> <p>Industry Standard: Jenkins is the most widely adopted CI/CD tool, with 20+ years of development, used by 70%+ of enterprises</p> </li> <li> <p>Kubernetes Native: Jenkins Kubernetes plugin provides:</p> </li> <li>Dynamic agent provisioning (pods created on-demand)</li> <li>Isolated build environments (each build in separate pod)</li> <li>Resource efficiency (agents destroyed after build)</li> <li>Scalability (limited only by cluster capacity)</li> <li> <p>Cost optimization (only pay for active builds)</p> </li> <li> <p>Pipeline as Code: Jenkinsfile DSL enables:</p> </li> <li>Version-controlled pipelines</li> <li>Code review of pipeline changes</li> <li>Reusable shared libraries</li> <li>Declarative and scripted syntax options</li> <li> <p>Mature, battle-tested</p> </li> <li> <p>Massive Plugin Ecosystem: 1,800+ plugins covering:</p> </li> <li>SCM: GitHub, GitLab, Bitbucket</li> <li>Build tools: Maven, Gradle, npm, pip</li> <li>Quality: SonarQube, Checkstyle, PMD</li> <li>Security: Trivy, OWASP, git-secrets</li> <li>Deployment: Kubernetes, ArgoCD, Spinnaker</li> <li> <p>Notifications: Mattermost, email, Slack</p> </li> <li> <p>Configuration as Code (JCasC):</p> </li> <li>Declarative YAML configuration</li> <li>Version controlled in Git</li> <li>Reproducible Jenkins setup</li> <li>No manual UI configuration</li> <li> <p>Easy disaster recovery</p> </li> <li> <p>Proven at Scale: Used by massive organizations:</p> </li> <li>Netflix (2,000+ builds/day)</li> <li>CloudBees customers (enterprise scale)</li> <li>Thousands of open source projects</li> <li> <p>Can handle 100+ concurrent builds easily</p> </li> <li> <p>Shared Libraries: Reusable pipeline code:</p> </li> <li>DRY principle for pipelines</li> <li>Golden path templates</li> <li>Consistent build patterns</li> <li> <p>Centralized updates (change once, apply everywhere)</p> </li> <li> <p>Enterprise Features Available:</p> </li> <li>RBAC and folder-based security</li> <li>Audit logging</li> <li>Blue Ocean UI (modern interface)</li> <li>Pipeline visualization</li> <li> <p>Extensive reporting</p> </li> <li> <p>Strong Community:</p> </li> <li>Active development (monthly releases)</li> <li>Large user community</li> <li>Extensive documentation</li> <li>Many tutorials and examples</li> <li> <p>Commercial support available (CloudBees)</p> </li> <li> <p>Backstage Integration: Official Jenkins plugin shows:</p> <ul> <li>Build status and history</li> <li>Console logs</li> <li>Test results</li> <li>Direct links to Jenkins</li> </ul> </li> <li> <p>Familiarity: Most developers have used Jenkins:</p> <ul> <li>Reduces learning curve</li> <li>Easier contributor onboarding</li> <li>Extensive knowledge base (Stack Overflow, blogs)</li> </ul> </li> <li> <p>Cost Effective:</p> <ul> <li>Open source (free)</li> <li>Only infrastructure costs</li> <li>Commercial support optional (CloudBees)</li> </ul> </li> </ol>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-004%20jenkins%204%20ci/#positive","title":"Positive","text":"<p>\u2705 Automated Quality Gates: Every commit tested, scanned, and validated before deployment</p> <p>\u2705 Fast Feedback: Developers get results in 5-10 minutes, not hours</p> <p>\u2705 Golden Paths: Shared libraries provide consistent, best-practice pipelines</p> <p>\u2705 Security Integration: SAST, dependency scanning, container scanning automated</p> <p>\u2705 Resource Efficiency: Dynamic Kubernetes agents scale up/down based on load</p> <p>\u2705 Pipeline as Code: Jenkinsfiles version-controlled, reviewed, and testable</p> <p>\u2705 Extensive Integrations: 1,800+ plugins cover virtually any tool</p> <p>\u2705 Proven Reliability: Battle-tested at enterprise scale for 15+ years</p> <p>\u2705 Developer Self-Service: Teams create/modify pipelines without platform team</p> <p>\u2705 DORA Metrics: Build events feed into deployment frequency and lead time calculations</p> <p>\u2705 Familiarity: Developers already know Jenkins, reducing onboarding time</p> <p>\u2705 Cost Effective: Open source with no licensing fees</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#negative","title":"Negative","text":"<p>\u26a0\ufe0f UI Complexity: Traditional Jenkins UI dated, can be overwhelming (Blue Ocean helps)</p> <p>\u26a0\ufe0f Plugin Management: Keeping plugins updated requires ongoing effort</p> <p>\u26a0\ufe0f Groovy DSL: Jenkinsfile syntax (Groovy) has learning curve</p> <p>\u26a0\ufe0f Resource Usage: Jenkins controller requires ~2GB RAM minimum</p> <p>\u26a0\ufe0f Security Concerns: Jenkins has had security vulnerabilities (requires updates)</p> <p>\u26a0\ufe0f Configuration Complexity: Advanced pipelines can become complex</p> <p>\u26a0\ufe0f Legacy Baggage: 15+ years of features means some cruft</p> <p>\u26a0\ufe0f Agent Configuration: Setting up Kubernetes plugin requires careful configuration</p> <p>\u26a0\ufe0f Maintenance: Jenkins and plugins need regular updates</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#neutral","title":"Neutral","text":"<p>\u25fd Alternative Modern Tools Exist: GitHub Actions, GitLab CI, Tekton are simpler but less feature-rich</p> <p>\u25fd Blue Ocean: Modern UI available but not default</p> <p>\u25fd CloudBees: Commercial support available if needed</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li>UI Complexity:</li> <li>Use Blue Ocean for modern UI</li> <li>Standardize on pipeline-as-code (minimize UI usage)</li> <li>Create clear documentation and screenshots</li> <li> <p>Consider Backstage as primary interface (show status there)</p> </li> <li> <p>Plugin Management:</p> </li> <li>Use dependabot or similar for plugin updates</li> <li>Test updates in staging before production</li> <li>Limit plugin count to essential ones</li> <li> <p>Document which plugins are used and why</p> </li> <li> <p>Groovy DSL Learning Curve:</p> </li> <li>Provide Jenkinsfile templates for common scenarios</li> <li>Create shared library with high-level abstractions</li> <li>Include examples and comments in templates</li> <li> <p>Run workshops for developers</p> </li> <li> <p>Security:</p> </li> <li>Subscribe to Jenkins security advisories</li> <li>Automate Jenkins updates (test first)</li> <li>Use RBAC to limit permissions</li> <li>Regular security audits</li> <li> <p>Keep plugins updated</p> </li> <li> <p>Configuration:</p> </li> <li>Use JCasC for all configuration</li> <li>Store configuration in Git</li> <li>Use Infrastructure as Code for Jenkins deployment</li> <li> <p>Document configuration decisions</p> </li> <li> <p>Kubernetes Plugin:</p> </li> <li>Start with simple pod templates</li> <li>Create library of pod templates for common scenarios</li> <li>Document resource limits and requests</li> <li>Monitor agent performance</li> </ol>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-004%20jenkins%204%20ci/#alternative-1-github-actions","title":"Alternative 1: GitHub Actions","text":"<p>Pros: - Native GitHub integration (no webhooks) - YAML-based, simple syntax - Matrix builds for testing multiple versions - Large marketplace of actions - Free for public repos, generous limits - Modern, fast, cloud-native</p> <p>Cons: - GitHub Lock-In: Only works with GitHub - Limited Self-Hosting: Self-hosted runners less mature than Jenkins - Cost: Expensive for private repos at scale ($0.008/minute, adds up) - Less Flexible: More opinionated than Jenkins - Smaller Plugin Ecosystem: Fewer actions than Jenkins plugins - No Shared Libraries: Harder to share pipeline code across repos - Limited RBAC: Access control less granular</p> <p>Reason for Rejection: While excellent for GitHub-centric projects, GitHub Actions creates vendor lock-in. Cost at scale significant (100 builds/day \u00d7 10 min \u00d7 $0.008 = $240/month, $2,880/year just for CI). Self-hosted runners less mature than Jenkins Kubernetes agents. May use for Fawkes repo itself but not as platform-wide CI solution.</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#alternative-2-gitlab-ci","title":"Alternative 2: GitLab CI","text":"<p>Pros: - Native GitLab integration - YAML-based pipelines - Built-in container registry - Auto DevOps features - Good UI and UX - Free tier generous</p> <p>Cons: - GitLab Required: We use GitHub, not GitLab - Migration Overhead: Would need to migrate or mirror repos - Less Flexible: More opinionated than Jenkins - Smaller Ecosystem: Fewer integrations than Jenkins - Learning Curve: Teams would need to learn new tool</p> <p>Reason for Rejection: GitLab CI excellent if using GitLab, but we use GitHub. Migrating repos or maintaining mirrors adds complexity without clear benefit. Jenkins works with any Git provider.</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#alternative-3-tekton-pipelines","title":"Alternative 3: Tekton Pipelines","text":"<p>Pros: - Kubernetes-native (CRDs) - Cloud-native, modern architecture - Pipeline-as-code (YAML) - CNCF project (good governance) - Growing adoption - True cloud-native approach</p> <p>Cons: - Immature: Newer project, less proven at scale - Steeper Learning Curve: CRDs and Tasks/Pipelines concepts unfamiliar - No UI: Requires separate UI (Tekton Dashboard basic) - Smaller Ecosystem: Fewer pre-built Tasks than Jenkins plugins - Limited Shared Libraries: Harder to share pipeline code - Complex Setup: More moving parts than Jenkins - Debugging Harder: Kubernetes-native means more abstraction</p> <p>Reason for Rejection: Tekton philosophically appealing (cloud-native) but less mature and harder to use. Jenkins provides 80% of benefits with 20% of complexity. May revisit Tekton in 2-3 years when more mature and ecosystem richer.</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#alternative-4-circleci-saas","title":"Alternative 4: CircleCI (SaaS)","text":"<p>Pros: - Fast builds (optimized infrastructure) - Good UI and developer experience - Docker-first approach - Orbs (reusable config) - Free tier available - Popular with startups</p> <p>Cons: - SaaS Only: No self-hosted option (CircleCI Server discontinued) - Cost: $15-60/user/month depending on tier (expensive at scale) - Vendor Lock-In: Proprietary platform - Limited Control: Can't customize deeply - Data on CircleCI Servers: Security/compliance concerns</p> <p>Reason for Rejection: SaaS-only and proprietary conflicts with self-hosted open source values. Cost at 100 developers: $18,000-$72,000/year. Cannot customize to our exact needs.</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#alternative-5-drone-ci","title":"Alternative 5: Drone CI","text":"<p>Pros: - Open source and self-hosted - Container-native (Docker) - YAML-based pipelines - Lightweight - Easy to set up - Good GitHub integration</p> <p>Cons: - Smaller Community: Much smaller than Jenkins - Limited Plugins: Fewer integrations than Jenkins - Less Mature: Newer, less battle-tested - Uncertain Future: Development pace variable - Limited Enterprise Features: RBAC, audit logging less robust - Smaller Ecosystem: Fewer shared pipelines</p> <p>Reason for Rejection: While simpler than Jenkins, Drone's smaller community and ecosystem are concerns. Jenkins' maturity and plugin ecosystem provide more value. Drone good for simple use cases but Fawkes needs comprehensive CI solution.</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#alternative-6-concourse-ci","title":"Alternative 6: Concourse CI","text":"<p>Pros: - Pipeline-as-code (YAML) - Resource-based model (interesting approach) - Reproducible builds - Open source - Kubernetes support</p> <p>Cons: - Steep Learning Curve: Resource model unintuitive - Small Community: Very small compared to Jenkins - Limited Plugins: Minimal ecosystem - Complex Setup: Many components to deploy - No UI for Configuration: All YAML, no web UI - Limited Adoption: Few large organizations use it</p> <p>Reason for Rejection: Concourse's resource-based model interesting but unintuitive. Very small community and ecosystem. Learning curve not justified by benefits over Jenkins.</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#alternative-7-spinnaker","title":"Alternative 7: Spinnaker","text":"<p>Pros: - Continuous delivery focus - Multi-cloud native - Advanced deployment strategies - Netflix-proven</p> <p>Cons: - Not CI Tool: Continuous delivery only, not continuous integration - Very Complex: Difficult to set up and maintain - Resource Heavy: 10+ microservices, high overhead - Overkill: More than we need</p> <p>Reason for Rejection: Spinnaker is CD tool, not CI. We need CI/CD together. Spinnaker's complexity unjustified. Using Jenkins (CI) + ArgoCD (CD) cleaner separation of concerns.</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-001: Kubernetes (Jenkins uses Kubernetes plugin for agents)</li> <li>ADR-002: Backstage (Jenkins plugin shows build status)</li> <li>ADR-003: ArgoCD (Jenkins triggers ArgoCD deployments)</li> <li>ADR-007: Mattermost (Jenkins sends build notifications)</li> <li>Future ADR: Shared Pipeline Library Structure</li> <li>Future ADR: Build Caching Strategy</li> </ul>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#implementation-notes","title":"Implementation Notes","text":""},{"location":"adr/ADR-004%20jenkins%204%20ci/#deployment-architecture","title":"Deployment Architecture","text":"<pre><code># Jenkins Deployment\njenkins:\n  namespace: fawkes-ci\n\n  components:\n    - jenkins-controller:\n        image: jenkins/jenkins:lts\n        replicas: 1 (stateful, uses persistent volume)\n        resources:\n          cpu: 2 cores\n          memory: 4Gi\n        storage: 50Gi (PVC for Jenkins home)\n\n    - jenkins-agents:\n        dynamic: true (Kubernetes plugin creates on-demand)\n        pod-templates:\n          - maven-agent:\n              resources:\n                cpu: 1 core\n                memory: 2Gi\n          - node-agent:\n              resources:\n                cpu: 1 core\n                memory: 1Gi\n          - python-agent:\n              resources:\n                cpu: 1 core\n                memory: 1Gi\n          - docker-agent:\n              resources:\n                cpu: 2 cores\n                memory: 4Gi\n\n  integrations:\n    - github (webhooks, status checks)\n    - sonarqube (code quality scanning)\n    - trivy (container scanning)\n    - argocd (deployment triggering)\n    - mattermost (notifications)\n    - backstage (build status plugin)\n    - harbor (container registry)\n    - dora-metrics-service (build events)\n</code></pre>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#configuration-as-code-jcasc","title":"Configuration as Code (JCasC)","text":"<pre><code># jenkins-casc.yaml\njenkins:\n  systemMessage: \"Fawkes Platform CI/CD\"\n  numExecutors: 0  # Use Kubernetes agents only\n\n  securityRealm:\n    github:\n      githubWebUri: \"https://github.com\"\n      clientID: \"${GITHUB_CLIENT_ID}\"\n      clientSecret: \"${GITHUB_CLIENT_SECRET}\"\n\n  authorizationStrategy:\n    globalMatrix:\n      permissions:\n        - \"Overall/Administer:admin\"\n        - \"Overall/Read:authenticated\"\n        - \"Job/Build:authenticated\"\n        - \"Job/Cancel:authenticated\"\n\n  clouds:\n    - kubernetes:\n        name: \"kubernetes\"\n        serverUrl: \"https://kubernetes.default\"\n        namespace: \"fawkes-ci\"\n        jenkinsUrl: \"http://jenkins:8080\"\n        jenkinsTunnel: \"jenkins-agent:50000\"\n        templates:\n          - name: \"maven\"\n            label: \"maven\"\n            containers:\n              - name: \"maven\"\n                image: \"maven:3.8-openjdk-17\"\n                command: \"/bin/sh -c\"\n                args: \"cat\"\n                ttyEnabled: true\n                resourceRequestCpu: \"1\"\n                resourceRequestMemory: \"2Gi\"\n                resourceLimitCpu: \"2\"\n                resourceLimitMemory: \"4Gi\"\n\nunclassified:\n  globalLibraries:\n    libraries:\n      - name: \"fawkes-pipeline-library\"\n        retriever:\n          modernSCM:\n            scm:\n              git:\n                remote: \"https://github.com/paruff/fawkes-pipeline-library\"\n                credentialsId: \"github-token\"\n</code></pre>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#shared-pipeline-library-structure","title":"Shared Pipeline Library Structure","text":"<pre><code>fawkes-pipeline-library/\n\u251c\u2500\u2500 vars/\n\u2502   \u251c\u2500\u2500 mavenPipeline.groovy\n\u2502   \u251c\u2500\u2500 nodePipeline.groovy\n\u2502   \u251c\u2500\u2500 pythonPipeline.groovy\n\u2502   \u251c\u2500\u2500 dockerBuild.groovy\n\u2502   \u251c\u2500\u2500 securityScan.groovy\n\u2502   \u2514\u2500\u2500 deployToArgoCD.groovy\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 com/\n\u2502       \u2514\u2500\u2500 fawkes/\n\u2502           \u251c\u2500\u2500 Build.groovy\n\u2502           \u251c\u2500\u2500 Test.groovy\n\u2502           \u251c\u2500\u2500 Security.groovy\n\u2502           \u2514\u2500\u2500 Deploy.groovy\n\u2514\u2500\u2500 resources/\n    \u2514\u2500\u2500 pod-templates/\n        \u251c\u2500\u2500 maven.yaml\n        \u251c\u2500\u2500 node.yaml\n        \u2514\u2500\u2500 python.yaml\n</code></pre>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#golden-path-jenkinsfile-examples","title":"Golden Path Jenkinsfile Examples","text":"<p>Java Spring Boot:</p> <pre><code>@Library('fawkes-pipeline-library') _\n\nmavenPipeline {\n    sonarQubeProject = 'my-service'\n    dockerImage = 'my-service'\n    argocdApp = 'my-service-dev'\n    notifyChannel = 'team-builds'\n}\n</code></pre> <p>Python FastAPI:</p> <pre><code>@Library('fawkes-pipeline-library') _\n\npythonPipeline {\n    pythonVersion = '3.11'\n    testCommand = 'pytest --cov=src tests/'\n    dockerImage = 'my-python-service'\n    argocdApp = 'my-python-service-dev'\n}\n</code></pre> <p>Node.js Express:</p> <pre><code>@Library('fawkes-pipeline-library') _\n\nnodePipeline {\n    nodeVersion = '18'\n    buildCommand = 'npm run build'\n    testCommand = 'npm test'\n    dockerImage = 'my-node-service'\n    argocdApp = 'my-node-service-dev'\n}\n</code></pre>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#complete-pipeline-example-without-library","title":"Complete Pipeline Example (Without Library)","text":"<pre><code>pipeline {\n    agent {\n        kubernetes {\n            yaml \"\"\"\napiVersion: v1\nkind: Pod\nspec:\n  containers:\n  - name: maven\n    image: maven:3.8-openjdk-17\n    command: ['cat']\n    tty: true\n  - name: docker\n    image: docker:latest\n    command: ['cat']\n    tty: true\n    volumeMounts:\n    - name: docker-sock\n      mountPath: /var/run/docker.sock\n  - name: trivy\n    image: aquasec/trivy:latest\n    command: ['cat']\n    tty: true\n  volumes:\n  - name: docker-sock\n    hostPath:\n      path: /var/run/docker.sock\n\"\"\"\n        }\n    }\n\n    environment {\n        DOCKER_REGISTRY = 'harbor.fawkes.io'\n        IMAGE_NAME = \"${DOCKER_REGISTRY}/myapp/myservice\"\n        IMAGE_TAG = \"${env.GIT_COMMIT.take(7)}\"\n    }\n\n    stages {\n        stage('Checkout') {\n            steps {\n                checkout scm\n            }\n        }\n\n        stage('Build') {\n            steps {\n                container('maven') {\n                    sh 'mvn clean package -DskipTests'\n                }\n            }\n        }\n\n        stage('Test') {\n            steps {\n                container('maven') {\n                    sh 'mvn test'\n                }\n            }\n            post {\n                always {\n                    junit 'target/surefire-reports/*.xml'\n                }\n            }\n        }\n\n        stage('SonarQube Analysis') {\n            steps {\n                container('maven') {\n                    withSonarQubeEnv('SonarQube') {\n                        sh 'mvn sonar:sonar'\n                    }\n                }\n            }\n        }\n\n        stage('Quality Gate') {\n            steps {\n                timeout(time: 5, unit: 'MINUTES') {\n                    waitForQualityGate abortPipeline: true\n                }\n            }\n        }\n\n        stage('Build Docker Image') {\n            steps {\n                container('docker') {\n                    sh \"\"\"\n                        docker build -t ${IMAGE_NAME}:${IMAGE_TAG} .\n                        docker tag ${IMAGE_NAME}:${IMAGE_TAG} ${IMAGE_NAME}:latest\n                    \"\"\"\n                }\n            }\n        }\n\n        stage('Security Scan') {\n            steps {\n                container('trivy') {\n                    sh \"\"\"\n                        trivy image --severity HIGH,CRITICAL --exit-code 1 ${IMAGE_NAME}:${IMAGE_TAG}\n                    \"\"\"\n                }\n            }\n        }\n\n        stage('Push Image') {\n            steps {\n                container('docker') {\n                    withCredentials([usernamePassword(credentialsId: 'harbor-credentials',\n                                                     usernameVariable: 'USER',\n                                                     passwordVariable: 'PASS')]) {\n                        sh \"\"\"\n                            echo \\$PASS | docker login ${DOCKER_REGISTRY} -u \\$USER --password-stdin\n                            docker push ${IMAGE_NAME}:${IMAGE_TAG}\n                            docker push ${IMAGE_NAME}:latest\n                        \"\"\"\n                    }\n                }\n            }\n        }\n\n        stage('Update GitOps') {\n            steps {\n                script {\n                    // Update image tag in GitOps repository\n                    sh \"\"\"\n                        git clone https://github.com/paruff/fawkes-gitops.git\n                        cd fawkes-gitops\n                        sed -i 's|image: .*|image: ${IMAGE_NAME}:${IMAGE_TAG}|' apps/dev/myservice/deployment.yaml\n                        git add apps/dev/myservice/deployment.yaml\n                        git commit -m \"Update myservice to ${IMAGE_TAG}\"\n                        git push\n                    \"\"\"\n                }\n            }\n        }\n\n        stage('Notify DORA Service') {\n            steps {\n                script {\n                    sh \"\"\"\n                        curl -X POST https://dora-metrics.fawkes.io/webhook/build \\\\\n                          -H 'Content-Type: application/json' \\\\\n                          -d '{\n                            \"service\": \"myservice\",\n                            \"commit\": \"${env.GIT_COMMIT}\",\n                            \"buildNumber\": \"${env.BUILD_NUMBER}\",\n                            \"status\": \"SUCCESS\",\n                            \"duration\": \"${currentBuild.duration}\",\n                            \"timestamp\": \"${new Date().format('yyyy-MM-dd HH:mm:ss')}\"\n                          }'\n                    \"\"\"\n                }\n            }\n        }\n    }\n\n    post {\n        success {\n            mattermostSend(\n                channel: 'team-builds',\n                color: 'good',\n                message: \"\u2705 Build #${env.BUILD_NUMBER} succeeded for ${env.JOB_NAME}\\nCommit: ${env.GIT_COMMIT.take(7)}\\nDuration: ${currentBuild.durationString}\"\n            )\n        }\n        failure {\n            mattermostSend(\n                channel: 'team-builds',\n                color: 'danger',\n                message: \"\u274c Build #${env.BUILD_NUMBER} failed for ${env.JOB_NAME}\\nCommit: ${env.GIT_COMMIT.take(7)}\"\n            )\n        }\n    }\n}\n</code></pre>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#plugin-list-essential","title":"Plugin List (Essential)","text":"<p>Core Plugins: - Kubernetes Plugin (dynamic agents) - Pipeline Plugin (Jenkinsfile support) - Git Plugin (Git integration) - GitHub Plugin (GitHub webhooks) - Credentials Plugin (secret management) - Configuration as Code Plugin (JCasC)</p> <p>Quality &amp; Security: - SonarQube Scanner Plugin - Warnings Next Generation Plugin - JUnit Plugin - Code Coverage Plugin</p> <p>Build Tools: - Maven Integration Plugin - NodeJS Plugin - Python Plugin - Docker Plugin</p> <p>Deployment: - Kubernetes CLI Plugin - HTTP Request Plugin (ArgoCD API)</p> <p>Notifications: - Mattermost Plugin - Email Extension Plugin</p> <p>UI: - Blue Ocean Plugin (modern UI) - Dashboard View Plugin</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<p>Prometheus Metrics (via Jenkins Prometheus plugin): - jenkins_builds_total - jenkins_builds_duration_seconds - jenkins_queue_size - jenkins_node_online_total - jenkins_job_success_rate</p> <p>Grafana Dashboard: - Build success/failure rates - Build duration trends (P50, P95, P99) - Queue size over time - Agent utilization - Plugin health</p> <p>Alerts: - Build queue &gt;10 for &gt;15 minutes - Build failure rate &gt;20% (rolling 24h) - Jenkins controller down &gt;5 minutes - Disk space &lt;20%</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#backup-disaster-recovery","title":"Backup &amp; Disaster Recovery","text":"<p>Backup Strategy: - Jenkins configuration in Git (JCasC) - Persistent volume snapshots (daily) - Plugin list documented - Job configurations in Git (Jenkinsfile per repo)</p> <p>Recovery: 1. Redeploy Jenkins from Helm + JCasC 2. Restore persistent volume from snapshot (job history) 3. Plugins auto-installed via JCasC 4. Jobs auto-discovered from GitHub organizations</p> <p>RTO: &lt;4 hours RPO: &lt;24 hours</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#performance-optimization","title":"Performance Optimization","text":"<p>Build Caching: - Maven local repository cache (PV) - npm cache (PV) - Docker layer caching - Workspace caching for reuse</p> <p>Agent Optimization: - Right-size agent resources - Use pod templates with pre-pulled images - Implement build timeouts - Limit concurrent builds per agent</p> <p>Controller Optimization: - Increase heap size for large installations - Use separate build agents (don't build on controller) - Regular cleanup of old builds - Archive artifacts externally (S3/MinIO)</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#monitoring-this-decision","title":"Monitoring This Decision","text":"<p>We will revisit this ADR if: - Jenkins development significantly slows or stops - A cloud-native alternative (Tekton, Dagger) becomes significantly more mature - Operational burden (updates, plugins) exceeds benefits - GitHub Actions or GitLab CI costs become competitive with self-hosted - Team strongly prefers different CI tool - Security concerns cannot be adequately addressed</p> <p>Next Review Date: April 8, 2026 (6 months)</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#references","title":"References","text":"<ul> <li>Jenkins Official Documentation</li> <li>Jenkins Kubernetes Plugin</li> <li>Configuration as Code Plugin</li> <li>Jenkins Pipeline Documentation</li> <li>Shared Libraries Documentation</li> <li>Jenkins Helm Chart</li> </ul>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#notes","title":"Notes","text":""},{"location":"adr/ADR-004%20jenkins%204%20ci/#why-not-github-actions","title":"Why Not GitHub Actions?","text":"<p>Most common question: \"Why not just use GitHub Actions?\"</p> <p>GitHub Actions excellent for: - GitHub-hosted open source projects - Simple CI workflows - GitHub-centric organizations</p> <p>Jenkins better for Fawkes because: - Vendor neutral: Works with any Git provider - Self-hosted first: True control, no SaaS lock-in - More flexible: Less opinionated, more customizable - Shared libraries: Better code reuse across pipelines - Enterprise features: RBAC, audit logging more mature - Cost at scale: Free except infrastructure vs. GitHub's per-minute pricing</p> <p>Can use both: GitHub Actions for Fawkes repo itself, Jenkins for platform users.</p>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#jenkins-security-best-practices","title":"Jenkins Security Best Practices","text":"<ol> <li>Keep Updated: Subscribe to security advisories, apply patches promptly</li> <li>Minimize Plugins: Only install necessary plugins</li> <li>Use RBAC: Least privilege access model</li> <li>Secrets Management: Use Credentials Plugin, not hardcoded secrets</li> <li>Network Segmentation: Restrict Jenkins network access</li> <li>Audit Logging: Enable and monitor audit logs</li> <li>CSRF Protection: Enable CSRF tokens</li> <li>Content Security Policy: Configure CSP headers</li> </ol>"},{"location":"adr/ADR-004%20jenkins%204%20ci/#kubernetes-plugin-configuration-tips","title":"Kubernetes Plugin Configuration Tips","text":"<ol> <li>Resource Limits: Always set limits and requests</li> <li>Service Account: Use dedicated service account with minimal permissions</li> <li>Network Policies: Restrict agent network access</li> <li>Image Pull Policy: Use IfNotPresent to reduce registry load</li> <li>Pod Templates: Create library of reusable templates</li> <li>Timeouts: Set appropriate pod and container timeouts</li> <li>Cleanup: Configure automatic pod deletion after build</li> </ol> <p>Decision Made By: Platform Architecture Team Approved By: Project Lead Date: October 8, 2025 Author: [Platform Architect Name] Last Updated: October 8, 2025</p>"},{"location":"adr/ADR-005%20terraform/","title":"ADR-005: Terraform for Infrastructure as Code","text":""},{"location":"adr/ADR-005%20terraform/#status","title":"Status","text":"<p>Accepted - October 8, 2025</p>"},{"location":"adr/ADR-005%20terraform/#context","title":"Context","text":"<p>Fawkes requires an Infrastructure as Code (IaC) tool to provision and manage cloud infrastructure declaratively. IaC is fundamental to platform engineering, enabling repeatable, version-controlled, auditable infrastructure management across multiple clouds.</p>"},{"location":"adr/ADR-005%20terraform/#the-need-for-infrastructure-as-code","title":"The Need for Infrastructure as Code","text":"<p>Current Challenges Without IaC: - Manual Provisioning: Error-prone, time-consuming, not documented - Configuration Drift: Infrastructure diverges from documented state - No Version Control: Can't track infrastructure changes over time - No Code Review: Infrastructure changes not peer-reviewed - Environment Inconsistencies: Dev, staging, prod configured differently - Disaster Recovery: Rebuilding infrastructure from scratch is slow/impossible - No Self-Service: Developers can't provision infrastructure without tickets - Tribal Knowledge: Infrastructure setup exists only in operators' heads</p> <p>What Infrastructure as Code Provides: 1. Declarative Configuration: Describe desired state, tool handles how to achieve it 2. Version Control: All infrastructure changes tracked in Git 3. Code Review: Infrastructure changes go through PR process 4. Repeatability: Provision identical infrastructure multiple times 5. Environment Parity: Dev/staging/prod from same code with different variables 6. Disaster Recovery: Rebuild entire infrastructure from code 7. Documentation: Code is documentation (always up-to-date) 8. Automation: Integrate with CI/CD for automated infrastructure changes</p>"},{"location":"adr/ADR-005%20terraform/#requirements-for-iac-tool","title":"Requirements for IaC Tool","text":"<p>Core Requirements: - Multi-Cloud: Support AWS, Azure, GCP with consistent workflow - Declarative: Describe desired state, not procedural steps - State Management: Track current infrastructure state - Plan/Preview: Show changes before applying - Modular: Reusable modules for common patterns - Mature Ecosystem: Providers for 100+ services - Large Community: Extensive documentation, examples, support - Open Source: Transparent, no vendor lock-in</p> <p>DORA Alignment: - Infrastructure Changes: Version-controlled, reviewable infrastructure - Deployment Frequency: Automated infrastructure enables faster deployments - Lead Time: Infrastructure provisioning no longer bottleneck - Change Failure Rate: Preview changes before applying reduces errors</p> <p>Integration Requirements: - GitHub: Store modules and configurations - Jenkins: Automate terraform apply in pipelines - Kubernetes: Provision clusters, configure resources - Cloud Providers: AWS, Azure, GCP - Backstage: Show infrastructure status (future)</p>"},{"location":"adr/ADR-005%20terraform/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Need multi-cloud support for flexibility - State management critical for tracking resources - Preview capability reduces risk of changes - Modular approach enables code reuse</p> <p>Operational Forces: - Platform team can't manually provision everything - Need disaster recovery capabilities - Environment parity critical for testing - Self-service infrastructure reduces tickets</p> <p>Developer Experience Forces: - Developers want infrastructure on-demand - Need clear documentation of infrastructure - Want confidence changes won't break production - Prefer familiar tools and workflows</p> <p>Ecosystem Forces: - Terraform has dominant market share - Extensive provider ecosystem - Large community and knowledge base - Enterprise adoption provides credibility</p>"},{"location":"adr/ADR-005%20terraform/#decision","title":"Decision","text":"<p>We will use Terraform as the primary Infrastructure as Code tool for Fawkes.</p> <p>Specifically: - Terraform OSS (Open Source, latest stable version) - HCL (HashiCorp Configuration Language) - Terraform Cloud for state management (free tier, 5 users) - Modular approach with reusable modules - Multi-environment support (dev, staging, prod) - Version pinning for providers and modules - Automated testing with Terratest (critical modules) - Crossplane for Kubernetes-native IaC (roadmap, Phase 2)</p>"},{"location":"adr/ADR-005%20terraform/#rationale","title":"Rationale","text":"<ol> <li> <p>Industry Standard: Terraform is the most widely adopted IaC tool, with 40,000+ GitHub stars, used by 70%+ of organizations doing multi-cloud</p> </li> <li> <p>True Multi-Cloud: Consistent workflow across clouds:</p> </li> <li>Same HCL syntax for AWS, Azure, GCP</li> <li>Unified state management</li> <li>Single tool to learn</li> <li> <p>Providers for 3,000+ services</p> </li> <li> <p>Mature and Battle-Tested:</p> </li> <li>10+ years of development</li> <li>Production-proven at enterprise scale</li> <li>Extensive real-world validation</li> <li> <p>Known edge cases well-documented</p> </li> <li> <p>Declarative Language: HCL describes desired state:</p> </li> <li>Easy to read and understand</li> <li>Predictable behavior</li> <li>Idempotent operations</li> <li> <p>Less error-prone than imperative scripts</p> </li> <li> <p>State Management:</p> </li> <li>Tracks actual infrastructure state</li> <li>Enables drift detection</li> <li>Supports team collaboration</li> <li> <p>Remote state backends (S3, Terraform Cloud)</p> </li> <li> <p>Plan Before Apply:</p> </li> <li>Preview changes before executing</li> <li>Reduces fear of infrastructure changes</li> <li>Catch mistakes before they happen</li> <li> <p>Show changes in PR reviews</p> </li> <li> <p>Massive Provider Ecosystem:</p> </li> <li>AWS: 1,000+ resources</li> <li>Azure: 1,500+ resources</li> <li>GCP: 800+ resources</li> <li>Kubernetes: Full support</li> <li> <p>3,000+ total providers</p> </li> <li> <p>Module Registry:</p> </li> <li>Public registry with 10,000+ modules</li> <li>Reusable, community-validated code</li> <li>Can publish private modules</li> <li> <p>Accelerates development</p> </li> <li> <p>Large Community:</p> </li> <li>Extensive documentation</li> <li>Thousands of tutorials and examples</li> <li>Active forums and Slack channels</li> <li> <p>Commercial support available (HashiCorp)</p> </li> <li> <p>Testing Support:</p> <ul> <li>Terratest for integration testing</li> <li>terraform validate for syntax</li> <li>terraform fmt for formatting</li> <li>tflint for best practices</li> </ul> </li> <li> <p>CI/CD Integration:</p> <ul> <li>Easy to integrate with Jenkins</li> <li>Automated plan on PR</li> <li>Automated apply on merge</li> <li>GitOps workflow support</li> </ul> </li> <li> <p>Crossplane Path:</p> <ul> <li>Can transition to Crossplane later</li> <li>Terraform modules can inform Crossplane compositions</li> <li>Provides foundation for Kubernetes-native IaC</li> </ul> </li> </ol>"},{"location":"adr/ADR-005%20terraform/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-005%20terraform/#positive","title":"Positive","text":"<p>\u2705 Multi-Cloud Freedom: Same tool and workflow across AWS, Azure, GCP</p> <p>\u2705 Version Controlled Infrastructure: All changes in Git with full audit trail</p> <p>\u2705 Repeatable Provisioning: Spin up identical environments reliably</p> <p>\u2705 Environment Parity: Dev, staging, prod consistent, reducing bugs</p> <p>\u2705 Disaster Recovery: Rebuild entire infrastructure from code in hours</p> <p>\u2705 Code Review: Infrastructure changes peer-reviewed before applying</p> <p>\u2705 Preview Changes: See exactly what will change before applying</p> <p>\u2705 Modular Code: Reusable modules reduce duplication and errors</p> <p>\u2705 State Awareness: Terraform knows current state, only changes what's needed</p> <p>\u2705 Extensive Ecosystem: 3,000+ providers cover virtually any service</p> <p>\u2705 Developer Self-Service: Developers can provision infrastructure via modules</p> <p>\u2705 Documentation as Code: Infrastructure configuration is documentation</p> <p>\u2705 Large Community: Easy to find help, examples, and best practices</p>"},{"location":"adr/ADR-005%20terraform/#negative","title":"Negative","text":"<p>\u26a0\ufe0f State Management Complexity: State files require careful handling and locking</p> <p>\u26a0\ufe0f Learning Curve: HCL syntax and concepts require learning</p> <p>\u26a0\ufe0f State Drift: Manual changes create drift between code and reality</p> <p>\u26a0\ufe0f Refresh Delays: terraform plan can be slow for large infrastructures</p> <p>\u26a0\ufe0f Provider Lag: New cloud features may lag behind AWS/Azure/GCP releases</p> <p>\u26a0\ufe0f Breaking Changes: Major Terraform/provider updates can break code</p> <p>\u26a0\ufe0f Resource Naming: Changing resource names often requires destroy/recreate</p> <p>\u26a0\ufe0f Cost of Mistakes: Accidental terraform destroy can be catastrophic</p> <p>\u26a0\ufe0f Complex Debugging: Error messages sometimes cryptic</p>"},{"location":"adr/ADR-005%20terraform/#neutral","title":"Neutral","text":"<p>\u25fd HCL vs. Other Languages: Declarative DSL (HCL) vs. general-purpose languages (Python, TypeScript)</p> <p>\u25fd Terraform Cloud: Free tier available, paid tiers for advanced features</p> <p>\u25fd HashiCorp Business: Company behind Terraform has commercial interests</p>"},{"location":"adr/ADR-005%20terraform/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li>State Management:</li> <li>Use remote state backend (Terraform Cloud or S3)</li> <li>Enable state locking (DynamoDB for S3)</li> <li>Never manually edit state files</li> <li>Regular state backups</li> <li> <p>Document state management procedures</p> </li> <li> <p>Learning Curve:</p> </li> <li>Provide Terraform training workshops</li> <li>Create comprehensive module documentation</li> <li>Use module examples extensively</li> <li>Start simple, add complexity gradually</li> <li> <p>Leverage community resources</p> </li> <li> <p>State Drift:</p> </li> <li>Educate team: never make manual changes</li> <li>Run terraform plan regularly to detect drift</li> <li>Use cloud provider guard rails (SCPs, policies)</li> <li>Consider drift detection automation</li> <li> <p>Document procedure for importing manual changes</p> </li> <li> <p>Breaking Changes:</p> </li> <li>Pin provider versions in code</li> <li>Test updates in non-production first</li> <li>Follow Terraform upgrade guides carefully</li> <li>Subscribe to provider changelogs</li> <li> <p>Budget time for major upgrades</p> </li> <li> <p>Cost of Mistakes:</p> </li> <li>Protect production with different credentials</li> <li>Use terraform plan before every apply</li> <li>Require PR approval for production changes</li> <li>Enable deletion protection on critical resources</li> <li> <p>Regular backups and disaster recovery testing</p> </li> <li> <p>Resource Naming:</p> </li> <li>Use computed names where possible</li> <li>Document naming conventions</li> <li>Use lifecycle blocks (create_before_destroy)</li> <li>Plan for resource replacement scenarios</li> </ol>"},{"location":"adr/ADR-005%20terraform/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-005%20terraform/#alternative-1-pulumi","title":"Alternative 1: Pulumi","text":"<p>Pros: - Use real programming languages (Python, TypeScript, Go, C#) - Familiar to developers (no new language to learn) - Strong typing and IDE support - Good testing story (use language's test framework) - Modern architecture - Growing quickly</p> <p>Cons: - Smaller Community: Much smaller than Terraform - Fewer Providers: 100+ providers vs. Terraform's 3,000+ - Less Mature: Newer (2018 vs. Terraform 2014) - SaaS State Backend: Free tier limited, paid for self-hosted - Steeper Troubleshooting: Stack traces vs. Terraform's clear errors - Less Enterprise Adoption: Fewer large-scale production examples</p> <p>Reason for Rejection: Pulumi philosophically appealing (real languages), but Terraform's maturity, ecosystem, and community provide more value. Pulumi excellent for organizations with strong programming culture, but Terraform's declarative approach and larger ecosystem better fit for Fawkes' needs. May revisit in 2-3 years as Pulumi matures.</p>"},{"location":"adr/ADR-005%20terraform/#alternative-2-aws-cloudformation","title":"Alternative 2: AWS CloudFormation","text":"<p>Pros: - Native AWS integration - No state management needed - AWS-supported and maintained - Free (no additional cost) - Stack rollback on failure - AWS console integration</p> <p>Cons: - AWS Only: Cannot manage Azure, GCP, or other providers - Verbose YAML/JSON: Much more verbose than Terraform HCL - Limited Features: Fewer advanced features than Terraform - Slow Updates: New AWS features delayed in CloudFormation - Poor Error Messages: Debugging difficult - No Multi-Cloud: Complete rewrite needed for other clouds</p> <p>Reason for Rejection: CloudFormation fine for AWS-only, but Fawkes multi-cloud from start. Vendor lock-in to AWS unacceptable. Terraform provides consistent multi-cloud experience. May use CloudFormation for AWS-specific features but not as primary IaC tool.</p>"},{"location":"adr/ADR-005%20terraform/#alternative-3-azure-resource-manager-arm-templates","title":"Alternative 3: Azure Resource Manager (ARM) Templates","text":"<p>Pros: - Native Azure integration - Free (included with Azure) - Azure portal integration - What-if preview capability</p> <p>Cons: - Azure Only: Cannot manage AWS, GCP - JSON Verbose: Very verbose JSON syntax - Complex Syntax: Difficult to write and maintain - Poor Error Messages: Debugging challenging - Limited Community: Smaller than Terraform</p> <p>Reason for Rejection: Same issues as CloudFormation\u2014Azure lock-in, verbose syntax, single-cloud only. Terraform multi-cloud approach much better.</p>"},{"location":"adr/ADR-005%20terraform/#alternative-4-ansible","title":"Alternative 4: Ansible","text":"<p>Pros: - General-purpose automation (not just infrastructure) - Agentless (SSH-based) - YAML syntax (familiar) - Large community - Can manage configuration in addition to infrastructure</p> <p>Cons: - Imperative, Not Declarative: Procedural scripts vs. desired state - No Built-In State: Doesn't track infrastructure state - Idempotency Issues: Not guaranteed idempotent - Not Designed for IaC: Configuration management tool, not IaC tool - No Plan Preview: Can't preview changes before applying - Slower: SSH-based approach slower than API calls</p> <p>Reason for Rejection: Ansible excellent for configuration management, but not purpose-built for infrastructure provisioning. Terraform's declarative approach and state management much better for IaC. May use Ansible for post-provisioning configuration alongside Terraform.</p>"},{"location":"adr/ADR-005%20terraform/#alternative-5-crossplane","title":"Alternative 5: Crossplane","text":"<p>Pros: - Kubernetes-native (CRDs) - Declarative, Kubernetes-style - GitOps integration native - Composable infrastructure - Cloud-agnostic abstractions - CNCF project (good governance)</p> <p>Cons: - Less Mature: Newer than Terraform (2018) - Smaller Ecosystem: Fewer providers than Terraform - Steeper Learning Curve: Kubernetes CRDs more complex than HCL - Debugging Harder: Kubernetes abstraction makes troubleshooting difficult - Smaller Community: Fewer examples and tutorials - Requires Kubernetes: Can't use without Kubernetes cluster</p> <p>Reason for Rejection: Crossplane philosophically aligned (Kubernetes-native, cloud-agnostic), but less mature and harder to use. Terraform provides better starting point. However, Crossplane is our Phase 2 goal\u2014we'll use Terraform initially, transition to Crossplane as it matures and team gains Kubernetes expertise. Terraform experience will inform Crossplane composition design.</p>"},{"location":"adr/ADR-005%20terraform/#alternative-6-opentofu","title":"Alternative 6: OpenTofu","text":"<p>Pros: - Terraform fork (fully compatible) - Open source (Linux Foundation) - Community-driven - No vendor control concerns - Free forever</p> <p>Cons: - Very New: Fork created August 2023 - Uncertain Future: Will it maintain compatibility? - Smaller Team: Fewer contributors than Terraform - Provider Ecosystem: May diverge from Terraform providers - Less Proven: No significant production usage yet</p> <p>Reason for Rejection: OpenTofu created in response to Terraform license change (BSL). While philosophically appealing (truly open source), too new and unproven. Terraform OSS (pre-license change) still available and sufficient for Fawkes. Will monitor OpenTofu and may switch if it proves mature and sustainable.</p>"},{"location":"adr/ADR-005%20terraform/#alternative-7-terraform-cdk-cloud-development-kit","title":"Alternative 7: Terraform CDK (Cloud Development Kit)","text":"<p>Pros: - Use programming languages (TypeScript, Python, Java, C#, Go) - Generates Terraform JSON - Familiar to developers - HashiCorp-maintained</p> <p>Cons: - Additional Layer: Complexity of language + Terraform - Less Mature: Newer than core Terraform - Smaller Community: Fewer examples than HCL - Debugging Harder: Two layers to debug (code + generated JSON) - Provider Support: Not all providers well-supported</p> <p>Reason for Rejection: Terraform CDK interesting but adds complexity. HCL's declarative nature and large ecosystem of HCL modules provide more value. If we wanted programming languages, would choose Pulumi directly. Terraform CDK feels like compromise without clear benefits.</p>"},{"location":"adr/ADR-005%20terraform/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-001: Kubernetes (Terraform provisions Kubernetes clusters)</li> <li>Future ADR: Crossplane for Kubernetes-Native IaC (Phase 2 migration path)</li> <li>Future ADR: Terraform Module Structure and Standards</li> <li>Future ADR: State Management and Locking Strategy</li> </ul>"},{"location":"adr/ADR-005%20terraform/#implementation-notes","title":"Implementation Notes","text":""},{"location":"adr/ADR-005%20terraform/#repository-structure","title":"Repository Structure","text":"<p>Monorepo Approach (recommended):</p> <pre><code>fawkes-infrastructure/\n\u251c\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 eks-cluster/\n\u2502   \u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u251c\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u251c\u2500\u2500 vpc/\n\u2502   \u251c\u2500\u2500 rds/\n\u2502   \u251c\u2500\u2500 elasticache/\n\u2502   \u2514\u2500\u2500 s3-bucket/\n\u251c\u2500\u2500 environments/\n\u2502   \u251c\u2500\u2500 dev/\n\u2502   \u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u251c\u2500\u2500 terraform.tfvars\n\u2502   \u2502   \u2514\u2500\u2500 backend.tf\n\u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2514\u2500\u2500 prod/\n\u251c\u2500\u2500 global/\n\u2502   \u251c\u2500\u2500 iam/\n\u2502   \u251c\u2500\u2500 route53/\n\u2502   \u2514\u2500\u2500 s3-backend/\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 plan.sh\n\u2502   \u251c\u2500\u2500 apply.sh\n\u2502   \u2514\u2500\u2500 destroy.sh\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u251c\u2500\u2500 terraform-plan.yml\n\u2502       \u2514\u2500\u2500 terraform-apply.yml\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"adr/ADR-005%20terraform/#module-example-eks-cluster","title":"Module Example (EKS Cluster)","text":"<pre><code># modules/eks-cluster/main.tf\n\nterraform {\n  required_version = \"&gt;= 1.6.0\"\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.20\"\n    }\n  }\n}\n\nresource \"aws_eks_cluster\" \"main\" {\n  name     = var.cluster_name\n  role_arn = aws_iam_role.cluster.arn\n  version  = var.kubernetes_version\n\n  vpc_config {\n    subnet_ids              = var.subnet_ids\n    endpoint_private_access = true\n    endpoint_public_access  = true\n    public_access_cidrs     = var.public_access_cidrs\n  }\n\n  encryption_config {\n    provider {\n      key_arn = var.kms_key_arn\n    }\n    resources = [\"secrets\"]\n  }\n\n  enabled_cluster_log_types = [\n    \"api\",\n    \"audit\",\n    \"authenticator\",\n    \"controllerManager\",\n    \"scheduler\"\n  ]\n\n  tags = merge(\n    var.tags,\n    {\n      \"Name\" = var.cluster_name\n      \"ManagedBy\" = \"Terraform\"\n    }\n  )\n}\n\nresource \"aws_eks_node_group\" \"main\" {\n  cluster_name    = aws_eks_cluster.main.name\n  node_group_name = \"${var.cluster_name}-nodegroup\"\n  node_role_arn   = aws_iam_role.node.arn\n  subnet_ids      = var.subnet_ids\n\n  scaling_config {\n    desired_size = var.desired_size\n    max_size     = var.max_size\n    min_size     = var.min_size\n  }\n\n  instance_types = var.instance_types\n\n  labels = {\n    Environment = var.environment\n    ManagedBy   = \"Terraform\"\n  }\n\n  tags = var.tags\n}\n</code></pre>"},{"location":"adr/ADR-005%20terraform/#environment-configuration","title":"Environment Configuration","text":"<pre><code># environments/dev/main.tf\n\nterraform {\n  backend \"s3\" {\n    bucket         = \"fawkes-terraform-state\"\n    key            = \"dev/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-state-lock\"\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = {\n      Environment = \"dev\"\n      Project     = \"fawkes\"\n      ManagedBy   = \"Terraform\"\n    }\n  }\n}\n\nmodule \"vpc\" {\n  source = \"../../modules/vpc\"\n\n  vpc_name            = \"fawkes-dev-vpc\"\n  cidr_block          = \"10.0.0.0/16\"\n  availability_zones  = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n  public_subnets      = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n  private_subnets     = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n\n  enable_nat_gateway = true\n  single_nat_gateway = true  # Cost optimization for dev\n\n  tags = local.tags\n}\n\nmodule \"eks\" {\n  source = \"../../modules/eks-cluster\"\n\n  cluster_name        = \"fawkes-dev\"\n  kubernetes_version  = \"1.28\"\n  subnet_ids          = module.vpc.private_subnet_ids\n\n  desired_size = 3\n  min_size     = 2\n  max_size     = 5\n\n  instance_types = [\"t3.large\"]\n\n  tags = local.tags\n}\n\nlocals {\n  tags = {\n    Environment = \"dev\"\n    Project     = \"fawkes\"\n    ManagedBy   = \"Terraform\"\n  }\n}\n</code></pre>"},{"location":"adr/ADR-005%20terraform/#cicd-integration-github-actions","title":"CI/CD Integration (GitHub Actions)","text":"<pre><code># .github/workflows/terraform-plan.yml\n\nname: Terraform Plan\n\non:\n  pull_request:\n    paths:\n      - 'environments/**'\n      - 'modules/**'\n\njobs:\n  plan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v2\n        with:\n          terraform_version: 1.6.0\n\n      - name: Terraform Init\n        working-directory: environments/dev\n        run: terraform init\n\n      - name: Terraform Format Check\n        run: terraform fmt -check -recursive\n\n      - name: Terraform Validate\n        working-directory: environments/dev\n        run: terraform validate\n\n      - name: Terraform Plan\n        working-directory: environments/dev\n        run: terraform plan -no-color\n        env:\n          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n\n      - name: Comment PR\n        uses: actions/github-script@v6\n        with:\n          script: |\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: 'Terraform plan completed. Review the output above.'\n            })\n</code></pre>"},{"location":"adr/ADR-005%20terraform/#testing-with-terratest","title":"Testing with Terratest","text":"<pre><code>// test/eks_test.go\n\npackage test\n\nimport (\n    \"testing\"\n    \"github.com/gruntwork-io/terratest/modules/terraform\"\n    \"github.com/stretchr/testify/assert\"\n)\n\nfunc TestEKSCluster(t *testing.T) {\n    terraformOptions := &amp;terraform.Options{\n        TerraformDir: \"../modules/eks-cluster\",\n\n        Vars: map[string]interface{}{\n            \"cluster_name\": \"test-cluster\",\n            \"kubernetes_version\": \"1.28\",\n            \"subnet_ids\": []string{\"subnet-123\", \"subnet-456\"},\n        },\n    }\n\n    defer terraform.Destroy(t, terraformOptions)\n\n    terraform.InitAndApply(t, terraformOptions)\n\n    clusterName := terraform.Output(t, terraformOptions, \"cluster_name\")\n    assert.Equal(t, \"test-cluster\", clusterName)\n\n    clusterVersion := terraform.Output(t, terraformOptions, \"kubernetes_version\")\n    assert.Equal(t, \"1.28\", clusterVersion)\n}\n</code></pre>"},{"location":"adr/ADR-005%20terraform/#state-management","title":"State Management","text":"<p>Terraform Cloud (recommended for MVP):</p> <pre><code>terraform {\n  cloud {\n    organization = \"fawkes-platform\"\n\n    workspaces {\n      name = \"fawkes-dev\"\n    }\n  }\n}\n</code></pre> <p>S3 Backend (alternative):</p> <pre><code>terraform {\n  backend \"s3\" {\n    bucket         = \"fawkes-terraform-state\"\n    key            = \"dev/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-state-lock\"\n\n    # Enable versioning for state file history\n    versioning = true\n  }\n}\n</code></pre>"},{"location":"adr/ADR-005%20terraform/#best-practices","title":"Best Practices","text":"<ol> <li>Always Use Remote State: Never store state locally for team projects</li> <li>Enable State Locking: Prevent concurrent modifications</li> <li>Pin Provider Versions: Avoid surprise breaking changes</li> <li>Use Modules: DRY principle, reusability</li> <li>Separate Environments: Different state files for dev/staging/prod</li> <li>Code Review: All changes via PR</li> <li>Plan Before Apply: Always review plan output</li> <li>Tag Everything: Consistent tagging for cost tracking and ownership</li> <li>Use Variables: Never hardcode values</li> <li>Document Modules: README with examples</li> </ol>"},{"location":"adr/ADR-005%20terraform/#migration-to-crossplane-phase-2","title":"Migration to Crossplane (Phase 2)","text":"<p>Path Forward: 1. Phase 1 (Months 1-6): Use Terraform exclusively 2. Phase 2 (Months 7-12): Evaluate Crossplane maturity 3. Phase 3 (Year 2): Gradual migration:    - Start with new resources in Crossplane    - Keep existing resources in Terraform    - Create Crossplane compositions based on Terraform modules    - Migrate non-critical resources first 4. Phase 4 (Year 2-3): Complete migration to Crossplane</p> <p>Why Crossplane Eventually: - Kubernetes-native (consistent with platform) - GitOps integration seamless - Better abstraction for self-service - Cloud-agnostic compositions - Unified control plane</p> <p>Why Terraform First: - Mature and proven today - Larger ecosystem and community - Easier learning curve - Better debugging and documentation - Lower risk for MVP</p>"},{"location":"adr/ADR-005%20terraform/#monitoring-this-decision","title":"Monitoring This Decision","text":"<p>We will revisit this ADR if: - Terraform license changes make OSS version unusable - Crossplane reaches maturity level where migration makes sense - Pulumi ecosystem and community significantly grow - Team expertise shifts toward different tool - OpenTofu becomes mature and clearly sustainable - Multi-cloud requirements change significantly</p> <p>Next Review Date: April 8, 2026 (6 months) Crossplane Evaluation: October 2026 (12 months)</p>"},{"location":"adr/ADR-005%20terraform/#references","title":"References","text":"<ul> <li>Terraform Official Documentation</li> <li>Terraform Registry</li> <li>Terraform Best Practices</li> <li>Terratest Documentation</li> <li>Terraform AWS Provider</li> <li>Crossplane Documentation</li> </ul>"},{"location":"adr/ADR-005%20terraform/#notes","title":"Notes","text":""},{"location":"adr/ADR-005%20terraform/#terraform-vs-pulumi-the-debate","title":"Terraform vs. Pulumi: The Debate","text":"<p>Use Terraform when: - Want largest ecosystem and community - Prefer declarative DSL over programming - Need maximum provider coverage - Want battle-tested maturity</p> <p>Use Pulumi when: - Strong programming culture in organization - Want to use existing language (Python, TypeScript, Go) - Need complex logic in infrastructure code - Prefer general-purpose language testing</p> <p>For Fawkes: Terraform's maturity, ecosystem, and community provide more value. Pulumi excellent choice for many organizations, but Terraform better fits Fawkes' needs as open source platform.</p>"},{"location":"adr/ADR-005%20terraform/#terraform-license-change-context","title":"Terraform License Change Context","text":"<p>In August 2023, HashiCorp changed Terraform license from MPL to BSL (Business Source License). This prevents: - Using Terraform in commercial competing products - Hosting Terraform as paid service</p> <p>For Fawkes: - Not Affected: Using Terraform for our platform is permitted - No Commercial Product: We're not selling Terraform itself - OpenTofu Available: Fork exists if needed</p> <p>This decision may be revisited if BSL becomes more restrictive or OpenTofu proves more sustainable.</p>"},{"location":"adr/ADR-005%20terraform/#state-management-is-critical","title":"State Management is Critical","text":"<p>State file contains: - All provisioned resource IDs - Resource attributes and metadata - Dependencies between resources - Terraform version used</p> <p>If state file is lost: - Terraform can't manage existing resources - Must import all resources manually (tedious) - Or destroy and recreate everything (disruptive)</p> <p>Protection strategies: - Remote state backend (S3, Terraform Cloud) - State file versioning enabled - Regular backups - Never edit state manually - State locking to prevent corruption</p> <p>Decision Made By: Platform Architecture Team Approved By: Project Lead Date: October 8, 2025 Author: [Platform Architect Name] Last Updated: October 8, 2025</p>"},{"location":"adr/ADR-006%20postgres/","title":"ADR-006: PostgreSQL for Data Persistence","text":""},{"location":"adr/ADR-006%20postgres/#status","title":"Status","text":"<p>Accepted - October 8, 2025</p>"},{"location":"adr/ADR-006%20postgres/#context","title":"Context","text":"<p>Fawkes platform components require a relational database for persistent data storage. Multiple components need databases: Backstage (service catalog), Mattermost (messages and boards), Jenkins (build metadata), SonarQube (code analysis), and custom services (DORA metrics, dojo progress). We need to choose a database that's reliable, performant, open source, and well-supported across our technology stack.</p>"},{"location":"adr/ADR-006%20postgres/#database-requirements-across-components","title":"Database Requirements Across Components","text":"<p>Backstage: - Service catalog entities and relationships - User preferences and settings - Plugin data storage - Search indexes - Moderate write load, high read load</p> <p>Mattermost + Focalboard: - Messages, channels, users - Project boards, cards, properties - File metadata - High write and read load - Real-time updates</p> <p>DORA Metrics Service: - Build events, deployment events - Historical metrics data - Team aggregations - Time-series queries - Write-heavy, analytical reads</p> <p>Dojo Progress Tracking: - Learner progress, assessment scores - Lab completion status - Certification records - Moderate write, frequent reads</p> <p>SonarQube: - Code analysis results - Quality metrics history - Security findings - High write during scans, read for dashboards</p> <p>Jenkins (optional, can use file system): - Build metadata and history - Job configurations - Plugin data</p>"},{"location":"adr/ADR-006%20postgres/#requirements-for-database","title":"Requirements for Database","text":"<p>Technical Requirements: - ACID Compliance: Data consistency and reliability - SQL Support: Complex queries, joins, transactions - JSON Support: Flexible schema for plugin data - Full-Text Search: Search across catalog, messages, documentation - High Availability: Replication, failover - Backup/Restore: Point-in-time recovery - Performance: Handle 1000+ concurrent connections - Scalability: Vertical and horizontal scaling options</p> <p>Operational Requirements: - Open Source: Transparent, no licensing costs - Mature: Production-proven, stable - Well-Documented: Extensive documentation and community - Cloud-Native: Works well in Kubernetes - Monitoring: Prometheus metrics, logging integration - Security: Encryption at rest and in transit, RBAC</p> <p>Integration Requirements: - Supported by Backstage, Mattermost, SonarQube, Jenkins - Kubernetes Operator available - Terraform provider for provisioning - Helm charts for deployment - Backup tools mature and reliable</p>"},{"location":"adr/ADR-006%20postgres/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Multiple components need databases - Could use single shared database or separate instances - Need balance between operational simplicity and isolation - Performance critical for developer experience</p> <p>Operational Forces: - Platform team capacity limited - Need reliable backups and disaster recovery - Monitoring and troubleshooting must be straightforward - Upgrades should be low-risk</p> <p>Cost Forces: - Open source preferred (no licensing) - Cloud-managed services convenient but expensive - Self-hosted requires operational overhead - Need cost-effective solution that scales</p> <p>Ecosystem Forces: - PostgreSQL has massive adoption in cloud-native space - Most tools support PostgreSQL natively - Large knowledge base and community - Cloud providers offer managed PostgreSQL</p>"},{"location":"adr/ADR-006%20postgres/#decision","title":"Decision","text":"<p>We will use PostgreSQL as the standard relational database for Fawkes platform components.</p> <p>Specifically: - PostgreSQL 15+ (latest stable version) - CloudNativePG Operator for Kubernetes-native management - Separate databases per component (single cluster, multiple databases) - Automated backups to S3/MinIO with point-in-time recovery - High Availability configuration (primary + replica) - Connection pooling via PgBouncer - Prometheus metrics for monitoring - Cloud-managed option available for production (AWS RDS, Azure Database, Google Cloud SQL)</p>"},{"location":"adr/ADR-006%20postgres/#rationale","title":"Rationale","text":"<ol> <li> <p>Industry Standard: PostgreSQL is the most popular open source relational database, with massive adoption across cloud-native applications and platform tools</p> </li> <li> <p>Universal Compatibility: All Fawkes components support PostgreSQL:</p> </li> <li>Backstage: Officially supported, recommended database</li> <li>Mattermost: Full support, production-ready</li> <li>Focalboard: Built-in support (uses Mattermost database)</li> <li>SonarQube: Officially supported</li> <li>Jenkins: Supported via plugins</li> <li> <p>Custom services: Excellent language support (Go, Python, TypeScript)</p> </li> <li> <p>Advanced Features:</p> </li> <li>JSONB: Flexible schema for plugin data, semi-structured content</li> <li>Full-Text Search: Built-in search without external tools</li> <li>CTEs and Window Functions: Complex analytical queries</li> <li>LISTEN/NOTIFY: Real-time event notifications</li> <li>Foreign Data Wrappers: Access external data sources</li> <li> <p>Extensions: PostGIS, pg_stat_statements, timescaledb</p> </li> <li> <p>ACID Compliance:</p> </li> <li>Strong consistency guarantees</li> <li>Transaction support</li> <li>Data integrity and reliability</li> <li> <p>Critical for catalog, messaging, metrics</p> </li> <li> <p>Performance:</p> </li> <li>Excellent query optimizer</li> <li>Efficient indexing (B-tree, GiST, GIN, BRIN)</li> <li>Parallel queries</li> <li>Materialized views for aggregations</li> <li> <p>Connection pooling support</p> </li> <li> <p>High Availability:</p> </li> <li>Streaming replication (synchronous and asynchronous)</li> <li>Automatic failover</li> <li>Point-in-time recovery</li> <li> <p>WAL archiving for backups</p> </li> <li> <p>Cloud-Native:</p> </li> <li>CloudNativePG operator for Kubernetes</li> <li>Runs well in containers</li> <li>Horizontal scaling via read replicas</li> <li> <p>Kubernetes-native backup solutions</p> </li> <li> <p>Mature and Stable:</p> </li> <li>35+ years of development</li> <li>Production-proven at massive scale</li> <li>Backward compatibility commitment</li> <li> <p>Predictable release cycle</p> </li> <li> <p>Excellent Tooling:</p> </li> <li>pgAdmin (GUI administration)</li> <li>psql (powerful CLI)</li> <li>pg_dump/pg_restore (backup/restore)</li> <li>Prometheus exporters (monitoring)</li> <li> <p>Migration tools (Flyway, Liquibase)</p> </li> <li> <p>Large Community:</p> <ul> <li>Extensive documentation</li> <li>Active mailing lists and forums</li> <li>Thousands of tutorials and examples</li> <li>Commercial support available (EnterpriseDB, Crunchy Data)</li> </ul> </li> <li> <p>Open Source:</p> <ul> <li>PostgreSQL License (permissive, like MIT)</li> <li>Community-driven development</li> <li>No vendor lock-in</li> <li>Free forever</li> </ul> </li> <li> <p>Security:</p> <ul> <li>SSL/TLS encryption</li> <li>Row-level security</li> <li>SCRAM authentication</li> <li>Role-based access control</li> <li>Audit logging</li> </ul> </li> </ol>"},{"location":"adr/ADR-006%20postgres/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-006%20postgres/#positive","title":"Positive","text":"<p>\u2705 Single Database Technology: One database to learn, operate, monitor</p> <p>\u2705 Universal Support: All platform components support PostgreSQL natively</p> <p>\u2705 Advanced Features: JSONB, full-text search, CTEs meet all requirements</p> <p>\u2705 High Availability: Built-in replication and failover</p> <p>\u2705 Performance: Excellent for both transactional and analytical workloads</p> <p>\u2705 Cloud-Native: Kubernetes operator provides native management</p> <p>\u2705 Backup &amp; Recovery: Mature tools, point-in-time recovery</p> <p>\u2705 Monitoring: Prometheus exporters, excellent observability</p> <p>\u2705 Scalability: Read replicas, connection pooling, sharding options</p> <p>\u2705 Large Community: Easy to find help, examples, best practices</p> <p>\u2705 Open Source: No licensing costs, transparent development</p> <p>\u2705 Operational Simplicity: One database system reduces complexity</p>"},{"location":"adr/ADR-006%20postgres/#negative","title":"Negative","text":"<p>\u26a0\ufe0f Write Scalability: Single primary for writes (read replicas for reads only)</p> <p>\u26a0\ufe0f Operational Overhead: Requires backup, monitoring, upgrade management</p> <p>\u26a0\ufe0f Resource Usage: ~200MB RAM minimum per database, can grow large</p> <p>\u26a0\ufe0f Vacuum Maintenance: Requires periodic vacuum for performance</p> <p>\u26a0\ufe0f Index Bloat: Indexes can bloat without maintenance</p> <p>\u26a0\ufe0f Learning Curve: Advanced features require PostgreSQL expertise</p> <p>\u26a0\ufe0f Connection Limits: Default 100 connections, requires pooling at scale</p> <p>\u26a0\ufe0f Replication Lag: Async replication can have slight delays</p>"},{"location":"adr/ADR-006%20postgres/#neutral","title":"Neutral","text":"<p>\u25fd Self-Hosted vs. Managed: Can self-host or use cloud-managed services</p> <p>\u25fd Version Management: Major upgrades require planning and testing</p> <p>\u25fd Storage Growth: Need to monitor and manage storage capacity</p>"},{"location":"adr/ADR-006%20postgres/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li>Write Scalability:</li> <li>Use connection pooling (PgBouncer)</li> <li>Optimize queries and indexes</li> <li>Consider read replicas for reporting</li> <li>Partition large tables if needed</li> <li> <p>Plan for vertical scaling</p> </li> <li> <p>Operational Overhead:</p> </li> <li>Use CloudNativePG operator (automates backups, failover)</li> <li>Implement automated monitoring and alerting</li> <li>Document runbooks for common operations</li> <li>Consider managed services for production (AWS RDS)</li> <li> <p>Regular automated backups</p> </li> <li> <p>Maintenance:</p> </li> <li>Configure autovacuum appropriately</li> <li>Monitor bloat with pg_stat_user_tables</li> <li>Regular ANALYZE for query planning</li> <li>Reindex periodically if needed</li> <li> <p>Schedule maintenance windows</p> </li> <li> <p>Connection Pooling:</p> </li> <li>Deploy PgBouncer for connection pooling</li> <li>Configure appropriate pool sizes</li> <li>Use transaction pooling for most apps</li> <li> <p>Monitor connection usage</p> </li> <li> <p>Monitoring:</p> </li> <li>Deploy postgres_exporter for Prometheus</li> <li>Create Grafana dashboards</li> <li>Alert on key metrics (connections, replication lag, disk usage)</li> <li> <p>Log slow queries for optimization</p> </li> <li> <p>Backup &amp; Recovery:</p> </li> <li>Automated daily backups with retention</li> <li>WAL archiving for point-in-time recovery</li> <li>Regular restore testing</li> <li>Document recovery procedures</li> <li>Backup to S3/MinIO with encryption</li> </ol>"},{"location":"adr/ADR-006%20postgres/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-006%20postgres/#alternative-1-mysqlmariadb","title":"Alternative 1: MySQL/MariaDB","text":"<p>Pros: - Very popular, large community - Good performance for read-heavy workloads - MariaDB fully open source - Wide adoption - Familiar to many developers</p> <p>Cons: - Weaker JSON Support: JSON type less powerful than PostgreSQL JSONB - Limited Full-Text Search: Not as robust as PostgreSQL - Fewer Advanced Features: Less support for CTEs, window functions - Fragmentation: MySQL (Oracle) vs. MariaDB (community) split - Less Cloud-Native: Kubernetes operators less mature</p> <p>Reason for Rejection: PostgreSQL's superior JSON support, full-text search, and advanced SQL features better fit Fawkes needs. Backstage and Mattermost work better with PostgreSQL. MySQL excellent database but PostgreSQL better alignment with cloud-native ecosystem.</p>"},{"location":"adr/ADR-006%20postgres/#alternative-2-mongodb","title":"Alternative 2: MongoDB","text":"<p>Pros: - Document-oriented (flexible schema) - Excellent for JSON data - Horizontal scaling built-in - High write throughput - Popular for modern applications</p> <p>Cons: - NoSQL: Not all components support MongoDB - No ACID Across Collections: Weak consistency by default - Limited Joins: Embedding vs. referencing trade-offs - Operational Complexity: Sharding complex to manage - Backstage Not Supported: Backstage requires SQL database - License Concerns: SSPL license controversial</p> <p>Reason for Rejection: MongoDB excellent for document storage but incompatible with key components (Backstage, SonarQube). ACID properties critical for catalog and metrics. SQL relationships important for service dependencies. PostgreSQL JSONB provides flexible schema when needed while maintaining SQL strengths.</p>"},{"location":"adr/ADR-006%20postgres/#alternative-3-sqlite","title":"Alternative 3: SQLite","text":"<p>Pros: - Zero configuration - No separate server process - Very lightweight - Fast for single-user scenarios - Embedded database</p> <p>Cons: - No Concurrency: Limited concurrent writes - No Network Access: File-based only - No Replication: No built-in HA - Not Kubernetes-Native: File-based doesn't fit pods well - Scalability Limits: Not designed for multi-user systems</p> <p>Reason for Rejection: SQLite excellent for local development and embedded use cases but not suitable for multi-user platform services. Need concurrent access, network access, and high availability. PostgreSQL designed for exactly these scenarios.</p>"},{"location":"adr/ADR-006%20postgres/#alternative-4-cockroachdb","title":"Alternative 4: CockroachDB","text":"<p>Pros: - PostgreSQL-compatible - Distributed SQL (horizontal scaling) - Built-in replication - Multi-region support - Strong consistency - Cloud-native architecture</p> <p>Cons: - Operational Complexity: More complex than PostgreSQL - Resource Intensive: Higher overhead than PostgreSQL - Less Mature: Newer (2015 vs. PostgreSQL 1986) - Smaller Community: Fewer examples and resources - Learning Curve: Distributed systems concepts required - Overkill: More than we need initially</p> <p>Reason for Rejection: CockroachDB philosophically appealing (distributed, PostgreSQL-compatible) but operationally complex and resource-intensive for our scale. PostgreSQL sufficient for foreseeable future. CockroachDB excellent choice at massive scale but unnecessary complexity for Fawkes. May revisit if we need multi-region or massive horizontal scale.</p>"},{"location":"adr/ADR-006%20postgres/#alternative-5-timescaledb","title":"Alternative 5: TimescaleDB","text":"<p>Pros: - PostgreSQL extension (full compatibility) - Optimized for time-series data - Excellent for metrics and logs - Compression and retention policies - Continuous aggregates</p> <p>Cons: - Not Needed for All Data: Only beneficial for time-series - Additional Complexity: Extension to install and manage - License: Some features require license (Cloud only)</p> <p>Reason for Rejection: TimescaleDB excellent for DORA metrics time-series data. However, not needed for Backstage, Mattermost, or other components. Can add TimescaleDB extension to DORA metrics database if needed, but standard PostgreSQL sufficient initially. Good option to consider for Phase 2 optimization.</p>"},{"location":"adr/ADR-006%20postgres/#alternative-6-cloud-managed-services-only-aws-rds-azure-database-cloud-sql","title":"Alternative 6: Cloud-Managed Services Only (AWS RDS, Azure Database, Cloud SQL)","text":"<p>Pros: - Fully managed (no operational overhead) - Automated backups and failover - Easy scaling - Security managed - High availability guaranteed - Support included</p> <p>Cons: - Cost: Much more expensive than self-hosted ($100-500+/month per database) - Vendor Lock-In: Specific to cloud provider - Less Control: Can't customize everything - Not Self-Hosted: Conflicts with open source platform values</p> <p>Reason for Rejection: Managed services convenient but expensive and create vendor lock-in. Self-hosted PostgreSQL with CloudNativePG provides similar benefits at fraction of cost. However, we support managed services as option for production deployments. Fawkes flexible: can use self-hosted for cost-conscious deployments, managed for convenience.</p>"},{"location":"adr/ADR-006%20postgres/#alternative-7-multiple-database-types-polyglot-persistence","title":"Alternative 7: Multiple Database Types (polyglot persistence)","text":"<p>Pros: - Best tool for each job - PostgreSQL for relational, MongoDB for documents, Redis for cache - Optimized for specific use cases</p> <p>Cons: - Operational Complexity: Multiple databases to manage, monitor, backup - Increased Overhead: More expertise required - Cost: More resources needed - Not Necessary: PostgreSQL JSONB handles semi-structured data well</p> <p>Reason for Rejection: Polyglot persistence has merits but increases operational complexity significantly. PostgreSQL versatile enough to handle all current needs (relational + JSON + full-text search). Simpler to have single database technology. May add Redis for caching in Phase 2, but one primary database reduces complexity.</p>"},{"location":"adr/ADR-006%20postgres/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-002: Backstage (uses PostgreSQL for catalog)</li> <li>ADR-007: Mattermost (uses PostgreSQL for messages and boards)</li> <li>Future ADR: Backup and Disaster Recovery Strategy</li> <li>Future ADR: Database Performance Optimization</li> </ul>"},{"location":"adr/ADR-006%20postgres/#implementation-notes","title":"Implementation Notes","text":""},{"location":"adr/ADR-006%20postgres/#deployment-architecture","title":"Deployment Architecture","text":"<p>Kubernetes Deployment with CloudNativePG:</p> <pre><code># PostgreSQL Cluster with HA\napiVersion: postgresql.cnpg.io/v1\nkind: Cluster\nmetadata:\n  name: fawkes-postgres\n  namespace: fawkes-data\nspec:\n  instances: 3  # 1 primary + 2 replicas\n\n  postgresql:\n    parameters:\n      max_connections: \"200\"\n      shared_buffers: \"256MB\"\n      effective_cache_size: \"1GB\"\n      work_mem: \"16MB\"\n      maintenance_work_mem: \"128MB\"\n\n  bootstrap:\n    initdb:\n      database: backstage\n      owner: backstage\n\n  storage:\n    size: 50Gi\n    storageClass: gp3\n\n  backup:\n    barmanObjectStore:\n      destinationPath: s3://fawkes-postgres-backups/\n      s3Credentials:\n        accessKeyId:\n          name: backup-creds\n          key: ACCESS_KEY_ID\n        secretAccessKey:\n          name: backup-creds\n          key: SECRET_ACCESS_KEY\n      wal:\n        compression: gzip\n      retentionPolicy: \"30d\"\n\n  monitoring:\n    enablePodMonitor: true\n\n  resources:\n    requests:\n      memory: \"1Gi\"\n      cpu: \"500m\"\n    limits:\n      memory: \"2Gi\"\n      cpu: \"2\"\n</code></pre>"},{"location":"adr/ADR-006%20postgres/#database-organization","title":"Database Organization","text":"<p>Strategy: Single PostgreSQL cluster, multiple databases</p> <pre><code>fawkes-postgres cluster\n\u251c\u2500\u2500 backstage_db (Backstage catalog)\n\u251c\u2500\u2500 mattermost_db (Mattermost + Focalboard)\n\u251c\u2500\u2500 sonarqube_db (SonarQube analysis)\n\u251c\u2500\u2500 dora_metrics_db (DORA metrics service)\n\u251c\u2500\u2500 dojo_progress_db (Learner progress)\n\u2514\u2500\u2500 jenkins_db (optional, Jenkins metadata)\n</code></pre> <p>Rationale: - Logical isolation between components - Easier to backup/restore individual databases - Resource sharing (connection pooling benefits) - Single cluster to manage (operational simplicity)</p>"},{"location":"adr/ADR-006%20postgres/#connection-pooling-with-pgbouncer","title":"Connection Pooling with PgBouncer","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pgbouncer\n  namespace: fawkes-data\nspec:\n  replicas: 2\n  template:\n    spec:\n      containers:\n      - name: pgbouncer\n        image: edoburu/pgbouncer:latest\n        env:\n        - name: DB_HOST\n          value: fawkes-postgres-rw\n        - name: DB_PORT\n          value: \"5432\"\n        - name: POOL_MODE\n          value: transaction\n        - name: MAX_CLIENT_CONN\n          value: \"1000\"\n        - name: DEFAULT_POOL_SIZE\n          value: \"25\"\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"200m\"\n</code></pre>"},{"location":"adr/ADR-006%20postgres/#backup-configuration","title":"Backup Configuration","text":"<p>Automated Backups: - Full backup: Daily at 2 AM UTC - WAL archiving: Continuous - Retention: 30 days - Destination: S3/MinIO bucket - Encryption: At rest (S3 SSE)</p> <p>Backup Verification: <pre><code># Weekly automated restore test\nkubectl cnpg backup fawkes-postgres-$(date +%Y%m%d)\n\n# Restore to test cluster\nkubectl cnpg restore fawkes-postgres-test \\\n  --backup fawkes-postgres-20251008 \\\n  --cluster fawkes-postgres\n</code></pre></p>"},{"location":"adr/ADR-006%20postgres/#monitoring-alerting","title":"Monitoring &amp; Alerting","text":"<p>Prometheus Metrics (via postgres_exporter): - <code>pg_up</code> - Database reachable - <code>pg_stat_database_*</code> - Database statistics - <code>pg_stat_replication_*</code> - Replication lag - <code>pg_locks_*</code> - Lock contention - <code>pg_stat_user_tables_*</code> - Table statistics</p> <p>Key Alerts: <pre><code>groups:\n- name: postgres\n  rules:\n  - alert: PostgreSQLDown\n    expr: pg_up == 0\n    for: 1m\n    annotations:\n      summary: \"PostgreSQL is down\"\n\n  - alert: PostgreSQLReplicationLag\n    expr: pg_replication_lag &gt; 30\n    for: 5m\n    annotations:\n      summary: \"Replication lag {{ $value }}s\"\n\n  - alert: PostgreSQLConnectionsHigh\n    expr: pg_stat_database_numbackends &gt; 180\n    for: 5m\n    annotations:\n      summary: \"High connection count: {{ $value }}\"\n\n  - alert: PostgreSQLDiskUsageHigh\n    expr: pg_database_size_bytes / pg_settings_max_wal_size &gt; 0.8\n    for: 5m\n    annotations:\n      summary: \"Database disk usage high\"\n</code></pre></p> <p>Grafana Dashboard: - Connection count and usage - Query performance (slow queries) - Replication lag - Database size growth - Cache hit ratio - Transaction rate - Lock contention</p>"},{"location":"adr/ADR-006%20postgres/#maintenance-tasks","title":"Maintenance Tasks","text":"<p>Automated (via CronJobs): <pre><code># Daily vacuum analyze\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: postgres-vacuum\nspec:\n  schedule: \"0 3 * * *\"  # 3 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: vacuum\n            image: postgres:15\n            command:\n            - /bin/sh\n            - -c\n            - |\n              psql -h fawkes-postgres-rw -U postgres -c \"VACUUM ANALYZE\"\n</code></pre></p> <p>Manual (quarterly): - Reindex large tables - Analyze table bloat - Review and optimize slow queries - Update statistics manually if needed</p>"},{"location":"adr/ADR-006%20postgres/#security-configuration","title":"Security Configuration","text":"<p>Authentication: <pre><code># PostgreSQL pg_hba.conf\nhost    all             all             10.0.0.0/8            scram-sha-256\nhost    replication     all             10.0.0.0/8            scram-sha-256\nhostssl all             all             0.0.0.0/0             scram-sha-256\n</code></pre></p> <p>Encryption: - TLS/SSL for connections (enforced) - Encryption at rest (storage level) - Backup encryption (S3 SSE)</p> <p>Access Control: <pre><code>-- Create role per application\nCREATE ROLE backstage WITH LOGIN PASSWORD 'secure_password';\nGRANT CONNECT ON DATABASE backstage_db TO backstage;\nGRANT ALL PRIVILEGES ON DATABASE backstage_db TO backstage;\n\n-- Read-only role for monitoring\nCREATE ROLE monitoring WITH LOGIN PASSWORD 'secure_password';\nGRANT CONNECT ON DATABASE backstage_db TO monitoring;\nGRANT SELECT ON ALL TABLES IN SCHEMA public TO monitoring;\n</code></pre></p>"},{"location":"adr/ADR-006%20postgres/#performance-tuning","title":"Performance Tuning","text":"<p>Connection Settings: <pre><code>max_connections = 200\nshared_buffers = 256MB          # 25% of RAM\neffective_cache_size = 1GB      # 50-75% of RAM\nwork_mem = 16MB                 # RAM / max_connections / 2\nmaintenance_work_mem = 128MB    # RAM / 16\n</code></pre></p> <p>Query Optimization: <pre><code># Enable query logging for slow queries\nlog_min_duration_statement = 1000  # Log queries &gt; 1s\nlog_statement = 'all'              # Log all statements (dev only)\n\n# Query planning\nrandom_page_cost = 1.1            # SSD storage\neffective_io_concurrency = 200    # SSD capability\n</code></pre></p> <p>Autovacuum: <pre><code>autovacuum = on\nautovacuum_max_workers = 3\nautovacuum_naptime = 1min\nautovacuum_vacuum_cost_delay = 20ms\n</code></pre></p>"},{"location":"adr/ADR-006%20postgres/#migration-strategy","title":"Migration Strategy","text":"<p>Schema Migrations: - Use Flyway or Liquibase for versioned migrations - Store migrations in Git - Apply migrations in CI/CD pipeline - Never modify schema manually</p> <p>Example Flyway Migration: <pre><code>-- V1__create_users_table.sql\nCREATE TABLE users (\n    id SERIAL PRIMARY KEY,\n    username VARCHAR(255) NOT NULL UNIQUE,\n    email VARCHAR(255) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE INDEX idx_users_email ON users(email);\n</code></pre></p>"},{"location":"adr/ADR-006%20postgres/#disaster-recovery","title":"Disaster Recovery","text":"<p>Recovery Time Objective (RTO): 4 hours Recovery Point Objective (RPO): 1 hour (WAL archiving)</p> <p>Recovery Procedure: 1. Create new PostgreSQL cluster 2. Restore from latest backup 3. Apply WAL files for point-in-time recovery 4. Verify data integrity 5. Update application connection strings 6. Resume operations</p> <p>Automated DR Testing: - Monthly restore test to separate cluster - Verify data integrity checks pass - Document any issues and resolution</p>"},{"location":"adr/ADR-006%20postgres/#managed-service-alternative","title":"Managed Service Alternative","text":"<p>For Production Deployments:</p> <p>AWS RDS PostgreSQL: - Multi-AZ for high availability - Automated backups with point-in-time recovery - Read replicas for scaling - Enhanced monitoring - Estimated cost: $200-400/month (db.t3.large)</p> <p>Azure Database for PostgreSQL: - Flexible Server with HA - Automated backups and patching - Read replicas - Advanced Threat Protection - Estimated cost: $180-350/month (similar specs)</p> <p>Google Cloud SQL for PostgreSQL: - High availability configuration - Automated backups - Read replicas - Cloud SQL Proxy for secure connections - Estimated cost: $190-370/month (similar specs)</p> <p>Decision: Support both self-hosted and managed options. Documentation for both approaches. Recommend self-hosted for dev/staging, managed for production (optional).</p>"},{"location":"adr/ADR-006%20postgres/#monitoring-this-decision","title":"Monitoring This Decision","text":"<p>We will revisit this ADR if: - PostgreSQL performance becomes bottleneck that can't be resolved - Write scalability becomes critical requirement - Operational burden exceeds team capacity - Cloud-managed services become cost-competitive with self-hosted - Alternative database provides significantly better features - Components add requirements PostgreSQL can't meet</p> <p>Next Review Date: April 8, 2026 (6 months)</p>"},{"location":"adr/ADR-006%20postgres/#references","title":"References","text":"<ul> <li>PostgreSQL Official Documentation</li> <li>CloudNativePG Documentation</li> <li>PostgreSQL High Availability</li> <li>PgBouncer Documentation</li> <li>Postgres Exporter</li> <li>PostgreSQL Performance Tuning</li> </ul>"},{"location":"adr/ADR-006%20postgres/#notes","title":"Notes","text":""},{"location":"adr/ADR-006%20postgres/#why-postgresql-over-mysql","title":"Why PostgreSQL Over MySQL?","text":"<p>PostgreSQL advantages: - Better JSON support (JSONB with indexing) - Full-text search built-in - More advanced SQL features (CTEs, window functions) - Better for complex queries - Stronger in cloud-native ecosystem</p> <p>MySQL advantages: - Slightly simpler for basic use cases - Some argue faster for simple reads - More familiar to some developers</p> <p>For Fawkes: PostgreSQL's advanced features (especially JSONB and full-text search) align better with platform needs. Both excellent databases, but PostgreSQL slight edge for our use cases.</p>"},{"location":"adr/ADR-006%20postgres/#single-cluster-vs-multiple-clusters","title":"Single Cluster vs. Multiple Clusters","text":"<p>Single Cluster Approach (chosen): - Operational simplicity (one cluster to manage) - Resource efficiency (shared resources) - Easier monitoring and backup - Lower infrastructure costs</p> <p>Multiple Clusters Approach: - Complete isolation between components - Independent scaling - Failure isolation - Higher operational overhead</p> <p>Decision: Single cluster with multiple databases provides good balance. Can split into multiple clusters later if needed.</p>"},{"location":"adr/ADR-006%20postgres/#when-to-consider-alternative-databases","title":"When to Consider Alternative Databases","text":"<p>Consider MySQL/MariaDB: - Team has strong MySQL expertise - Simple transactional workloads only - No need for advanced PostgreSQL features</p> <p>Consider MongoDB: - Truly schemaless data needed - Horizontal write scaling critical - All components support NoSQL (not our case)</p> <p>Consider CockroachDB: - Multi-region requirements - Massive horizontal scaling needed - Can absorb operational complexity</p> <p>For most teams: PostgreSQL is the pragmatic, proven choice.</p> <p>Decision Made By: Platform Architecture Team Approved By: Project Lead Date: October 8, 2025 Author: [Platform Architect Name] Last Updated: October 8, 2025</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/","title":"ADR-007: Mattermost for Team Collaboration","text":""},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#status","title":"Status","text":"<p>Accepted - October 7, 2025</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#context","title":"Context","text":"<p>Fawkes is evolving from an infrastructure-focused Internal Delivery Platform to a comprehensive Internal Product Delivery Platform. To support product delivery effectively, teams need integrated collaboration capabilities that go beyond code and CI/CD pipelines.</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#the-need-for-integrated-collaboration","title":"The Need for Integrated Collaboration","text":"<p>Current Gap: Teams using Fawkes must use external tools for: - Real-time communication: Slack, Microsoft Teams, Discord - Bot integrations and ChatOps: Limited integration with external tools - Platform notifications: Email or external chat platforms - Community building: Fragmented across multiple platforms - Dojo learning support: No integrated space for learner discussions</p> <p>Requirements for Collaboration Tool: 1. Self-Hosted: Data sovereignty, no vendor lock-in, customizable 2. Open Source: Aligns with Fawkes' values, community-driven 3. Platform Integration: Webhooks, bots, API for CI/CD notifications 4. ChatOps: Trigger platform actions from chat 5. Rich Features: Threads, search, file sharing, video calls 6. Dojo Integration: Dedicated channels for learning, mentorship 7. Project Management Integration: Connect with Focalboard seamlessly 8. Scalable: Support growing communities (100+ users initially, 1000+ future) 9. Mobile Support: Native iOS and Android apps 10. Cost Effective: Free or low-cost at scale</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Need real-time communication for incident response - ChatOps capabilities increasingly expected in platforms - Notification fatigue from email-only communications - Integration complexity with external tools</p> <p>Business Forces: - Data sovereignty and security concerns with SaaS tools - Cost at scale (Slack pricing: $7.25-$12.50/user/month \u00d7 100 users = $725-$1,250/month) - Vendor lock-in risks with proprietary platforms - Open source preference for transparency and control</p> <p>Community Forces: - Community members prefer familiar platforms (Slack, Discord) - Learning curve for new platforms - Network effects (everyone uses Slack already) - Need for inclusive, welcoming community space</p> <p>Organizational Forces: - Platform team wants to avoid platform sprawl - Desire for single integrated platform experience - Need to model self-hosted, open-source values</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#decision","title":"Decision","text":"<p>We will use Mattermost as the integrated team collaboration platform for Fawkes.</p> <p>Specifically: - Self-hosted deployment in Kubernetes alongside other Fawkes components - Mattermost Team Edition (open source) with optional Enterprise upgrade path - Native Focalboard integration for project management - Deep platform integration via webhooks, slash commands, and bots - Backstage integration via iframe or custom plugin</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#rationale","title":"Rationale","text":"<ol> <li> <p>Open Source &amp; Self-Hosted: Mattermost is fully open source (MIT/Apache 2.0), aligns with Fawkes values, and gives complete control over data</p> </li> <li> <p>Feature Completeness: Comparable feature set to Slack (channels, threads, search, reactions, file sharing, video calls)</p> </li> <li> <p>Native Focalboard Integration: Focalboard (Notion-like project management) is built into Mattermost, creating seamless collaboration + project management experience</p> </li> <li> <p>Strong Integration Capabilities:</p> </li> <li>Webhooks (incoming/outgoing)</li> <li>Slash commands for ChatOps</li> <li>REST API for custom integrations</li> <li>Bot framework</li> <li> <p>700+ integrations available</p> </li> <li> <p>Platform Notifications: Natural home for CI/CD notifications, deployment updates, DORA metric alerts, security scan results</p> </li> <li> <p>Dojo Community Support: Dedicated channels for each belt level, peer learning, mentor office hours</p> </li> <li> <p>Cost Effectiveness:</p> </li> <li>Team Edition: Free, unlimited users</li> <li>Enterprise: Optional, $10/user/year (10x cheaper than Slack at scale)</li> <li> <p>Self-hosted: No per-user fees, only infrastructure costs (~$50-100/month)</p> </li> <li> <p>Mobile &amp; Desktop Apps: Native apps for all major platforms (iOS, Android, macOS, Windows, Linux)</p> </li> <li> <p>Slack Compatibility: Can import Slack workspaces, familiar keyboard shortcuts, similar UX reduces learning curve</p> </li> <li> <p>Active Development: Backed by Mattermost Inc., regular releases, large community (30,000+ stars on GitHub)</p> </li> <li> <p>Security &amp; Compliance:</p> <ul> <li>SOC 2 Type II certified</li> <li>GDPR compliant</li> <li>End-to-end encryption available</li> <li>Audit logging</li> <li>Advanced security controls in Enterprise</li> </ul> </li> </ol>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#positive","title":"Positive","text":"<p>\u2705 Complete Platform Integration: Single ecosystem for code, CI/CD, collaboration, project management, and learning</p> <p>\u2705 Data Ownership: Full control over data, no third-party access, can backup/restore as needed</p> <p>\u2705 Cost Predictability: Infrastructure costs only, no per-user fees, scales economically</p> <p>\u2705 Customization: Can modify, extend, and customize to exact needs</p> <p>\u2705 ChatOps Enablement: Build platform automation triggered from chat (deploy, rollback, check metrics)</p> <p>\u2705 Community Building: Dedicated, branded space for Fawkes community</p> <p>\u2705 Learning Integration: Natural home for dojo learner discussions and support</p> <p>\u2705 Project Management: Focalboard built-in creates seamless workflow</p> <p>\u2705 Open Source Alignment: Demonstrates commitment to open source values</p> <p>\u2705 Privacy &amp; Security: No data leaves your infrastructure, audit trail for compliance</p> <p>\u2705 Long-Term Sustainability: Open source ensures platform won't disappear or change terms</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#negative","title":"Negative","text":"<p>\u26a0\ufe0f Operational Overhead: Must deploy, maintain, backup, upgrade (mitigated: Kubernetes-native, automated)</p> <p>\u26a0\ufe0f Learning Curve: Users familiar with Slack/Discord need to learn new platform (mitigated: similar UX)</p> <p>\u26a0\ufe0f Network Effects: Many users already have Slack/Discord accounts (mitigated: Slack import, SSO)</p> <p>\u26a0\ufe0f Mobile App Quality: Mobile apps good but not quite as polished as Slack (improving rapidly)</p> <p>\u26a0\ufe0f Integration Ecosystem: Smaller than Slack's marketplace (mitigated: REST API, webhook support)</p> <p>\u26a0\ufe0f Voice/Video Calls: Built-in but not as robust as Zoom/Teams (mitigated: can integrate with external tools)</p> <p>\u26a0\ufe0f Adoption Challenge: Convincing community to join new platform (mitigated: showcase integration benefits)</p> <p>\u26a0\ufe0f Resource Requirements: Requires ~500MB RAM, 1 CPU core, 5GB storage minimum</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#neutral","title":"Neutral","text":"<p>\u25fd Maturity: Mature product (10+ years) but less ubiquitous than Slack</p> <p>\u25fd Brand Recognition: Less well-known than Slack (opportunity to educate about open source alternatives)</p> <p>\u25fd Enterprise Features: Some features require Enterprise license (can start with Team Edition)</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li>Operational Overhead:</li> <li>Use Mattermost Operator for Kubernetes (automated deployment, upgrades)</li> <li>Include in platform monitoring and backup strategy</li> <li> <p>Document runbooks for common operations</p> </li> <li> <p>Learning Curve:</p> </li> <li>Create onboarding guide with screenshots</li> <li>Highlight Slack-compatible shortcuts</li> <li>Provide comparison guide (Slack vs. Mattermost)</li> <li> <p>Video walkthrough for new users</p> </li> <li> <p>Adoption:</p> </li> <li>Lead by example (maintainers active in Mattermost)</li> <li>Showcase platform integration benefits</li> <li>Make it the official channel for announcements</li> <li> <p>Offer Slack/Discord bridges during transition (bot that mirrors messages)</p> </li> <li> <p>Integration Gaps:</p> </li> <li>Build custom integrations where needed</li> <li>Contribute integrations back to community</li> <li> <p>Document integration patterns</p> </li> <li> <p>Voice/Video:</p> </li> <li>Use Mattermost's built-in calls for quick discussions</li> <li>Integrate with Zoom/Jitsi for larger meetings</li> <li>Document best practices</li> </ol>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#alternative-1-slack-saas","title":"Alternative 1: Slack (SaaS)","text":"<p>Pros: - Most popular enterprise chat platform - Excellent user experience and mobile apps - Huge integration marketplace (2,400+ apps) - Familiar to most users (minimal learning curve) - Best-in-class search and features - Strong voice/video calling</p> <p>Cons: - Cost: $7.25-$12.50/user/month (prohibitively expensive at scale) - Vendor Lock-In: Proprietary platform, terms can change - Data Privacy: All data on Slack's servers, compliance concerns - Message History Limits: Free tier limited to 90 days history - No Self-Hosting: Must use Slack's infrastructure - Misaligned Values: SaaS, proprietary, not open source</p> <p>Reason for Rejection: Cost at scale is prohibitive for open source project. At 500 users (medium-term goal), cost would be $43,500-$75,000/year. Data sovereignty and vendor lock-in concerns conflict with platform values. Slack doesn't integrate with self-hosted Focalboard.</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#alternative-2-discord","title":"Alternative 2: Discord","text":"<p>Pros: - Free for unlimited users - Excellent voice/video quality - Popular with developer communities - Great mobile apps - Rich media support (embeds, reactions, GIFs) - Screen sharing and streaming</p> <p>Cons: - Gaming-Centric UX: Designed for gaming, not professional collaboration - Limited Integrations: Fewer business integrations than Slack/Mattermost - No Self-Hosting: SaaS only, data on Discord servers - Professional Perception: Less professional than Slack/Mattermost - Search Limitations: Search not as powerful as Slack/Mattermost - No Project Management: No Focalboard equivalent - Organization Features: Weaker organization/threading than alternatives</p> <p>Reason for Rejection: While free and popular with developers, Discord's gaming focus, lack of self-hosting, and limited business integrations make it suboptimal for a professional platform engineering community. No project management integration path.</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#alternative-3-rocketchat","title":"Alternative 3: Rocket.Chat","text":"<p>Pros: - Open source and self-hosted - Feature-complete (channels, threads, video calls) - Strong security features - Active community - Free and scalable - Slack-compatible (can import)</p> <p>Cons: - Less Mature: Smaller community than Mattermost - Integration Ecosystem: Fewer integrations available - Performance: Can be slower with large communities - Documentation: Less comprehensive than Mattermost - Mobile Apps: Not as polished - No Project Management: No integrated project management tool - Smaller Development Team: Less resourced than Mattermost</p> <p>Reason for Rejection: While solid open source alternative, Rocket.Chat has smaller ecosystem, less mature integrations, and no project management integration like Focalboard. Mattermost has stronger momentum and backing.</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#alternative-4-microsoft-teams","title":"Alternative 4: Microsoft Teams","text":"<p>Pros: - Deep Microsoft 365 integration - Excellent voice/video (backed by Skype) - Widely used in enterprises - Strong security and compliance - File collaboration (SharePoint integration) - Free tier available</p> <p>Cons: - Microsoft Ecosystem Lock-In: Strongly tied to Microsoft services - Complex Self-Hosting: Teams self-hosting extremely complex - Not Truly Open Source: Proprietary platform - Resource Heavy: High resource requirements - Overly Complex: Feature bloat, steep learning curve - Poor UX for Chat: Optimized for meetings, not async chat - Limited Customization: Restricted API, hard to integrate deeply</p> <p>Reason for Rejection: Teams is designed for Microsoft ecosystem and prioritizes video meetings over chat. Self-hosting is impractical, not open source, and doesn't align with platform values. Poor fit for developer community.</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#alternative-5-matrixelement","title":"Alternative 5: Matrix/Element","text":"<p>Pros: - Fully open source and decentralized - Strong encryption and privacy - Federation support (connect multiple servers) - Active development - Growing community - Modern protocol (Matrix)</p> <p>Cons: - Immature Features: Missing some expected features (threads, polls) - Complex Setup: Federation and encryption add complexity - Performance: Can be slow with large communities - Mobile Apps: Still improving - Integration Ecosystem: Limited compared to Mattermost - No Project Management: No Focalboard equivalent - Learning Curve: Decentralization concepts unfamiliar to most users</p> <p>Reason for Rejection: While philosophically aligned (decentralized, encrypted), Matrix/Element is still maturing and has a steeper learning curve. Mattermost provides better immediate user experience while remaining open source and self-hosted.</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#alternative-6-zulip","title":"Alternative 6: Zulip","text":"<p>Pros: - Open source and self-hosted - Unique threading model (topic-based) - Excellent for asynchronous communication - Strong search capabilities - Free and scalable - Good integrations</p> <p>Cons: - Unusual UX: Topic-based threading very different from Slack - Smaller Community: Less widely known/adopted - Learning Curve: Unique model requires mindset shift - Integration Ecosystem: Smaller than Mattermost - No Project Management: No integrated project management - Mobile Apps: Good but less mature than alternatives</p> <p>Reason for Rejection: Zulip's topic-based threading, while powerful for some use cases, is a significant departure from familiar chat UX. Would increase friction for community adoption. No project management integration.</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-008: Focalboard for Project Management (direct integration with Mattermost)</li> <li>ADR-002: Backstage for Developer Portal (Mattermost integration via iframe/plugin)</li> <li>Future ADR: SSO/OIDC strategy (Mattermost will be SSO-enabled)</li> </ul>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#implementation-notes","title":"Implementation Notes","text":""},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#deployment-architecture","title":"Deployment Architecture","text":"<pre><code># Mattermost deployment in Kubernetes\nmattermost:\n  namespace: fawkes-collaboration\n  resources:\n    - mattermost-app (4 replicas for HA)\n    - postgresql (database)\n    - minio (file storage, optional - can use S3)\n    - nginx-ingress (TLS termination)\n\n  integrations:\n    - backstage (iframe embed or plugin)\n    - jenkins (webhook notifications)\n    - argocd (deployment notifications)\n    - grafana (alert notifications)\n    - github (PR/issue notifications)\n    - focalboard (built-in integration)\n</code></pre>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#initial-channel-structure","title":"Initial Channel Structure","text":"<p>System Channels: - \ud83d\udce2 <code>announcements</code> - Official announcements (maintainers only post) - \ud83d\udcac <code>general</code> - General discussion - \ud83c\udd98 <code>help-and-support</code> - Q&amp;A and troubleshooting - \ud83d\udc65 <code>introductions</code> - New member introductions</p> <p>Platform Component Channels: - <code>backstage</code> - <code>jenkins-cicd</code> - <code>argocd-gitops</code> - <code>observability</code> - <code>security</code> - <code>infrastructure</code></p> <p>Dojo Learning Channels: - \ud83c\udf93 <code>dojo-general</code> - Learning discussions - \ud83e\udd4b <code>dojo-white-belt</code> - \ud83d\udfe1 <code>dojo-yellow-belt</code> - \ud83d\udfe2 <code>dojo-green-belt</code> - \ud83d\udfe4 <code>dojo-brown-belt</code> - \u26ab <code>dojo-black-belt</code> - \ud83c\udfc6 <code>dojo-achievements</code> - Celebrate completions</p> <p>Contributor Channels: - \ud83d\udc68\u200d\ud83d\udcbb <code>contributors</code> - General contributor discussion - \ud83d\udc1b <code>good-first-issues</code> - Synced from GitHub - \ud83d\udcdd <code>documentation</code> - \ud83d\udd12 <code>security-private</code> (private channel)</p> <p>Cloud Provider Channels: - \u2601\ufe0f <code>aws</code> - \u2601\ufe0f <code>azure</code> - \u2601\ufe0f <code>gcp</code> - \u2601\ufe0f <code>multi-cloud</code></p> <p>Community Channels: - \ud83c\udf89 <code>random</code> - Off-topic, fun - \ud83c\udf8a <code>wins</code> - Celebrate successes - \ud83d\udcda <code>resources</code> - Share articles, talks, etc.</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#platform-integration-examples","title":"Platform Integration Examples","text":"<p>1. CI/CD Notifications: <pre><code>// Jenkins pipeline sends to Mattermost\nPOST https://mattermost.fawkes.io/hooks/jenkins\n{\n  \"channel\": \"jenkins-cicd\",\n  \"username\": \"Jenkins Bot\",\n  \"text\": \"\u2705 Build #42 succeeded for `sample-app`\\n\" +\n          \"Deployment time: 2m 15s\\n\" +\n          \"DORA Lead Time: 8m 42s\"\n}\n</code></pre></p> <p>2. ChatOps - Deploy from Chat: <pre><code>User: /deploy sample-app to production\nBot: \ud83d\ude80 Deploying sample-app to production...\n     Using image: registry.fawkes.io/sample-app:v1.2.3\n     Triggering ArgoCD sync...\n     \u2705 Deployment successful! (2m 18s)\n     \ud83d\udcca DORA Metrics updated\n</code></pre></p> <p>3. DORA Metric Alerts: <pre><code>DORA Bot: \u26a0\ufe0f Change Failure Rate Alert\n          Team: platform-team\n          Current: 18% (threshold: 15%)\n          Last 24h: 3 failed deployments out of 17\n          Action: Review recent changes in #platform-team\n</code></pre></p> <p>4. Dojo Lab Completion: <pre><code>Dojo Bot: \ud83c\udf89 @john completed Lab 3: Deploy with GitOps!\n          Belt: White Belt\n          Score: 48/50 (96%)\n          Time: 18 minutes\n          Say congrats in #dojo-white-belt!\n</code></pre></p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#sso-integration","title":"SSO Integration","text":"<ul> <li>Phase 1 (MVP): Email/password authentication</li> <li>Phase 2 (Month 2): OIDC/SAML SSO with Keycloak</li> <li>Phase 3 (Month 4): GitHub OAuth integration</li> </ul>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#mobile-app-strategy","title":"Mobile App Strategy","text":"<ul> <li>Encourage users to install Mattermost mobile apps</li> <li>Provide download links and setup guide</li> <li>Configure push notifications for critical alerts</li> <li>Test mobile experience regularly</li> </ul>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#migration-from-external-platforms","title":"Migration from External Platforms","text":"<p>For communities using Slack/Discord: 1. Export data from existing platform 2. Import into Mattermost using Slack import tool 3. Run bridge bot for transition period (messages mirrored) 4. Sunset bridge after 30 days</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#resource-requirements","title":"Resource Requirements","text":"<p>Minimum (100 users): - 2 CPU cores - 4GB RAM - 20GB storage - PostgreSQL database</p> <p>Recommended (500 users): - 4 CPU cores - 8GB RAM - 100GB storage - PostgreSQL with replication</p> <p>Enterprise (1000+ users): - 8+ CPU cores - 16GB+ RAM - 500GB+ storage - PostgreSQL cluster - Redis cache - S3/MinIO for file storage</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<ul> <li>Prometheus metrics endpoint enabled</li> <li>Grafana dashboard for Mattermost metrics</li> <li>Alert on:</li> <li>High response time (&gt;2s)</li> <li>Database connection errors</li> <li>Websocket disconnections</li> <li>High memory usage (&gt;80%)</li> <li>Failed login attempts (potential attack)</li> </ul>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#backup-disaster-recovery","title":"Backup &amp; Disaster Recovery","text":"<ul> <li>Database: Daily backups via PostgreSQL dump</li> <li>File Storage: S3 versioning or MinIO backup</li> <li>Configuration: Store in Git (Infrastructure as Code)</li> <li>Recovery Time Objective (RTO): &lt;4 hours</li> <li>Recovery Point Objective (RPO): &lt;24 hours</li> </ul>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#monitoring-this-decision","title":"Monitoring This Decision","text":"<p>We will revisit this ADR if: - Community adoption is below 60% after 6 months - Operational burden is significantly higher than alternatives - Critical features are missing that block workflows - A superior open source alternative emerges - Cost of running Mattermost exceeds $200/month at scale</p> <p>Next Review Date: April 7, 2026 (6 months)</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#references","title":"References","text":"<ul> <li>Mattermost Documentation</li> <li>Mattermost vs Slack Comparison</li> <li>Mattermost Kubernetes Operator</li> <li>Focalboard Integration</li> <li>Mattermost Integrations Directory</li> </ul>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#notes","title":"Notes","text":""},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#why-not-start-with-slackdiscord","title":"Why Not Start with Slack/Discord?","text":"<p>We considered using Slack or Discord initially and migrating later, but: - Migration Pain: Moving established communities is difficult and disruptive - Platform Fragmentation: Running collaboration outside main platform defeats integration purpose - Cost Trap: Once on Slack, hard to justify migration due to sunk costs - Value Demonstration: Integrated Mattermost showcases complete platform vision from day one</p>"},{"location":"adr/ADR-007%20mattermost%204%20collaboration/#open-source-community-expectations","title":"Open Source Community Expectations","text":"<p>The open source community increasingly expects: - Self-hosted communication options (data sovereignty) - No reliance on proprietary platforms - Transparency and control - Alignment with open source values</p> <p>Mattermost aligns with these expectations while providing enterprise-grade features.</p> <p>Decision Made By: Platform Architecture Team Approved By: Project Lead Date: October 7, 2025 Author: [Platform Architect Name] Last Updated: October 7, 2025</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/","title":"ADR-008: Focalboard for Project Management","text":""},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#status","title":"Status","text":"<p>Accepted - October 7, 2025</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#context","title":"Context","text":"<p>Fawkes is a comprehensive Internal Product Delivery Platform that integrates infrastructure, collaboration, learning, and project management. While we've addressed collaboration needs with Mattermost (ADR-007), teams need integrated project management capabilities to:</p> <ul> <li>Track Platform Work: Sprint planning, roadmap visualization, backlog management</li> <li>Manage Product Delivery: Feature planning, release management, dependency tracking</li> <li>Coordinate Dojo Learning: Track learner progress, module completion, assessment status</li> <li>Visualize Workflows: Kanban boards, calendars, tables for different team needs</li> <li>Enable Self-Service: Teams manage their own work without external tools</li> </ul>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#the-need-for-integrated-project-management","title":"The Need for Integrated Project Management","text":"<p>Current Gap: Teams using Fawkes must use external tools for: - Sprint Planning: Jira, Azure DevOps, Linear, or spreadsheets - Roadmap Visualization: Separate roadmapping tools (ProductPlan, Aha!) - Task Management: Trello, Asana, Monday.com, or GitHub Projects - Learner Progress Tracking: Manual spreadsheets or LMS platforms - Resource Planning: Disconnected from delivery platform</p> <p>Problems with External Tools: - Context Switching: Jump between platforms (Fawkes \u2192 Jira \u2192 Confluence) - Integration Overhead: Custom integrations required, often fragile - Data Silos: Work tracking separate from actual delivery metrics - Access Control: Different permission models, SSO complexity - Cost: Commercial tools expensive at scale (Jira: $7-14/user/month) - Vendor Lock-In: Proprietary data formats, migration challenges</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#requirements-for-project-management-tool","title":"Requirements for Project Management Tool","text":"<ol> <li>Self-Hosted &amp; Open Source: Aligns with Fawkes values, data sovereignty</li> <li>Native Mattermost Integration: Seamless with our collaboration platform</li> <li>Multiple View Types: Boards (Kanban), tables, calendar, gallery</li> <li>Dojo Integration: Track learner progress, module completion, assessments</li> <li>DORA Metrics Connection: Link work items to deployments and metrics</li> <li>Flexible &amp; Lightweight: Not overly complex like Jira, but powerful enough</li> <li>Developer-Friendly: API for automation, CLI support, GitOps integration</li> <li>Template System: Pre-built templates for sprints, roadmaps, dojo tracking</li> <li>Real-Time Collaboration: Multiple users editing simultaneously</li> <li>Mobile Support: iOS and Android apps for on-the-go updates</li> </ol>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Need to track both platform development and team usage - Dojo learner progress requires structured tracking - Sprint planning needs integration with CI/CD metrics - Multiple stakeholders with different view preferences</p> <p>Business Forces: - Cost consciousness (avoid per-user fees) - Data sovereignty and compliance requirements - Desire for unified platform experience - Open source community expectations</p> <p>User Experience Forces: - Teams familiar with Trello/Jira/Asana expect similar UX - Learning curve for new tools creates friction - Mobile access increasingly important - Real-time collaboration expected</p> <p>Integration Forces: - Must integrate deeply with Mattermost (discussions, notifications) - Should connect to DORA metrics and deployments - Needs SSO with platform authentication - API for automation and custom workflows</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#decision","title":"Decision","text":"<p>We will use Focalboard as the integrated project management tool for Fawkes.</p> <p>Specifically: - Focalboard bundled with Mattermost (native integration) - Self-hosted deployment in Kubernetes alongside Mattermost - Deep integration with Mattermost channels (board discussions, notifications) - Custom templates for dojo tracking, sprint planning, platform roadmaps - Backstage integration via iframe or custom plugin for visibility</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#rationale","title":"Rationale","text":"<ol> <li>Native Mattermost Integration: Focalboard is developed by Mattermost, Inc. and integrates seamlessly:</li> <li>Built into Mattermost (no separate deployment complexity)</li> <li>Linked discussions (board cards \u2192 Mattermost threads)</li> <li>Unified notifications (updates appear in Mattermost)</li> <li>Single SSO and permission model</li> <li> <p>Share boards directly in channels</p> </li> <li> <p>Open Source &amp; Self-Hosted: Fully open source (MIT/Apache 2.0), aligns with Fawkes values, complete control over data</p> </li> <li> <p>Notion-Like Experience: Modern, intuitive UX inspired by Notion:</p> </li> <li>Flexible databases with custom properties</li> <li>Multiple views (board, table, calendar, gallery)</li> <li>Rich content (markdown, embeds, checklists)</li> <li> <p>Templates for quick setup</p> </li> <li> <p>Perfect for Dojo Tracking: Ideal for tracking learner progress:</p> </li> <li>Board per belt level (White, Yellow, Green, Brown, Black)</li> <li>Cards represent learners with completion status</li> <li>Custom properties: score, time spent, assessment results</li> <li>Calendar view for cohort scheduling</li> <li> <p>Gallery view for learner profiles</p> </li> <li> <p>Lightweight &amp; Fast: Unlike Jira, Focalboard is lightweight:</p> </li> <li>Fast page loads, responsive UI</li> <li>Simple setup, minimal configuration</li> <li>Not overly complex for small teams</li> <li> <p>Scales well to large teams when needed</p> </li> <li> <p>Developer-Friendly:</p> </li> <li>REST API for automation</li> <li>Import/export in JSON format</li> <li>Can integrate with CI/CD pipelines</li> <li> <p>Archive and backup easily</p> </li> <li> <p>Cost Effectiveness:</p> </li> <li>Free with Mattermost (no additional cost)</li> <li>No per-user fees</li> <li> <p>Only infrastructure costs (already paying for Mattermost)</p> </li> <li> <p>Multiple Use Cases:</p> </li> <li>Sprint Planning: Kanban boards for backlog \u2192 in progress \u2192 done</li> <li>Roadmap Visualization: Timeline view for quarters/releases</li> <li>Dojo Tracking: Learner progress boards with custom properties</li> <li>Incident Management: Board for tracking incidents and postmortems</li> <li>Team OKRs: Tables for objectives and key results</li> <li> <p>Content Calendar: Calendar view for blog posts, webinars</p> </li> <li> <p>Mobile Support: Native mobile apps for iOS and Android (via Mattermost apps)</p> </li> <li> <p>Active Development: Actively maintained by Mattermost with regular updates</p> </li> <li> <p>Familiar UX: Similar to Trello/Notion/Asana, reducing learning curve</p> </li> </ol>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#positive","title":"Positive","text":"<p>\u2705 Unified Platform Experience: Single ecosystem eliminates context switching (chat \u2192 boards \u2192 tasks)</p> <p>\u2705 Seamless Collaboration: Discuss board cards directly in Mattermost channels</p> <p>\u2705 Perfect Dojo Tracking: Custom boards track learner progress, module completion, assessment scores</p> <p>\u2705 Cost Effective: No additional cost beyond Mattermost infrastructure</p> <p>\u2705 Data Sovereignty: Complete control over project data, no third-party access</p> <p>\u2705 Flexible Views: Teams choose board, table, calendar, or gallery based on needs</p> <p>\u2705 Real-Time Updates: Collaborative editing, changes visible immediately</p> <p>\u2705 Simple Setup: Minimal configuration, template-based quick start</p> <p>\u2705 Open Source Alignment: Demonstrates commitment to open source stack</p> <p>\u2705 Developer Automation: API enables custom workflows and integrations</p> <p>\u2705 Template Ecosystem: Can create and share templates for common workflows</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#negative","title":"Negative","text":"<p>\u26a0\ufe0f Less Mature Than Jira: Newer product (launched 2021), fewer advanced features</p> <p>\u26a0\ufe0f Smaller Ecosystem: Fewer third-party integrations compared to Jira/Asana</p> <p>\u26a0\ufe0f Limited Reporting: Basic analytics, lacks advanced reporting of Jira</p> <p>\u26a0\ufe0f No Native Time Tracking: Requires custom properties or external integration</p> <p>\u26a0\ufe0f Simpler Workflow Engine: Less complex workflows than Jira (but this is often a benefit)</p> <p>\u26a0\ufe0f Dependency Management: Limited dependency tracking between cards</p> <p>\u26a0\ufe0f Resource Management: No built-in capacity planning or resource allocation</p> <p>\u26a0\ufe0f Learning Curve: Teams need to learn new tool (mitigated by familiar UX)</p> <p>\u26a0\ufe0f Feature Gaps: Some Jira power-user features don't exist</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#neutral","title":"Neutral","text":"<p>\u25fd Bundled vs. Standalone: Can deploy standalone but better bundled with Mattermost</p> <p>\u25fd Enterprise Features: Some features in paid Mattermost Enterprise edition</p> <p>\u25fd Customization: Less customizable than Jira but easier to configure</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li>Maturity Concerns:</li> <li>Start with core use cases (sprint planning, dojo tracking)</li> <li>Contribute features back to open source project</li> <li>Build custom extensions via API where needed</li> <li> <p>Monitor roadmap for feature additions</p> </li> <li> <p>Reporting Limitations:</p> </li> <li>Export data to Grafana for advanced analytics</li> <li>Build custom dashboards using REST API</li> <li>Integrate with DORA metrics for delivery insights</li> <li> <p>Create weekly/monthly summary reports</p> </li> <li> <p>Time Tracking:</p> </li> <li>Use custom properties for estimated/actual time</li> <li>Integrate with external time tracking if needed</li> <li> <p>Consider building simple time-tracking plugin</p> </li> <li> <p>Workflow Complexity:</p> </li> <li>Keep workflows simple (aligns with agile principles)</li> <li>Use Mattermost bot commands for complex automations</li> <li> <p>Document standard workflows in templates</p> </li> <li> <p>Dependency Management:</p> </li> <li>Use linked cards feature for simple dependencies</li> <li>Document complex dependencies in card descriptions</li> <li> <p>Consider building dependency visualization</p> </li> <li> <p>Adoption:</p> </li> <li>Create video tutorials</li> <li>Provide pre-built templates</li> <li>Show integration benefits (Mattermost notifications, DORA links)</li> <li>Run pilot with one team before broader rollout</li> </ol>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#alternative-1-jira-saas-or-self-hosted","title":"Alternative 1: Jira (SaaS or Self-Hosted)","text":"<p>Pros: - Industry-standard for software teams - Extremely powerful and feature-rich - Extensive reporting and analytics - Huge marketplace of plugins (1,000+) - Advanced workflow engine - Time tracking, resource management, roadmaps - Familiar to most development teams - Strong integration ecosystem</p> <p>Cons: - Cost: $7.75-$14.50/user/month SaaS, or $42,000+ for self-hosted Data Center - Complexity: Notoriously complex, requires dedicated admin - Performance: Often slow, especially self-hosted - Vendor Lock-In: Proprietary data format, difficult to migrate - No Native Mattermost Integration: Requires custom webhooks - Heavy Resource Requirements: Self-hosted needs significant infrastructure - Not Open Source: Proprietary software, no source code access - Misaligned Values: Commercial SaaS doesn't align with open source platform</p> <p>Reason for Rejection: Cost is prohibitive for open source project (at 500 users: $46,500-$87,000/year). Complexity overkill for most teams. Self-hosted Data Center extremely expensive and complex to operate. No native Mattermost integration. Proprietary nature conflicts with Fawkes' open source values.</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#alternative-2-taiga","title":"Alternative 2: Taiga","text":"<p>Pros: - Open source (AGPL license) - Self-hosted and free - Built for agile teams (Scrum/Kanban) - Beautiful, modern UI - Epics, user stories, tasks, issues - Sprint planning and burndown charts - Time tracking and velocity reports - Wiki for documentation - Active community</p> <p>Cons: - No Mattermost Integration: Separate platform, no native integration - Separate Deployment: Another service to deploy and maintain - Different Tech Stack: Django/Angular vs. Go/React - More Complex: Feature-rich but steeper learning curve than Focalboard - Resource Overhead: Separate database, more infrastructure - Mobile App Quality: Mobile apps less polished - Harder to Customize: Codebase more complex to extend</p> <p>Reason for Rejection: While excellent tool, running separate platform defeats unified platform vision. No Mattermost integration means context switching. Deployment and maintenance overhead higher than bundled Focalboard. More complexity than needed for most use cases.</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#alternative-3-plane","title":"Alternative 3: Plane","text":"<p>Pros: - Open source (AGPL license) - Modern, beautiful UI (Linear-inspired) - Fast and lightweight - Built for engineering teams - Cycles, modules, views - Real-time collaboration - Self-hosted option - Active development</p> <p>Cons: - Very New: Launched 2023, still maturing - No Mattermost Integration: Separate platform - Smaller Community: Newer project, less proven - Limited Documentation: Still building out docs - Feature Set Evolving: Core features still being added - No Mobile Apps Yet: Web-only currently - Separate Infrastructure: Another service to deploy - Unknown Stability: Too new to assess long-term viability</p> <p>Reason for Rejection: Too new and unproven for critical platform component. No Mattermost integration. Separate deployment adds complexity. While promising, risk too high for early-stage project. Revisit in 1-2 years when more mature.</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#alternative-4-github-projects","title":"Alternative 4: GitHub Projects","text":"<p>Pros: - Free and unlimited - Native GitHub integration - Familiar to developers - Board, table, and roadmap views - Issue and PR linking - GitHub Actions automation - No separate deployment needed - Already using GitHub</p> <p>Cons: - Limited to Code Repositories: Not general-purpose project management - Basic Features: Lacks advanced PM capabilities - No Mattermost Integration: Separate platform, notifications via email - Poor for Non-Code Work: Not suitable for dojo tracking, general planning - No Standalone Boards: Tied to repositories - Limited Customization: Can't customize fields, workflows much - Not Self-Hosted: GitHub is SaaS (even with GitHub Enterprise) - No Real-Time Collaboration: More static than Focalboard/Jira</p> <p>Reason for Rejection: GitHub Projects excellent for code-centric work but too limited for general project management. Not suitable for dojo learner tracking, team planning, roadmaps. No Mattermost integration. Can complement Focalboard but not replace it.</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#alternative-5-trello-saas","title":"Alternative 5: Trello (SaaS)","text":"<p>Pros: - Simple, intuitive Kanban boards - Free tier available - Widely known and used - Power-Ups for extensions - Mobile apps excellent - Real-time collaboration - Butler automation - Visual and easy to learn</p> <p>Cons: - SaaS Only: No self-hosted option, data on Atlassian servers - Cost at Scale: $5-$17.50/user/month for paid tiers - Limited Views: Primarily Kanban, limited table/calendar - Basic Features: Less powerful than Jira/Focalboard for complex needs - No Mattermost Integration: Separate platform - Vendor Lock-In: Proprietary, owned by Atlassian - Not Open Source: Closed source, can't customize deeply - Data Export Limited: Proprietary format</p> <p>Reason for Rejection: SaaS-only conflicts with self-hosted platform vision. Cost adds up at scale. No Mattermost integration. Atlassian ownership means potential future pricing changes. Too basic for complex project management needs.</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#alternative-6-wekan","title":"Alternative 6: Wekan","text":"<p>Pros: - Open source (MIT license) - Self-hosted and free - Kanban boards (Trello-like) - Lightweight and simple - Docker deployment easy - Multiple languages - Integrations via webhooks</p> <p>Cons: - Limited Features: Very basic compared to alternatives - Development Pace: Slower development, smaller team - No Mattermost Integration: Separate platform - Single View Type: Only Kanban boards, no tables/calendars - Basic Customization: Limited custom fields - Mobile Experience: Web-only, no native apps - Smaller Community: Less active than alternatives</p> <p>Reason for Rejection: While simple and open source, too basic for needs. No Mattermost integration. Limited to Kanban view. Would need to run separately. Focalboard provides much richer feature set with same self-hosted benefits.</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#alternative-7-notion-saas","title":"Alternative 7: Notion (SaaS)","text":"<p>Pros: - Excellent UX, beautiful design - Flexible databases with multiple views - Rich content editing (markdown, embeds) - Templates and team collaboration - Real-time updates - Mobile apps excellent - Integrations and API - Very popular with teams</p> <p>Cons: - SaaS Only: No self-hosted option - Cost: $8-$15/user/month for teams - Vendor Lock-In: Proprietary platform and format - No Mattermost Integration: Separate platform - Performance: Can be slow with large databases - Data Sovereignty: All data on Notion servers - Not Open Source: Closed source, can't customize - Export Limitations: Limited export options</p> <p>Reason for Rejection: SaaS-only and proprietary conflicts with values. No self-hosting option. No Mattermost integration. Cost at scale. Focalboard provides Notion-like experience in open source, self-hosted package.</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-007: Mattermost for Team Collaboration (Focalboard integrates natively)</li> <li>Future ADR: Backstage Plugin for Focalboard (embed boards in developer portal)</li> <li>Future ADR: DORA Metrics Integration (link deployments to board cards)</li> </ul>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#implementation-notes","title":"Implementation Notes","text":""},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#deployment-architecture","title":"Deployment Architecture","text":"<pre><code># Focalboard bundled with Mattermost\nmattermost:\n  namespace: fawkes-collaboration\n  components:\n    - mattermost-app:\n        focalboard:\n          enabled: true\n          settings:\n            enablePublicSharedBoards: true\n            enableDataRetention: true\n\n  integrations:\n    - mattermost-channels (board discussions)\n    - backstage (iframe embed)\n    - dora-metrics-service (link cards to deployments)\n</code></pre>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#initial-board-templates","title":"Initial Board Templates","text":"<p>1. Sprint Planning Board <pre><code>template: \"Sprint Planning\"\nviews:\n  - type: board\n    columns: [\"Backlog\", \"This Sprint\", \"In Progress\", \"Review\", \"Done\"]\n  - type: table\n    groupBy: \"Priority\"\n  - type: calendar\n    dateProperty: \"Due Date\"\n\nproperties:\n  - name: \"Priority\"\n    type: select\n    options: [\"P0\", \"P1\", \"P2\", \"P3\"]\n  - name: \"Estimate\"\n    type: number\n  - name: \"Assignee\"\n    type: person\n  - name: \"Component\"\n    type: multiSelect\n    options: [\"Backstage\", \"Jenkins\", \"ArgoCD\", \"Observability\", \"Security\"]\n  - name: \"Sprint\"\n    type: select\n  - name: \"Story Points\"\n    type: number\n</code></pre></p> <p>2. Dojo Learner Progress Board <pre><code>template: \"Dojo - White Belt\"\nviews:\n  - type: board\n    columns: [\"Not Started\", \"Module 1\", \"Module 2\", \"Module 3\", \"Module 4\", \"Assessment\", \"Certified\"]\n  - type: table\n    groupBy: \"Status\"\n  - type: gallery\n    cardCover: \"profile_image\"\n\nproperties:\n  - name: \"Learner Name\"\n    type: text\n  - name: \"Email\"\n    type: email\n  - name: \"Start Date\"\n    type: date\n  - name: \"Target Completion\"\n    type: date\n  - name: \"Modules Completed\"\n    type: number\n  - name: \"Assessment Score\"\n    type: number\n  - name: \"Time Spent (hours)\"\n    type: number\n  - name: \"Status\"\n    type: select\n    options: [\"Not Started\", \"In Progress\", \"Assessment\", \"Certified\", \"On Hold\"]\n  - name: \"Notes\"\n    type: text\n</code></pre></p> <p>3. Platform Roadmap Board <pre><code>template: \"Platform Roadmap\"\nviews:\n  - type: board\n    columns: [\"Idea\", \"Planned\", \"In Development\", \"Testing\", \"Released\"]\n  - type: table\n    groupBy: \"Quarter\"\n  - type: calendar\n    dateProperty: \"Target Date\"\n\nproperties:\n  - name: \"Feature\"\n    type: text\n  - name: \"Quarter\"\n    type: select\n    options: [\"Q4 2025\", \"Q1 2026\", \"Q2 2026\", \"Q3 2026\", \"Q4 2026\"]\n  - name: \"Impact\"\n    type: select\n    options: [\"High\", \"Medium\", \"Low\"]\n  - name: \"Effort\"\n    type: select\n    options: [\"Small\", \"Medium\", \"Large\", \"XL\"]\n  - name: \"Owner\"\n    type: person\n  - name: \"Target Date\"\n    type: date\n  - name: \"Status\"\n    type: select\n  - name: \"Dependencies\"\n    type: text\n</code></pre></p> <p>4. Incident Management Board <pre><code>template: \"Incident Tracking\"\nviews:\n  - type: board\n    columns: [\"Reported\", \"Investigating\", \"Fixing\", \"Monitoring\", \"Resolved\"]\n  - type: table\n    sortBy: \"Severity\"\n\nproperties:\n  - name: \"Incident ID\"\n    type: text\n  - name: \"Severity\"\n    type: select\n    options: [\"SEV1\", \"SEV2\", \"SEV3\", \"SEV4\"]\n  - name: \"Reported By\"\n    type: person\n  - name: \"Incident Commander\"\n    type: person\n  - name: \"Reported At\"\n    type: dateTime\n  - name: \"Resolved At\"\n    type: dateTime\n  - name: \"MTTR (minutes)\"\n    type: number\n  - name: \"Affected Services\"\n    type: multiSelect\n  - name: \"Root Cause\"\n    type: text\n  - name: \"Postmortem Link\"\n    type: url\n</code></pre></p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#mattermost-integration-examples","title":"Mattermost Integration Examples","text":"<p>1. Board Updates in Channels: <pre><code>[Focalboard Bot] \ud83d\udccb Card moved in \"Sprint 01\"\n@john moved \"Implement DORA metrics\"\nFrom: In Progress \u2192 Review\nBoard: https://mattermost.fawkes.io/boards/abc123\n</code></pre></p> <p>2. Card Discussions: <pre><code>User clicks \"Discuss in Mattermost\" on card\n\u2192 Creates thread in linked channel\n\u2192 Thread automatically linked back to card\n\u2192 Comments sync bidirectionally\n</code></pre></p> <p>3. Daily Stand-up Automation: <pre><code>[Focalboard Bot] \ud83d\udcca Daily Stand-up - Sprint 01\nCards completed yesterday: 3\nCards in progress: 7\nBlocked cards: 1 \u26a0\ufe0f\n\n@alice: 2 cards in review\n@bob: Working on \"Security scanning\" (blocked)\n@carol: Completed \"Deploy Backstage\"\n</code></pre></p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#backstage-integration","title":"Backstage Integration","text":"<ul> <li>Phase 1: Iframe embed in Backstage (boards visible in developer portal)</li> <li>Phase 2: Custom Backstage plugin (<code>@fawkes/plugin-focalboard</code>)</li> <li>Phase 3: Deep integration (create cards from Backstage, link to services)</li> </ul>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#dora-metrics-integration","title":"DORA Metrics Integration","text":"<p>Link board cards to deployments: <pre><code>// When deployment completes\nPOST /focalboard/api/cards/{cardId}/properties\n{\n  \"deployed\": true,\n  \"deployment_time\": \"2025-10-07T14:30:00Z\",\n  \"dora_lead_time\": \"8h 42m\",\n  \"deployment_id\": \"deploy-12345\"\n}\n</code></pre></p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#mobile-experience","title":"Mobile Experience","text":"<ul> <li>Access via Mattermost mobile app</li> <li>Focalboard integrated in Mattermost mobile (iOS/Android)</li> <li>Full board editing on mobile</li> <li>Push notifications for card updates</li> <li>Offline support with sync</li> </ul>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#backup-data-export","title":"Backup &amp; Data Export","text":"<ul> <li>Backup: Included in Mattermost backup strategy</li> <li>Export: JSON format for all boards</li> <li>Import: Can import from Trello, Asana, Notion</li> <li>Git Backup: Export boards to Git for version control</li> </ul>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#resource-requirements","title":"Resource Requirements","text":"<p>Included in Mattermost deployment: - No additional CPU/memory beyond Mattermost - Shares PostgreSQL database - File attachments use same storage (S3/MinIO) - ~100MB additional storage per 100 active boards</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Board loading: &lt;1 second for boards with &lt;1000 cards</li> <li>Real-time updates via WebSocket</li> <li>Card search indexed for fast queries</li> <li>Archive old boards to improve performance</li> </ul>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#monitoring-this-decision","title":"Monitoring This Decision","text":"<p>We will revisit this ADR if: - Focalboard becomes unmaintained or development slows significantly - Critical features remain missing after 12 months - Performance issues arise that can't be resolved - A superior open source alternative emerges with Mattermost integration - Community adoption is below 50% (teams prefer external tools)</p> <p>Next Review Date: April 7, 2026 (6 months)</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#references","title":"References","text":"<ul> <li>Focalboard Documentation</li> <li>Focalboard GitHub</li> <li>Mattermost Boards Documentation</li> <li>Focalboard vs. Alternatives Comparison</li> </ul>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#notes","title":"Notes","text":""},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#why-focalboard-over-jira","title":"Why Focalboard Over Jira?","text":"<p>The most common question: \"Why not use Jira, the industry standard?\"</p> <p>Three key reasons:</p> <ol> <li> <p>Integration: Focalboard's native Mattermost integration creates unified experience. Jira requires complex external integrations.</p> </li> <li> <p>Cost &amp; Values: Open source and self-hosted aligns with Fawkes values. Jira's licensing costs don't scale for open source community.</p> </li> <li> <p>Simplicity: Most teams don't need Jira's complexity. Focalboard's simplicity is a feature, not a limitation. Start simple, scale up as needed.</p> </li> </ol>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#focalboards-evolution","title":"Focalboard's Evolution","text":"<p>Focalboard started as standalone project, acquired by Mattermost in 2021. Now: - Core part of Mattermost platform - Active development (monthly releases) - Growing feature set - Increasing adoption - Path to maturity clear</p>"},{"location":"adr/ADR-008%20focalboard%204%20project%20management/#enterprise-considerations","title":"Enterprise Considerations","text":"<p>While Focalboard is free, some advanced features require Mattermost Enterprise: - Advanced permissions and compliance - SAML authentication - Data retention policies - Advanced audit logging</p> <p>For open source Fawkes: Start with free version, upgrade if enterprise adopters need these features.</p> <p>Decision Made By: Platform Architecture Team Approved By: Project Lead Date: October 7, 2025 Author: [Platform Architect Name] Last Updated: October 7, 2025</p>"},{"location":"adr/ADR-009%20secrets%20managment/","title":"ADR-009: Secrets Management for Platform Services","text":""},{"location":"adr/ADR-009%20secrets%20managment/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-009%20secrets%20managment/#context","title":"Context","text":"<p>The Fawkes platform integrates numerous services that require secure storage and management of sensitive credentials:</p> <p>Service Credentials Required: - ArgoCD: Admin password, GitHub/GitLab tokens, webhook secrets, cluster credentials - Jenkins: Admin password, GitHub tokens, Docker registry credentials, cloud provider credentials, SSH keys - PostgreSQL: Root password, application user passwords (Backstage, Mattermost, SonarQube, Harbor) - Mattermost: Database password, SMTP credentials, OAuth2 client secrets, encryption keys - Harbor: Admin password, database password, Redis password, registry storage credentials - SonarQube: Admin password, database password, authentication tokens - Grafana: Admin password, database password, OAuth2 secrets, data source credentials - Backstage: Database password, GitHub tokens, catalog integration tokens, OAuth2 secrets - Prometheus: Basic auth credentials, remote write credentials, alertmanager credentials - External Secrets Operator: Cloud provider credentials (AWS, Azure, GCP service accounts)</p> <p>Security Requirements: - Secrets must never be stored in Git repositories (even encrypted) - Secrets must be encrypted at rest in the Kubernetes cluster - Secrets must be encrypted in transit - Secrets must support rotation without service downtime - Secrets must have audit logging for access and changes - Secrets must support multi-tenancy (namespace isolation) - Secrets must work across cloud providers and on-premises - Secrets must integrate with external secret stores (AWS Secrets Manager, Azure Key Vault, GCP Secret Manager, HashiCorp Vault)</p> <p>Operational Requirements: - Automatic secret injection into pods (no manual mounting) - Secret synchronization from external stores - Automatic rotation support - Disaster recovery (backup/restore) - GitOps compatibility (declarative, version-controlled configuration without exposing secrets) - Easy troubleshooting (visibility without exposing plaintext) - Low operational overhead for platform team - Clear separation between secret metadata (who/what/where) and secret values</p> <p>Developer Experience Requirements: - Simple secret consumption (environment variables or file mounts) - No custom code required in applications - Clear documentation and examples - Minimal learning curve for dojo students - Self-service secret creation (with RBAC controls)</p> <p>Dojo Learning Requirements: - Students need isolated secret environments per learner - Must support rapid provisioning/teardown - Should demonstrate enterprise-grade practices - Must work in local/development environments (Minikube, Kind)</p>"},{"location":"adr/ADR-009%20secrets%20managment/#decision","title":"Decision","text":"<p>We will use External Secrets Operator (ESO) as the primary secrets management solution for the Fawkes platform, with support for multiple backend secret stores.</p>"},{"location":"adr/ADR-009%20secrets%20managment/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  External Secret Stores (Backends)                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502 AWS Secrets  \u2502  \u2502 Azure Key    \u2502  \u2502  HashiCorp   \u2502     \u2502\n\u2502  \u2502   Manager    \u2502  \u2502    Vault     \u2502  \u2502    Vault     \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502         \u2502                 \u2502                  \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502                 \u2502                  \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            v\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502  External Secrets Operator (ESO)    \u2502\n          \u2502  - Secret synchronization           \u2502\n          \u2502  - Automatic rotation               \u2502\n          \u2502  - Multi-backend support            \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            v\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502  Kubernetes Secrets (Encrypted)     \u2502\n          \u2502  - namespace: fawkes-core           \u2502\n          \u2502  - namespace: fawkes-collaboration  \u2502\n          \u2502  - namespace: fawkes-observability  \u2502\n          \u2502  - namespace: learner-*             \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502                                    \u2502\n          v                                    v\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 ArgoCD   \u2502                        \u2502 Jenkins  \u2502\n    \u2502 Pod      \u2502                        \u2502 Pod      \u2502\n    \u2502          \u2502                        \u2502          \u2502\n    \u2502 ENV vars \u2502                        \u2502 Files in \u2502\n    \u2502 from     \u2502                        \u2502 /secrets \u2502\n    \u2502 secrets  \u2502                        \u2502          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-009%20secrets%20managment/#backend-strategy","title":"Backend Strategy","text":"<p>Multi-Backend Support (Choose based on environment):</p> <ol> <li>AWS Secrets Manager (AWS deployments)</li> <li>Azure Key Vault (Azure deployments)</li> <li>GCP Secret Manager (GCP deployments)</li> <li>HashiCorp Vault (On-premises, multi-cloud, advanced use cases)</li> <li>Kubernetes Secrets (Development, learning environments)</li> </ol> <p>Default Recommendation by Environment: - Production: Cloud provider secret store (AWS/Azure/GCP) - Staging: Cloud provider secret store - Development: Kubernetes secrets (ESO optional) - Dojo/Learning: Kubernetes secrets with ESO synchronization from templates</p>"},{"location":"adr/ADR-009%20secrets%20managment/#core-components","title":"Core Components","text":"<p>1. External Secrets Operator - Deployed in <code>fawkes-system</code> namespace - Monitors <code>ExternalSecret</code> and <code>SecretStore</code> resources - Synchronizes secrets from external stores to Kubernetes - Automatic refresh interval (configurable, default 1 hour)</p> <p>2. SecretStore Resources Define connections to external secret backends per namespace:</p> <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: aws-secretsmanager\n  namespace: fawkes-core\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      region: us-east-1\n      auth:\n        jwt:\n          serviceAccountRef:\n            name: external-secrets-sa\n</code></pre> <p>3. ClusterSecretStore Cluster-wide secret store for shared secrets:</p> <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: vault-backend\nspec:\n  provider:\n    vault:\n      server: \"https://vault.fawkes.example.com\"\n      path: \"secret\"\n      version: \"v2\"\n      auth:\n        kubernetes:\n          mountPath: \"kubernetes\"\n          role: \"fawkes-platform\"\n</code></pre> <p>4. ExternalSecret Resources Define which secrets to sync and how:</p> <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: argocd-credentials\n  namespace: fawkes-core\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: aws-secretsmanager\n    kind: SecretStore\n  target:\n    name: argocd-secret\n    creationPolicy: Owner\n  data:\n  - secretKey: admin.password\n    remoteRef:\n      key: fawkes/argocd/admin\n      property: password\n  - secretKey: github.token\n    remoteRef:\n      key: fawkes/github/integration\n      property: token\n</code></pre>"},{"location":"adr/ADR-009%20secrets%20managment/#secret-naming-convention","title":"Secret Naming Convention","text":"<p>Path Structure in External Stores: <pre><code>fawkes/\n  \u251c\u2500\u2500 core/\n  \u2502   \u251c\u2500\u2500 argocd/\n  \u2502   \u2502   \u251c\u2500\u2500 admin-password\n  \u2502   \u2502   \u251c\u2500\u2500 github-token\n  \u2502   \u2502   \u2514\u2500\u2500 webhook-secret\n  \u2502   \u251c\u2500\u2500 backstage/\n  \u2502   \u2502   \u251c\u2500\u2500 postgres-password\n  \u2502   \u2502   \u251c\u2500\u2500 github-token\n  \u2502   \u2502   \u2514\u2500\u2500 oauth2-client-secret\n  \u2502   \u2514\u2500\u2500 postgres/\n  \u2502       \u251c\u2500\u2500 root-password\n  \u2502       \u2514\u2500\u2500 replication-password\n  \u251c\u2500\u2500 collaboration/\n  \u2502   \u251c\u2500\u2500 mattermost/\n  \u2502   \u2502   \u251c\u2500\u2500 postgres-password\n  \u2502   \u2502   \u251c\u2500\u2500 smtp-password\n  \u2502   \u2502   \u2514\u2500\u2500 encryption-key\n  \u2502   \u2514\u2500\u2500 focalboard/\n  \u2502       \u2514\u2500\u2500 session-secret\n  \u251c\u2500\u2500 cicd/\n  \u2502   \u251c\u2500\u2500 jenkins/\n  \u2502   \u2502   \u251c\u2500\u2500 admin-password\n  \u2502   \u2502   \u251c\u2500\u2500 github-token\n  \u2502   \u2502   \u251c\u2500\u2500 docker-registry-password\n  \u2502   \u2502   \u2514\u2500\u2500 aws-credentials\n  \u2502   \u2514\u2500\u2500 harbor/\n  \u2502       \u251c\u2500\u2500 admin-password\n  \u2502       \u251c\u2500\u2500 postgres-password\n  \u2502       \u2514\u2500\u2500 s3-credentials\n  \u2514\u2500\u2500 observability/\n      \u251c\u2500\u2500 grafana/\n      \u2502   \u251c\u2500\u2500 admin-password\n      \u2502   \u2514\u2500\u2500 oauth2-client-secret\n      \u2514\u2500\u2500 prometheus/\n          \u2514\u2500\u2500 remote-write-password\n</code></pre></p>"},{"location":"adr/ADR-009%20secrets%20managment/#example-configurations","title":"Example Configurations","text":"<p>ArgoCD Admin Password: <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: argocd-secret\n  namespace: fawkes-core\nspec:\n  refreshInterval: 15m\n  secretStoreRef:\n    name: aws-secretsmanager\n    kind: SecretStore\n  target:\n    name: argocd-secret\n    creationPolicy: Owner\n    template:\n      engineVersion: v2\n      data:\n        admin.password: \"{{ .adminPassword | bcrypt }}\"\n        server.secretkey: \"{{ .serverSecretKey }}\"\n  dataFrom:\n  - extract:\n      key: fawkes/core/argocd/credentials\n</code></pre></p> <p>Jenkins Credentials (Multiple Secrets): <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: jenkins-credentials\n  namespace: fawkes-cicd\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: aws-secretsmanager\n    kind: SecretStore\n  target:\n    name: jenkins-credentials\n    creationPolicy: Owner\n  data:\n  - secretKey: admin-user\n    remoteRef:\n      key: fawkes/cicd/jenkins/admin\n      property: username\n  - secretKey: admin-password\n    remoteRef:\n      key: fawkes/cicd/jenkins/admin\n      property: password\n  - secretKey: github-token\n    remoteRef:\n      key: fawkes/github/integration\n      property: token\n  - secretKey: docker-config.json\n    remoteRef:\n      key: fawkes/cicd/docker-registry\n      property: config\n</code></pre></p> <p>PostgreSQL Passwords (Templated): <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: postgres-credentials\n  namespace: fawkes-core\nspec:\n  refreshInterval: 24h\n  secretStoreRef:\n    name: aws-secretsmanager\n    kind: SecretStore\n  target:\n    name: postgres-credentials\n    creationPolicy: Owner\n    template:\n      engineVersion: v2\n      data:\n        postgres-password: \"{{ .rootPassword }}\"\n        backstage-password: \"{{ .backstagePassword }}\"\n        argocd-password: \"{{ .argocdPassword }}\"\n        connection-string: \"postgresql://postgres:{{ .rootPassword }}@postgres.fawkes-core.svc.cluster.local:5432/postgres\"\n  dataFrom:\n  - extract:\n      key: fawkes/core/postgres/passwords\n</code></pre></p>"},{"location":"adr/ADR-009%20secrets%20managment/#secret-rotation-strategy","title":"Secret Rotation Strategy","text":"<p>Automatic Rotation: 1. Update secret in external store (AWS Secrets Manager, Vault, etc.) 2. ESO detects change on next refresh interval (default 1 hour) 3. ESO updates Kubernetes secret 4. Pods with secret volumes automatically get updated files 5. Pods with environment variables require restart (handled by Reloader)</p> <p>Reloader Integration: Deploy Reloader to automatically restart pods when secrets change:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: jenkins-config\n  namespace: fawkes-cicd\n  annotations:\n    reloader.stakater.com/match: \"true\"\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  namespace: fawkes-cicd\n  annotations:\n    reloader.stakater.com/auto: \"true\"\nspec:\n  template:\n    spec:\n      containers:\n      - name: jenkins\n        env:\n        - name: ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: jenkins-credentials\n              key: admin-password\n</code></pre>"},{"location":"adr/ADR-009%20secrets%20managment/#security-hardening","title":"Security Hardening","text":"<p>1. Encryption at Rest: Enable Kubernetes secret encryption:</p> <pre><code>apiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n  - resources:\n      - secrets\n    providers:\n      - aescbc:\n          keys:\n            - name: key1\n              secret: &lt;base64-encoded-32-byte-key&gt;\n      - identity: {}\n</code></pre> <p>2. RBAC Policies: Restrict access to secrets by namespace and role:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: secret-reader\n  namespace: fawkes-core\nrules:\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"get\", \"list\"]\n  resourceNames: [\"argocd-secret\", \"postgres-credentials\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: argocd-secret-access\n  namespace: fawkes-core\nsubjects:\n- kind: ServiceAccount\n  name: argocd-server\n  namespace: fawkes-core\nroleRef:\n  kind: Role\n  name: secret-reader\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>3. Pod Security Standards: Enforce that pods cannot access secrets they don't need:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: jenkins\n  namespace: fawkes-cicd\nspec:\n  serviceAccountName: jenkins\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n  containers:\n  - name: jenkins\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - ALL\n</code></pre> <p>4. Audit Logging: Enable Kubernetes audit logs for secret access:</p> <pre><code>apiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n- level: Metadata\n  resources:\n  - group: \"\"\n    resources: [\"secrets\"]\n  omitStages:\n  - RequestReceived\n</code></pre>"},{"location":"adr/ADR-009%20secrets%20managment/#aws-secrets-manager-integration","title":"AWS Secrets Manager Integration","text":"<p>IAM Role for ESO (IRSA): <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\",\n        \"secretsmanager:DescribeSecret\",\n        \"secretsmanager:ListSecretVersionIds\"\n      ],\n      \"Resource\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:fawkes/*\"\n    }\n  ]\n}\n</code></pre></p> <p>Service Account Annotation: <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: external-secrets-sa\n  namespace: fawkes-system\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/fawkes-external-secrets\n</code></pre></p> <p>SecretStore for AWS: <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: aws-secrets-manager\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      region: us-east-1\n      auth:\n        jwt:\n          serviceAccountRef:\n            name: external-secrets-sa\n            namespace: fawkes-system\n</code></pre></p>"},{"location":"adr/ADR-009%20secrets%20managment/#hashicorp-vault-integration-alternative","title":"HashiCorp Vault Integration (Alternative)","text":"<p>Vault Setup: <pre><code># Enable Kubernetes auth\nvault auth enable kubernetes\n\n# Configure Kubernetes auth\nvault write auth/kubernetes/config \\\n    kubernetes_host=\"https://kubernetes.default.svc:443\" \\\n    kubernetes_ca_cert=@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n\n# Create policy\nvault policy write fawkes-secrets - &lt;&lt;EOF\npath \"secret/data/fawkes/*\" {\n  capabilities = [\"read\"]\n}\nEOF\n\n# Create Kubernetes role\nvault write auth/kubernetes/role/fawkes-platform \\\n    bound_service_account_names=external-secrets-sa \\\n    bound_service_account_namespaces=fawkes-system \\\n    policies=fawkes-secrets \\\n    ttl=24h\n</code></pre></p> <p>ClusterSecretStore for Vault: <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: vault-backend\nspec:\n  provider:\n    vault:\n      server: \"https://vault.fawkes.example.com\"\n      path: \"secret\"\n      version: \"v2\"\n      auth:\n        kubernetes:\n          mountPath: \"kubernetes\"\n          role: \"fawkes-platform\"\n          serviceAccountRef:\n            name: external-secrets-sa\n            namespace: fawkes-system\n</code></pre></p>"},{"location":"adr/ADR-009%20secrets%20managment/#disaster-recovery","title":"Disaster Recovery","text":"<p>Backup Strategy: 1. External Store: Secrets in AWS/Azure/GCP have built-in backup/versioning 2. ExternalSecret Manifests: Version controlled in Git (no secret values) 3. Emergency Access: Break-glass procedures documented 4. Key Rotation Records: Maintain audit log of all rotations</p> <p>Recovery Procedure: <pre><code># 1. Restore External Secrets Operator\nkubectl apply -f manifests/external-secrets-operator/\n\n# 2. Restore SecretStore configurations\nkubectl apply -f manifests/secret-stores/\n\n# 3. ESO automatically syncs all ExternalSecret resources\nkubectl apply -f manifests/external-secrets/\n\n# 4. Verify secret creation\nkubectl get secrets -A | grep fawkes\n\n# 5. Restart pods if needed\nkubectl rollout restart deployment -n fawkes-core\n</code></pre></p>"},{"location":"adr/ADR-009%20secrets%20managment/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-009%20secrets%20managment/#positive","title":"Positive","text":"<ol> <li>GitOps Compatible: ExternalSecret manifests can be stored in Git without exposing secrets</li> <li>Multi-Cloud Support: Works with AWS, Azure, GCP, Vault, and 20+ providers</li> <li>Automatic Synchronization: Secrets updated automatically from external stores</li> <li>Audit Trail: All secret access logged in external store (AWS CloudTrail, Vault audit)</li> <li>Separation of Concerns: Platform team manages external stores, developers consume via Kubernetes</li> <li>Rotation Support: Built-in support for automatic secret rotation</li> <li>Namespace Isolation: Secrets scoped to namespaces, preventing cross-namespace access</li> <li>CNCF Project: External Secrets Operator is a CNCF sandbox project with active community</li> <li>Low Operational Overhead: Minimal maintenance once configured</li> <li>Developer Friendly: Secrets consumed as standard Kubernetes secrets (no custom code)</li> </ol>"},{"location":"adr/ADR-009%20secrets%20managment/#negative","title":"Negative","text":"<ol> <li>Additional Component: ESO adds operational complexity (another component to monitor)</li> <li>External Dependency: Requires external secret store (AWS Secrets Manager, Vault, etc.)</li> <li>Sync Delay: Secrets not immediately updated (default 1-hour refresh interval)</li> <li>Initial Setup Complexity: Learning curve for ExternalSecret manifests</li> <li>Cost: External secret stores have usage costs (AWS Secrets Manager: $0.40/secret/month)</li> <li>Troubleshooting: Adds layer between external store and Kubernetes (more places for issues)</li> <li>IRSA/Workload Identity: Requires cloud IAM integration (IRSA on AWS, Workload Identity on GCP)</li> </ol>"},{"location":"adr/ADR-009%20secrets%20managment/#neutral","title":"Neutral","text":"<ol> <li>Templating Required: Complex secret transformations need template syntax</li> <li>Reloader Dependency: Pods with env vars need Reloader for automatic updates</li> <li>Multi-Store Management: Organizations using multiple clouds need multiple SecretStore configs</li> <li>Version Pinning: Need to manage ESO version upgrades carefully</li> </ol>"},{"location":"adr/ADR-009%20secrets%20managment/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-009%20secrets%20managment/#alternative-1-sealed-secrets","title":"Alternative 1: Sealed Secrets","text":"<p>Pros: - Secrets encrypted and stored directly in Git - No external dependency (secret store) - Simple mental model (encrypt secret, commit, controller decrypts) - Good for GitOps workflows - No cost for external secret store</p> <p>Cons: - Secrets still in Git (even if encrypted) - compliance/security concerns - Key management burden (must protect unsealing key) - No integration with external secret stores (AWS Secrets Manager, Vault) - Rotation requires re-encrypting and committing - Limited to Kubernetes secrets (no external source of truth) - If unsealing key compromised, all secrets exposed</p> <p>Reason for Rejection: Sealed Secrets forces secrets into Git, which violates many compliance frameworks (SOC2, PCI-DSS). Organizations with established secret management (Vault, AWS Secrets Manager) cannot leverage existing infrastructure. The sealed secret key becomes a single point of failure.</p>"},{"location":"adr/ADR-009%20secrets%20managment/#alternative-2-hashicorp-vault-direct-integration","title":"Alternative 2: HashiCorp Vault (Direct Integration)","text":"<p>Pros: - Industry-leading secret management solution - Advanced features (dynamic secrets, leasing, PKI) - Superior audit logging and access controls - Secret engines for databases, clouds, SSH, PKI - Multi-tenancy and namespace support - Secret rotation and expiration built-in</p> <p>Cons: - High operational overhead (Vault cluster management, upgrades, HA) - Requires Vault expertise on platform team - Steep learning curve for developers - Significant infrastructure costs (Vault Enterprise for advanced features) - Applications need Vault-aware clients or sidecar injectors - Overkill for basic secret storage needs</p> <p>Reason for Rejection: While Vault is excellent, it requires dedicated operational expertise and introduces significant complexity. ESO provides integration with Vault for organizations that already have it, while also supporting simpler backends (AWS Secrets Manager) for teams without Vault. This gives Fawkes flexibility.</p>"},{"location":"adr/ADR-009%20secrets%20managment/#alternative-3-kubernetes-secrets-native-encrypted-at-rest","title":"Alternative 3: Kubernetes Secrets (Native, Encrypted at Rest)","text":"<p>Pros: - No additional components (native Kubernetes) - Zero operational overhead - Simple API (kubectl create secret) - Well understood by developers - No cost</p> <p>Cons: - No integration with external secret stores - Manual rotation (no automation) - No audit logging (beyond Kubernetes audit logs) - Secrets must be base64 encoded and put in manifests (risky) - No centralized secret management - Difficult to share secrets across clusters - Limited access controls (namespace-level only)</p> <p>Reason for Rejection: Native Kubernetes secrets are suitable for development but inadequate for production. Lack of integration with external stores means organizations cannot leverage existing secret infrastructure. No rotation support creates operational burden. However, Kubernetes secrets remain the consumption mechanism (ESO creates them), so developers still use the familiar API.</p>"},{"location":"adr/ADR-009%20secrets%20managment/#alternative-4-cloud-specific-solutions-aws-secrets-csi-driver-azure-key-vault-csi","title":"Alternative 4: Cloud-Specific Solutions (AWS Secrets CSI Driver, Azure Key Vault CSI)","text":"<p>Pros: - Deep cloud integration (native IAM, audit logging) - No intermediate controller (CSI driver directly mounts secrets) - Lower latency (secrets mounted on-demand) - Automatic rotation via CSI driver - Minimal resource overhead</p> <p>Cons: - Cloud vendor lock-in (different implementation per cloud) - Cannot work on-premises or in multi-cloud - Different configuration per cloud (AWS \u2260 Azure \u2260 GCP) - Limited to volume mounts (no environment variables without wrapper) - Learner environments need cloud accounts - Inconsistent developer experience across environments</p> <p>Reason for Rejection: Violates Fawkes' cloud portability principle. Developers and learners should have consistent experience regardless of deployment target. ESO provides abstraction layer that works with any backend, while CSI drivers lock you into cloud-specific patterns.</p>"},{"location":"adr/ADR-009%20secrets%20managment/#alternative-5-sops-secrets-operations","title":"Alternative 5: SOPS (Secrets OPerationS)","text":"<p>Pros: - Encrypt secrets in Git with AWS KMS, GCP KMS, Azure Key Vault, PGP - GitOps-friendly (encrypted secrets committed) - Supports multiple formats (YAML, JSON, ENV, INI) - Integration with FluxCD and ArgoCD - Partial encryption (encrypt values, leave keys plaintext)</p> <p>Cons: - Secrets still in Git (compliance concerns) - Requires KMS key management - Manual rotation (re-encrypt and commit) - ArgoCD integration complex (requires custom tooling) - No runtime secret refresh (static secrets) - Limited audit trail (Git commits only)</p> <p>Reason for Rejection: Similar issues to Sealed Secrets - storing secrets in Git creates compliance and security challenges. SOPS is excellent for configuration management, but ESO provides better separation between secret storage (external) and consumption (Kubernetes). Organizations prefer secrets in dedicated secret stores, not Git.</p>"},{"location":"adr/ADR-009%20secrets%20managment/#alternative-6-kubernetes-external-secrets-older-project","title":"Alternative 6: Kubernetes External Secrets (Older Project)","text":"<p>Pros: - Original external secrets project (inspired ESO) - Similar concept to ESO - Works with AWS, GCP, Azure</p> <p>Cons: - Deprecated in favor of External Secrets Operator - Smaller community and less active development - Fewer backend integrations - Less mature API (v1alpha1) - Not CNCF project</p> <p>Reason for Rejection: External Secrets Operator (ESO) is the successor project with broader community, CNCF sandbox status, and more active development. No reason to use the deprecated version when ESO provides superset of functionality.</p>"},{"location":"adr/ADR-009%20secrets%20managment/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-009%20secrets%20managment/#phase-1-mvp-week-4-of-sprint-01","title":"Phase 1: MVP (Week 4 of Sprint 01)","text":"<p>Day 1-2: External Secrets Operator Deployment [8 hours] 1. Deploy ESO via Helm chart to <code>fawkes-system</code> namespace 2. Configure RBAC for ESO service account 3. Set up AWS IRSA role for ESO (or cloud-specific workload identity) 4. Create ClusterSecretStore for AWS Secrets Manager 5. Verify ESO controller is running and can authenticate</p> <p>Day 3: Core Service Secrets [6 hours] 6. Create secrets in AWS Secrets Manager for:    - PostgreSQL (root password, database passwords)    - ArgoCD (admin password, GitHub token)    - Backstage (database password, GitHub token, OAuth2 secrets) 7. Create ExternalSecret manifests for each 8. Verify Kubernetes secrets created successfully 9. Test secret consumption by deploying test pod</p> <p>Day 4: CI/CD Service Secrets [6 hours] 10. Create secrets in AWS Secrets Manager for:     - Jenkins (admin password, GitHub token, Docker credentials)     - Harbor (admin password, database password, S3 credentials) 11. Create ExternalSecret manifests 12. Deploy Jenkins and Harbor with external secrets 13. Verify services start successfully with secrets</p> <p>Day 5: Documentation &amp; Validation [4 hours] 14. Document secret naming conventions 15. Create runbook for secret rotation 16. Write troubleshooting guide 17. Create Dojo module outline for secrets management</p>"},{"location":"adr/ADR-009%20secrets%20managment/#phase-2-advanced-features-week-5","title":"Phase 2: Advanced Features (Week 5)","text":"<p>Secret Rotation [4 hours] - Deploy Reloader for automatic pod restarts - Document rotation procedures for each service - Test rotation end-to-end for PostgreSQL - Create Grafana alerts for secret sync failures</p> <p>Multi-Environment Setup [4 hours] - Create separate secret paths for dev/staging/prod - Configure namespace-scoped SecretStores - Implement RBAC for namespace isolation - Test learner namespace provisioning with secrets</p> <p>Backup &amp; Disaster Recovery [3 hours] - Document break-glass procedures - Create backup scripts for ExternalSecret manifests - Test secret recovery procedures - Create incident response runbook</p>"},{"location":"adr/ADR-009%20secrets%20managment/#phase-3-dojo-integration-week-6","title":"Phase 3: Dojo Integration (Week 6)","text":"<p>Yellow Belt - Module 3: \"Securing Secrets\" [8 hours]</p> <p>Learning Objectives: - Understand secrets management anti-patterns (secrets in Git, plain text) - Learn External Secrets Operator concepts - Create ExternalSecret manifests - Implement secret rotation - Troubleshoot secret sync issues</p> <p>Hands-On Lab: 1. Create secret in AWS Secrets Manager (or learner-specific backend) 2. Deploy ExternalSecret manifest to learner namespace 3. Consume secret in test application (environment variables and volume mounts) 4. Rotate secret and observe automatic sync 5. Troubleshoot intentionally broken ExternalSecret</p> <p>Assessment: - Quiz on secrets best practices (10 questions) - Practical: Deploy application with database password from external store - Troubleshoot secret sync failure scenario</p> <p>Time: 2 hours (45 min theory + 75 min hands-on)</p>"},{"location":"adr/ADR-009%20secrets%20managment/#phase-4-production-hardening-week-7","title":"Phase 4: Production Hardening (Week 7)","text":"<p>Security Hardening [6 hours] - Enable Kubernetes secret encryption at rest - Implement least-privilege RBAC policies - Configure audit logging for secret access - Security scan all secret configurations - Penetration testing for secret access paths</p> <p>Monitoring &amp; Alerting [4 hours] - Create Prometheus metrics for ESO - Build Grafana dashboard for secret sync status - Configure alerts for sync failures - Set up alert for certificate/secret expiration - Integrate with PagerDuty/OpsGenie</p> <p>Documentation [4 hours] - Complete architecture documentation with diagrams - Write comprehensive troubleshooting guide - Create secret rotation playbook - Document disaster recovery procedures - Create RBAC guidelines</p>"},{"location":"adr/ADR-009%20secrets%20managment/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"adr/ADR-009%20secrets%20managment/#key-metrics","title":"Key Metrics","text":"<p>External Secrets Operator Metrics: ```</p>"},{"location":"adr/ADR-009%20secrets%20managment/#sync-success-rate","title":"Sync success rate","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/","title":"ADR-010: Ingress Controller for Service Access","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#context","title":"Context","text":"<p>The Fawkes platform integrates multiple services that require external access:</p> <p>Core Services: - Backstage (Developer Portal &amp; Dojo Hub) - Primary user interface - Mattermost (Team Collaboration) - Chat and collaboration - Focalboard (Project Management) - Kanban boards and planning - ArgoCD (GitOps UI) - Deployment visualization - Jenkins (CI/CD UI) - Pipeline management - Grafana (Observability) - Metrics and dashboards - Harbor (Container Registry UI) - Image management - SonarQube (Code Quality) - Security and quality reports</p> <p>Access Requirements: - Single entry point with consistent domain structure - TLS/SSL encryption for all services - Path-based or subdomain-based routing - Rate limiting and DDoS protection - Authentication integration (OIDC/OAuth2) - Certificate management automation - Load balancing across replicas - WebSocket support (Mattermost, ArgoCD, Jenkins) - Health check integration - Request/response logging for security auditing</p> <p>Technical Constraints: - Must work across AWS, Azure, GCP, and on-premises environments - Should integrate with cert-manager for automated certificate provisioning - Must support both path-based (/backstage) and subdomain-based (backstage.fawkes.example.com) routing - Should minimize cloud provider lock-in - Must support learner environments with dynamic provisioning - Should provide observability (request metrics, tracing)</p> <p>Security Requirements: - Force HTTPS/TLS for all traffic - Support for custom certificates and Let's Encrypt - Web Application Firewall (WAF) capabilities - Rate limiting per service and per IP - DDoS protection - Security headers (HSTS, CSP, X-Frame-Options) - IP whitelisting capabilities for sensitive services</p> <p>Operational Requirements: - Easy configuration via annotations or CRDs - Automatic service discovery - Rolling updates without downtime - Clear error pages and troubleshooting - Integration with platform monitoring</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#decision","title":"Decision","text":"<p>We will use NGINX Ingress Controller as the primary ingress solution for the Fawkes platform.</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#architecture","title":"Architecture","text":"<pre><code>Internet\n   |\n   v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Cloud Load Balancer (AWS NLB/ALB)      \u2502\n\u2502  (Optional, for production)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n   |\n   v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  NGINX Ingress Controller                \u2502\n\u2502  - TLS Termination                       \u2502\n\u2502  - Path/Subdomain Routing                \u2502\n\u2502  - Rate Limiting                         \u2502\n\u2502  - Authentication (OAuth2 Proxy)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n   |\n   \u251c\u2500\u2500&gt; Backstage Service (/)\n   \u251c\u2500\u2500&gt; Mattermost Service (/mattermost)\n   \u251c\u2500\u2500&gt; Focalboard Service (/focalboard)\n   \u251c\u2500\u2500&gt; ArgoCD Service (/argocd)\n   \u251c\u2500\u2500&gt; Jenkins Service (/jenkins)\n   \u251c\u2500\u2500&gt; Grafana Service (/grafana)\n   \u251c\u2500\u2500&gt; Harbor Service (/harbor)\n   \u2514\u2500\u2500&gt; SonarQube Service (/sonarqube)\n</code></pre>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#routing-strategy","title":"Routing Strategy","text":"<p>Primary: Subdomain-Based Routing (Production) <pre><code>https://backstage.fawkes.example.com  \u2192 Backstage\nhttps://chat.fawkes.example.com       \u2192 Mattermost\nhttps://boards.fawkes.example.com     \u2192 Focalboard\nhttps://cd.fawkes.example.com         \u2192 ArgoCD\nhttps://ci.fawkes.example.com         \u2192 Jenkins\nhttps://metrics.fawkes.example.com    \u2192 Grafana\nhttps://registry.fawkes.example.com   \u2192 Harbor\nhttps://quality.fawkes.example.com    \u2192 SonarQube\n</code></pre></p> <p>Alternative: Path-Based Routing (Development/Learning) <pre><code>https://fawkes.example.com/           \u2192 Backstage\nhttps://fawkes.example.com/chat       \u2192 Mattermost\nhttps://fawkes.example.com/boards     \u2192 Focalboard\nhttps://fawkes.example.com/cd         \u2192 ArgoCD\nhttps://fawkes.example.com/ci         \u2192 Jenkins\nhttps://fawkes.example.com/metrics    \u2192 Grafana\nhttps://fawkes.example.com/registry   \u2192 Harbor\nhttps://fawkes.example.com/quality    \u2192 SonarQube\n</code></pre></p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#certificate-management","title":"Certificate Management","text":"<p>Integration with cert-manager for automated certificate provisioning:</p> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: platform-team@example.com\n    privateKeySecretRef:\n      name: letsencrypt-prod-key\n    solvers:\n    - http01:\n        ingress:\n          class: nginx\n</code></pre>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#example-ingress-configuration","title":"Example Ingress Configuration","text":"<p>Backstage (Primary Portal): <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: backstage\n  namespace: fawkes-core\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/ssl-protocols: \"TLSv1.2 TLSv1.3\"\n    nginx.ingress.kubernetes.io/proxy-body-size: \"50m\"\n    nginx.ingress.kubernetes.io/rate-limit: \"100\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - backstage.fawkes.example.com\n    secretName: backstage-tls\n  rules:\n  - host: backstage.fawkes.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: backstage\n            port:\n              number: 7007\n</code></pre></p> <p>Mattermost (WebSocket Support): <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: mattermost\n  namespace: fawkes-collaboration\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"600\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"600\"\n    nginx.ingress.kubernetes.io/websocket-services: \"mattermost\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - chat.fawkes.example.com\n    secretName: mattermost-tls\n  rules:\n  - host: chat.fawkes.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: mattermost\n            port:\n              number: 8065\n</code></pre></p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#security-configuration","title":"Security Configuration","text":"<p>Rate Limiting: <pre><code>annotations:\n  nginx.ingress.kubernetes.io/limit-rps: \"10\"\n  nginx.ingress.kubernetes.io/limit-connections: \"20\"\n</code></pre></p> <p>IP Whitelisting (for admin services): <pre><code>annotations:\n  nginx.ingress.kubernetes.io/whitelist-source-range: \"10.0.0.0/8,172.16.0.0/12\"\n</code></pre></p> <p>Security Headers: <pre><code>annotations:\n  nginx.ingress.kubernetes.io/configuration-snippet: |\n    more_set_headers \"X-Frame-Options: DENY\";\n    more_set_headers \"X-Content-Type-Options: nosniff\";\n    more_set_headers \"X-XSS-Protection: 1; mode=block\";\n    more_set_headers \"Strict-Transport-Security: max-age=31536000; includeSubDomains\";\n</code></pre></p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#oauth2-proxy-integration","title":"OAuth2 Proxy Integration","text":"<p>For services without native SSO support:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana\n  annotations:\n    nginx.ingress.kubernetes.io/auth-url: \"https://oauth2.fawkes.example.com/oauth2/auth\"\n    nginx.ingress.kubernetes.io/auth-signin: \"https://oauth2.fawkes.example.com/oauth2/start?rd=$escaped_request_uri\"\n</code></pre>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#monitoring-integration","title":"Monitoring Integration","text":"<p>NGINX Ingress Controller exposes Prometheus metrics: - Request rate per service - Request duration percentiles - Error rates (4xx, 5xx) - Bytes transferred - Upstream response time</p> <p>Grafana dashboards: NGINX Ingress Controller (official dashboard ID: 9614)</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#deployment-configuration","title":"Deployment Configuration","text":"<p>NGINX Ingress Controller Helm Values: <pre><code>controller:\n  replicaCount: 3\n\n  resources:\n    requests:\n      cpu: 100m\n      memory: 128Mi\n    limits:\n      cpu: 500m\n      memory: 512Mi\n\n  service:\n    type: LoadBalancer\n    annotations:\n      service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\n      service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: \"true\"\n\n  metrics:\n    enabled: true\n    serviceMonitor:\n      enabled: true\n\n  config:\n    use-forwarded-headers: \"true\"\n    compute-full-forwarded-for: \"true\"\n    use-proxy-protocol: \"false\"\n    enable-real-ip: \"true\"\n    proxy-body-size: \"50m\"\n    ssl-protocols: \"TLSv1.2 TLSv1.3\"\n    ssl-ciphers: \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384\"\n\n  podAnnotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"10254\"\n</code></pre></p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#positive","title":"Positive","text":"<ol> <li>Cloud Agnostic: NGINX Ingress works identically across AWS, Azure, GCP, and on-premises</li> <li>Mature &amp; Proven: Battle-tested in production at massive scale, large community support</li> <li>Feature Rich: Comprehensive feature set including rate limiting, WebSocket, authentication</li> <li>Observable: Native Prometheus metrics integration</li> <li>Flexible Routing: Supports both path-based and subdomain-based routing strategies</li> <li>Cost Effective: Open source with no licensing costs</li> <li>Well Documented: Extensive documentation, examples, and community resources</li> <li>Security Hardened: Regular security updates, CVE tracking, hardening guides available</li> <li>GitOps Friendly: Declarative YAML configuration fits ArgoCD workflow</li> <li>Learning Friendly: Simple annotation-based configuration good for dojo learners</li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#negative","title":"Negative","text":"<ol> <li>Resource Overhead: NGINX controller pods consume cluster resources (mitigated by proper sizing)</li> <li>Single Point of Failure: Requires 3+ replicas for high availability</li> <li>Configuration Complexity: Advanced features require learning NGINX-specific annotations</li> <li>Path-Based Routing Limitations: Some applications (like Mattermost) work better with subdomain routing</li> <li>Certificate Management Dependency: Requires cert-manager for automated TLS (adds complexity)</li> <li>Reload on Configuration Change: Configuration changes trigger NGINX reload (brief traffic disruption)</li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#neutral","title":"Neutral","text":"<ol> <li>Load Balancer Costs: Cloud load balancers incur costs (AWS NLB ~$16/month + data transfer)</li> <li>Monitoring Overhead: Requires Prometheus/Grafana for observability</li> <li>DNS Management: Subdomain routing requires wildcard DNS or multiple A records</li> <li>Learning Curve: Platform team must understand NGINX configuration paradigms</li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#alternative-1-traefik","title":"Alternative 1: Traefik","text":"<p>Pros: - Native Let's Encrypt integration (no cert-manager needed) - Dynamic configuration via labels - Built-in dashboard for traffic visualization - Smaller resource footprint - Excellent WebSocket support - Modern, actively developed</p> <p>Cons: - Smaller community compared to NGINX - Less enterprise adoption - More limited advanced features (rate limiting, WAF) - Documentation less comprehensive for complex scenarios - Fewer third-party integrations</p> <p>Reason for Rejection: While Traefik is excellent and modern, NGINX Ingress has broader enterprise adoption, more comprehensive documentation for complex scenarios, and better alignment with DORA best practices documentation. The larger community makes it easier for Fawkes learners to find troubleshooting resources.</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#alternative-2-istioenvoy-service-mesh","title":"Alternative 2: Istio/Envoy Service Mesh","text":"<p>Pros: - Full service mesh capabilities (mTLS, traffic management, observability) - Advanced traffic routing (A/B testing, canary, circuit breaking) - Superior observability (distributed tracing, detailed metrics) - Built-in security (zero-trust networking) - Envoy is modern, high-performance proxy</p> <p>Cons: - Significant complexity overhead (steep learning curve) - High resource consumption (sidecar for every pod) - Operational burden (control plane management, upgrades) - Overkill for ingress-only use case - Adds 6-8 weeks to MVP timeline - Too complex for learner environments</p> <p>Reason for Rejection: Service mesh capabilities are valuable but represent over-engineering for MVP. Fawkes needs ingress management, not full service mesh. Istio/Envoy can be considered post-MVP as \"Advanced Networking\" module in Brown Belt curriculum.</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#alternative-3-kong-ingress-controller","title":"Alternative 3: Kong Ingress Controller","text":"<p>Pros: - API gateway features (rate limiting, authentication, transformation) - Plugin ecosystem for extensibility - Enterprise version available with support - Good for API-heavy platforms - Lua-based customization - Built-in developer portal</p> <p>Cons: - More complex than pure ingress controller - Requires PostgreSQL for production (additional dependency) - Licensing considerations (enterprise features) - Smaller community than NGINX - API gateway features not needed for internal platform</p> <p>Reason for Rejection: Kong's strength is API management, which is not a primary Fawkes requirement. The additional complexity and PostgreSQL dependency don't provide sufficient value for our use case. NGINX provides everything we need without API gateway overhead.</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#alternative-4-haproxy-ingress","title":"Alternative 4: HAProxy Ingress","text":"<p>Pros: - Extremely high performance and efficiency - Very low resource consumption - Battle-tested load balancing capabilities - Excellent documentation - Used by major internet properties</p> <p>Cons: - Smaller Kubernetes community compared to NGINX - Less flexible annotation-based configuration - Fewer examples and tutorials for Kubernetes - Less integration with cloud-native ecosystem - Limited WebSocket support compared to NGINX</p> <p>Reason for Rejection: While HAProxy is excellent for performance-critical scenarios, NGINX Ingress provides better Kubernetes-native integration, more comprehensive documentation for learners, and broader community support. HAProxy's performance advantages are not critical for Fawkes' scale.</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#alternative-5-cloud-provider-ingress-aws-alb-gcp-gclb-azure-app-gateway","title":"Alternative 5: Cloud Provider Ingress (AWS ALB, GCP GCLB, Azure App Gateway)","text":"<p>Pros: - Native cloud integration - Managed service (no controller to maintain) - Tight security integration (IAM, security groups) - Automatic scaling - Lower operational overhead</p> <p>Cons: - Cloud vendor lock-in (violates Fawkes portability principle) - Inconsistent behavior across clouds - Limited customization compared to NGINX - Annotations differ per cloud - Cannot run on-premises or in learner laptops - Makes dojo lab provisioning cloud-specific</p> <p>Reason for Rejection: Violates core Fawkes principle of cloud portability. Learners need consistent experience across environments. Platform teams should be able to deploy Fawkes anywhere, including on-premises or local Kubernetes clusters. Cloud ingress controllers prevent this flexibility.</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#alternative-6-contour-envoy-based","title":"Alternative 6: Contour (Envoy-based)","text":"<p>Pros: - Uses Envoy proxy (modern, high-performance) - Simpler than full Istio deployment - Good HTTPProxy CRD for advanced routing - CNCF project with growing community - Excellent for multi-tenancy</p> <p>Cons: - Smaller community and ecosystem than NGINX - Less mature documentation - Fewer examples and tutorials - Less enterprise adoption - Not as feature-complete for edge use cases</p> <p>Reason for Rejection: While Contour is a good middle ground between NGINX and Istio, its smaller community and less mature documentation make it less suitable for a learning-focused platform. NGINX's extensive resources better support dojo learners troubleshooting issues independently.</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#phase-1-mvp-week-3-of-sprint-01","title":"Phase 1: MVP (Week 3 of Sprint 01)","text":"<ol> <li>Deploy NGINX Ingress Controller [4 hours]</li> <li>Install via Helm chart</li> <li>Configure for AWS NLB (or equivalent)</li> <li>Verify controller pods running</li> <li> <p>Test basic HTTP routing</p> </li> <li> <p>Deploy cert-manager [2 hours]</p> </li> <li>Install cert-manager via Helm</li> <li>Create ClusterIssuer for Let's Encrypt staging</li> <li>Test certificate provisioning</li> <li> <p>Create production ClusterIssuer</p> </li> <li> <p>Create Ingress for Backstage [2 hours]</p> </li> <li>Subdomain-based routing (backstage.fawkes.dev)</li> <li>TLS certificate from Let's Encrypt</li> <li>Force HTTPS redirect</li> <li> <p>Test end-to-end access</p> </li> <li> <p>Document Standard Ingress Pattern [2 hours]</p> </li> <li>Create ingress template for new services</li> <li>Document annotation patterns</li> <li>Create troubleshooting guide</li> <li>Add to Dojo Module 2 curriculum</li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#phase-2-core-services-weeks-4-5","title":"Phase 2: Core Services (Weeks 4-5)","text":"<ol> <li>Deploy Ingress for Collaboration Services [4 hours]</li> <li>Mattermost with WebSocket support</li> <li>Focalboard (integrated with Mattermost)</li> <li> <p>Test real-time features</p> </li> <li> <p>Deploy Ingress for CI/CD Services [4 hours]</p> </li> <li>Jenkins with authentication</li> <li>ArgoCD with SSO</li> <li> <p>Harbor with rate limiting</p> </li> <li> <p>Deploy Ingress for Observability Services [3 hours]</p> </li> <li>Grafana with OAuth2 proxy</li> <li>Prometheus (internal only, IP whitelist)</li> <li>OpenSearch dashboards</li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#phase-3-security-monitoring-week-6","title":"Phase 3: Security &amp; Monitoring (Week 6)","text":"<ol> <li>Implement Security Hardening [4 hours]</li> <li>Configure rate limiting</li> <li>Add security headers</li> <li>IP whitelisting for admin services</li> <li> <p>Test DDoS protection</p> </li> <li> <p>Configure Monitoring [3 hours]</p> </li> <li>Prometheus ServiceMonitor for NGINX metrics</li> <li>Grafana dashboard for ingress monitoring</li> <li>Alerting rules for high error rates</li> <li> <p>Log aggregation for access logs</p> </li> <li> <p>Create Dojo Lab Automation [4 hours]</p> <ul> <li>Automated ingress provisioning for learner namespaces</li> <li>Dynamic subdomain creation (learner-01.labs.fawkes.dev)</li> <li>Wildcard certificate management</li> <li>Cleanup automation</li> </ul> </li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#phase-4-documentation-training-week-7","title":"Phase 4: Documentation &amp; Training (Week 7)","text":"<ol> <li> <p>Write Comprehensive Documentation [6 hours]</p> <ul> <li>Architecture overview with diagrams</li> <li>Configuration patterns and best practices</li> <li>Troubleshooting guide (common issues)</li> <li>Security hardening checklist</li> </ul> </li> <li> <p>Create Dojo Module Content [4 hours]</p> <ul> <li>Yellow Belt Module: \"Exposing Services with Ingress\"</li> <li>Hands-on lab: Create custom ingress</li> <li>Assessment questions on TLS, routing, security</li> <li>Video walkthrough (15 minutes)</li> </ul> </li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#dojo-integration","title":"Dojo Integration","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#yellow-belt-module-4-exposing-services-with-ingress","title":"Yellow Belt - Module 4: \"Exposing Services with Ingress\"","text":"<p>Learning Objectives: - Understand Kubernetes Ingress concepts - Configure NGINX Ingress Controller - Implement TLS/SSL with cert-manager - Apply security best practices (rate limiting, headers) - Troubleshoot common ingress issues</p> <p>Hands-On Lab: 1. Deploy a sample application to learner namespace 2. Create Ingress resource with subdomain routing 3. Configure TLS certificate via cert-manager 4. Test HTTPS access and forced redirect 5. Add rate limiting and security headers 6. Monitor ingress metrics in Grafana</p> <p>Assessment: - Quiz on Ingress concepts (5 questions) - Practical: Deploy and expose a new service - Troubleshoot broken ingress configuration</p> <p>Time: 90 minutes (30 min theory + 60 min hands-on)</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#key-metrics","title":"Key Metrics","text":"<p>NGINX Ingress Controller Metrics: - <code>nginx_ingress_controller_requests</code> - Total requests per service - <code>nginx_ingress_controller_request_duration_seconds</code> - Request latency percentiles - <code>nginx_ingress_controller_response_size</code> - Response sizes - <code>nginx_ingress_controller_ssl_expire_time_seconds</code> - Certificate expiration - <code>nginx_ingress_controller_nginx_process_connections</code> - Active connections</p> <p>Grafana Dashboard Panels: 1. Request Rate (per service, per ingress) 2. Request Duration (P50, P95, P99) 3. HTTP Status Codes (2xx, 4xx, 5xx rates) 4. SSL Certificate Expiration Timeline 5. Ingress Controller Resource Usage (CPU, memory) 6. Error Rate by Service</p> <p>Alerting Rules: <pre><code>groups:\n- name: ingress_alerts\n  rules:\n  - alert: HighErrorRate\n    expr: sum(rate(nginx_ingress_controller_requests{status=~\"5..\"}[5m])) / sum(rate(nginx_ingress_controller_requests[5m])) &gt; 0.05\n    for: 5m\n    annotations:\n      summary: \"High 5xx error rate detected\"\n\n  - alert: CertificateExpiring\n    expr: (nginx_ingress_controller_ssl_expire_time_seconds - time()) / 86400 &lt; 7\n    annotations:\n      summary: \"TLS certificate expiring in less than 7 days\"\n\n  - alert: HighLatency\n    expr: histogram_quantile(0.95, nginx_ingress_controller_request_duration_seconds_bucket) &gt; 5\n    for: 10m\n    annotations:\n      summary: \"P95 latency above 5 seconds\"\n</code></pre></p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#security-considerations","title":"Security Considerations","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#tlsssl-management","title":"TLS/SSL Management","text":"<ol> <li>Certificate Rotation: cert-manager automatically renews certificates 30 days before expiration</li> <li>Protocol Enforcement: Only TLSv1.2 and TLSv1.3 allowed</li> <li>Cipher Suites: Strong ciphers only, no deprecated algorithms</li> <li>HSTS: Strict-Transport-Security header enforced</li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#rate-limiting","title":"Rate Limiting","text":"<p>Per-Service Defaults: - Public services (Backstage): 100 requests/second per IP - Internal services (Jenkins, ArgoCD): 50 requests/second per IP - Admin services (Prometheus): 10 requests/second per IP</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#ip-whitelisting","title":"IP Whitelisting","text":"<p>Sensitive services restricted to: - Corporate VPN CIDR blocks - Platform team IP ranges - CI/CD pipeline source IPs</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#web-application-firewall-waf","title":"Web Application Firewall (WAF)","text":"<p>ModSecurity integration (post-MVP): - OWASP Core Rule Set (CRS) - SQL injection prevention - XSS attack blocking - Request validation</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#cost-analysis","title":"Cost Analysis","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#aws-deployment-production","title":"AWS Deployment (Production)","text":"<p>Infrastructure: - Network Load Balancer: $16/month + $0.006/GB data transfer - EBS volumes (NGINX controller state): $8/month for 80GB - Data transfer (estimated 1TB/month): $90/month</p> <p>NGINX Controller Resources: - 3 replicas \u00d7 0.5 CPU \u00d7 $0.04/hour = $43/month - 3 replicas \u00d7 512MB RAM \u00d7 $0.005/hour = $5/month</p> <p>Total Monthly Cost: ~$162/month</p> <p>Cost Optimization: - Use AWS ALB for learner/dev environments (cheaper) - Reduce replica count in non-production - Implement caching to reduce data transfer</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#multi-environment-cost-breakdown","title":"Multi-Environment Cost Breakdown","text":"Environment Load Balancer Replicas Monthly Cost Production NLB 3 $162 Staging ALB 2 $40 Development NodePort 1 $0 Learner Labs ALB (shared) 2 $40"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#documentation-structure","title":"Documentation Structure","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#for-platform-teams","title":"For Platform Teams","text":"<ol> <li>Architecture Overview</li> <li>Request flow diagrams</li> <li>TLS termination architecture</li> <li>Certificate management workflow</li> <li> <p>Multi-environment routing strategy</p> </li> <li> <p>Deployment Guide</p> </li> <li>Helm chart installation</li> <li>Configuration recommendations</li> <li>Cloud-specific considerations</li> <li> <p>Troubleshooting common issues</p> </li> <li> <p>Operations Runbook</p> </li> <li>Certificate renewal procedures</li> <li>Ingress controller upgrades</li> <li>Scaling guidelines</li> <li>Incident response procedures</li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#for-dojo-learners","title":"For Dojo Learners","text":"<ol> <li>Concepts Tutorial</li> <li>What is an Ingress Controller?</li> <li>How TLS/SSL works</li> <li>Routing strategies comparison</li> <li> <p>Security best practices</p> </li> <li> <p>Hands-On Lab Guide</p> </li> <li>Step-by-step ingress creation</li> <li>TLS configuration walkthrough</li> <li>Troubleshooting exercises</li> <li> <p>Real-world scenarios</p> </li> <li> <p>Reference Materials</p> </li> <li>Annotation cheat sheet</li> <li>Common patterns library</li> <li>Error message decoder</li> <li>kubectl commands reference</li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#migration-path","title":"Migration Path","text":""},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#from-default-cloud-ingress","title":"From Default Cloud Ingress","text":"<p>If organizations start with cloud-native ingress:</p> <ol> <li>Week 1: Deploy NGINX Ingress alongside existing ingress</li> <li>Week 2: Migrate non-critical services to NGINX</li> <li>Week 3: Validate routing, TLS, monitoring</li> <li>Week 4: Migrate critical services with rollback plan</li> <li>Week 5: Decommission cloud ingress controller</li> </ol> <p>Rollback Strategy: Maintain both controllers for 2 weeks, allow instant DNS cutover</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#from-path-based-to-subdomain-routing","title":"From Path-Based to Subdomain Routing","text":"<ol> <li>Configure subdomain routing for new services</li> <li>Maintain path-based routing for existing services</li> <li>Gradually migrate services based on traffic patterns</li> <li>Update documentation and bookmarks</li> <li>Deprecate path-based routing after 6 months</li> </ol>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-001: Kubernetes for Container Orchestration (ingress is Kubernetes-native)</li> <li>ADR-002: Backstage for Developer Portal (primary ingress endpoint)</li> <li>ADR-009: External Secrets Operator (integrates with ingress for secrets)</li> <li>Future ADR: OAuth2 Proxy for Unified Authentication (auth layer on ingress)</li> <li>Future ADR: Service Mesh (potential Istio migration path)</li> </ul>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#references","title":"References","text":"<ul> <li>NGINX Ingress Controller Documentation: https://kubernetes.github.io/ingress-nginx/</li> <li>cert-manager Documentation: https://cert-manager.io/docs/</li> <li>CNCF Ingress Controller Comparison: https://docs.google.com/spreadsheets/d/191WWNpjJ2za6-nbG4ZoUMXMpUK8KlCIosvQB0f-oq3k</li> <li>OWASP TLS Cheat Sheet: https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html</li> <li>Kubernetes Ingress Concepts: https://kubernetes.io/docs/concepts/services-networking/ingress/</li> </ul>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#notes","title":"Notes","text":"<p>Production Readiness Checklist: - [ ] 3+ replicas for high availability - [ ] Cloud load balancer provisioned - [ ] TLS certificates from trusted CA (Let's Encrypt or corporate) - [ ] Rate limiting configured - [ ] Security headers enabled - [ ] Monitoring dashboards created - [ ] Alerting rules configured - [ ] Runbook documented - [ ] Team trained on ingress operations</p> <p>Learner Environment Considerations: - Use path-based routing to minimize DNS complexity - Provide pre-configured ingress templates - Automate certificate provisioning - Create self-service ingress creation workflow - Include ingress troubleshooting in curriculum</p>"},{"location":"adr/ADR-010%3A%20Ingress%20Controller%20for%20Service%20Access/#last-updated","title":"Last Updated","text":"<p>December 7, 2024 - Initial version documenting NGINX Ingress Controller selection</p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/","title":"ADR-011: Centralized Log Management","text":""},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#context","title":"Context","text":"<p>The Fawkes platform requires comprehensive log management for both platform services and applications deployed by teams:</p> <p>Platform Service Logs: - Kubernetes control plane (API server, scheduler, controller manager, etcd) - NGINX Ingress Controller (access logs, error logs) - ArgoCD (deployment events, sync operations, application health) - Jenkins (build logs, pipeline execution, agent activities) - Backstage (catalog operations, template scaffolding, API requests) - Mattermost (user activity, integrations, webhooks) - Harbor (registry operations, image scanning, vulnerability reports) - Grafana (dashboard access, alert notifications, data source queries) - Prometheus (scrape operations, rule evaluations, alert firing) - PostgreSQL (query logs, connection logs, errors) - External Secrets Operator (secret synchronization, errors)</p> <p>Application Logs (from teams using Fawkes): - Microservice application logs (structured and unstructured) - Container stdout/stderr - Application performance metrics - Error and exception tracking - Audit logs for security and compliance - Business event logs</p> <p>Logging Requirements: - Centralized Storage: All logs in one searchable location - Long-Term Retention: 30 days hot storage, 90+ days cold storage - Fast Search: Sub-second queries across billions of log entries - Structured Logging: Support for JSON and structured formats - Log Correlation: Trace ID correlation across services - Multi-Tenancy: Team-level log isolation and access control - Real-Time Streaming: Live log tailing for debugging - Alerting: Trigger alerts based on log patterns - Visualization: Dashboard creation from log data - Cost Efficiency: Minimize storage and compute costs</p> <p>Security &amp; Compliance Requirements: - Encryption at rest and in transit - Role-based access control (RBAC) - Audit trail of log access - PII/sensitive data masking - Retention policies for compliance (GDPR, SOC 2) - Immutable log storage (tamper-proof) - Log integrity verification</p> <p>Operational Requirements: - Cloud-agnostic (works on AWS, Azure, GCP, on-premises) - Low operational overhead (minimal maintenance) - Automatic log collection (no application code changes) - Handling high throughput (10,000+ logs/second) - Graceful degradation (buffering during outages) - Easy troubleshooting (logs about logging) - GitOps-compatible deployment</p> <p>Integration Requirements: - Kubernetes native (DaemonSet for log collection) - Prometheus metrics integration - Grafana dashboard integration - Alert manager integration - SIEM integration capabilities - OpenTelemetry compatibility</p> <p>Dojo Learning Requirements: - Simple enough for learners to understand - Clear troubleshooting workflows - Hands-on labs for log analysis - Integration with DORA metrics (deployment events, incident response)</p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#decision","title":"Decision","text":"<p>We will use OpenSearch as the centralized log storage and search engine, with Fluent Bit as the lightweight log collector.</p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Kubernetes Cluster                                            \u2502\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502  \u2502 Application  \u2502  \u2502 Application  \u2502  \u2502 Platform     \u2502        \u2502\n\u2502  \u2502 Pod          \u2502  \u2502 Pod          \u2502  \u2502 Service Pod  \u2502        \u2502\n\u2502  \u2502              \u2502  \u2502              \u2502  \u2502              \u2502        \u2502\n\u2502  \u2502 stdout/stderr\u2502  \u2502 stdout/stderr\u2502  \u2502 stdout/stderr\u2502        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502         \u2502                  \u2502                  \u2502                 \u2502\n\u2502         \u25bc                  \u25bc                  \u25bc                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502 /var/log/containers/*.log                            \u2502     \u2502\n\u2502  \u2502 (Kubernetes logs each container to host filesystem)  \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502         \u2502                                                       \u2502\n\u2502         \u25bc                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502 Fluent Bit DaemonSet (runs on every node)          \u2502      \u2502\n\u2502  \u2502 - Tail container logs                               \u2502      \u2502\n\u2502  \u2502 - Parse and enrich (add metadata)                   \u2502      \u2502\n\u2502  \u2502 - Filter and transform                              \u2502      \u2502\n\u2502  \u2502 - Buffer during outages                             \u2502      \u2502\n\u2502  \u2502 - Forward to OpenSearch                             \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502                      \u2502                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502 HTTPS (with buffering)\n                       \u2502\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  OpenSearch Cluster                                              \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Master Node       \u2502  \u2502 Master Node       \u2502  \u2502 Master Node \u2502 \u2502\n\u2502  \u2502 (Cluster mgmt)    \u2502  \u2502 (Cluster mgmt)    \u2502  \u2502 (Cluster mgmt)\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Data Node         \u2502  \u2502 Data Node         \u2502  \u2502 Data Node   \u2502 \u2502\n\u2502  \u2502 - Log storage     \u2502  \u2502 - Log storage     \u2502  \u2502 - Log storage\u2502 \u2502\n\u2502  \u2502 - Indexing        \u2502  \u2502 - Indexing        \u2502  \u2502 - Indexing  \u2502 \u2502\n\u2502  \u2502 - Query execution \u2502  \u2502 - Query execution \u2502  \u2502 - Query exec\u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                   \u2502\n\u2502  Index Management:                                                \u2502\n\u2502  - Hot tier (last 7 days): SSD storage, fast queries            \u2502\n\u2502  - Warm tier (7-30 days): HDD storage, slower queries           \u2502\n\u2502  - Cold tier (30-90 days): S3/object storage, archive           \u2502\n\u2502                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n                       \u2502 Query Interface\n                       \u2502\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Visualization &amp; Query Interfaces                                \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 OpenSearch        \u2502  \u2502 Grafana           \u2502  \u2502 CLI Tools   \u2502 \u2502\n\u2502  \u2502 Dashboards        \u2502  \u2502 (Loki datasource) \u2502  \u2502 (kubectl)   \u2502 \u2502\n\u2502  \u2502 - Log search      \u2502  \u2502 - Unified view    \u2502  \u2502             \u2502 \u2502\n\u2502  \u2502 - Dashboards      \u2502  \u2502 - Log + metrics   \u2502  \u2502             \u2502 \u2502\n\u2502  \u2502 - Alerting        \u2502  \u2502 - Correlations    \u2502  \u2502             \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#log-flow","title":"Log Flow","text":"<ol> <li>Collection: Fluent Bit DaemonSet collects logs from <code>/var/log/containers/</code></li> <li>Enrichment: Add Kubernetes metadata (namespace, pod, container, labels)</li> <li>Parsing: Parse JSON logs, multiline logs (stack traces), timestamps</li> <li>Filtering: Filter out noisy logs, health checks, debug messages (configurable)</li> <li>Buffering: Buffer logs during OpenSearch unavailability</li> <li>Forwarding: Send to OpenSearch via HTTPS with authentication</li> <li>Indexing: OpenSearch indexes logs by date and namespace</li> <li>Retention: Automatically move logs to warm/cold tiers based on age</li> <li>Querying: Users search via OpenSearch Dashboards or Grafana</li> </ol>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#opensearch-configuration","title":"OpenSearch Configuration","text":"<p>Cluster Sizing (Production): <pre><code>Master Nodes: 3 replicas\n  - CPU: 2 cores\n  - Memory: 4 GB\n  - Storage: 20 GB (minimal, only metadata)\n  - Purpose: Cluster coordination, no data\n\nData Nodes (Hot): 3 replicas\n  - CPU: 4 cores\n  - Memory: 16 GB (50% heap)\n  - Storage: 500 GB SSD\n  - Purpose: Recent logs (last 7 days)\n\nData Nodes (Warm): 2 replicas (optional for MVP)\n  - CPU: 2 cores\n  - Memory: 8 GB\n  - Storage: 1 TB HDD\n  - Purpose: Older logs (7-30 days)\n</code></pre></p> <p>Index Template: <pre><code>{\n  \"index_patterns\": [\"fawkes-logs-*\"],\n  \"template\": {\n    \"settings\": {\n      \"number_of_shards\": 3,\n      \"number_of_replicas\": 1,\n      \"index.refresh_interval\": \"30s\",\n      \"index.lifecycle.name\": \"fawkes-log-policy\"\n    },\n    \"mappings\": {\n      \"properties\": {\n        \"@timestamp\": { \"type\": \"date\" },\n        \"kubernetes\": {\n          \"properties\": {\n            \"namespace\": { \"type\": \"keyword\" },\n            \"pod_name\": { \"type\": \"keyword\" },\n            \"container_name\": { \"type\": \"keyword\" },\n            \"labels\": { \"type\": \"object\" }\n          }\n        },\n        \"log\": { \"type\": \"text\" },\n        \"level\": { \"type\": \"keyword\" },\n        \"message\": { \"type\": \"text\" },\n        \"trace_id\": { \"type\": \"keyword\" },\n        \"span_id\": { \"type\": \"keyword\" }\n      }\n    }\n  }\n}\n</code></pre></p> <p>Index Lifecycle Policy (ILM): <pre><code>{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"min_age\": \"0ms\",\n        \"actions\": {\n          \"rollover\": {\n            \"max_age\": \"1d\",\n            \"max_size\": \"50gb\"\n          }\n        }\n      },\n      \"warm\": {\n        \"min_age\": \"7d\",\n        \"actions\": {\n          \"shrink\": { \"number_of_shards\": 1 },\n          \"forcemerge\": { \"max_num_segments\": 1 }\n        }\n      },\n      \"cold\": {\n        \"min_age\": \"30d\",\n        \"actions\": {\n          \"searchable_snapshot\": {\n            \"snapshot_repository\": \"fawkes-logs-s3\"\n          }\n        }\n      },\n      \"delete\": {\n        \"min_age\": \"90d\",\n        \"actions\": {\n          \"delete\": {}\n        }\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#fluent-bit-configuration","title":"Fluent Bit Configuration","text":"<p>DaemonSet Deployment: <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluent-bit\n  namespace: fawkes-logging\nspec:\n  selector:\n    matchLabels:\n      app: fluent-bit\n  template:\n    metadata:\n      labels:\n        app: fluent-bit\n    spec:\n      serviceAccountName: fluent-bit\n      containers:\n      - name: fluent-bit\n        image: fluent/fluent-bit:2.2\n        resources:\n          limits:\n            cpu: 200m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n          readOnly: true\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: fluent-bit-config\n          mountPath: /fluent-bit/etc/\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: fluent-bit-config\n        configMap:\n          name: fluent-bit-config\n</code></pre></p> <p>Fluent Bit Pipeline Configuration: <pre><code>[SERVICE]\n    Flush         5\n    Daemon        off\n    Log_Level     info\n    Parsers_File  parsers.conf\n\n[INPUT]\n    Name              tail\n    Path              /var/log/containers/*.log\n    Parser            docker\n    Tag               kube.*\n    Refresh_Interval  5\n    Mem_Buf_Limit     5MB\n    Skip_Long_Lines   On\n\n[FILTER]\n    Name                kubernetes\n    Match               kube.*\n    Kube_URL            https://kubernetes.default.svc:443\n    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token\n    Kube_Tag_Prefix     kube.var.log.containers.\n    Merge_Log           On\n    Keep_Log            Off\n    K8S-Logging.Parser  On\n    K8S-Logging.Exclude On\n    Labels              On\n    Annotations         Off\n\n[FILTER]\n    Name         modify\n    Match        *\n    Add          cluster_name fawkes-production\n\n[FILTER]\n    Name         nest\n    Match        *\n    Operation    lift\n    Nested_under kubernetes\n    Add_prefix   k8s_\n\n[FILTER]\n    Name         grep\n    Match        *\n    Exclude      log /healthz|/readyz|/livez\n\n[OUTPUT]\n    Name            opensearch\n    Match           *\n    Host            opensearch.fawkes-logging.svc.cluster.local\n    Port            9200\n    Index           fawkes-logs\n    Type            _doc\n    Logstash_Format On\n    Logstash_Prefix fawkes-logs\n    Logstash_DateFormat %Y.%m.%d\n    Suppress_Type_Name On\n    TLS             On\n    TLS.Verify      On\n    HTTP_User       ${OPENSEARCH_USER}\n    HTTP_Passwd     ${OPENSEARCH_PASSWORD}\n    Retry_Limit     5\n    Buffer_Size     False\n</code></pre></p> <p>Parsing Configuration (parsers.conf): <pre><code>[PARSER]\n    Name         docker\n    Format       json\n    Time_Key     time\n    Time_Format  %Y-%m-%dT%H:%M:%S.%LZ\n    Time_Keep    On\n\n[PARSER]\n    Name         json\n    Format       json\n    Time_Key     timestamp\n    Time_Format  %Y-%m-%dT%H:%M:%S.%LZ\n\n[PARSER]\n    Name         java_multiline\n    Format       regex\n    Regex        /^(?&lt;time&gt;\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2}.\\d{3})\\s+(?&lt;level&gt;[A-Z]+)\\s+(?&lt;message&gt;.*)/\n    Time_Key     time\n    Time_Format  %Y-%m-%d %H:%M:%S.%L\n</code></pre></p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#multi-tenancy-access-control","title":"Multi-Tenancy &amp; Access Control","text":"<p>Namespace-Based Log Isolation: <pre><code>apiVersion: v1\nkind: Role\nmetadata:\n  name: log-reader\n  namespace: team-alpha\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"pods/log\"]\n  verbs: [\"get\", \"list\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: team-alpha-log-readers\n  namespace: team-alpha\nsubjects:\n- kind: Group\n  name: team-alpha\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: log-reader\n  apiGroup: rbac.authorization.k8s.io\n</code></pre></p> <p>OpenSearch Role-Based Access: <pre><code>{\n  \"team-alpha-logs\": {\n    \"cluster_permissions\": [],\n    \"index_permissions\": [\n      {\n        \"index_patterns\": [\"fawkes-logs-*\"],\n        \"dls\": \"{\\\"term\\\": {\\\"k8s_namespace\\\": \\\"team-alpha\\\"}}\",\n        \"fls\": [],\n        \"masked_fields\": [],\n        \"allowed_actions\": [\"read\"]\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#grafana-integration","title":"Grafana Integration","text":"<p>Loki Datasource Configuration (simulated via OpenSearch): <pre><code>apiVersion: 1\ndatasources:\n  - name: OpenSearch Logs\n    type: grafana-opensearch-datasource\n    access: proxy\n    url: http://opensearch.fawkes-logging.svc.cluster.local:9200\n    basicAuth: true\n    basicAuthUser: grafana\n    secureJsonData:\n      basicAuthPassword: ${OPENSEARCH_GRAFANA_PASSWORD}\n    jsonData:\n      timeField: \"@timestamp\"\n      esVersion: \"7.10.0\"\n      logMessageField: log\n      logLevelField: level\n      database: \"fawkes-logs-*\"\n</code></pre></p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#structured-logging-best-practices","title":"Structured Logging Best Practices","text":"<p>Recommended Log Format (JSON): <pre><code>{\n  \"@timestamp\": \"2024-12-07T10:30:00.123Z\",\n  \"level\": \"INFO\",\n  \"logger\": \"com.example.UserService\",\n  \"message\": \"User login successful\",\n  \"trace_id\": \"a1b2c3d4e5f6\",\n  \"span_id\": \"1234567890\",\n  \"user_id\": \"user-123\",\n  \"ip_address\": \"192.168.1.100\",\n  \"duration_ms\": 45,\n  \"kubernetes\": {\n    \"namespace\": \"team-alpha\",\n    \"pod\": \"user-service-abc123\",\n    \"container\": \"user-service\"\n  }\n}\n</code></pre></p> <p>Fields to Always Include: - <code>@timestamp</code>: ISO 8601 timestamp - <code>level</code>: Log level (ERROR, WARN, INFO, DEBUG) - <code>message</code>: Human-readable message - <code>trace_id</code>: Distributed tracing ID (OpenTelemetry) - <code>span_id</code>: Span ID for correlation - Context fields: user_id, request_id, correlation_id</p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#common-query-patterns","title":"Common Query Patterns","text":"<p>Search for Errors in Namespace: <pre><code>k8s_namespace:\"team-alpha\" AND level:\"ERROR\"\n</code></pre></p> <p>Find Logs with Trace ID: <pre><code>trace_id:\"a1b2c3d4e5f6\"\n</code></pre></p> <p>Logs from Specific Pod: <pre><code>k8s_pod_name:\"jenkins-agent-*\"\n</code></pre></p> <p>Slow Requests (Duration &gt; 1000ms): <pre><code>duration_ms:&gt;1000\n</code></pre></p> <p>Deployment Events: <pre><code>message:\"deployment\" AND k8s_namespace:\"production\"\n</code></pre></p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#alerting-rules","title":"Alerting Rules","text":"<p>High Error Rate: <pre><code>{\n  \"trigger\": {\n    \"schedule\": { \"interval\": \"5m\" },\n    \"condition\": {\n      \"script\": {\n        \"source\": \"ctx.results[0].hits.total.value &gt; 100\"\n      }\n    }\n  },\n  \"input\": {\n    \"search\": {\n      \"request\": {\n        \"indices\": [\"fawkes-logs-*\"],\n        \"body\": {\n          \"query\": {\n            \"bool\": {\n              \"must\": [\n                { \"term\": { \"level\": \"ERROR\" }},\n                { \"range\": { \"@timestamp\": { \"gte\": \"now-5m\" }}}\n              ]\n            }\n          }\n        }\n      }\n    }\n  },\n  \"actions\": {\n    \"slack\": {\n      \"webhook\": {\n        \"url\": \"https://hooks.slack.com/...\",\n        \"body\": \"High error rate detected: {{ctx.results.0.hits.total.value}} errors in last 5 minutes\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Service Unavailable: <pre><code>{\n  \"trigger\": {\n    \"schedule\": { \"interval\": \"1m\" },\n    \"condition\": {\n      \"script\": {\n        \"source\": \"ctx.results[0].hits.total.value &gt; 0\"\n      }\n    }\n  },\n  \"input\": {\n    \"search\": {\n      \"request\": {\n        \"indices\": [\"fawkes-logs-*\"],\n        \"body\": {\n          \"query\": {\n            \"bool\": {\n              \"must\": [\n                { \"match\": { \"message\": \"connection refused\" }},\n                { \"term\": { \"k8s_namespace\": \"production\" }},\n                { \"range\": { \"@timestamp\": { \"gte\": \"now-1m\" }}}\n              ]\n            }\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#positive","title":"Positive","text":"<ol> <li>Cloud Agnostic: OpenSearch works identically across AWS, Azure, GCP, on-premises</li> <li>Open Source: No licensing costs, Apache 2.0 license, community-driven</li> <li>Scalable: Handles billions of log entries, horizontal scaling via data nodes</li> <li>Fast Search: Sub-second queries across large datasets, optimized inverted indices</li> <li>Rich Query Language: SQL and DSL query support, aggregations, complex filters</li> <li>Multi-Tenancy: Document-level security for team isolation</li> <li>Cost Efficient: Tiered storage (hot/warm/cold) reduces costs significantly</li> <li>Integration Rich: Grafana, Prometheus, SIEM tools, OpenTelemetry</li> <li>Lightweight Collection: Fluent Bit minimal resource footprint (~100MB memory)</li> <li>GitOps Compatible: Declarative configuration, ArgoCD-managed</li> </ol>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#negative","title":"Negative","text":"<ol> <li>Operational Complexity: OpenSearch cluster requires careful sizing, monitoring, tuning</li> <li>Resource Intensive: Data nodes need significant CPU/memory/storage</li> <li>Learning Curve: Query DSL, index management, cluster operations require training</li> <li>Index Management Overhead: Need to configure ILM policies, monitor shard distribution</li> <li>No Native Multi-Line Support: Requires Fluent Bit parser configuration</li> <li>Storage Costs: Hot storage on SSD can be expensive (mitigated by tiered storage)</li> <li>Backup Complexity: Snapshot repository setup, restoration testing required</li> </ol>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#neutral","title":"Neutral","text":"<ol> <li>Elasticsearch Compatibility: OpenSearch fork maintains compatibility (mostly)</li> <li>Alternative to ELK: Uses OpenSearch instead of Elasticsearch (licensing differences)</li> <li>Dashboards vs. Kibana: OpenSearch Dashboards UI similar to Kibana</li> <li>S3 Cold Storage: Requires object storage configuration for cold tier</li> </ol>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#alternative-1-grafana-loki","title":"Alternative 1: Grafana Loki","text":"<p>Pros: - Designed for Kubernetes logging (cloud-native) - Very cost-efficient (indexes only metadata, not log content) - Tight Grafana integration (unified metrics + logs) - Simple deployment and operation - LogQL query language (similar to PromQL) - Good for high-volume, short-retention use cases</p> <p>Cons: - Limited full-text search capabilities (no inverted index) - Less powerful query language than OpenSearch DSL - Smaller community and ecosystem than OpenSearch/Elasticsearch - Less suitable for compliance (long-term retention, complex queries) - Fewer visualization options in dashboards - Multi-tenancy requires Loki enterprise features</p> <p>Reason for Rejection: While Loki is excellent for operational logging, Fawkes requires robust full-text search for debugging, compliance auditing, and security investigations. OpenSearch's powerful query DSL and proven scalability better support DORA metrics analysis and incident post-mortems. However, Loki remains a strong alternative for cost-sensitive deployments.</p>"},{"location":"adr/ADR-011%20Centralized%20Log%20Management/#alternative-2-elastic-cloud-elk-stack","title":"Alternative 2: Elastic Cloud (ELK Stack)","text":"<p>Pros: - Industry standard (Elasticsearch, Logstash, Kibana) - Massive ecosystem and community - Extremely powerful search and analytics - Best-in-class visualization (Kibana) - Mature machine learning features - Extensive documentation and training</p> <p>Cons: - Licensing concerns (Elastic License 2.0, not fully open source) - High cost for managed service ($50-500+/month) - Vendor lock-in potential - Self-hosted ELK requires significant operational expertise - Logstash resource-heavy (replaced by Fluent Bit in modern stacks) - Complex licensing tiers (basic, gold, platinum)</p> <p>Reason for Rejection: Elastic's move away from Apache 2.0 license conflicts with Fawkes' open-source principles. O</p>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/","title":"ADR-012: Metrics Monitoring and Management","text":""},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#context","title":"Context","text":"<p>The Fawkes platform requires comprehensive metrics monitoring to support multiple critical use cases:</p> <p>Platform Monitoring Needs: - Kubernetes cluster health (nodes, pods, deployments, resource utilization) - Core service availability (Backstage, ArgoCD, Jenkins, Mattermost, Focalboard, Harbor) - Infrastructure performance (CPU, memory, disk, network across all nodes) - Service-level indicators (SLIs) for platform components - Capacity planning data (growth trends, resource forecasting) - Cost allocation and optimization metrics</p> <p>DORA Metrics Requirements (Core Platform Value Proposition): - Deployment Frequency: Deployments per day/week/month by team - Lead Time for Changes: Time from commit to production deployment - Change Failure Rate: Percentage of deployments causing incidents - Time to Restore Service: Mean time to recovery (MTTR) from incidents</p> <p>Application Monitoring Needs: - Application-specific metrics (request rates, latency, error rates) - Custom business metrics defined by teams - Service dependency mapping - Distributed tracing correlation - Database performance metrics - Message queue depths and processing rates</p> <p>Developer Experience Metrics: - Build duration (P50, P95, P99 percentiles) - Pipeline success/failure rates - Time spent in code review - Environment provisioning time - Developer onboarding time</p> <p>Security &amp; Compliance Metrics: - Failed authentication attempts - Privileged access usage - Security scan results over time - Vulnerability remediation time - Certificate expiration tracking</p> <p>Learner/Dojo Metrics: - Lab environment resource usage - Module completion times - Assessment success rates - Active learners by belt level - Infrastructure costs per learner</p> <p>Technical Requirements: - Multi-dimensional metrics (labels/tags for filtering) - Long-term retention (13+ months for year-over-year analysis) - High cardinality support (per-team, per-service, per-environment) - PromQL-compatible query language for flexibility - Alert rule engine with notification routing - Horizontal scalability for growing metric volumes - Multi-tenancy (team-level metric isolation) - Integration with Kubernetes service discovery - Support for push and pull metric collection models</p> <p>Operational Requirements: - Self-service dashboarding for teams - Alerting without constant platform team intervention - Backup and disaster recovery - Low operational overhead - Works across cloud providers and on-premises - GitOps-compatible configuration - Cost-effective at scale</p> <p>Integration Requirements: - Native Kubernetes integration (kube-state-metrics, node-exporter) - OpenTelemetry compatibility - Grafana for visualization - Jenkins, ArgoCD, Backstage metrics exporters - Custom application instrumentation (Go, Java, Python, Node.js) - Webhook receivers for DORA metrics calculation</p>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#decision","title":"Decision","text":"<p>We will use Prometheus as the core metrics collection and storage engine, deployed via the kube-prometheus-stack Helm chart, with Thanos for long-term storage and multi-cluster querying.</p>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Metrics Sources                                                 \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502  \u2502 Kubernetes  \u2502  \u2502 Platform    \u2502  \u2502 Application \u2502            \u2502\n\u2502  \u2502 Cluster     \u2502  \u2502 Services    \u2502  \u2502 Services    \u2502            \u2502\n\u2502  \u2502             \u2502  \u2502             \u2502  \u2502             \u2502            \u2502\n\u2502  \u2502 \u2022 Nodes     \u2502  \u2502 \u2022 ArgoCD    \u2502  \u2502 \u2022 Custom    \u2502            \u2502\n\u2502  \u2502 \u2022 Pods      \u2502  \u2502 \u2022 Jenkins   \u2502  \u2502   metrics   \u2502            \u2502\n\u2502  \u2502 \u2022 Services  \u2502  \u2502 \u2022 Backstage \u2502  \u2502 \u2022 Business  \u2502            \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502         \u2502                 \u2502                 \u2502                    \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                           \u2502                                       \u2502\n\u2502                           \u2502 /metrics endpoints (pull)             \u2502\n\u2502                           \u2502                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Prometheus Federation Layer                                     \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 kube-prometheus-stack                                     \u2502   \u2502\n\u2502  \u2502                                                            \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502   \u2502\n\u2502  \u2502  \u2502 Prometheus \u2502  \u2502 Prometheus \u2502  \u2502 Prometheus \u2502         \u2502   \u2502\n\u2502  \u2502  \u2502 (Core)     \u2502  \u2502 (Apps)     \u2502  \u2502 (Learner)  \u2502         \u2502   \u2502\n\u2502  \u2502  \u2502            \u2502  \u2502            \u2502  \u2502            \u2502         \u2502   \u2502\n\u2502  \u2502  \u2502 Platform   \u2502  \u2502 Application\u2502  \u2502 Dojo Labs  \u2502         \u2502   \u2502\n\u2502  \u2502  \u2502 metrics    \u2502  \u2502 metrics    \u2502  \u2502 metrics    \u2502         \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502   \u2502\n\u2502  \u2502        \u2502               \u2502               \u2502                 \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502           \u2502               \u2502               \u2502                     \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502                           \u2502                                       \u2502\n\u2502                           \u2502 Remote Write                          \u2502\n\u2502                           \u25bc                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 Thanos (Long-term Storage)                                \u2502   \u2502\n\u2502  \u2502                                                            \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502   \u2502\n\u2502  \u2502  \u2502 Thanos     \u2502  \u2502 Thanos     \u2502  \u2502 Thanos     \u2502         \u2502   \u2502\n\u2502  \u2502  \u2502 Sidecar    \u2502  \u2502 Store      \u2502  \u2502 Compactor  \u2502         \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502   \u2502\n\u2502  \u2502                                                            \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u2502   \u2502\n\u2502  \u2502  \u2502 Thanos     \u2502  \u2502 Object     \u2502                          \u2502   \u2502\n\u2502  \u2502  \u2502 Query      \u2502  \u2502 Storage    \u2502                          \u2502   \u2502\n\u2502  \u2502  \u2502            \u2502  \u2502 (S3/GCS)   \u2502                          \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502           \u2502                                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502 Query API\n            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Visualization &amp; Alerting                                        \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502  \u2502 Grafana    \u2502  \u2502 Alert      \u2502  \u2502 DORA       \u2502                \u2502\n\u2502  \u2502 Dashboards \u2502  \u2502 Manager    \u2502  \u2502 Metrics    \u2502                \u2502\n\u2502  \u2502            \u2502  \u2502            \u2502  \u2502 Service    \u2502                \u2502\n\u2502  \u2502 \u2022 Platform \u2502  \u2502 \u2022 Routing  \u2502  \u2502            \u2502                \u2502\n\u2502  \u2502 \u2022 DORA     \u2502  \u2502 \u2022 Silencing\u2502  \u2502 Custom     \u2502                \u2502\n\u2502  \u2502 \u2022 Apps     \u2502  \u2502 \u2022 Grouping \u2502  \u2502 aggregator \u2502                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Notification Channels                                           \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502  \u2502 Mattermost \u2502  \u2502 Email      \u2502  \u2502 PagerDuty  \u2502                \u2502\n\u2502  \u2502 (Primary)  \u2502  \u2502            \u2502  \u2502 (Critical) \u2502                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#component-breakdown","title":"Component Breakdown","text":"<p>1. Prometheus Core (kube-prometheus-stack) - Prometheus Server: Metrics collection and short-term storage (15-30 days) - Prometheus Operator: Manages Prometheus instances via CRDs - kube-state-metrics: Kubernetes object state metrics - node-exporter: Node-level system metrics (CPU, memory, disk, network) - Alertmanager: Alert routing, grouping, and notification - Grafana: Pre-configured dashboards and visualization</p> <p>2. Thanos (Long-term Storage &amp; Global Query) - Thanos Sidecar: Uploads Prometheus data to object storage - Thanos Store Gateway: Queries historical data from object storage - Thanos Query: Provides global query interface across all Prometheus instances - Thanos Compactor: Downsamples and compacts historical data - Thanos Ruler: Evaluates recording rules on historical data</p> <p>3. Service Monitors (Automated Discovery) Kubernetes-native ServiceMonitor CRDs for automatic metric collection: - Platform services (ArgoCD, Jenkins, Backstage, Harbor, etc.) - Application services (auto-discovered via labels) - Custom exporters (database, message queue, etc.)</p> <p>4. DORA Metrics Service Custom microservice for DORA metrics calculation: - Receives webhooks from Git, CI/CD, incident management - Calculates and exposes the 4 key metrics as Prometheus metrics - Stores raw event data for audit and recalculation - Provides team-level aggregation</p>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#deployment-strategy","title":"Deployment Strategy","text":"<p>Multi-Prometheus Architecture:</p> <ol> <li>Prometheus-Core (fawkes-monitoring namespace)</li> <li>Platform infrastructure metrics</li> <li>Kubernetes cluster metrics</li> <li>Core service metrics (ArgoCD, Jenkins, Backstage)</li> <li> <p>Retention: 30 days local, unlimited in Thanos</p> </li> <li> <p>Prometheus-Apps (fawkes-monitoring namespace)</p> </li> <li>Application team metrics</li> <li>Custom business metrics</li> <li>Tenant-scoped via namespace labels</li> <li> <p>Retention: 15 days local, unlimited in Thanos</p> </li> <li> <p>Prometheus-Learner (fawkes-dojo namespace)</p> </li> <li>Dojo lab environment metrics</li> <li>Learner activity tracking</li> <li>Resource usage per learner</li> <li>Retention: 7 days local, 90 days in Thanos</li> </ol> <p>Federation: Thanos Query provides unified interface across all Prometheus instances</p>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#example-configurations","title":"Example Configurations","text":"<p>ServiceMonitor for ArgoCD: <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: argocd-metrics\n  namespace: fawkes-cicd\n  labels:\n    app: argocd\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n</code></pre></p> <p>PrometheusRule for Platform Alerts: <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: platform-alerts\n  namespace: fawkes-monitoring\nspec:\n  groups:\n  - name: platform\n    interval: 30s\n    rules:\n    - alert: PlatformServiceDown\n      expr: up{job=~\"argocd|jenkins|backstage\"} == 0\n      for: 5m\n      labels:\n        severity: critical\n        team: platform\n      annotations:\n        summary: \"Platform service {{ $labels.job }} is down\"\n        description: \"{{ $labels.job }} has been unavailable for 5 minutes\"\n        runbook_url: \"https://docs.fawkes.io/runbooks/service-down\"\n\n    - alert: HighMemoryUsage\n      expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes &gt; 0.85\n      for: 10m\n      labels:\n        severity: warning\n        team: platform\n      annotations:\n        summary: \"High memory usage on {{ $labels.instance }}\"\n        description: \"Memory usage is above 85% for 10 minutes\"\n\n    - alert: PodCrashLooping\n      expr: rate(kube_pod_container_status_restarts_total[15m]) &gt; 0\n      for: 15m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping\"\n</code></pre></p> <p>DORA Metrics Recording Rules: <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: dora-metrics\n  namespace: fawkes-monitoring\nspec:\n  groups:\n  - name: dora_deployment_frequency\n    interval: 1m\n    rules:\n    - record: fawkes:dora:deployment_frequency:per_day\n      expr: |\n        sum(rate(fawkes_deployment_total[24h])) by (team, environment)\n\n  - name: dora_lead_time\n    interval: 1m\n    rules:\n    - record: fawkes:dora:lead_time_seconds:p50\n      expr: |\n        histogram_quantile(0.50, \n          sum(rate(fawkes_lead_time_seconds_bucket[1h])) by (team, le))\n\n    - record: fawkes:dora:lead_time_seconds:p95\n      expr: |\n        histogram_quantile(0.95, \n          sum(rate(fawkes_lead_time_seconds_bucket[1h])) by (team, le))\n\n  - name: dora_change_failure_rate\n    interval: 5m\n    rules:\n    - record: fawkes:dora:change_failure_rate\n      expr: |\n        sum(rate(fawkes_deployment_failed_total[7d])) by (team) \n        / \n        sum(rate(fawkes_deployment_total[7d])) by (team)\n\n  - name: dora_mttr\n    interval: 5m\n    rules:\n    - record: fawkes:dora:mttr_seconds:median\n      expr: |\n        histogram_quantile(0.50, \n          sum(rate(fawkes_incident_resolution_seconds_bucket[7d])) by (team, le))\n</code></pre></p> <p>Thanos Configuration: <pre><code># thanos-storage-secret.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: thanos-objstore-config\n  namespace: fawkes-monitoring\nstringData:\n  objstore.yml: |\n    type: S3\n    config:\n      bucket: fawkes-metrics-storage\n      endpoint: s3.us-west-2.amazonaws.com\n      region: us-west-2\n      access_key: ${AWS_ACCESS_KEY_ID}\n      secret_key: ${AWS_SECRET_ACCESS_KEY}\n</code></pre></p> <pre><code># prometheus-with-thanos.yaml\napiVersion: monitoring.coreos.com/v1\nkind: Prometheus\nmetadata:\n  name: prometheus-core\n  namespace: fawkes-monitoring\nspec:\n  replicas: 2\n  retention: 30d\n  retentionSize: 50GB\n\n  resources:\n    requests:\n      cpu: 500m\n      memory: 2Gi\n    limits:\n      cpu: 2000m\n      memory: 8Gi\n\n  storageSpec:\n    volumeClaimTemplate:\n      spec:\n        accessModes: [\"ReadWriteOnce\"]\n        resources:\n          requests:\n            storage: 100Gi\n\n  thanos:\n    version: v0.32.5\n    objectStorageConfig:\n      key: objstore.yml\n      name: thanos-objstore-config\n\n  serviceMonitorSelector:\n    matchLabels:\n      prometheus: core\n\n  podMonitorSelector:\n    matchLabels:\n      prometheus: core\n\n  ruleSelector:\n    matchLabels:\n      prometheus: core\n</code></pre>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#grafana-dashboard-strategy","title":"Grafana Dashboard Strategy","text":"<p>Pre-configured Dashboards (Included in MVP):</p> <ol> <li>Platform Overview Dashboard</li> <li>Cluster resource utilization (CPU, memory, disk)</li> <li>Node health status</li> <li>Pod count by namespace</li> <li>Top resource consumers</li> <li> <p>Alert summary</p> </li> <li> <p>DORA Metrics Dashboard</p> </li> <li>4 key metrics with benchmark comparison</li> <li>Team-level breakdown</li> <li>Trend analysis (7d, 30d, 90d)</li> <li>Elite/High/Medium/Low performer classification</li> <li> <p>Deployment calendar heatmap</p> </li> <li> <p>Service Health Dashboard</p> </li> <li>Service availability (uptime %)</li> <li>Request rate, latency (P50, P95, P99)</li> <li>Error rate (4xx, 5xx)</li> <li>Saturation metrics</li> <li> <p>Dependency map</p> </li> <li> <p>Kubernetes Cluster Dashboard</p> </li> <li>Node resource usage</li> <li>Pod status distribution</li> <li>Persistent volume usage</li> <li>Network I/O</li> <li> <p>API server performance</p> </li> <li> <p>CI/CD Pipeline Dashboard</p> </li> <li>Build duration trends</li> <li>Success/failure rates</li> <li>Queue depth and wait time</li> <li>Test coverage trends</li> <li> <p>Deployment frequency</p> </li> <li> <p>Cost Allocation Dashboard</p> </li> <li>Resource costs by team/namespace</li> <li>Over-provisioned resources</li> <li>Idle resource identification</li> <li>Cost trends and forecasting</li> </ol> <p>Self-Service Dashboarding: - Teams can create custom dashboards using Grafana UI - Dashboard-as-code via ConfigMaps for GitOps - Dashboard templates for common patterns - Export/import for sharing across teams</p>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#dora-metrics-service-architecture","title":"DORA Metrics Service Architecture","text":"<p>Custom Go microservice for DORA metrics calculation:</p> <p>Components: 1. Webhook Receiver: Accepts events from Git, CI/CD, incident management 2. Event Store: PostgreSQL database for raw event storage 3. Metrics Calculator: Aggregates events into DORA metrics 4. Prometheus Exporter: Exposes metrics on /metrics endpoint 5. REST API: Provides historical data and drill-down capabilities</p> <p>Event Types: - <code>commit</code> - Git commit with author, timestamp, repository - <code>build_started</code> - CI pipeline initiated - <code>build_completed</code> - CI pipeline finished (success/failure) - <code>deployment_started</code> - Deployment initiated - <code>deployment_completed</code> - Deployment finished (success/failure) - <code>incident_created</code> - Production incident reported - <code>incident_resolved</code> - Incident closed</p> <p>Metrics Exposed: <pre><code># Deployment Frequency\nfawkes_deployment_total{team=\"teamA\",environment=\"production\"} 45\n\n# Lead Time (histogram)\nfawkes_lead_time_seconds_bucket{team=\"teamA\",le=\"3600\"} 30\nfawkes_lead_time_seconds_bucket{team=\"teamA\",le=\"7200\"} 50\nfawkes_lead_time_seconds_sum{team=\"teamA\"} 180000\nfawkes_lead_time_seconds_count{team=\"teamA\"} 75\n\n# Change Failure Rate\nfawkes_deployment_failed_total{team=\"teamA\",environment=\"production\"} 5\n\n# MTTR (histogram)\nfawkes_incident_resolution_seconds_bucket{team=\"teamA\",le=\"1800\"} 12\nfawkes_incident_resolution_seconds_bucket{team=\"teamA\",le=\"3600\"} 18\nfawkes_incident_resolution_seconds_sum{team=\"teamA\"} 54000\nfawkes_incident_resolution_seconds_count{team=\"teamA\"} 20\n</code></pre></p> <p>API Endpoints: - <code>POST /webhook/commit</code> - Receive Git commit events - <code>POST /webhook/build</code> - Receive CI build events - <code>POST /webhook/deployment</code> - Receive deployment events - <code>POST /webhook/incident</code> - Receive incident events - <code>GET /metrics</code> - Prometheus metrics endpoint - <code>GET /api/v1/dora/{team}</code> - DORA metrics for specific team - <code>GET /api/v1/deployments/{team}</code> - Deployment history</p>"},{"location":"adr/ADR-012%20Metrics%20Monitoring%20and%20Management/#application-instrumentation","title":"Application Instrumentation","text":"<p>Supported Languages (Client Libraries): - Go: <code>prometheus/client_golang</code> - Java: <code>micrometer</code> with Prometheus registry - Python: <code>prometheus_client</code> - Node.js: <code>prom-client</code> - .NET: <code>prometheus-net</code></p> <p>Standard Metrics (RED Method): - **Rate</p>"},{"location":"adr/ADR-013%20distributed%20tracing/","title":"ADR-013: Distributed Tracing for Platform and Applications","text":""},{"location":"adr/ADR-013%20distributed%20tracing/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#context","title":"Context","text":"<p>The Fawkes platform consists of multiple interconnected services where a single user request may traverse numerous components:</p> <p>Platform Request Flows: - Developer Portal Access: User \u2192 NGINX Ingress \u2192 Backstage \u2192 PostgreSQL \u2192 GitHub API \u2192 ArgoCD API - CI/CD Pipeline: Git Push \u2192 Jenkins Webhook \u2192 Jenkins Build \u2192 Harbor Push \u2192 ArgoCD Sync \u2192 Kubernetes Deployment - Dojo Learning: User \u2192 Backstage \u2192 Lab Provisioning Service \u2192 Terraform \u2192 AWS API \u2192 Kubernetes API - Collaboration: User \u2192 Mattermost \u2192 PostgreSQL \u2192 S3 (file storage) \u2192 Elasticsearch (search) - Deployment: Developer \u2192 ArgoCD UI \u2192 Kubernetes API \u2192 Application Pods \u2192 Database</p> <p>Application Request Flows: - Microservice architectures with service-to-service calls - Database queries across multiple services - External API integrations - Message queue processing - Asynchronous job execution</p> <p>Troubleshooting Challenges Without Tracing: - Latency Attribution: \"Why is this request slow?\" - Which service is the bottleneck? - Error Root Cause: \"Where did this error originate?\" - Which service in the chain failed? - Dependency Mapping: \"What services does this request touch?\" - Understanding call paths - Performance Optimization: \"Which database queries are slow?\" - Query-level visibility - Cascading Failures: \"Why are all services degraded?\" - Tracing failure propagation - Cross-Team Debugging: Multiple teams own services in a request path</p> <p>DORA Metrics Requirements: - Lead Time for Changes: Trace deployment pipeline from commit to production - Change Failure Rate: Correlate failed deployments with application errors - Mean Time to Recovery: Quickly identify root cause of incidents - Deployment Frequency: Understand deployment pipeline performance</p> <p>Technical Requirements: - Support for multiple programming languages (Java, Python, Node.js, Go) - Low overhead (&lt;5% CPU, &lt;100MB memory per service) - Sampling strategies to control data volume - Integration with existing observability (metrics, logs) - Correlation IDs linking traces to logs - Support for synchronous and asynchronous operations - Trace context propagation across HTTP, gRPC, message queues - Long-term trace storage for trend analysis - Real-time trace querying for active troubleshooting</p> <p>Operational Requirements: - Automatic instrumentation where possible (minimal code changes) - Manual instrumentation for custom spans - Scalable backend (handle 100K+ spans/second) - Data retention policy (7 days detailed, 30 days sampled, 90 days aggregated) - Multi-tenancy (namespace/team isolation) - Integration with Grafana for visualization - Alert on trace-based SLIs (P95 latency, error rates)</p> <p>Security Requirements: - Sensitive data scrubbing (PII, credentials) - Access control for trace data - Encryption in transit and at rest - Compliance with data retention policies</p> <p>Learning &amp; Dojo Requirements: - Learners should understand distributed tracing concepts - Hands-on labs demonstrating tracing implementation - Troubleshooting exercises using traces - Integration with Brown Belt (Observability &amp; SRE) curriculum</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#decision","title":"Decision","text":"<p>We will use Grafana Tempo as the distributed tracing backend, integrated with OpenTelemetry for instrumentation and trace collection.</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Applications &amp; Platform Services                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Backstage  \u2502  \u2502 Jenkins    \u2502  \u2502 ArgoCD     \u2502  \u2502 Custom   \u2502  \u2502\n\u2502  \u2502 (Node.js)  \u2502  \u2502 (Java)     \u2502  \u2502 (Go)       \u2502  \u2502 Apps     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502        \u2502               \u2502               \u2502              \u2502         \u2502\n\u2502        \u2502 OpenTelemetry SDK instrumentation           \u2502         \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                              \u2502                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502 OTLP (gRPC/HTTP)\n                               \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Kubernetes Cluster          \u2502                                   \u2502\n\u2502                              \u25bc                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502  \u2502 OpenTelemetry Collector (DaemonSet/Deployment) \u2502             \u2502\n\u2502  \u2502 - Receives traces via OTLP                     \u2502             \u2502\n\u2502  \u2502 - Batching and buffering                       \u2502             \u2502\n\u2502  \u2502 - Sampling strategies                          \u2502             \u2502\n\u2502  \u2502 - Tail-based sampling (intelligent)            \u2502             \u2502\n\u2502  \u2502 - Attribute processing and enrichment          \u2502             \u2502\n\u2502  \u2502 - Sensitive data scrubbing                     \u2502             \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2502                         \u2502                                        \u2502\n\u2502                         \u25bc                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502  \u2502 Grafana Tempo (Trace Storage)        \u2502                       \u2502\n\u2502  \u2502 - Object storage backend (S3/MinIO)  \u2502                       \u2502\n\u2502  \u2502 - Block-based columnar storage       \u2502                       \u2502\n\u2502  \u2502 - TraceQL query language             \u2502                       \u2502\n\u2502  \u2502 - Multi-tenancy support              \u2502                       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                         \u2502                                        \u2502\n\u2502                         \u25bc                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502  \u2502 Grafana (Visualization)              \u2502                       \u2502\n\u2502  \u2502 - Trace search and visualization     \u2502                       \u2502\n\u2502  \u2502 - Trace-to-logs correlation          \u2502                       \u2502\n\u2502  \u2502 - Trace-to-metrics correlation       \u2502                       \u2502\n\u2502  \u2502 - Service dependency graphs          \u2502                       \u2502\n\u2502  \u2502 - RED metrics from traces            \u2502                       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Integration with Observability Stack                            \u2502\n\u2502                                                                   \u2502\n\u2502  Tempo \u2190\u2192 Prometheus (Exemplars link metrics to traces)         \u2502\n\u2502  Tempo \u2190\u2192 Loki (Trace IDs in logs for correlation)              \u2502\n\u2502  Tempo \u2190\u2192 Grafana (Unified visualization)                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-013%20distributed%20tracing/#technology-stack","title":"Technology Stack","text":"<p>Instrumentation: OpenTelemetry SDKs - Java: <code>opentelemetry-java-instrumentation</code> (auto-instrumentation agent) - Python: <code>opentelemetry-distro</code> with <code>opentelemetry-instrumentation</code> - Node.js: <code>@opentelemetry/sdk-node</code> with auto-instrumentation - Go: <code>go.opentelemetry.io/otel</code> with manual instrumentation</p> <p>Collection: OpenTelemetry Collector - Deployed as DaemonSet (node-level collection) - Deployed as Deployment (centralized processing) - OTLP receivers (gRPC and HTTP) - Tail-based sampling processor - Batch processor for efficiency</p> <p>Storage: Grafana Tempo - Backend: S3-compatible object storage (AWS S3, MinIO) - Retention: 7 days full detail, 30 days sampled - Compression: Snappy/LZ4 for cost efficiency - Ingestion rate: 100K+ spans/second</p> <p>Visualization: Grafana - Tempo data source integration - TraceQL query builder - Node graph visualization - Trace comparison tools</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#opentelemetry-instrumentation-strategy","title":"OpenTelemetry Instrumentation Strategy","text":"<p>Automatic Instrumentation (Preferred for rapid adoption):</p> <p>Java Applications (Jenkins plugins, Spring Boot apps): <pre><code># Download OpenTelemetry Java agent\nwget https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar\n\n# Add to JVM arguments\njava -javaagent:opentelemetry-javaagent.jar \\\n     -Dotel.service.name=jenkins \\\n     -Dotel.exporter.otlp.endpoint=http://otel-collector:4317 \\\n     -jar jenkins.war\n</code></pre></p> <p>Python Applications (FastAPI, Django): <pre><code># Install OpenTelemetry distro\npip install opentelemetry-distro opentelemetry-exporter-otlp\n\n# Auto-instrument\nopentelemetry-bootstrap -a install\nopentelemetry-instrument \\\n  --service_name my-python-app \\\n  --exporter_otlp_endpoint http://otel-collector:4317 \\\n  python app.py\n</code></pre></p> <p>Node.js Applications (Backstage, Express): <pre><code>// app.js - Add at the very top\nconst { NodeSDK } = require('@opentelemetry/sdk-node');\nconst { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-http');\nconst { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');\n\nconst sdk = new NodeSDK({\n  serviceName: 'backstage',\n  traceExporter: new OTLPTraceExporter({\n    url: 'http://otel-collector:4318/v1/traces',\n  }),\n  instrumentations: [getNodeAutoInstrumentations()],\n});\n\nsdk.start();\n</code></pre></p> <p>Manual Instrumentation (For custom spans):</p> <p>Go Example (ArgoCD, custom controllers): <pre><code>import (\n    \"go.opentelemetry.io/otel\"\n    \"go.opentelemetry.io/otel/trace\"\n)\n\nfunc processDeployment(ctx context.Context, app string) error {\n    tracer := otel.Tracer(\"argocd\")\n    ctx, span := tracer.Start(ctx, \"process-deployment\",\n        trace.WithAttributes(\n            attribute.String(\"app.name\", app),\n            attribute.String(\"namespace\", \"default\"),\n        ),\n    )\n    defer span.End()\n\n    // Business logic here\n    if err := syncApplication(ctx, app); err != nil {\n        span.RecordError(err)\n        span.SetStatus(codes.Error, err.Error())\n        return err\n    }\n\n    return nil\n}\n</code></pre></p>"},{"location":"adr/ADR-013%20distributed%20tracing/#opentelemetry-collector-configuration","title":"OpenTelemetry Collector Configuration","text":"<p>DaemonSet Deployment (for application traces): <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: otel-collector-config\n  namespace: fawkes-observability\ndata:\n  config.yaml: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n            endpoint: 0.0.0.0:4317\n          http:\n            endpoint: 0.0.0.0:4318\n\n    processors:\n      batch:\n        timeout: 10s\n        send_batch_size: 1024\n\n      # Tail-based sampling - keep all errors, sample successes\n      tail_sampling:\n        decision_wait: 10s\n        num_traces: 100\n        expected_new_traces_per_sec: 10\n        policies:\n          - name: errors\n            type: status_code\n            status_code: {status_codes: [ERROR]}\n          - name: slow-requests\n            type: latency\n            latency: {threshold_ms: 1000}\n          - name: probabilistic-sampling\n            type: probabilistic\n            probabilistic: {sampling_percentage: 10}\n\n      # Add Kubernetes metadata\n      k8sattributes:\n        auth_type: \"serviceAccount\"\n        passthrough: false\n        extract:\n          metadata:\n            - k8s.pod.name\n            - k8s.pod.uid\n            - k8s.deployment.name\n            - k8s.namespace.name\n            - k8s.node.name\n\n      # Scrub sensitive data\n      attributes:\n        actions:\n          - key: http.request.header.authorization\n            action: delete\n          - key: http.request.header.cookie\n            action: delete\n          - key: db.statement\n            action: hash\n\n    exporters:\n      otlp:\n        endpoint: tempo:4317\n        tls:\n          insecure: true\n\n      # Also export to Prometheus for exemplars\n      prometheus:\n        endpoint: 0.0.0.0:8889\n\n    service:\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: [k8sattributes, tail_sampling, attributes, batch]\n          exporters: [otlp]\n\n        metrics:\n          receivers: [otlp]\n          processors: [batch]\n          exporters: [prometheus]\n</code></pre></p>"},{"location":"adr/ADR-013%20distributed%20tracing/#grafana-tempo-configuration","title":"Grafana Tempo Configuration","text":"<p>Deployment Manifest: <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: tempo-config\n  namespace: fawkes-observability\ndata:\n  tempo.yaml: |\n    server:\n      http_listen_port: 3200\n\n    distributor:\n      receivers:\n        otlp:\n          protocols:\n            grpc:\n              endpoint: 0.0.0.0:4317\n            http:\n              endpoint: 0.0.0.0:4318\n\n    ingester:\n      trace_idle_period: 10s\n      max_block_bytes: 1_000_000\n      max_block_duration: 5m\n\n    compactor:\n      compaction:\n        block_retention: 168h  # 7 days\n\n    storage:\n      trace:\n        backend: s3\n        s3:\n          bucket: fawkes-tempo-traces\n          endpoint: s3.amazonaws.com\n          region: us-east-1\n        wal:\n          path: /var/tempo/wal\n        pool:\n          max_workers: 100\n          queue_depth: 10000\n\n    overrides:\n      defaults:\n        metrics_generator:\n          processors: [service-graphs, span-metrics]\n          storage:\n            path: /var/tempo/generator/wal\n            remote_write:\n              - url: http://prometheus:9090/api/v1/write\n                send_exemplars: true\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: tempo\n  namespace: fawkes-observability\nspec:\n  serviceName: tempo\n  replicas: 3\n  selector:\n    matchLabels:\n      app: tempo\n  template:\n    metadata:\n      labels:\n        app: tempo\n    spec:\n      containers:\n      - name: tempo\n        image: grafana/tempo:latest\n        args:\n          - -config.file=/etc/tempo/tempo.yaml\n        ports:\n        - containerPort: 3200\n          name: http\n        - containerPort: 4317\n          name: otlp-grpc\n        - containerPort: 4318\n          name: otlp-http\n        volumeMounts:\n        - name: config\n          mountPath: /etc/tempo\n        - name: storage\n          mountPath: /var/tempo\n        resources:\n          requests:\n            cpu: 500m\n            memory: 1Gi\n          limits:\n            cpu: 2000m\n            memory: 4Gi\n      volumes:\n      - name: config\n        configMap:\n          name: tempo-config\n  volumeClaimTemplates:\n  - metadata:\n      name: storage\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 100Gi\n</code></pre></p>"},{"location":"adr/ADR-013%20distributed%20tracing/#trace-correlation-with-logs","title":"Trace Correlation with Logs","text":"<p>Log Entry with Trace Context: <pre><code>{\n  \"timestamp\": \"2024-12-07T10:30:45Z\",\n  \"level\": \"ERROR\",\n  \"message\": \"Failed to sync application\",\n  \"service\": \"argocd\",\n  \"trace_id\": \"4bf92f3577b34da6a3ce929d0e0e4736\",\n  \"span_id\": \"00f067aa0ba902b7\",\n  \"trace_flags\": \"01\",\n  \"namespace\": \"production\",\n  \"app_name\": \"payment-service\"\n}\n</code></pre></p> <p>Loki Configuration for Trace Correlation: <pre><code># Grafana data source configuration\napiVersion: 1\ndatasources:\n  - name: Loki\n    type: loki\n    uid: loki\n    url: http://loki:3100\n    jsonData:\n      derivedFields:\n        - datasourceUid: tempo\n          matcherRegex: \"trace_id=(\\\\w+)\"\n          name: TraceID\n          url: \"$${__value.raw}\"\n</code></pre></p>"},{"location":"adr/ADR-013%20distributed%20tracing/#grafana-dashboard-configuration","title":"Grafana Dashboard Configuration","text":"<p>Service Dependency Graph: - Automatically generated from trace data - Shows request flow between services - Color-coded by error rate - Size proportional to request volume</p> <p>TraceQL Queries:</p> <p>Find slow database queries: <pre><code>{span.db.system=\"postgresql\" &amp;&amp; duration &gt; 1s}\n</code></pre></p> <p>Find all traces with errors in production: <pre><code>{status=error &amp;&amp; resource.namespace=\"production\"}\n</code></pre></p> <p>Find traces for specific user: <pre><code>{resource.service.name=\"backstage\" &amp;&amp; span.http.route=\"/api/catalog/*\" &amp;&amp; trace.user.id=\"alice@example.com\"}\n</code></pre></p> <p>Deployment trace (commit to production): <pre><code>{resource.service.name=\"jenkins\" || resource.service.name=\"argocd\"} \n  | {span.git.commit.sha=\"abc123def\"}\n</code></pre></p>"},{"location":"adr/ADR-013%20distributed%20tracing/#sampling-strategies","title":"Sampling Strategies","text":"<p>Head-Based Sampling (at application): - 100% of errors - 100% of requests &gt; 1 second - 10% of successful requests &lt; 1 second</p> <p>Tail-Based Sampling (at collector): - Keep all traces with errors - Keep all traces with latency &gt; P95 - Keep traces matching specific criteria (user ID, request path) - Sample remaining traces at 10%</p> <p>Cost Optimization: - Production: 10% sampling \u2192 ~50GB/day traces - Staging: 50% sampling \u2192 ~20GB/day traces - Development: 100% sampling \u2192 ~5GB/day traces</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#dora-metrics-integration","title":"DORA Metrics Integration","text":"<p>Lead Time for Changes Tracing: 1. Git commit event \u2192 creates trace context 2. Jenkins build \u2192 child span with commit SHA 3. Docker build \u2192 child span with image tag 4. Harbor push \u2192 child span with artifact metadata 5. ArgoCD sync \u2192 child span with deployment details 6. Application start \u2192 final span with health check</p> <p>Query to calculate lead time: <pre><code>{span.git.commit.sha=\"abc123\"} \n  | {span.name=\"deploy-to-production\"}\n</code></pre></p> <p>Change Failure Rate: - Trace deployments with <code>deployment.status=failed</code> - Correlate with application error traces - Generate failure rate dashboard</p> <p>Mean Time to Recovery: - Incident start \u2192 trace ID in alert - Trace investigation \u2192 linked troubleshooting actions - Incident resolution \u2192 final span - Calculate MTTR from trace duration</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#security-privacy","title":"Security &amp; Privacy","text":"<p>Sensitive Data Scrubbing: <pre><code># OpenTelemetry Collector processor\nprocessors:\n  attributes:\n    actions:\n      # Remove authorization headers\n      - key: http.request.header.authorization\n        action: delete\n\n      # Hash SQL statements (preserve structure, hide values)\n      - key: db.statement\n        action: hash\n\n      # Redact email addresses\n      - key: user.email\n        action: update\n        value: \"REDACTED\"\n\n      # Remove credit card numbers from URLs\n      - key: http.url\n        action: update\n        from_attribute: http.url\n        pattern: '\\d{4}-\\d{4}-\\d{4}-\\d{4}'\n        value: 'XXXX-XXXX-XXXX-XXXX'\n</code></pre></p> <p>Access Control: - Grafana RBAC for trace viewing - Namespace-based trace isolation - Tempo multi-tenancy (tenant ID from namespace)</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#performance-impact","title":"Performance Impact","text":"<p>Benchmarks (per-service overhead): - CPU: 2-5% increase - Memory: 50-100MB increase - Network: ~1KB per span (compressed) - Latency: &lt;1ms per instrumented operation</p> <p>Production Optimizations: - Use tail-based sampling - Batch span exports (10s intervals) - Compress spans before export - Use gRPC for OTLP (more efficient than HTTP)</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-013%20distributed%20tracing/#positive","title":"Positive","text":"<ol> <li>Root Cause Analysis: Quickly identify bottlenecks across distributed services</li> <li>Performance Optimization: Data-driven latency improvements</li> <li>Dependency Visualization: Automatic service dependency mapping</li> <li>Error Attribution: Precise identification of failing services</li> <li>DORA Metrics: End-to-end deployment pipeline visibility</li> <li>Cross-Team Collaboration: Shared visibility into request flows</li> <li>Unified Observability: Traces linked to metrics and logs</li> <li>Cost-Effective: Tempo uses object storage (~$10/TB/month vs. $100+ for commercial solutions)</li> <li>Vendor-Neutral: OpenTelemetry standard, not locked to Tempo</li> <li>Learning-Friendly: Clear visualization helps dojo learners understand distributed systems</li> </ol>"},{"location":"adr/ADR-013%20distributed%20tracing/#negative","title":"Negative","text":"<ol> <li>Learning Curve: Teams must understand tracing concepts and instrumentation</li> <li>Storage Costs: Trace data requires significant storage (~50GB/day for production)</li> <li>Instrumentation Effort: Applications require SDK integration</li> <li>Sampling Complexity: Tail-based sampling configuration requires tuning</li> <li>Performance Overhead: 2-5% CPU overhead per service</li> <li>Cardinality Challenges: High-cardinality attributes can degrade performance</li> </ol>"},{"location":"adr/ADR-013%20distributed%20tracing/#neutral","title":"Neutral","text":"<ol> <li>Tempo Maturity: Tempo is newer than Jaeger/Zipkin but rapidly maturing</li> <li>TraceQL Learning: New query language to learn (though similar to LogQL/PromQL)</li> <li>Object Storage Dependency: Requires S3-compatible storage</li> </ol>"},{"location":"adr/ADR-013%20distributed%20tracing/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-013%20distributed%20tracing/#alternative-1-jaeger","title":"Alternative 1: Jaeger","text":"<p>Pros: - CNCF graduated project, very mature - Excellent UI with service dependency graphs - Strong community and documentation - Battle-tested in production - Built-in sampling strategies - Supports multiple storage backends (Cassandra, Elasticsearch, Badger)</p> <p>Cons: - Higher operational complexity (requires Elasticsearch or Cassandra for scale) - Higher storage costs (~5x more than Tempo for equivalent data) - Less integration with Grafana (requires separate UI) - No native metrics generation from traces - Elasticsearch/Cassandra adds infrastructure overhead</p> <p>Reason for Rejection: Operational complexity and storage costs. Tempo's integration with Grafana provides unified observability, and object storage backend is significantly cheaper than Elasticsearch. Jaeger's maturity is valuable, but Tempo's simplicity better suits Fawkes' goals.</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#alternative-2-zipkin","title":"Alternative 2: Zipkin","text":"<p>Pros: - Original distributed tracing system, very mature - Simple architecture, easy to deploy - Low resource requirements - Multiple language SDK support - Compatible with OpenTelemetry</p> <p>Cons: - Less feature-rich than modern alternatives - No native Grafana integration - Limited query capabilities - In-memory storage default (poor retention) - Requires Elasticsearch for production (added complexity) - Smaller active community compared to CNCF projects</p> <p>Reason for Rejection: While simple, Zipkin lacks modern features like TraceQL queries, Grafana integration, and metrics generation. Tempo provides better long-term value with similar deployment simplicity.</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#alternative-3-aws-x-ray","title":"Alternative 3: AWS X-Ray","text":"<p>Pros: - Fully managed service (no infrastructure to maintain) - Native AWS integration (Lambda, ECS, EC2) - Automatic instrumentation for AWS services - Low operational overhead - Pay-per-use pricing</p> <p>Cons: - Cloud vendor lock-in (AWS only) - No multi-cloud support - Limited customization - Higher costs at scale (~$5/million traces) - Cannot run on-premises or in dojo labs - Separate UI from other observability tools</p> <p>Reason for Rejection: Violates Fawkes' cloud-agnostic principle. Learners need portable skills, not cloud-specific tools. X-Ray's managed benefits don't outweigh lock-in costs.</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#alternative-4-elastic-apm","title":"Alternative 4: Elastic APM","text":"<p>Pros: - Integrated with Elastic Stack (logs, metrics, traces in one UI) - Excellent UI and visualization - Strong Java and Node.js support - Machine learning for anomaly detection - Good documentation</p> <p>Cons: - Requires Elasticsearch cluster (high resource usage) - Complex scaling and tuning - Higher costs (compute + storage) - OpenTelemetry support is secondary (Elastic APM agents preferred) - Not CNCF/vendor-neutral</p> <p>Reason for Rejection: Elasticsearch operational complexity and costs. Fawkes already uses Grafana for visualization, so Elastic APM adds redundancy. Tempo + Grafana provides equivalent value with lower operational burden.</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#alternative-5-lightstep-honeycomb-datadog-apm-commercial-saas","title":"Alternative 5: Lightstep / Honeycomb / Datadog APM (Commercial SaaS)","text":"<p>Pros: - Best-in-class UX and query capabilities - Advanced sampling and trace analysis - Fully managed (zero operational burden) - Superior support and documentation - Advanced features (BubbleUp, trace comparison, service catalog)</p> <p>Cons: - Very high costs ($100-500/month per host) - SaaS-only (not self-hosted) - Data sent to third-party - Cannot use in air-gapped or on-premises environments - Not suitable for learner environments (cost prohibitive)</p> <p>Reason for Rejection: Cost prohibitive for open-source platform. Learners cannot use these tools without organization sponsorship. Self-hosted Tempo provides 90% of functionality at 5% of cost.</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#alternative-6-no-distributed-tracing-logs-metrics-only","title":"Alternative 6: No Distributed Tracing (Logs + Metrics Only)","text":"<p>Pros: - Lower complexity - Smaller operational footprint - Existing tools (Loki, Prometheus) sufficient - No additional instrumentation required</p> <p>Cons: - Cannot trace requests across services (critical gap) - Debugging distributed systems is extremely difficult - No service dependency visualization - Cannot calculate accurate DORA lead time metrics - Poor learner experience (can't see end-to-end flows)</p> <p>Reason for Rejection: Distributed tracing is essential for modern microservices platforms. DORA State of DevOps research shows observability (including tracing) strongly correlates with elite performance. Omitting tracing would cripple platform effectiveness.</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-013%20distributed%20tracing/#phase-1-foundation-week-6-days-1-2","title":"Phase 1: Foundation (Week 6, Days 1-2)","text":"<p>Day 1: OpenTelemetry Collector Deployment [4 hours] 1. Deploy OpenTelemetry Collector as DaemonSet 2. Configure OTLP receivers (gRPC + HTTP) 3. Set up batch and tail-sampling processors 4. Test with sample trace data 5. Verify Prometheus metrics export</p> <p>Day 2: Grafana Tempo Deployment [4 hours] 1. Deploy Tempo StatefulSet (3 replicas) 2. Configure S3/MinIO backend storage 3. Set up retention policies 4. Configure Grafana data source 5. Test trace ingestion and querying</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#phase-2-platform-service-instrumentation-week-6-days-3-5","title":"Phase 2: Platform Service Instrumentation (Week 6, Days 3-5)","text":"<p>Day 3: Backstage Tracing [3 hours] 1. Add OpenTelemetry Node.js SDK to Backstage 2. Configure auto-instrumentation 3. Test trace collection for catalog API calls 4. Add custom spans for plugin operations 5. Verify Grafana visualization</p> <p>Day 4: Jenkins &amp; ArgoCD Tracing [4 hours] 1. Jenkins: Add OpenTelemetry Java agent to JVM 2. Configure trace export for pipeline execution 3. ArgoCD: Manual Go instrumentation for sync operations 4. Test deployment trace (Jenkins \u2192 ArgoCD) 5. Create Grafana dashboard for CI/CD traces</p> <p>Day 5: Ingress &amp; Database Tracing [3 hours] 1. NGINX Ingress: Configure trace propagation headers 2. PostgreSQL: Add pg_stat_statements for query tracing 3. Test end-to-end trace (User \u2192 NGINX \u2192 Backstage \u2192 PostgreSQL) 4. Validate trace-to-log correlation</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#phase-3-application-instrumentation-templates-week-7-days-1-2","title":"Phase 3: Application Instrumentation Templates (Week 7, Days 1-2)","text":"<p>Day 1: Create Language-Specific Templates [4 hours] 1. Java Spring Boot template with OTel auto-instrumentation 2. Python FastAPI template with OTel SDK 3. Node.js Express template with OTel SDK 4. Go template with manual instrumentation 5. Document instrumentation patterns</p> <p>Day 2: Golden Path Integration [4 hours] 1. Update Backstage templates with OTel dependencies 2. Add Dockerfile entries for OTel agents 3. Update Helm charts with OTel environment variables 4. Create CI/CD pipeline checks for instrumentation 5. Test end-to-end application deployment with tracing</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#phase-4-observability-integration-week-7-days-3-5","title":"Phase 4: Observability Integration (Week 7, Days 3-5)","text":"<p>Day 3: Trace-to-Metrics Integration [3 hours] 1. Configure Tempo metrics generator 2. Send exemplars to Prometheus 3. Create Grafana dashboard linking metrics to traces 4. Add \"View Trace\" links from Prometheus alerts</p> <p>Day 4: Trace-to-Logs Integration [3 hours] 1. Configure Loki derived fields for trace IDs 2. Update application logging to include trace context 3. Test correlation (click trace ID in logs \u2192 opens trace in Tempo) 4. Create unified dashboard with logs + traces</p> <p>Day 5: DORA Metrics Tracing [4 hours] 1. Instrument deployment pipeline with trace context 2. Track commit SHA through build \u2192 deploy \u2192 release 3. Calculate lead time from traces 4. Create DORA dashboard with trace links</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#phase-5-performance-optimization-week-8-days-1-2","title":"Phase 5: Performance &amp; Optimization (Week 8, Days 1-2)","text":"<p>Day 1: Sampling Optimization [3 hours] 1. Analyze trace volumes and costs 2. Tune tail-based sampling policies 3. Implement adaptive sampling based on load 4. Verify sample representativeness 5. Document sampling strategies</p> <p>Day 2: Performance Testing [3 hours] 1. Load test with tracing enabled (measure overhead) 2. Benchmark trace ingestion rates 3. Test Tempo query performance 4. Optimize collector configurations 5. Document performance baseline</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#phase-6-documentation-training-week-8-days-3-5","title":"Phase 6: Documentation &amp; Training (Week 8, Days 3-5)","text":"<p>Day 3: Platform Documentation [4 hours] 1. Architecture overview with data flow diagrams 2. Instrumentation guide for each language 3. TraceQL query examples and cookbook 4. Troubleshooting guide 5. Runbook for Tempo operations</p> <p>Day 4: Dojo Module - Brown Belt [4 hours] 1. Module: \"Distributed Tracing for Microservices\" 2. Theory: Trace context, spans, sampling 3. Hands-on lab: Instrument sample app, query traces 4. Troubleshooting exercise: Debug slow request 5. Assessment quiz on tracing concepts</p> <p>Day 5: Dashboard &amp; Playbooks [4 hours] 1. Create standard Grafana dashboards:    - Service dependency graph    - Request latency heatmap    - Error rate by service    - Deployment trace timeline 2. Create troubleshooting playbooks 3. Document common trace patterns 4. Create video walkthrough (15 minutes)</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#dojo-integration","title":"Dojo Integration","text":""},{"location":"adr/ADR-013%20distributed%20tracing/#brown-belt-module-6-distributed-tracing-request-flow-analysis","title":"Brown Belt - Module 6: \"Distributed Tracing &amp; Request Flow Analysis\"","text":"<p>Learning Objectives: - Understand distributed tracing concepts (spans, traces, context propagation) - Implement OpenTelemetry instrumentation in applications - Query traces using TraceQL - Correlate traces with metrics and logs - Debug performance issues using distributed tracing - Calculate DORA lead time metrics from traces</p> <p>Hands-On Lab (90 minutes):</p> <p>Part 1: Instrument a Microservice (30 min) 1. Deploy sample 3-tier app (frontend \u2192 API \u2192 database) 2. Add OpenTelemetry SDK to each service 3. Configure trace export to Tempo 4. Generate traffic and view traces in Grafana 5. Observe request flow across services</p> <p>Part 2: Advanced Querying (30 min) 1. Write TraceQL queries to find:    - Slow database queries    - Requests with errors    - Specific user journeys    - Deployment traces 2. Create custom Grafana dashboard 3. Set up trace-based alerts</p> <p>Part 3: Troubleshooting Exercise (30 min) - Scenario: Application experiencing intermittent slowness - Task: Use traces to identify:   - Which service is the bottleneck   - Slow database queries   - External API latency   - Network issues - Deliverable: Root cause analysis report with trace evidence</p> <p>Assessment: - Quiz: 10 questions on tracing concepts - Practical: Instrument new service and create dashboard - Troubleshooting: Debug broken trace (missing context propagation)</p> <p>Time: 2 hours (30 min theory + 90 min hands-on + assessment)</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"adr/ADR-013%20distributed%20tracing/#tempo-health-metrics","title":"Tempo Health Metrics","text":"<p>Key Metrics to Monitor: - <code>tempo_ingester_bytes_received_total</code> - Trace ingestion rate - <code>tempo_ingester_blocks_flushed_total</code> - Block flush rate - <code>tempo_query_frontend_result_metrics_inspected_bytes</code> - Query performance - <code>tempo_distributor_spans_received_total</code> - Span reception rate - <code>tempo_compactor_blocks_compacted_total</code> - Compaction health</p> <p>Grafana Dashboard: \"Tempo Operations\" - Ingestion rate by tenant - Query latency (P50, P95, P99) - Storage usage and growth - Compaction lag - Error rates</p> <p>Alerting Rules: <pre><code>groups:\n- name: tempo_alerts\n  rules:\n  - alert: TempoHighIngestionErrors\n    expr: rate(tempo_distributor_spans_received_total{status=\"error\"}[5m]) &gt; 100\n    for: 10m\n    annotations:\n      summary: \"High trace ingestion error rate\"\n\n  - alert: TempoHighQueryLatency\n    expr: histogram_quantile(0.95, tempo_query_frontend_duration_seconds_bucket) &gt; 10\n    for: 5m\n    annotations:\n      summary: \"Tempo query latency P95 &gt; 10s\"\n\n  - alert: TempoStorageUsageHigh\n    expr: tempo_ingester_bytes_metric_total &gt; 100e9  # 100GB\n    annotations:\n      summary: \"Tempo ingester storage usage high\"\n</code></pre></p>"},{"location":"adr/ADR-013%20distributed%20tracing/#opentelemetry-collector-health","title":"OpenTelemetry Collector Health","text":"<p>Key Metrics: - <code>otelcol_receiver_accepted_spans</code> - Spans received - <code>otelcol_receiver_refused_spans</code> - Spans refused (backpressure) - <code>otelcol_processor_batch_batch_send_size</code> - Batch sizes - <code>otelcol_exporter_sent_spans</code> - Spans successfully exported - <code>otelcol_exporter_send_failed_spans</code> - Export failures</p> <p>Dashboard: \"OpenTelemetry Collector Health\" - Span throughput (in/out) - Processor queue depth - Export success/failure rates - Memory usage by component</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#security-considerations","title":"Security Considerations","text":""},{"location":"adr/ADR-013%20distributed%20tracing/#data-privacy","title":"Data Privacy","text":"<p>Sensitive Data Scrubbing: - Remove authorization headers - Hash SQL statements - Redact PII from URLs and headers - Obfuscate API keys in trace attributes</p> <p>Access Control: - Grafana RBAC for trace viewing - Namespace-based trace isolation (teams only see their traces) - Audit logging for trace access</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#compliance","title":"Compliance","text":"<p>Data Retention: - 7 days detailed traces (compliance with GDPR \"right to be forgotten\") - 30 days sampled traces - Automated deletion after retention period</p> <p>Encryption: - TLS for all trace transmission (OTLP over gRPC/HTTPS) - S3 server-side encryption for stored traces - No plaintext credentials in trace attributes</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#cost-analysis","title":"Cost Analysis","text":""},{"location":"adr/ADR-013%20distributed%20tracing/#storage-costs-production","title":"Storage Costs (Production)","text":"<p>Assumptions: - 100 services generating traces - 1,000 requests/second average - 10 spans per trace average - 10% sampling rate (tail-based) - ~1KB per span (compressed)</p> <p>Daily Trace Volume: - Raw spans: 100 services \u00d7 1,000 req/s \u00d7 10 spans \u00d7 86,400 s = 86.4 billion spans/day - After sampling: 8.64 billion spans/day - Storage: 8.64B spans \u00d7 1KB = 8.64 TB/day (before compression) - After compression (10:1): ~864 GB/day</p> <p>Monthly Storage (7-day retention): - 864 GB/day \u00d7 7 days = 6 TB active storage - S3 Standard: $0.023/GB = $138/month - S3 Intelligent-Tiering (after 7 days): $0.0125/GB = $75/month</p> <p>Total Monthly Cost: ~$213/month (vs. $5,000+/month for commercial APM at 100 services)</p> <p>Cost Optimization: - Increase sampling rate in non-production (less cost-sensitive) - Use S3 Lifecycle policies to move old traces to Glacier - Tune tail-based sampling to focus on valuable traces - Compress spans aggressively (Snappy \u2192 LZ4)</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#infrastructure-costs","title":"Infrastructure Costs","text":"<p>Tempo Pods: - 3 replicas \u00d7 2 CPU \u00d7 $0.04/CPU/hour = $5.76/day = $173/month - 3 replicas \u00d7 4GB RAM \u00d7 $0.005/GB/hour = $1.44/day = $43/month</p> <p>OpenTelemetry Collector: - DaemonSet (1 per node, 10 nodes): 10 \u00d7 0.1 CPU \u00d7 $0.04 = $0.96/day = $29/month - DaemonSet memory: 10 \u00d7 128MB \u00d7 $0.005/GB/hour = negligible</p> <p>Total Infrastructure: ~$245/month</p> <p>Grand Total: ~$458/month for distributed tracing (100 services, production scale)</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#documentation-structure","title":"Documentation Structure","text":""},{"location":"adr/ADR-013%20distributed%20tracing/#for-platform-teams","title":"For Platform Teams","text":"<ol> <li>Architecture &amp; Design</li> <li>Trace collection flow</li> <li>Sampling strategies explained</li> <li>Storage architecture (S3 layout)</li> <li> <p>Query performance optimization</p> </li> <li> <p>Deployment Guide</p> </li> <li>Helm chart installation (Tempo, OTel Collector)</li> <li>Cloud-specific configurations (AWS, Azure, GCP)</li> <li>Scaling guidelines</li> <li> <p>Backup and disaster recovery</p> </li> <li> <p>Operations Runbook</p> </li> <li>Common troubleshooting scenarios</li> <li>Tempo upgrade procedures</li> <li>Storage management (compaction, cleanup)</li> <li>Performance tuning guide</li> </ol>"},{"location":"adr/ADR-013%20distributed%20tracing/#for-application-teams","title":"For Application Teams","text":"<ol> <li>Instrumentation Guide</li> <li>Language-specific SDKs (Java, Python, Node.js, Go)</li> <li>Auto vs. manual instrumentation</li> <li>Custom span creation</li> <li> <p>Best practices (span naming, attributes)</p> </li> <li> <p>Querying &amp; Troubleshooting</p> </li> <li>TraceQL query cookbook</li> <li>Common debugging patterns</li> <li>Grafana dashboard usage</li> <li> <p>Trace-to-logs/metrics correlation</p> </li> <li> <p>Performance Impact</p> </li> <li>Overhead benchmarks</li> <li>Sampling recommendations</li> <li>Optimization techniques</li> </ol>"},{"location":"adr/ADR-013%20distributed%20tracing/#for-dojo-learners","title":"For Dojo Learners","text":"<ol> <li>Concepts Tutorial</li> <li>What is distributed tracing?</li> <li>Spans, traces, and context propagation</li> <li>When to use tracing vs. logs/metrics</li> <li> <p>Real-world use cases</p> </li> <li> <p>Hands-On Labs</p> </li> <li>Lab 1: Instrument a simple app</li> <li>Lab 2: Query traces with TraceQL</li> <li>Lab 3: Debug performance issue</li> <li> <p>Lab 4: Trace a deployment pipeline</p> </li> <li> <p>Reference Materials</p> </li> <li>OpenTelemetry SDK quick reference</li> <li>TraceQL cheat sheet</li> <li>Common trace patterns</li> <li>Troubleshooting decision tree</li> </ol>"},{"location":"adr/ADR-013%20distributed%20tracing/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-011: Centralized Log Management (Loki) - Trace-to-log correlation via trace IDs</li> <li>ADR-012: Metrics Monitoring (Prometheus/Grafana) - Exemplars link metrics to traces</li> <li>ADR-002: Backstage for Developer Portal - Primary UI instrumentation</li> <li>ADR-004: Jenkins for CI/CD - Pipeline trace instrumentation</li> <li>ADR-003: ArgoCD for GitOps - Deployment trace instrumentation</li> <li>Future ADR: Service Mesh (Istio) - Alternative instrumentation via sidecar proxies</li> </ul>"},{"location":"adr/ADR-013%20distributed%20tracing/#references","title":"References","text":"<ul> <li>OpenTelemetry Documentation: https://opentelemetry.io/docs/</li> <li>Grafana Tempo Documentation: https://grafana.com/docs/tempo/</li> <li>TraceQL Language Reference: https://grafana.com/docs/tempo/latest/traceql/</li> <li>CNCF Distributed Tracing Best Practices: https://github.com/cncf/tag-observability</li> <li>Distributed Tracing Patterns (book) by Austin Parker</li> <li>OpenTelemetry Best Practices: https://opentelemetry.io/docs/concepts/instrumentation/</li> </ul>"},{"location":"adr/ADR-013%20distributed%20tracing/#notes","title":"Notes","text":"<p>Production Readiness Checklist: - [ ] Tempo deployed with 3+ replicas for HA - [ ] S3/MinIO backend configured with proper retention - [ ] OpenTelemetry Collector deployed (DaemonSet + Deployment) - [ ] Tail-based sampling configured and tested - [ ] Grafana data source configured with Tempo - [ ] Trace-to-logs correlation working (Loki derived fields) - [ ] Trace-to-metrics correlation working (Prometheus exemplars) - [ ] Sensitive data scrubbing verified - [ ] Performance benchmarks completed (overhead &lt; 5%) - [ ] Monitoring dashboards created - [ ] Alerting rules configured - [ ] Documentation complete - [ ] Team trained on querying and troubleshooting</p> <p>Learner Environment Considerations: - Use in-memory Tempo backend for short-lived labs - Pre-instrument sample applications - Provide TraceQL query examples - Include broken traces for troubleshooting practice - Show real-world debugging scenarios - Integrate with DORA metrics curriculum</p> <p>Future Enhancements (Post-MVP): - Service mesh integration (Istio sidecar auto-instrumentation) - Trace-based SLO monitoring - Anomaly detection from trace patterns - Cost attribution per service from trace data - Automated performance recommendations - Trace replay for testing</p>"},{"location":"adr/ADR-013%20distributed%20tracing/#last-updated","title":"Last Updated","text":"<p>December 7, 2024 - Initial version documenting Grafana Tempo + OpenTelemetry for distributed tracing</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/","title":"ADR-014: SonarQube for Code Quality and Security Gates","text":""},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#status","title":"Status","text":"<p>Accepted - November 30, 2025</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#context","title":"Context","text":"<p>Fawkes platform requires a centralized code quality and security analysis solution integrated into the Golden Path CI/CD pipeline. Currently, code quality review and security vulnerability checks are inconsistent, often relying on manual review or isolated scanning tools that do not enforce pass/fail criteria. There is no central dashboard to track the Quality Debt or security status across all platform repositories.</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#requirements","title":"Requirements","text":"<p>Functional Requirements: - Static Application Security Testing (SAST) - Code quality metrics and technical debt tracking - Security vulnerability detection - Code coverage analysis - Duplicate code detection - Quality Gate enforcement in CI/CD pipelines - Multi-language support (Java, Python, Node.js, Go) - Branch-based analysis for PR reviews</p> <p>Non-Functional Requirements: - Fast feedback (&lt; 5 minutes for analysis) - Scalable to 50+ repositories - SSO/OAuth integration for developer access - Secure token-based CI/CD integration - Persistent data storage with PostgreSQL - High availability for production use</p> <p>Integration Requirements: - Jenkins pipeline integration via scanner token - GitHub repository linking - ArgoCD deployment management - Prometheus metrics export - Developer portal (Backstage) integration</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Need comprehensive language support - Must integrate seamlessly with Jenkins pipelines - Require fast, accurate analysis without blocking development</p> <p>Operational Forces: - Platform team capacity for maintenance - Need for simple deployment and upgrades - Backup and disaster recovery requirements</p> <p>Developer Experience Forces: - Clear, actionable feedback in CI/CD - Easy access to detailed analysis reports - Minimal friction in development workflow</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#decision","title":"Decision","text":"<p>We will deploy SonarQube as the centralized code quality and security analysis platform for Fawkes.</p> <p>Specifically: - SonarQube 10.7+ (Community Edition) as the analysis engine - CloudNativePG PostgreSQL for persistent data storage - Jenkins Shared Library integration for scanner execution and Quality Gate enforcement - NGINX Ingress for external access with SSO integration - Mandatory Quality Gate enforcement on main branch commits - PR branch analysis for early feedback</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Developer Workflow                           \u2502\n\u2502                                                                   \u2502\n\u2502  Git Commit \u2192 Jenkins Pipeline \u2192 SonarQube Analysis \u2192 Quality Gate\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     SonarQube Platform                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502   Web UI     \u2502  \u2502   Compute    \u2502  \u2502   Search     \u2502          \u2502\n\u2502  \u2502   (Java)     \u2502  \u2502   Engine     \u2502  \u2502   (ES)       \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                           \u2502                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                    PostgreSQL                             \u2502  \u2502\n\u2502  \u2502              (db-sonarqube-dev cluster)                   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#quality-gate-strategy","title":"Quality Gate Strategy","text":"<p>Default Quality Gate Conditions: | Metric | Operator | Threshold | Rationale | |--------|----------|-----------|-----------| | New Bugs | Is Greater Than | 0 | Prevent bug introduction | | New Vulnerabilities | Is Greater Than | 0 | Security-first approach | | New Security Hotspots Reviewed | Is Less Than | 100% | Ensure security review | | New Code Coverage | Is Less Than | 80% | Maintain test coverage | | New Duplicated Lines (%) | Is Greater Than | 3% | Limit code duplication | | New Maintainability Rating | Is Worse Than | A | Quality standards |</p> <p>Quality Gate Enforcement: 1. Main branch commits MUST pass Quality Gate before image push 2. PR builds report Quality Gate status but don't block (informational) 3. Pipeline fails immediately on Quality Gate failure with detailed logs 4. Direct link to SonarQube dashboard provided in build output</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#rationale","title":"Rationale","text":"<ol> <li> <p>Industry Standard: SonarQube is the most widely adopted code quality platform with over 400K organizations using it</p> </li> <li> <p>Comprehensive Analysis:</p> </li> <li>27+ programming languages supported</li> <li>5000+ rules for bug, vulnerability, and code smell detection</li> <li>Security hotspot identification</li> <li> <p>Coverage integration</p> </li> <li> <p>Quality Gate Enforcement:</p> </li> <li>Automated pass/fail criteria</li> <li>Configurable thresholds</li> <li> <p>Webhook integration for CI/CD</p> </li> <li> <p>Developer Experience:</p> </li> <li>Clear, actionable feedback</li> <li>IDE plugins (SonarLint) for local feedback</li> <li> <p>Detailed remediation guidance</p> </li> <li> <p>Open Source:</p> </li> <li>Community Edition is free</li> <li>Large community and ecosystem</li> <li> <p>Regular updates and security patches</p> </li> <li> <p>Cloud-Native Ready:</p> </li> <li>Kubernetes-ready Helm chart</li> <li>External PostgreSQL support</li> <li>Prometheus metrics integration</li> </ol>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#positive","title":"Positive","text":"<p>\u2705 Centralized Quality Dashboard: Single pane of glass for all code quality metrics</p> <p>\u2705 Consistent Standards: Same quality rules enforced across all repositories</p> <p>\u2705 Security Shift-Left: Vulnerabilities caught early in development</p> <p>\u2705 Developer Feedback: Clear, actionable guidance on code improvements</p> <p>\u2705 Technical Debt Tracking: Visibility into accumulated technical debt</p> <p>\u2705 Integration with CI/CD: Automated enforcement in Golden Path pipeline</p> <p>\u2705 Multi-Language Support: Java, Python, Node.js, Go, and more</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#negative","title":"Negative","text":"<p>\u26a0\ufe0f Resource Requirements: SonarQube requires significant memory (2-4GB minimum)</p> <p>\u26a0\ufe0f Initial Configuration: Requires setup of projects, quality profiles, and gates</p> <p>\u26a0\ufe0f Analysis Time: Large projects may take several minutes to analyze</p> <p>\u26a0\ufe0f False Positives: Some rules may flag non-issues requiring suppression</p> <p>\u26a0\ufe0f Learning Curve: Developers need to understand SonarQube feedback</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#neutral","title":"Neutral","text":"<p>\u25fd Community vs. Developer Edition: Some features (branch analysis depth, security reports) require paid edition</p> <p>\u25fd Maintenance: Requires periodic updates and database maintenance</p> <p>\u25fd Storage Growth: Analysis history grows over time</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li>Resource Management:</li> <li>Right-size Kubernetes resources</li> <li>Configure housekeeping to clean old analysis data</li> <li> <p>Use separate PostgreSQL cluster for isolation</p> </li> <li> <p>Analysis Performance:</p> </li> <li>Enable incremental analysis where supported</li> <li>Configure appropriate exclusions</li> <li> <p>Run analysis in parallel with other pipeline stages</p> </li> <li> <p>False Positives:</p> </li> <li>Create custom quality profiles</li> <li>Use inline comments for legitimate suppressions</li> <li> <p>Regular review of flagged issues</p> </li> <li> <p>Developer Adoption:</p> </li> <li>Provide SonarLint IDE plugin guidance</li> <li>Document common issues and resolutions</li> <li>Include SonarQube links in build notifications</li> </ol>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#alternative-1-snyk","title":"Alternative 1: Snyk","text":"<p>Pros: - Strong security focus - SaaS offering (less maintenance) - Good dependency scanning</p> <p>Cons: - Limited code quality analysis - No quality gate enforcement - Primarily security-focused</p> <p>Reason for Rejection: Snyk excellent for security but lacks comprehensive code quality analysis. SonarQube provides both security and quality in one platform.</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#alternative-2-codeclimate","title":"Alternative 2: CodeClimate","text":"<p>Pros: - Clean UI - Quality focus - Good maintainability scores</p> <p>Cons: - Limited security features - Fewer language support - SaaS-only (no self-hosted)</p> <p>Reason for Rejection: CodeClimate strong on quality but weak on security. Self-hosted option important for enterprise deployments.</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#alternative-3-codacy","title":"Alternative 3: Codacy","text":"<p>Pros: - Multi-language support - Security patterns - SaaS and self-hosted options</p> <p>Cons: - Less mature than SonarQube - Smaller community - Limited enterprise features</p> <p>Reason for Rejection: Codacy capable but SonarQube has larger community, more rules, and better Jenkins integration.</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#alternative-4-github-advanced-security","title":"Alternative 4: GitHub Advanced Security","text":"<p>Pros: - Native GitHub integration - Code scanning and secret scanning - Dependency review</p> <p>Cons: - Expensive ($49/user/month) - Limited to GitHub repositories - Less comprehensive quality analysis</p> <p>Reason for Rejection: GitHub Advanced Security powerful but expensive and limited to GitHub. SonarQube works with any Git provider.</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-004: Jenkins for CI/CD (provides pipeline integration)</li> <li>ADR-006: PostgreSQL for Data Persistence (provides database backend)</li> <li>ADR-009: Secrets Management (SonarQube token storage)</li> </ul>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#implementation-notes","title":"Implementation Notes","text":""},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#deployment-configuration","title":"Deployment Configuration","text":"<p>SonarQube ArgoCD Application: <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: sonarqube\n  namespace: fawkes\nspec:\n  source:\n    repoURL: https://charts.sonarsource.com\n    chart: sonarqube\n    targetRevision: \"2025.1.0\"\n    helm:\n      values: |\n        jdbcOverwrite:\n          enable: true\n          jdbcUrl: \"jdbc:postgresql://db-sonarqube-dev-rw.fawkes.svc:5432/sonarqube\"\n</code></pre></p> <p>Jenkins Credentials Configuration: <pre><code>credentials:\n  - id: sonarqube-token\n    type: secretText\n    secret: ${SONARQUBE_TOKEN}\n    description: \"SonarQube Scanner Token\"\n</code></pre></p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#quality-gate-enforcement-in-pipeline","title":"Quality Gate Enforcement in Pipeline","text":"<pre><code>stage('Quality Gate') {\n    steps {\n        timeout(time: 5, unit: 'MINUTES') {\n            def qg = waitForQualityGate()\n            if (qg.status != 'OK') {\n                error \"Quality Gate failed: ${qg.status}\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#initial-setup-checklist","title":"Initial Setup Checklist","text":"<ol> <li>[ ] Deploy PostgreSQL cluster (db-sonarqube-dev)</li> <li>[ ] Deploy SonarQube via ArgoCD</li> <li>[ ] Configure admin password and SSO</li> <li>[ ] Create scanner token for Jenkins</li> <li>[ ] Add token to Jenkins credentials</li> <li>[ ] Configure SonarQube server in Jenkins</li> <li>[ ] Create default Quality Gate</li> <li>[ ] Create language-specific quality profiles</li> <li>[ ] Document developer onboarding</li> </ol>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#monitoring","title":"Monitoring","text":"<p>Prometheus Metrics: - <code>sonarqube_health_status</code> - <code>sonarqube_compute_engine_tasks</code> - <code>sonarqube_database_connections</code></p> <p>Key Alerts: - SonarQube unhealthy - Analysis queue growing - Database connection issues</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#monitoring-this-decision","title":"Monitoring This Decision","text":"<p>We will revisit this ADR if: - Analysis time consistently exceeds 5 minutes - False positive rate becomes problematic - Community Edition features are insufficient - Alternative tools provide better value</p> <p>Next Review Date: May 30, 2026 (6 months)</p>"},{"location":"adr/ADR-014%20sonarqube%20quality%20gates/#references","title":"References","text":"<ul> <li>SonarQube Documentation</li> <li>SonarQube Helm Chart</li> <li>Quality Gates Documentation</li> <li>Jenkins SonarQube Plugin</li> <li>Fawkes Jenkins Shared Library</li> </ul> <p>Decision Made By: Platform Architecture Team Approved By: Project Lead Date: November 30, 2025 Author: Fawkes Platform Team Last Updated: November 30, 2025</p>"},{"location":"adr/ADR-015%20vault%20deployment/","title":"ADR-015: HashiCorp Vault for Centralized Secrets Management","text":""},{"location":"adr/ADR-015%20vault%20deployment/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-015%20vault%20deployment/#context","title":"Context","text":"<p>The Fawkes platform requires a robust, centralized secrets management solution that provides:</p> <ul> <li>High Availability: Secrets infrastructure must be resilient to failures</li> <li>Kubernetes Integration: Native authentication for service accounts</li> <li>Dynamic Secrets: Automatic credential generation and rotation</li> <li>Audit Logging: Complete trail of secret access for compliance</li> <li>Multi-method Injection: Support for sidecar and CSI-based secret delivery</li> </ul>"},{"location":"adr/ADR-015%20vault%20deployment/#current-state","title":"Current State","text":"<p>The platform currently uses External Secrets Operator (ESO) to synchronize secrets from cloud provider secret stores (AWS Secrets Manager, Azure Key Vault) into Kubernetes Secrets. While ESO works well for cloud-native deployments, it has limitations:</p> <ol> <li>Cloud Dependency: Requires external cloud secret store</li> <li>No Dynamic Secrets: Cannot generate credentials on-demand</li> <li>Limited Rotation: Relies on external store for rotation logic</li> <li>On-premises Gap: Difficult to use in air-gapped environments</li> </ol>"},{"location":"adr/ADR-015%20vault%20deployment/#requirements-from-issue","title":"Requirements from Issue","text":"<ol> <li>Deploy HashiCorp Vault in HA mode (3 replicas)</li> <li>Use Kubernetes Auth Method for service account authentication</li> <li>Implement Vault Agent Sidecar for secret injection</li> <li>Support CSI Secret Store Driver as alternative injection method</li> <li>Enable automatic secret rotation without pod restarts</li> <li>Enforce least-privilege access controls</li> <li>Achieve RTO &lt; 120 seconds for HA failover</li> </ol>"},{"location":"adr/ADR-015%20vault%20deployment/#decision","title":"Decision","text":"<p>We will deploy HashiCorp Vault as the centralized secrets management solution for the Fawkes platform, complementing (not replacing) the existing External Secrets Operator.</p>"},{"location":"adr/ADR-015%20vault%20deployment/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          Secrets Management Layer                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502    HashiCorp Vault (HA)    \u2502    \u2502   External Secrets Operator        \u2502  \u2502\n\u2502  \u2502                            \u2502    \u2502                                    \u2502  \u2502\n\u2502  \u2502  \u2022 Dynamic secrets         \u2502    \u2502  \u2022 Cloud provider integration     \u2502  \u2502\n\u2502  \u2502  \u2022 K8s Auth                \u2502    \u2502  \u2022 AWS/Azure/GCP sync             \u2502  \u2502\n\u2502  \u2502  \u2022 Agent sidecar           \u2502    \u2502  \u2022 Legacy secret migration        \u2502  \u2502\n\u2502  \u2502  \u2022 CSI provider            \u2502    \u2502                                    \u2502  \u2502\n\u2502  \u2502  \u2022 Audit logging           \u2502    \u2502                                    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502              \u2502                                    \u2502                          \u2502\n\u2502              \u2502 Kubernetes Auth                    \u2502 ClusterSecretStore       \u2502\n\u2502              \u25bc                                    \u25bc                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502                        Kubernetes Secrets                                \u2502\u2502\n\u2502  \u2502  (Mounted as volumes or environment variables in application pods)      \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-015%20vault%20deployment/#deployment-configuration","title":"Deployment Configuration","text":""},{"location":"adr/ADR-015%20vault%20deployment/#high-availability","title":"High Availability","text":"<ul> <li>Replicas: 3 (1 active + 2 standby)</li> <li>Storage: Raft integrated storage (no external database required)</li> <li>Failover: Automatic leader election via Raft consensus</li> <li>RTO: &lt; 120 seconds</li> </ul>"},{"location":"adr/ADR-015%20vault%20deployment/#storage-backend","title":"Storage Backend","text":"<p>We chose Raft integrated storage over PostgreSQL for:</p> <ol> <li>Simplicity: No external database dependency</li> <li>Performance: Optimized for Vault's access patterns</li> <li>HA Built-in: Raft handles replication and failover</li> <li>Portability: Works the same in any environment</li> </ol>"},{"location":"adr/ADR-015%20vault%20deployment/#secret-injection-methods","title":"Secret Injection Methods","text":"Method Use Case Pros Cons Vault Agent Sidecar Most applications Auto-rotation, no app changes Extra container per pod CSI Driver Stateful apps, legacy Native volume mount No auto-rotation in files Direct API CI/CD pipelines Full control Requires Vault SDK/client"},{"location":"adr/ADR-015%20vault%20deployment/#kubernetes-auth-configuration","title":"Kubernetes Auth Configuration","text":"<pre><code>Service Account \u2192 Kubernetes Auth \u2192 Vault Policy \u2192 Secrets Access\n       \u2502                 \u2502                \u2502               \u2502\n       \u2502     Token JWT   \u2502    Validate    \u2502   Evaluate    \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n                         \u2502                \u2502               \u2502\n                     K8s API          Vault           KV Store\n</code></pre>"},{"location":"adr/ADR-015%20vault%20deployment/#access-control-policies","title":"Access Control Policies","text":"Role Service Accounts Allowed Paths jenkins jenkins, jenkins-agent secret/data/fawkes/cicd/, apps/, shared/* backstage backstage secret/data/fawkes/core/backstage/, shared/ platform-service * in fawkes namespace secret/data/fawkes/{namespace}/, shared/ observability grafana, prometheus secret/data/fawkes/observability/, shared/"},{"location":"adr/ADR-015%20vault%20deployment/#integration-with-existing-eso","title":"Integration with Existing ESO","text":"<p>Vault and ESO will coexist:</p> <ol> <li>ESO: Cloud-native deployments, existing cloud secret stores</li> <li>Vault: On-premises, dynamic secrets, advanced use cases</li> </ol> <p>A <code>ClusterSecretStore</code> for Vault can be configured in ESO for migration:</p> <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: vault-backend\nspec:\n  provider:\n    vault:\n      server: \"http://vault.vault.svc:8200\"\n      path: \"secret\"\n      version: \"v2\"\n      auth:\n        kubernetes:\n          mountPath: \"kubernetes\"\n          role: \"external-secrets\"\n</code></pre>"},{"location":"adr/ADR-015%20vault%20deployment/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-015%20vault%20deployment/#positive","title":"Positive","text":"<ol> <li>Unified Secrets Management: Single source of truth for platform secrets</li> <li>Dynamic Secrets: Database credentials generated on-demand with TTL</li> <li>Automatic Rotation: Vault Agent refreshes secrets without pod restart</li> <li>Audit Compliance: Complete access log for regulatory requirements</li> <li>On-premises Ready: Works in air-gapped and hybrid environments</li> <li>Kubernetes Native: Auth via service accounts, no extra credentials</li> </ol>"},{"location":"adr/ADR-015%20vault%20deployment/#negative","title":"Negative","text":"<ol> <li>Operational Complexity: Vault cluster requires monitoring and maintenance</li> <li>Unseal Process: Manual intervention needed after restarts (mitigate with    auto-unseal)</li> <li>Learning Curve: Teams need to learn Vault policies and injection patterns</li> <li>Resource Overhead: Additional pods for Vault cluster and injectors</li> </ol>"},{"location":"adr/ADR-015%20vault%20deployment/#risks-and-mitigations","title":"Risks and Mitigations","text":"Risk Mitigation Vault cluster unavailable HA with 3 replicas, monitoring alerts Unseal keys lost Store in secure location, use cloud auto-unseal Policy misconfiguration Infrastructure as code, policy testing Agent injection failures Webhook fallback policy, health monitoring"},{"location":"adr/ADR-015%20vault%20deployment/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-015%20vault%20deployment/#1-external-secrets-operator-only-current-state","title":"1. External Secrets Operator Only (Current State)","text":"<p>Rejected because: Does not provide dynamic secrets, on-premises support, or native rotation capabilities.</p>"},{"location":"adr/ADR-015%20vault%20deployment/#2-aws-secrets-manager-azure-key-vault-direct","title":"2. AWS Secrets Manager / Azure Key Vault (Direct)","text":"<p>Rejected because: Cloud vendor lock-in, no on-premises support, no Kubernetes-native auth.</p>"},{"location":"adr/ADR-015%20vault%20deployment/#3-sealed-secrets","title":"3. Sealed Secrets","text":"<p>Rejected because: Secrets in Git (compliance risk), no dynamic secrets, key management burden.</p>"},{"location":"adr/ADR-015%20vault%20deployment/#4-cyberark-conjur","title":"4. CyberArk Conjur","text":"<p>Rejected because: Commercial licensing, more complex than needed, smaller community.</p>"},{"location":"adr/ADR-015%20vault%20deployment/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-015%20vault%20deployment/#phase-1-core-deployment-week-1","title":"Phase 1: Core Deployment (Week 1)","text":"<ul> <li>[ ] Deploy Vault HA cluster via ArgoCD</li> <li>[ ] Configure Kubernetes Auth Method</li> <li>[ ] Create platform access policies</li> <li>[ ] Set up audit logging</li> </ul>"},{"location":"adr/ADR-015%20vault%20deployment/#phase-2-integration-week-2","title":"Phase 2: Integration (Week 2)","text":"<ul> <li>[ ] Deploy Vault CSI Driver</li> <li>[ ] Configure SecretProviderClasses for services</li> <li>[ ] Migrate Jenkins to Vault secrets</li> <li>[ ] Update Golden Path pipeline for Vault</li> </ul>"},{"location":"adr/ADR-015%20vault%20deployment/#phase-3-documentation-training-week-3","title":"Phase 3: Documentation &amp; Training (Week 3)","text":"<ul> <li>[ ] Developer integration guide</li> <li>[ ] Dojo learning module</li> <li>[ ] Runbook for operations</li> <li>[ ] Grafana dashboards for monitoring</li> </ul>"},{"location":"adr/ADR-015%20vault%20deployment/#references","title":"References","text":"<ul> <li>HashiCorp Vault Documentation</li> <li>Vault Agent Injector</li> <li>Kubernetes Auth Method</li> <li>CSI Secret Store Driver</li> <li>ADR-009: Secrets Management</li> </ul>"},{"location":"adr/ADR-016%20devlake-dora-strategy/","title":"ADR-016: DevLake for DORA Metrics Visualization","text":""},{"location":"adr/ADR-016%20devlake-dora-strategy/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#context","title":"Context","text":"<p>The Fawkes platform requires a unified way to collect, calculate, and display the five core DORA metrics to enable teams to assess their service performance, identify bottlenecks, and ensure adherence to Golden Path standards.</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#current-state","title":"Current State","text":"<p>IDP concepts (CI/CD, secrets, infrastructure provisioning, policy enforcement) are disconnected, residing across various URLs (Jenkins, Vault UI, Kubernetes CLI). There is no integrated interface for developers to interact with the platform or view consolidated DORA metrics.</p> <p>The existing ADR-012 (Metrics Monitoring and Management) defines a custom DORA Metrics Service for webhook-based event collection. While this approach provides flexibility, it requires significant custom development effort.</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#requirements","title":"Requirements","text":"<ol> <li>Deployment Frequency: Track successful production deployments per day/week</li> <li>Lead Time for Changes: Measure commit time to production deployment time</li> <li>Change Failure Rate (CFR): Calculate failed deployments / total deployments</li> <li>Mean Time to Restore (MTTR): Measure incident detection to resolution time</li> <li>Operational Performance: Track SLO/SLI adherence for reliability metrics</li> </ol>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#evaluation-criteria","title":"Evaluation Criteria","text":"<ul> <li>Open source with active community</li> <li>Native DORA metrics calculation</li> <li>Integration with Git, Jenkins, and incident management</li> <li>Backstage integration capability</li> <li>Kubernetes-native deployment</li> <li>Minimal operational overhead</li> </ul>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#decision","title":"Decision","text":"<p>We will deploy Apache DevLake as the DORA metrics collection, calculation, and visualization platform for Fawkes.</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#why-apache-devlake","title":"Why Apache DevLake","text":"<p>Advantages: 1. Purpose-built for DORA: Native support for all four DORA metrics 2. Multi-source Integration: Pre-built collectors for GitHub, GitLab, Jenkins,    Jira, and more 3. Open Source: Apache 2.0 license, active CNCF community 4. Extensible: Plugin architecture for custom data sources 5. Grafana Integration: Pre-built dashboards for DORA visualization 6. Low Custom Development: Reduces need for custom webhook handlers</p> <p>Trade-offs: 1. Additional Component: Adds DevLake stack (API, UI, collector workers) 2. Database Requirement: Requires MySQL/PostgreSQL for data storage 3. Learning Curve: Teams need to understand DevLake configuration</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          DevLake DORA Metrics Layer                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                       Data Sources (Collectors)                          \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502 \u2502\n\u2502  \u2502  \u2502   GitHub    \u2502  \u2502   Jenkins   \u2502  \u2502 Observability\u2502 \u2502   Custom    \u2502    \u2502 \u2502\n\u2502  \u2502  \u2502   Plugin    \u2502  \u2502   Plugin    \u2502  \u2502   Webhook   \u2502  \u2502   Webhook   \u2502    \u2502 \u2502\n\u2502  \u2502  \u2502             \u2502  \u2502             \u2502  \u2502             \u2502  \u2502             \u2502    \u2502 \u2502\n\u2502  \u2502  \u2502 \u2022 Commits   \u2502  \u2502 \u2022 Builds    \u2502  \u2502 \u2022 Incidents \u2502  \u2502 \u2022 CFR Events\u2502    \u2502 \u2502\n\u2502  \u2502  \u2502 \u2022 PRs       \u2502  \u2502 \u2022 Deploys   \u2502  \u2502 \u2022 Restores  \u2502  \u2502 \u2022 MTTR Data \u2502    \u2502 \u2502\n\u2502  \u2502  \u2502 \u2022 Branches  \u2502  \u2502 \u2022 Pipelines \u2502  \u2502 \u2022 Alerts    \u2502  \u2502             \u2502    \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 \u2502\n\u2502  \u2502         \u2502                 \u2502                 \u2502                \u2502          \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502            \u2502                 \u2502                 \u2502                \u2502            \u2502\n\u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                                      \u2502                                        \u2502\n\u2502                                      \u25bc                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                      DevLake Core Services                               \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502 \u2502\n\u2502  \u2502  \u2502  DevLake API    \u2502  \u2502  DevLake UI     \u2502  \u2502  Lake Workers   \u2502         \u2502 \u2502\n\u2502  \u2502  \u2502  (Config/Data)  \u2502  \u2502  (Dashboard)    \u2502  \u2502  (Collectors)   \u2502         \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502 \u2502\n\u2502  \u2502           \u2502                                          \u2502                  \u2502 \u2502\n\u2502  \u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502 \u2502\n\u2502  \u2502                            \u2502                                             \u2502 \u2502\n\u2502  \u2502                            \u25bc                                             \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 \u2502\n\u2502  \u2502  \u2502                      MySQL Database                                  \u2502\u2502 \u2502\n\u2502  \u2502  \u2502     (Raw data, domain models, DORA calculations)                    \u2502\u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                      \u2502                                        \u2502\n\u2502                                      \u2502 Prometheus Metrics Export              \u2502\n\u2502                                      \u25bc                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                      Visualization Layer                                 \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502 \u2502\n\u2502  \u2502  \u2502    Grafana      \u2502  \u2502    Backstage    \u2502  \u2502   DevLake UI    \u2502         \u2502 \u2502\n\u2502  \u2502  \u2502  DORA Dashboard \u2502  \u2502  Plugin Widget  \u2502  \u2502  (Native UI)    \u2502         \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#dora-metrics-calculation","title":"DORA Metrics Calculation","text":"<p>DevLake calculates DORA metrics using the appropriate data sources for a GitOps architecture where ArgoCD handles deployments:</p> Metric Primary Data Source Secondary Source Calculation Deployment Frequency ArgoCD sync events GitHub deployments Successful production syncs per time period Lead Time for Changes Git commits + ArgoCD - Time from first commit to ArgoCD sync completion Change Failure Rate ArgoCD + Incidents Observability alerts Failed syncs / Total syncs Mean Time to Restore Incident records + ArgoCD - Time from incident to restore sync Operational Performance Prometheus SLO/SLI data - Uptime, latency, error rate adherence <p>Note on Jenkins Role: In a GitOps architecture, Jenkins handles CI (build, test, scan) but does not perform deployments. Jenkins updates the GitOps repository, which ArgoCD then reconciles. Therefore:</p> <ul> <li>ArgoCD is the source of truth for deployment events</li> <li>Jenkins provides build/test metrics and rework tracking (build failures,   test reruns, quality gate failures)</li> </ul>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#jenkins-rework-metrics","title":"Jenkins Rework Metrics","text":"<p>Jenkins contributes to developer productivity metrics beyond core DORA:</p> Metric Description Calculation Build Success Rate Percentage of successful builds Passed builds / Total builds Test Flakiness Frequency of non-deterministic test failures Flaky runs / Total runs Quality Gate Pass Rate SonarQube gate success Passed gates / Total scans Rework Rate Builds triggered by same commit Rebuilds / Unique commits Build Duration Trend Average build time over time Mean/P95 build duration"},{"location":"adr/ADR-016%20devlake-dora-strategy/#deployment-configuration","title":"Deployment Configuration","text":"<p>Namespace Isolation: - DevLake deployed in <code>fawkes-devlake</code> namespace - Secrets managed via Vault/External Secrets - Network policies restrict access to approved sources</p> <p>Resource Requirements: <pre><code>devlake-api:\n  requests:\n    cpu: 200m\n    memory: 512Mi\n  limits:\n    cpu: 1000m\n    memory: 2Gi\n\ndevlake-ui:\n  requests:\n    cpu: 100m\n    memory: 128Mi\n  limits:\n    cpu: 500m\n    memory: 512Mi\n\nmysql:\n  requests:\n    cpu: 500m\n    memory: 1Gi\n  limits:\n    cpu: 2000m\n    memory: 4Gi\n</code></pre></p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#data-source-configuration","title":"Data Source Configuration","text":"<p>GitHub/Git Integration: - OAuth app for repository access - Webhook receiver for real-time events - Collect: commits, PRs, branches</p> <p>ArgoCD Integration (Primary deployment source): - API access for sync event collection - Deployment frequency from successful syncs - Lead time correlation with commit timestamps - Failure detection from sync failures</p> <p>Jenkins Integration (CI and rework metrics): - API token for build data access - Build success/failure tracking - Quality gate results - Rework metrics: build retries, flaky tests, repeated failures</p> <p>Observability Integration: - Webhook endpoint for incident events - Alert-to-incident correlation - Resolution tracking for MTTR</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#backstage-integration","title":"Backstage Integration","text":"<p>DevLake will integrate with Backstage via: 1. Iframe Plugin: Embed DevLake dashboards in Backstage 2. API Integration: Fetch DORA metrics for service cards 3. Entity Annotation: Link catalog entities to DevLake projects</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#edge-case-handling","title":"Edge Case Handling","text":"Scenario Behavior No deployments for service Display \"N/A\" instead of 0 Partial data (missing incidents) Calculate available metrics, show warnings High cardinality (many services) Use pagination and caching Data source unavailable Show last known values with staleness indicator"},{"location":"adr/ADR-016%20devlake-dora-strategy/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-016%20devlake-dora-strategy/#positive","title":"Positive","text":"<ol> <li>Immediate DORA visibility: Pre-built dashboards reduce time to value</li> <li>Standardized metrics: Consistent calculation across all teams</li> <li>Reduced custom development: Leverage DevLake's tested collectors</li> <li>Extensibility: Plugin architecture for future data sources</li> <li>Community support: Active Apache project with regular updates</li> </ol>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#negative","title":"Negative","text":"<ol> <li>Additional infrastructure: MySQL database and DevLake services</li> <li>Configuration complexity: Multiple data source configurations</li> <li>Storage requirements: Historical data requires database capacity</li> </ol>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#risks-and-mitigations","title":"Risks and Mitigations","text":"Risk Mitigation DevLake version incompatibility Pin to stable versions, test upgrades Data collection failures Alerting on collector health, retry logic Dashboard performance Enable caching, limit historical queries Security exposure Vault-managed credentials, network policies"},{"location":"adr/ADR-016%20devlake-dora-strategy/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-016%20devlake-dora-strategy/#1-custom-dora-metrics-service-adr-012-approach","title":"1. Custom DORA Metrics Service (ADR-012 Approach)","text":"<p>Description: Build custom Go/Python service with webhook receivers</p> <p>Rejected because: - Higher development and maintenance cost - Need to implement all collectors from scratch - No pre-built visualization</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#2-sleuthio-commercial","title":"2. Sleuth.io (Commercial)","text":"<p>Description: SaaS DORA metrics platform</p> <p>Rejected because: - Commercial licensing costs - External data residency concerns - Vendor lock-in</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#3-faros-ai-commercial","title":"3. Faros AI (Commercial)","text":"<p>Description: Engineering metrics platform</p> <p>Rejected because: - Commercial licensing - More complex than needed - Over-featured for core DORA requirements</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#4-haystack-open-source","title":"4. Haystack (Open Source)","text":"<p>Description: Engineering analytics platform</p> <p>Rejected because: - Smaller community than DevLake - Less mature DORA implementation - Limited documentation</p>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-016%20devlake-dora-strategy/#phase-1-core-deployment-week-1","title":"Phase 1: Core Deployment (Week 1)","text":"<ul> <li>[x] Create ADR-016 for DevLake strategy</li> <li>[ ] Deploy DevLake Helm chart via ArgoCD</li> <li>[ ] Configure MySQL persistence</li> <li>[ ] Set up ingress for DevLake UI</li> </ul>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#phase-2-data-source-integration-week-2","title":"Phase 2: Data Source Integration (Week 2)","text":"<ul> <li>[ ] Configure GitHub/Git collector</li> <li>[ ] Configure Jenkins collector</li> <li>[ ] Set up incident webhook receiver</li> <li>[ ] Create initial projects in DevLake</li> </ul>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#phase-3-visualization-week-3","title":"Phase 3: Visualization (Week 3)","text":"<ul> <li>[ ] Import DORA Grafana dashboards</li> <li>[ ] Create Backstage DevLake plugin</li> <li>[ ] Configure team-level views</li> <li>[ ] Set up alerting for metric degradation</li> </ul>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#phase-4-documentation-training-week-4","title":"Phase 4: Documentation &amp; Training (Week 4)","text":"<ul> <li>[ ] Update architecture documentation</li> <li>[ ] Create DORA metrics definition guide</li> <li>[ ] Add Dojo learning module</li> <li>[ ] Create runbooks for operations</li> </ul>"},{"location":"adr/ADR-016%20devlake-dora-strategy/#references","title":"References","text":"<ul> <li>Apache DevLake Documentation</li> <li>DORA Metrics Definition</li> <li>DevLake Grafana Dashboards</li> <li>ADR-012: Metrics Monitoring and Management</li> </ul>"},{"location":"adr/ADR-017%20kyverno-policy-engine/","title":"ADR-017: Kyverno Policy Engine for Policy-as-Code","text":""},{"location":"adr/ADR-017%20kyverno-policy-engine/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#context","title":"Context","text":"<p>The Fawkes platform requires a policy enforcement mechanism to ensure:</p> <ul> <li>Security Standards: All workloads comply with Pod Security Standards</li> <li>Platform Standardization: Consistent labels, annotations, and configurations</li> <li>Governance: Resource quotas, network policies, and compliance requirements</li> <li>Runtime Enforcement: Policies enforced at admission time, not just CI</li> </ul>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#current-state","title":"Current State","text":"<p>Security and standardization are enforced primarily by CI pipeline checks (pre-deployment). Post-deployment compliance relies on manual cluster administrator oversight, leading to:</p> <ol> <li>Inconsistent Enforcement: Different teams may bypass CI checks</li> <li>No Runtime Protection: Malicious or accidental misconfigurations can    be applied directly via kubectl</li> <li>Manual Overhead: Administrators must manually review and correct    non-compliant resources</li> <li>No Automatic Standardization: Platform labels and configurations    require manual addition</li> </ol>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#requirements-from-issue","title":"Requirements from Issue","text":"<ol> <li>Deploy Kyverno as the Kubernetes-native policy engine</li> <li>Implement validation policies for security (Pod Security Standards)</li> <li>Implement mutation policies for automatic standardization</li> <li>Implement generation policies for namespace defaults</li> <li>Enable policy reporting for audit and compliance</li> <li>Avoid duplication with CI security scans (SonarQube)</li> </ol>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#decision","title":"Decision","text":"<p>We will deploy Kyverno as the policy-as-code engine for the Fawkes platform, providing validation, mutation, and generation capabilities through native Kubernetes admission control.</p>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#why-kyverno-over-opagatekeeper","title":"Why Kyverno over OPA/Gatekeeper","text":"Criteria Kyverno OPA/Gatekeeper Learning Curve YAML-based, familiar Rego language, steep Mutation Support Native Limited Generation Support Native Not supported Kubernetes Native Yes, CRDs Abstraction layer Policy Testing kyverno CLI opa test Community Growing rapidly Established <p>We chose Kyverno because:</p> <ol> <li>Lower barrier to entry: Platform teams can write policies in YAML</li> <li>Mutation capabilities: Critical for automatic Vault integration</li> <li>Generation capabilities: Essential for namespace standardization</li> <li>Kubernetes-native: Better integration with ArgoCD and GitOps workflows</li> </ol>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          Kyverno Policy Engine                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                    Admission Controllers                              \u2502   \u2502\n\u2502  \u2502                                                                        \u2502   \u2502\n\u2502  \u2502  ValidatingWebhook \u2500\u2500\u25ba Validate \u2500\u2500\u25ba Allow/Deny                        \u2502   \u2502\n\u2502  \u2502  MutatingWebhook \u2500\u2500\u25ba Mutate \u2500\u2500\u25ba Modified Resource                     \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                    Background Controllers                             \u2502   \u2502\n\u2502  \u2502                                                                        \u2502   \u2502\n\u2502  \u2502  GenerateController \u2500\u2500\u25ba Watch Resources \u2500\u2500\u25ba Create Generated          \u2502   \u2502\n\u2502  \u2502  ReportsController \u2500\u2500\u25ba Collect Results \u2500\u2500\u25ba PolicyReport               \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502   ClusterPolicy         \u2502   Policy (Namespace-scoped)                \u2502   \u2502\n\u2502  \u2502   \u2022 Security            \u2502   \u2022 Team-specific                          \u2502   \u2502\n\u2502  \u2502   \u2022 Platform standards  \u2502   \u2022 Application exceptions                 \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#policy-categories","title":"Policy Categories","text":""},{"location":"adr/ADR-017%20kyverno-policy-engine/#1-mandatory-security-policies-enforce-mode","title":"1. Mandatory Security Policies (Enforce Mode)","text":"<p>These policies DENY non-compliant resources:</p> Policy Description Enforcement <code>require-run-as-non-root</code> Containers must run as non-root Enforce <code>disallow-privileged-containers</code> No privileged containers Enforce <code>restrict-host-namespaces</code> No hostNetwork/hostPID/hostIPC Enforce <code>disallow-host-ports</code> No host port bindings Enforce <code>disallow-capabilities</code> Must drop ALL capabilities Enforce <code>require-resource-limits</code> CPU/memory limits required Enforce"},{"location":"adr/ADR-017%20kyverno-policy-engine/#2-standardization-policies-mutate-mode","title":"2. Standardization Policies (Mutate Mode)","text":"<p>These policies automatically modify resources:</p> Policy Mutation Purpose <code>add-platform-labels</code> Add <code>app.fawkes.idp/*</code> labels Consistent labeling <code>add-vault-annotations</code> Add Vault Agent annotations Secret injection <code>set-ingress-class</code> Set <code>ingressClassName: nginx</code> Traffic routing <code>set-default-security-context</code> Add secure defaults Security baseline <code>add-default-resources</code> Add default requests Scheduling"},{"location":"adr/ADR-017%20kyverno-policy-engine/#3-generation-policies-generate-mode","title":"3. Generation Policies (Generate Mode)","text":"<p>These policies create resources automatically:</p> Policy Generated Resources Trigger <code>generate-namespace-network-policy</code> NetworkPolicy New Namespace <code>generate-namespace-resource-quota</code> ResourceQuota New Namespace <code>generate-namespace-limit-range</code> LimitRange New Namespace <code>generate-namespace-service-account</code> ServiceAccount New Namespace"},{"location":"adr/ADR-017%20kyverno-policy-engine/#deployment-configuration","title":"Deployment Configuration","text":""},{"location":"adr/ADR-017%20kyverno-policy-engine/#high-availability","title":"High Availability","text":"<ul> <li>Admission Controller: 3 replicas with pod anti-affinity</li> <li>Background Controller: 2 replicas</li> <li>Reports Controller: 1 replica</li> <li>Cleanup Controller: 1 replica</li> </ul>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#excluded-namespaces","title":"Excluded Namespaces","text":"<p>System namespaces are excluded from policy enforcement:</p> <ul> <li><code>kube-system</code></li> <li><code>kube-public</code></li> <li><code>kube-node-lease</code></li> <li><code>kyverno</code></li> </ul>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#cicd-integration-avoiding-duplication","title":"CI/CD Integration (Avoiding Duplication)","text":"<p>Kyverno complements rather than duplicates CI security scanning:</p> Layer Tool Purpose Source Code SonarQube SAST, code quality, security hotspots Dependencies OWASP Check Known vulnerabilities in libraries Container Image Trivy Image vulnerabilities, SBOM Admission Kyverno Runtime policy enforcement <p>SonarQube detects code-level issues; Kyverno enforces deployment configuration. There is no overlap.</p>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-017%20kyverno-policy-engine/#positive","title":"Positive","text":"<ol> <li>Consistent Enforcement: All resources validated at admission time</li> <li>Automatic Standardization: Platform labels and configurations applied    automatically</li> <li>Self-Service Namespaces: Standard resources generated for new namespaces</li> <li>Audit Trail: PolicyReports provide compliance evidence</li> <li>GitOps Compatible: Policies stored in Git, deployed via ArgoCD</li> <li>Low Learning Curve: YAML-based policies familiar to Kubernetes users</li> </ol>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#negative","title":"Negative","text":"<ol> <li>Webhook Overhead: Slight latency added to API server requests</li> <li>Policy Complexity: Complex policies may be hard to debug</li> <li>False Positives: Overly strict policies may block legitimate workloads</li> <li>Operational Burden: Kyverno cluster requires monitoring and maintenance</li> </ol>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#risks-and-mitigations","title":"Risks and Mitigations","text":"Risk Mitigation Webhook unavailable blocks deployments <code>failurePolicy: Ignore</code> for non-critical Policy blocks legitimate workload Start with Audit mode, transition to Enforce Complex policies hard to maintain Policy testing in CI, clear documentation Performance impact Adequate resources, caching, excluded namespaces"},{"location":"adr/ADR-017%20kyverno-policy-engine/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-017%20kyverno-policy-engine/#1-opagatekeeper","title":"1. OPA/Gatekeeper","text":"<p>Rejected because: Steeper learning curve (Rego), no native mutation or generation support, less Kubernetes-native feel.</p>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#2-pod-security-admission-psa","title":"2. Pod Security Admission (PSA)","text":"<p>Rejected because: Only provides predefined security levels (baseline, restricted), no custom policies, no mutation or generation.</p>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#3-custom-admission-webhooks","title":"3. Custom Admission Webhooks","text":"<p>Rejected because: High development and maintenance burden, requires custom code for each policy type.</p>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#4-ci-only-enforcement","title":"4. CI-Only Enforcement","text":"<p>Rejected because: Can be bypassed, no runtime protection, no automatic standardization.</p>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-017%20kyverno-policy-engine/#phase-1-core-deployment-week-1","title":"Phase 1: Core Deployment (Week 1)","text":"<ul> <li>[x] Deploy Kyverno via ArgoCD Application</li> <li>[x] Create mandatory security policies</li> <li>[x] Create mutation policies for standardization</li> <li>[x] Create generation policies for namespaces</li> </ul>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#phase-2-testing-validation-week-2","title":"Phase 2: Testing &amp; Validation (Week 2)","text":"<ul> <li>[ ] Test all policies in development environment</li> <li>[ ] Create BDD acceptance tests</li> <li>[ ] Document policy exceptions process</li> <li>[ ] Set up Grafana dashboard for metrics</li> </ul>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#phase-3-production-rollout-week-3","title":"Phase 3: Production Rollout (Week 3)","text":"<ul> <li>[ ] Enable Audit mode in production</li> <li>[ ] Review PolicyReports for false positives</li> <li>[ ] Transition to Enforce mode</li> <li>[ ] Developer documentation and training</li> </ul>"},{"location":"adr/ADR-017%20kyverno-policy-engine/#references","title":"References","text":"<ul> <li>Kyverno Documentation</li> <li>Kyverno Policy Library</li> <li>Pod Security Standards</li> <li>ADR-014: SonarQube Quality Gates</li> <li>ADR-015: Vault Deployment</li> </ul>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/","title":"ADR-018: Developer Experience Measurement Framework (SPACE)","text":""},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#context","title":"Context","text":"<p>The 2025 DORA Report identifies user-centric focus as the single most critical capability for successful AI adoption and high-performing teams. The research found with high certainty that:</p> <p>\u201cWhen teams adopt a user-centric focus, the positive influence of AI on their performance is amplified. Conversely, in the absence of a user-centric focus, AI adoption can have a negative impact on team performance.\u201d</p> <p>For Fawkes to succeed as an Internal Delivery Platform, we must treat developers as our users and continuously measure, understand, and improve their experience. Without systematic measurement of developer experience (DevEx), we risk building features that don\u2019t solve real problems, implementing AI tools that create friction rather than value, and making platform decisions based on assumptions rather than data.</p> <p>Current State:</p> <ul> <li>\u274c No systematic measurement of developer satisfaction</li> <li>\u274c No tracking of cognitive load or friction points</li> <li>\u274c No understanding of time spent on valuable vs. toil work</li> <li>\u274c No feedback loops from developers to platform team</li> <li>\u274c Platform decisions made on assumptions, not validated needs</li> <li>\u274c No baseline metrics to measure improvement over time</li> </ul> <p>The Problem: Organizations often measure outputs (deployments, lines of code, tickets closed) but fail to measure the experience of the people doing the work. This leads to:</p> <ul> <li>Productivity theater (looking busy without delivering value)</li> <li>Burnout from measuring activity instead of outcomes</li> <li>Tools and processes that optimize metrics but harm humans</li> <li>Disconnect between platform team goals and developer needs</li> </ul> <p>Industry Context: The SPACE framework, developed by researchers at GitHub, Microsoft, and University of Victoria, provides a holistic approach to measuring developer productivity and experience across five dimensions:</p> <ol> <li>Satisfaction: How fulfilled developers feel</li> <li>Performance: System and process outcomes</li> <li>Activity: Developer actions and outputs</li> <li>Communication &amp; Collaboration: Team interaction quality</li> <li>Efficiency &amp; Flow: Ability to complete work with minimal interruption</li> </ol> <p>This framework has been validated in industry and aligns with DORA\u2019s research on high-performing teams.</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#decision","title":"Decision","text":"<p>We will adopt the SPACE framework as our comprehensive Developer Experience measurement strategy for the Fawkes platform. This framework will guide what we measure, how we collect data, and how we act on insights to continuously improve the platform.</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Developer Experience Measurement System                    \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 SATISFACTION (Self-Reported)                           \u2502 \u2502\n\u2502  \u2502 - NPS surveys (quarterly)                              \u2502 \u2502\n\u2502  \u2502 - Platform satisfaction ratings (5-point scale)        \u2502 \u2502\n\u2502  \u2502 - Recommendation likelihood                            \u2502 \u2502\n\u2502  \u2502 - Well-being assessments                               \u2502 \u2502\n\u2502  \u2502 - Job satisfaction                                     \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                          \u2193                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 PERFORMANCE (System Metrics)                           \u2502 \u2502\n\u2502  \u2502 - DORA 4 keys (deployment freq, lead time, CFR, MTTR) \u2502 \u2502\n\u2502  \u2502 - Build success rate                                   \u2502 \u2502\n\u2502  \u2502 - Test coverage                                        \u2502 \u2502\n\u2502  \u2502 - Code review turnaround time                          \u2502 \u2502\n\u2502  \u2502 - Incident response time                               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                          \u2193                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 ACTIVITY (Behavioral Metrics)                          \u2502 \u2502\n\u2502  \u2502 - Commits per developer                                \u2502 \u2502\n\u2502  \u2502 - Pull requests opened/merged                          \u2502 \u2502\n\u2502  \u2502 - Code review participation                            \u2502 \u2502\n\u2502  \u2502 - Documentation contributions                          \u2502 \u2502\n\u2502  \u2502 - Platform feature usage                               \u2502 \u2502\n\u2502  \u2502 - AI tool adoption rates                               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                          \u2193                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 COMMUNICATION &amp; COLLABORATION (Interaction Quality)    \u2502 \u2502\n\u2502  \u2502 - Mattermost engagement metrics                        \u2502 \u2502\n\u2502  \u2502 - Code review quality (comment depth, resolution time) \u2502 \u2502\n\u2502  \u2502 - Documentation clarity ratings                        \u2502 \u2502\n\u2502  \u2502 - Cross-team collaboration frequency                   \u2502 \u2502\n\u2502  \u2502 - Knowledge sharing (wiki edits, blog posts)          \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                          \u2193                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 EFFICIENCY &amp; FLOW (Experience Quality)                 \u2502 \u2502\n\u2502  \u2502 - Time spent in flow state (self-reported)            \u2502 \u2502\n\u2502  \u2502 - Cognitive load assessments                           \u2502 \u2502\n\u2502  \u2502 - Context switching frequency                          \u2502 \u2502\n\u2502  \u2502 - Percentage of time on valuable work                 \u2502 \u2502\n\u2502  \u2502 - Friction incident logging                            \u2502 \u2502\n\u2502  \u2502 - Interruption tracking                                \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                          \u2193                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 DevEx Dashboard (Grafana)                              \u2502 \u2502\n\u2502  \u2502 - Real-time metrics visualization                      \u2502 \u2502\n\u2502  \u2502 - Historical trend analysis                            \u2502 \u2502\n\u2502  \u2502 - Team-level drill-downs                               \u2502 \u2502\n\u2502  \u2502 - Alert on degrading metrics                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#implementation-five-space-dimensions","title":"Implementation: Five SPACE Dimensions","text":""},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#1-satisfaction-how-happy-are-developers","title":"1. SATISFACTION (How Happy Are Developers?)","text":"<p>What We\u2019ll Measure:</p> <ul> <li>Net Promoter Score (NPS): \u201cHow likely are you to recommend Fawkes to a colleague?\u201d (0-10 scale)</li> <li>Platform Satisfaction: \u201cHow satisfied are you with the Fawkes platform?\u201d (1-5 scale)</li> <li>Feature Satisfaction: Rate specific features (Backstage, CI/CD, GitOps, etc.)</li> <li>Well-being: \u201cI feel burned out from work\u201d (strongly disagree to strongly agree)</li> <li>Job Satisfaction: \u201cI find my work meaningful and fulfilling\u201d</li> </ul> <p>Collection Methods:</p> <ul> <li>Quarterly NPS surveys (5 minutes)</li> <li>Post-interaction micro-surveys (1 question after major platform actions)</li> <li>Annual comprehensive DevEx survey (15 minutes)</li> <li>In-platform feedback widget (always available)</li> </ul> <p>Target Metrics:</p> <ul> <li>NPS &gt;50 (good), &gt;70 (excellent)</li> <li>Platform satisfaction &gt;4.0/5.0</li> <li>&lt;20% reporting burnout symptoms</li> </ul> <p>Example Survey Question:</p> <pre><code>On a scale of 0-10, how likely are you to recommend \nthe Fawkes platform to a colleague?\n\n0 = Not at all likely\n10 = Extremely likely\n\n[0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10]\n\nFollow-up: What's the primary reason for your score?\n[Text box]\n</code></pre>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#2-performance-how-well-do-systems-work","title":"2. PERFORMANCE (How Well Do Systems Work?)","text":"<p>What We\u2019ll Measure:</p> <ul> <li>DORA Metrics: Deployment frequency, lead time, change failure rate, MTTR</li> <li>Build Metrics: Build success rate, build duration (P50, P95)</li> <li>Quality Metrics: Test coverage, security scan pass rate, code quality scores</li> <li>Reliability Metrics: Service uptime, incident count, MTTR</li> <li>Time-to-Value: Hours from onboarding to first deployment</li> </ul> <p>Collection Methods:</p> <ul> <li>Automated telemetry from Jenkins, ArgoCD, GitHub</li> <li>Prometheus metrics collection</li> <li>Grafana dashboards with historical trends</li> <li>Automated alerting on threshold breaches</li> </ul> <p>Target Metrics:</p> <ul> <li>Deployment frequency: &gt;1/day</li> <li>Lead time for changes: &lt;24 hours</li> <li>Change failure rate: &lt;15%</li> <li>MTTR: &lt;1 hour</li> <li>Build success rate: &gt;95%</li> <li>Time to first deployment: &lt;4 hours</li> </ul> <p>Example Dashboard Panel:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 DORA Metrics - Last 30 Days             \u2502\n\u2502                                         \u2502\n\u2502 Deployment Frequency: 2.3/day \u2191 +15%  \u2502\n\u2502 Lead Time: 18 hours        \u2193 -22%     \u2502\n\u2502 Change Failure Rate: 12%   \u2193 -3%      \u2502\n\u2502 MTTR: 47 minutes          \u2193 -18%      \u2502\n\u2502                                         \u2502\n\u2502 [View Details] [Team Breakdown]        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#3-activity-what-are-developers-doing","title":"3. ACTIVITY (What Are Developers Doing?)","text":"<p>What We\u2019ll Measure:</p> <ul> <li>Code Contributions: Commits, PRs, lines added/deleted</li> <li>Review Activity: PRs reviewed, comments per review, approval rate</li> <li>Platform Usage: Backstage views, dojo module completions, tool adoption</li> <li>AI Tool Usage: Copilot acceptance rate, AI-generated code percentage</li> <li>Documentation: Wiki edits, TechDocs updates, README improvements</li> <li>Learning: Dojo progress, certification completions, training attendance</li> </ul> <p>Collection Methods:</p> <ul> <li>GitHub API for code metrics</li> <li>Backstage analytics</li> <li>Application logs and usage tracking</li> <li>AI tool telemetry (Copilot, RAG queries)</li> </ul> <p>Target Metrics:</p> <ul> <li>80%+ developers active on platform weekly</li> <li>Average 10+ commits per developer per week</li> <li>90%+ PRs reviewed within 24 hours</li> <li>70%+ AI tool adoption within 6 months</li> <li>50%+ developers complete White Belt within 3 months</li> </ul> <p>Warning: Activity metrics alone are dangerous. Never use these for:</p> <ul> <li>Individual performance reviews</li> <li>Ranking developers</li> <li>Setting quotas or minimums</li> <li>Punitive actions</li> </ul> <p>These metrics show patterns, not individual worth. High activity \u2260 high value.</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#4-communication-collaboration-how-well-do-teams-work-together","title":"4. COMMUNICATION &amp; COLLABORATION (How Well Do Teams Work Together?)","text":"<p>What We\u2019ll Measure:</p> <ul> <li>Code Review Quality: Average comments per PR, time to first review, resolution time</li> <li>Collaboration Patterns: Cross-team PRs, pair programming sessions, mob programming</li> <li>Knowledge Sharing: Mattermost channel activity, documentation contributions</li> <li>Feedback Quality: Constructive comment ratio, conflict resolution time</li> <li>Onboarding Support: Mentorship assignments, new developer success rate</li> </ul> <p>Collection Methods:</p> <ul> <li>GitHub PR metadata analysis</li> <li>Mattermost analytics</li> <li>Backstage TechDocs engagement</li> <li>Manual tagging of collaboration events</li> <li>Onboarding survey feedback</li> </ul> <p>Target Metrics:</p> <ul> <li>&lt;12 hour average time to first code review</li> <li>80% PRs with at least 1 constructive comment</li> <li>60% developers actively helping in Mattermost</li> <li>&lt;5% \u201ctoxic\u201d or unconstructive review comments</li> <li>90%+ new developers feel supported during onboarding</li> </ul> <p>Example Metric:</p> <pre><code>Code Review Health Score: 87/100\n\n\u2705 Fast response: 8 hours avg (target: &lt;12)\n\u2705 Thorough: 3.2 comments avg (target: &gt;2)\n\u26a0\ufe0f  Approval rate: 92% (investigate rubber-stamping?)\n\u2705 Constructive tone: 96% positive\n</code></pre>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#5-efficiency-flow-can-developers-focus-and-deliver-value","title":"5. EFFICIENCY &amp; FLOW (Can Developers Focus and Deliver Value?)","text":"<p>What We\u2019ll Measure:</p> <ul> <li>Flow State: \u201cHow often did you achieve deep focus?\u201d (self-reported weekly)</li> <li>Valuable Work Time: \u201c% of time spent on work you consider valuable\u201d (weekly survey)</li> <li>Friction Incidents: Logging when tools/processes create blockers</li> <li>Context Switching: \u201cHow many different tools/tasks did you use today?\u201d</li> <li>Cognitive Load: \u201cRate your mental effort today\u201d (1-5 scale, daily pulse)</li> <li>Wait Time: Time spent blocked on external dependencies</li> </ul> <p>Collection Methods:</p> <ul> <li>Weekly pulse surveys (2 minutes, 5 questions)</li> <li>Friction logging widget in Backstage (\u201cReport a friction point\u201d)</li> <li>Time tracking (optional, privacy-preserving)</li> <li>Meeting calendar analysis (% time in meetings)</li> </ul> <p>Target Metrics:</p> <ul> <li>60% time spent on valuable work</li> <li>3 days per week achieving flow state</li> <li>&lt;30 friction incidents per 100 developers per month</li> <li>Cognitive load average &lt;3.5/5.0 (below \u201coverwhelmed\u201d)</li> <li>&lt;25% time in meetings</li> </ul> <p>Example Weekly Pulse Survey:</p> <pre><code>Quick Check-In (2 minutes)\n\n1. This week, approximately what % of your time \n   was spent on work you found valuable?\n   [Slider: 0% - 100%]\n\n2. How many times did you achieve \"flow state\" \n   (deep, focused work)?\n   [ ] Never  [ ] 1-2 times  [ ] 3-4 times  [ ] 5+ times\n\n3. Rate your cognitive load this week:\n   [ ] Very Low  [ ] Low  [ ] Moderate  [ ] High  [ ] Overwhelming\n\n4. Did you experience any significant friction \n   using the platform?\n   [ ] No  [ ] Yes \u2192 [Report details]\n\n5. One thing to celebrate or improve?\n   [Optional text box]\n</code></pre>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#data-collection-infrastructure","title":"Data Collection Infrastructure","text":"<p>Technology Stack:</p> <ul> <li>Surveys: Qualtrics or Typeform (quarterly NPS, annual DevEx)</li> <li>Pulse Surveys: Custom Backstage plugin (weekly 2-min check-in)</li> <li>Metrics Collection: Prometheus (system metrics)</li> <li>Dashboards: Grafana (DevEx Dashboard with SPACE dimensions)</li> <li>Feedback Widget: Backstage plugin (always-on feedback)</li> <li>Analytics: PostHog or Amplitude (product analytics)</li> <li>Data Warehouse: PostgreSQL (survey responses, aggregated metrics)</li> </ul> <p>Data Pipeline:</p> <pre><code>Survey Tools \u2192 API \u2192 Data Warehouse (PostgreSQL)\n                \u2193\nPlatform Logs \u2192 Prometheus \u2192 Grafana DevEx Dashboard\n                \u2193\nGitHub API \u2192 ETL \u2192 Data Warehouse\n                \u2193\n          Analysis &amp; Reports\n</code></pre>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#privacy-ethics","title":"Privacy &amp; Ethics","text":"<p>Privacy-First Principles:</p> <ol> <li>Individual data is never shared: Managers never see individual survey responses</li> <li>Aggregation threshold: Metrics only shown for groups of 5+ people</li> <li>Opt-in for detailed tracking: Time tracking, keystroke analytics always optional</li> <li>Anonymous feedback: Developers can always provide feedback anonymously</li> <li>Data retention limits: Survey responses deleted after 2 years</li> <li>Right to be forgotten: Developers can request data deletion at any time</li> </ol> <p>Never Use DevEx Data For:</p> <ul> <li>\u274c Individual performance reviews</li> <li>\u274c Ranking developers</li> <li>\u274c Firing decisions</li> <li>\u274c Bonus calculations</li> <li>\u274c Comparing individuals</li> </ul> <p>Always Use DevEx Data For:</p> <ul> <li>\u2705 Identifying platform improvement opportunities</li> <li>\u2705 Understanding team-level trends</li> <li>\u2705 Measuring impact of platform changes</li> <li>\u2705 Celebrating successes</li> <li>\u2705 Advocating for developer needs to leadership</li> </ul>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#the-devex-dashboard","title":"The DevEx Dashboard","text":"<p>Grafana Dashboard Structure (3 pages):</p> <p>Page 1: Executive Summary</p> <ul> <li>Overall NPS score with trend</li> <li>DORA 4 keys summary</li> <li>Satisfaction score across dimensions</li> <li>Key alerts (metrics degrading)</li> </ul> <p>Page 2: SPACE Deep Dive</p> <ul> <li>5 panels (one per SPACE dimension)</li> <li>Historical trends (30/60/90 day views)</li> <li>Team-level breakdowns</li> <li>Correlation analysis (e.g., satisfaction vs. lead time)</li> </ul> <p>Page 3: Action Dashboard</p> <ul> <li>Top 5 friction points (from feedback)</li> <li>Suggested improvements (from analysis)</li> <li>Experiment tracking (what we\u2019re trying)</li> <li>Impact measurement (did changes help?)</li> </ul>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#measurement-cadence","title":"Measurement Cadence","text":"Metric Type Frequency Duration Purpose NPS Survey Quarterly 5 min Track overall satisfaction trend DevEx Survey Annual 15 min Comprehensive assessment Weekly Pulse Weekly 2 min Quick check-in, catch issues early Friction Reports Continuous 1 min Log blockers in real-time DORA Metrics Continuous N/A Automated system metrics Platform Analytics Continuous N/A Usage patterns, adoption"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#acting-on-insights-the-feedback-loop","title":"Acting on Insights: The Feedback Loop","text":"<p>Monthly DevEx Review Meeting (Platform Team):</p> <ol> <li>Review dashboard (30 minutes)</li> <li>Identify top 3 issues (from friction reports, survey feedback)</li> <li>Prioritize improvements (impact vs. effort)</li> <li>Commit to 1-2 experiments for next month</li> <li>Measure impact in following month</li> </ol> <p>Quarterly DevEx Report (to Leadership):</p> <ul> <li>NPS trend and key drivers</li> <li>DORA metrics performance</li> <li>Platform adoption metrics</li> <li>Top improvements delivered</li> <li>Planned focus areas for next quarter</li> </ul> <p>Communicating Back to Developers:</p> <ul> <li>Monthly \u201cYou Said, We Did\u201d post in Mattermost</li> <li>Quarterly DevEx town hall (results + roadmap)</li> <li>Always close the loop on feedback: \u201cWe heard X, here\u2019s what we\u2019re doing about it\u201d</li> </ul>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#positive","title":"Positive","text":"<ol> <li>Data-Driven Decisions: Platform roadmap based on validated user needs, not assumptions</li> <li>Early Warning System: Degrading metrics alert us to problems before they become crises</li> <li>Demonstrate Value: Quantify platform impact for leadership (ROI, productivity gains)</li> <li>Continuous Improvement: Systematic process for getting better over time</li> <li>Developer Trust: Developers feel heard when feedback leads to action</li> <li>AI Readiness: User-centric foundation amplifies AI benefits (per DORA research)</li> <li>Attract Talent: High DevEx scores help recruit top engineers</li> <li>Reduce Turnover: Satisfied developers stay longer, reducing hiring costs</li> <li>Cultural Shift: Treating developers as users changes how we build platforms</li> <li>Benchmark Progress: Baselines enable \u201cbefore/after\u201d analysis of changes</li> </ol>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#negative","title":"Negative","text":"<ol> <li>Survey Fatigue: Too many surveys can reduce response rates (mitigate with short, purposeful surveys)</li> <li>Privacy Concerns: Developers may worry about surveillance (mitigate with clear privacy policy)</li> <li>Overhead: Collecting, analyzing, and acting on data takes time (~20% of platform team)</li> <li>Expectation Management: Measuring creates expectation that we\u2019ll act on findings</li> <li>Analysis Paralysis: Too much data can delay decisions (mitigate with monthly review cadence)</li> <li>Gaming Metrics: Teams may try to optimize metrics rather than outcomes (mitigate with education)</li> <li>Initial Low Scores: First measurements may reveal uncomfortable truths about current state</li> </ol>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#neutral","title":"Neutral","text":"<ol> <li>Requires Cultural Buy-In: Leadership must support user-centric approach</li> <li>Learning Curve: Platform team must develop research and analysis skills</li> <li>Ongoing Effort: DevEx measurement is a permanent practice, not a one-time project</li> </ol>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#alternative-1-no-formal-measurement-status-quo","title":"Alternative 1: No Formal Measurement (Status Quo)","text":"<p>Pros:</p> <ul> <li>Zero overhead</li> <li>No survey fatigue</li> <li>No privacy concerns</li> </ul> <p>Cons:</p> <ul> <li>Decisions based on loudest voices or HiPPO (Highest Paid Person\u2019s Opinion)</li> <li>No way to prove platform value</li> <li>Can\u2019t measure improvement over time</li> <li>Miss early warning signs of problems</li> </ul> <p>Reason for Rejection: DORA research conclusively shows user-centric focus amplifies AI benefits and team performance. Without measurement, we can\u2019t be user-centric.</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#alternative-2-dora-metrics-only","title":"Alternative 2: DORA Metrics Only","text":"<p>Pros:</p> <ul> <li>Well-established framework</li> <li>Automated data collection</li> <li>Proven correlation with outcomes</li> </ul> <p>Cons:</p> <ul> <li>Only measures system performance, not human experience</li> <li>Misses satisfaction, cognitive load, friction</li> <li>Can create perverse incentives if used alone</li> <li>Doesn\u2019t capture communication/collaboration quality</li> </ul> <p>Reason for Rejection: DORA metrics are necessary but insufficient. SPACE framework encompasses DORA metrics (Performance dimension) plus human factors.</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#alternative-3-custom-metrics-framework","title":"Alternative 3: Custom Metrics Framework","text":"<p>Pros:</p> <ul> <li>Tailored precisely to Fawkes needs</li> <li>No need to learn existing framework</li> </ul> <p>Cons:</p> <ul> <li>Reinventing the wheel</li> <li>No industry benchmarks for comparison</li> <li>Lacks research validation</li> <li>Hard to explain to stakeholders</li> </ul> <p>Reason for Rejection: SPACE is well-researched, industry-validated, and comprehensive. Better to adopt proven framework than create our own.</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#alternative-4-simple-nps-only","title":"Alternative 4: Simple NPS Only","text":"<p>Pros:</p> <ul> <li>Very simple to implement</li> <li>Low survey burden</li> <li>Easy to track over time</li> </ul> <p>Cons:</p> <ul> <li>NPS tells you \u201cwhat\u201d (satisfaction level) but not \u201cwhy\u201d</li> <li>No diagnostic capability</li> <li>Can\u2019t identify specific improvement areas</li> <li>Misses entire dimensions (activity, flow, collaboration)</li> </ul> <p>Reason for Rejection: NPS is a great summary metric but insufficient for driving improvements. We need diagnostic metrics to understand what to fix.</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#alternative-5-devex-framework-dx-core-4","title":"Alternative 5: DevEx Framework (DX Core 4)","text":"<p>Pros:</p> <ul> <li>Focused specifically on developer experience</li> <li>Simpler than SPACE (4 dimensions vs. 5)</li> <li>Good research backing</li> </ul> <p>Cons:</p> <ul> <li>Less comprehensive than SPACE</li> <li>Newer framework (less industry adoption)</li> <li>Doesn\u2019t explicitly include collaboration dimension</li> </ul> <p>Reason for Rejection: SPACE is more comprehensive and has broader industry adoption. DevEx framework is good but SPACE is better established.</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#phase-1-foundation-weeks-1-2","title":"Phase 1: Foundation (Weeks 1-2)","text":"<p>Week 1: Infrastructure Setup</p> <ol> <li>Deploy survey tools (Qualtrics/Typeform account)</li> <li>Create data warehouse schema in PostgreSQL</li> <li>Design Grafana DevEx dashboard (mockup)</li> <li>Draft privacy policy and data handling procedures</li> <li>Write initial NPS survey (5 questions)</li> </ol> <p>Week 2: Baseline Measurement</p> <ol> <li>Launch first NPS survey to all developers</li> <li>Collect DORA metrics baseline (automated)</li> <li>Deploy friction reporting widget in Backstage</li> <li>Analyze NPS results and identify themes</li> <li>Set initial targets for each SPACE dimension</li> </ol>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#phase-2-full-rollout-weeks-3-4","title":"Phase 2: Full Rollout (Weeks 3-4)","text":"<p>Week 3: Automated Metrics</p> <ol> <li>Implement Prometheus collectors for activity metrics</li> <li>Build Grafana dashboards (all 5 SPACE dimensions)</li> <li>Set up alerting for degrading metrics</li> <li>Document data collection infrastructure</li> <li>Train platform team on dashboard usage</li> </ol> <p>Week 4: Feedback Loops</p> <ol> <li>Deploy weekly pulse survey (automated in Backstage)</li> <li>Create feedback response process (monthly review meetings)</li> <li>Launch first \u201cYou Said, We Did\u201d communication</li> <li>Schedule quarterly DevEx review with leadership</li> <li>Establish monthly user interview schedule (5 devs/month)</li> </ol>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#phase-3-iteration-month-2","title":"Phase 3: Iteration (Month 2+)","text":"<ol> <li>Conduct first monthly DevEx review meeting</li> <li>Implement 1-2 improvements based on feedback</li> <li>Measure impact of changes</li> <li>Refine metrics and surveys based on learnings</li> <li>Build momentum: celebrate wins, share results</li> </ol>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#metrics-for-success","title":"Metrics for Success","text":"<p>Adoption Metrics (First 3 Months):</p> <ul> <li>70%+ response rate on NPS surveys</li> <li>50%+ response rate on weekly pulse surveys</li> <li>20+ friction reports submitted per month</li> <li>100% platform team trained on dashboard usage</li> <li>Monthly DevEx review meetings established</li> </ul> <p>Outcome Metrics (First 6 Months):</p> <ul> <li>NPS &gt;50 (baseline + improvement)</li> <li>60% developers report time on valuable work</li> <li>&lt;30 friction incidents per 100 developers per month</li> <li>DORA metrics trending upward</li> <li>3+ platform improvements delivered from feedback</li> </ul> <p>Long-Term Metrics (12+ Months):</p> <ul> <li>NPS &gt;60 (elite performer territory)</li> <li>Deployment frequency &gt;2/day</li> <li>Lead time &lt;12 hours</li> <li>&lt;10% developers reporting burnout</li> <li>Platform team can articulate clear ROI with data</li> </ul>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-002: Backstage for Developer Portal (primary vehicle for surveys, feedback widget)</li> <li>ADR-006: Prometheus for Metrics (Performance and Activity dimension data collection)</li> <li>ADR-015: User Research &amp; Feedback System (complements quantitative metrics with qualitative insights)</li> <li>ADR-016: Platform-as-Product Operating Model (DevEx metrics inform product roadmap)</li> </ul>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#references","title":"References","text":"<ul> <li>SPACE Framework Paper: https://queue.acm.org/detail.cfm?id=3454124</li> <li>2025 DORA Report: https://dora.dev/dora-report-2025</li> <li>DevEx Framework: https://queue.acm.org/detail.cfm?id=3595878</li> <li>GitHub Octoverse: Developer productivity research</li> <li>Accelerate (Book): Forsgren, Humble, Kim - DORA metrics foundation</li> <li>Team Topologies (Book): Skelton &amp; Pais - Cognitive load research</li> </ul>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#notes","title":"Notes","text":"<p>Key Insight from DORA 2025:</p> <p>\u201cWe found with a high degree of certainty that when teams adopt a user-centric focus, the positive influence of AI on their performance is amplified. Conversely, in the absence of a user-centric focus, AI adoption can have a negative impact on team performance.\u201d</p> <p>Translation for Fawkes:</p> <ul> <li>DevEx measurement is not optional\u2014it\u2019s the foundation for AI success</li> <li>Without measuring developer experience, AI adoption may harm performance</li> <li>SPACE framework provides the comprehensive measurement system we need</li> <li>Measurement without action is worthless\u2014commit to monthly improvements</li> </ul> <p>Cultural Note: Implementing DevEx measurement is a cultural transformation as much as a technical one. The platform team must genuinely care about developer experience and be willing to change based on feedback. If leadership views this as \u201cjust more metrics,\u201d it will fail.</p>"},{"location":"adr/ADR-018%20Developer%20Experience%20Measurement%20Framework%20SPACE/#last-updated","title":"Last Updated","text":"<p>December 7, 2024 - Initial version documenting SPACE framework adoption for Fawkes DevEx measurement</p>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/","title":"ADR-019: User Research &amp; Feedback Collection System","text":""},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#context","title":"Context","text":"<p>ADR-018 established the SPACE framework for quantitative measurement of developer experience. However, numbers alone cannot tell the complete story. Metrics show what is happening but rarely explain why. To build a truly user-centric platform, we need deep qualitative insights to complement our quantitative metrics.</p> <p>The 2025 DORA Report Finding:</p> <p>\u201cUser-centric focus is THE differentiator. Without it, AI adoption can have a negative impact on team performance.\u201d</p> <p>What \u201cUser-Centric\u201d Actually Means:</p> <ul> <li>Regular direct contact with developers (our users)</li> <li>Understanding their goals, pain points, and workflows</li> <li>Validating assumptions before building features</li> <li>Closing the feedback loop: \u201cYou said X, we did Y\u201d</li> <li>Treating the platform as a product, developers as customers</li> </ul> <p>Current State - Critical Gaps:</p> <ul> <li>\u274c No systematic user interviews</li> <li>\u274c No user journey mapping</li> <li>\u274c No usability testing of platform features</li> <li>\u274c No process for collecting/triaging feedback</li> <li>\u274c Platform decisions made by platform team in isolation</li> <li>\u274c Developers have no clear way to influence roadmap</li> </ul> <p>Why This Matters for Fawkes:</p> <ol> <li>AI Amplification: User-centric focus amplifies AI benefits (DORA finding)</li> <li>Avoid \u201cBuild It and They Won\u2019t Come\u201d: Features nobody asked for = wasted effort</li> <li>Early Problem Detection: Catch issues before they become widespread</li> <li>Build Trust: Developers feel heard when their feedback shapes the platform</li> <li>Competitive Advantage: Great DevEx attracts and retains top talent</li> </ol>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#decision","title":"Decision","text":"<p>We will implement a comprehensive User Research &amp; Feedback Collection System with three interconnected components:</p> <ol> <li>Continuous Feedback Channels (always-on, low-friction)</li> <li>Structured User Research (proactive, scheduled)</li> <li>Feedback Processing Pipeline (turning insights into action)</li> </ol>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  FEEDBACK COLLECTION LAYER                                   \u2502\n\u2502                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 In-Platform    \u2502  \u2502 Mattermost     \u2502  \u2502 Office Hours   \u2502 \u2502\n\u2502  \u2502 Feedback       \u2502  \u2502 #platform      \u2502  \u2502 (Bi-weekly)    \u2502 \u2502\n\u2502  \u2502 Widget         \u2502  \u2502 -feedback      \u2502  \u2502                \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 User           \u2502  \u2502 Usability      \u2502  \u2502 Feature        \u2502 \u2502\n\u2502  \u2502 Interviews     \u2502  \u2502 Testing        \u2502  \u2502 Requests       \u2502 \u2502\n\u2502  \u2502 (Monthly)      \u2502  \u2502 Sessions       \u2502  \u2502 (GitHub)       \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  AGGREGATION &amp; ANALYSIS LAYER                                \u2502\n\u2502                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Feedback Database (PostgreSQL)                         \u2502  \u2502\n\u2502  \u2502 - All feedback tagged and categorized                  \u2502  \u2502\n\u2502  \u2502 - Sentiment analysis (AI-powered)                      \u2502  \u2502\n\u2502  \u2502 - Deduplication and clustering                         \u2502  \u2502\n\u2502  \u2502 - Priority scoring algorithm                           \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                            \u2193                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Analysis &amp; Insights                                    \u2502  \u2502\n\u2502  \u2502 - Theme identification (qualitative coding)            \u2502  \u2502\n\u2502  \u2502 - Trend analysis (increasing/decreasing issues)        \u2502  \u2502\n\u2502  \u2502 - Impact assessment (how many users affected?)         \u2502  \u2502\n\u2502  \u2502 - User journey pain point mapping                      \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  ACTION &amp; COMMUNICATION LAYER                                \u2502\n\u2502                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Monthly DevEx Review Meeting                           \u2502  \u2502\n\u2502  \u2502 - Review top feedback themes                           \u2502  \u2502\n\u2502  \u2502 - Prioritize improvements (impact vs. effort)          \u2502  \u2502\n\u2502  \u2502 - Assign owners and set deadlines                      \u2502  \u2502\n\u2502  \u2502 - Track experiments and measure impact                 \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                            \u2193                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 \"You Said, We Did\" Communication                       \u2502  \u2502\n\u2502  \u2502 - Monthly update post (Mattermost + email)             \u2502  \u2502\n\u2502  \u2502 - Quarterly DevEx town hall                            \u2502  \u2502\n\u2502  \u2502 - Close the loop on every piece of feedback            \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#component-1-continuous-feedback-channels","title":"Component 1: Continuous Feedback Channels","text":""},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#11-in-platform-feedback-widget-backstage-plugin","title":"1.1 In-Platform Feedback Widget (Backstage Plugin)","text":"<p>What: A persistent feedback button in Backstage that allows developers to submit feedback in &lt;30 seconds without leaving their workflow.</p> <p>Implementation:</p> <pre><code>// Backstage Plugin: @fawkes/plugin-feedback\n// Appears in every Backstage page header\n\ninterface FeedbackSubmission {\n  type: 'bug' | 'friction' | 'feature-request' | 'praise';\n  category: 'ci-cd' | 'gitops' | 'docs' | 'dojo' | 'other';\n  description: string;\n  context: {\n    page: string;\n    timestamp: Date;\n    userRole: string;\n    anonymized: boolean;\n  };\n  sentiment: 'positive' | 'neutral' | 'negative';\n}\n</code></pre> <p>Features:</p> <ul> <li>One-click access from any Backstage page</li> <li>Pre-categorized feedback types (reduces friction)</li> <li>Optional anonymous submission</li> <li>Automatically captures context (page, time, user role)</li> <li>AI-powered sentiment analysis</li> <li>\u201cThank you\u201d confirmation with ticket number</li> </ul> <p>Example Flow:</p> <pre><code>[User clicks \"Give Feedback\" button in Backstage header]\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Quick Feedback (30 seconds)            \u2502\n\u2502                                          \u2502\n\u2502  What type of feedback?                 \u2502\n\u2502  ( ) Bug - Something's broken           \u2502\n\u2502  (\u2022) Friction - Something's annoying    \u2502\n\u2502  ( ) Feature Request - I need...        \u2502\n\u2502  ( ) Praise - Something's great!        \u2502\n\u2502                                          \u2502\n\u2502  Which area?                             \u2502\n\u2502  [Dropdown: CI/CD, GitOps, Docs, etc.]  \u2502\n\u2502                                          \u2502\n\u2502  Tell us more: (required)                \u2502\n\u2502  [Text area - 50-500 characters]         \u2502\n\u2502                                          \u2502\n\u2502  [\u2713] Make this feedback anonymous        \u2502\n\u2502                                          \u2502\n\u2502  [Cancel]  [Submit Feedback]             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n[After submission]\n\u2705 Thanks! Your feedback has been recorded as FEEDBACK-1234.\n   The platform team reviews all feedback monthly.\n</code></pre> <p>Target: 50+ feedback submissions per month (for 100 developers = 50% monthly participation)</p>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#12-mattermost-platform-feedback-channel","title":"1.2 Mattermost #platform-feedback Channel","text":"<p>What: A dedicated, monitored channel where developers can share feedback, ask questions, and discuss platform topics.</p> <p>Purpose:</p> <ul> <li>Lower-friction than formal feedback form</li> <li>Enables peer-to-peer discussion</li> <li>Platform team can ask clarifying questions</li> <li>Public transparency (everyone sees responses)</li> </ul> <p>Guidelines:</p> <ul> <li>Platform team commits to &lt;24 hour response time</li> <li>All feedback is acknowledged, even if not immediately actionable</li> <li>Emoji reactions for quick validation (\u201c\ud83d\udc4d we hear you\u201d)</li> <li>Monthly summary post of feedback received and actions taken</li> </ul> <p>Example Interaction:</p> <pre><code>@developer_alice [10:23 AM]\nThe Jenkins build for my service is taking 45 minutes now. \nIt used to be 15 minutes last month. Anyone else seeing this?\n\ud83d\udc0c\n\n@platform_engineer [10:41 AM]\nThanks for flagging @developer_alice! We'll investigate. \nCan you share which service? (DM if sensitive)\n\n@developer_bob [11:02 AM]\nSame issue here. My builds went from 12 mins \u2192 35 mins\nSeems like it started after the Jenkins upgrade last week?\n\n@platform_engineer [11:15 AM]\nGood catch on the timing. We upgraded Jenkins on Oct 28th.\nI'll check if we inadvertently changed build parallelism settings.\nCreated ticket: FAWKES-567. Will update here by EOD.\n\n@platform_engineer [4:30 PM]\nUpdate: Found the issue. Jenkins upgrade reset parallel build \nsettings. Fix deployed. Builds should be back to normal speed now.\n@developer_alice @developer_bob can you confirm?\n\n@developer_alice [4:45 PM]\nConfirmed! Back to 16 minutes. Thanks! \ud83c\udf89\n</code></pre>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#13-bi-weekly-office-hours","title":"1.3 Bi-Weekly Office Hours","text":"<p>What: Scheduled 1-hour sessions where developers can drop in to discuss platform topics, demo features, or raise concerns.</p> <p>Format:</p> <ul> <li>Every other Wednesday, 2:00-3:00 PM (recorded for async viewing)</li> <li>Open agenda (anyone can add topics to shared doc)</li> <li>Mix of platform team updates + developer Q&amp;A</li> <li>Virtual (Zoom/Google Meet) with Mattermost live chat</li> </ul> <p>Typical Agenda:</p> <pre><code>Fawkes Platform Office Hours - Nov 15, 2024\n\n\ud83d\udccb Agenda (add your topics below):\n1. [Platform Team] Demo: New AI code review bot (10 min)\n2. [Platform Team] Update: DORA metrics dashboard launch (5 min)\n3. [@developer_charlie] Question: How do I set up multi-region deployments? (10 min)\n4. [@developer_diana] Feedback: Backstage search is slow (10 min)\n5. Open discussion + Q&amp;A (25 min)\n\n\ud83d\udcca Since Last Office Hours:\n- 47 feedback submissions received\n- Top issue: Jenkins build times \u2192 Fixed\n- NPS score: 62 (\u2191 from 58 last quarter)\n\n\ud83c\udfaf Coming Next Sprint:\n- AI-powered PR review suggestions\n- Dojo Module 6: Advanced GitOps\n- Backstage performance improvements\n</code></pre> <p>Target: 10-15 attendees per session, 40+ watching recording</p>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#14-github-issues-feature-requests","title":"1.4 GitHub Issues (Feature Requests)","text":"<p>What: A public repository (<code>fawkes/platform-feedback</code>) where developers can submit feature requests, vote on proposals, and discuss implementations.</p> <p>Process:</p> <ol> <li>Developer opens issue with feature request template</li> <li>Platform team labels and categorizes (P0/P1/P2)</li> <li>Community can upvote (\ud83d\udc4d reactions)</li> <li>Monthly review: Top 3 upvoted features \u2192 roadmap consideration</li> <li>Status updates posted as comments</li> <li>Closed with link to implementation or explanation if rejected</li> </ol> <p>Feature Request Template:</p> <pre><code>## Feature Request\n\n**Problem Statement**:\nWhat problem are you trying to solve? (Be specific)\n\n**Proposed Solution**:\nHow would you like this to work?\n\n**Alternatives Considered**:\nWhat workarounds are you currently using?\n\n**Impact**:\nHow many people would benefit? How often would this be used?\n\n**Additional Context**:\nScreenshots, examples, related issues?\n</code></pre> <p>Success Metric: 10+ feature requests per month, 80% receive response within 1 week</p>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#component-2-structured-user-research","title":"Component 2: Structured User Research","text":""},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#21-monthly-user-interviews-5-per-month","title":"2.1 Monthly User Interviews (5 per month)","text":"<p>What: One-on-one, semi-structured interviews with developers to deeply understand their workflows, pain points, and needs.</p> <p>Recruitment:</p> <ul> <li>Stratified sampling: Mix of roles, teams, experience levels</li> <li>Rotate through teams (don\u2019t interview same people repeatedly)</li> <li>$50 gift card incentive for 1-hour participation</li> <li>Opt-in via Mattermost announcement</li> </ul> <p>Interview Guide Template:</p> <pre><code>Fawkes User Interview Guide (60 minutes)\n\nIntroduction (5 min):\n- Thank participant, explain purpose\n- Emphasize: No right/wrong answers, all feedback valuable\n- Confirm recording consent\n\nWarm-Up (5 min):\n- What's your role and team?\n- How long have you been using Fawkes?\n- On a scale of 1-5, how would you rate your overall experience?\n\nCurrent Workflow (15 min):\n- Walk me through your typical day using Fawkes\n- What's the first thing you do in the morning?\n- How do you deploy code from idea to production?\n- [Screen share: Show me how you do X]\n\nPain Points (15 min):\n- What's the most frustrating part of using Fawkes?\n- When was the last time Fawkes slowed you down?\n- If you could fix one thing tomorrow, what would it be?\n- What workarounds have you developed?\n\nAI Tools (10 min):\n- Are you using AI coding assistants (Copilot, etc.)?\n- How has AI changed your workflow?\n- What would make AI tools more useful in Fawkes?\n\nAspirations (5 min):\n- What does an ideal platform look like to you?\n- What would make you recommend Fawkes to others?\n\nWrap-Up (5 min):\n- Anything we haven't covered?\n- Can we follow up if we have clarifying questions?\n- Thank you + next steps\n</code></pre> <p>Analysis Process:</p> <ol> <li>Transcribe interviews (automated via Otter.ai)</li> <li>Qualitative coding: Tag themes (e.g., \u201cJenkins slow\u201d, \u201cdocs unclear\u201d, \u201cAI helpful\u201d)</li> <li>Affinity mapping: Cluster similar feedback</li> <li>Synthesis: Write 1-page summary per interview</li> <li>Monthly report: Top 5 themes across all interviews</li> </ol> <p>Target: 5 interviews per month = 60/year = ~60% of developers interviewed annually (for 100-person org)</p>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#22-user-journey-mapping-workshops-quarterly","title":"2.2 User Journey Mapping Workshops (Quarterly)","text":"<p>What: Collaborative workshops where developers and platform team map the end-to-end journey of using Fawkes, identifying pain points and opportunities.</p> <p>Process:</p> <ol> <li>Select 1-2 key journeys (e.g., \u201cOnboarding a new service\u201d, \u201cDeploying a hotfix\u201d)</li> <li>Invite 6-8 developers who\u2019ve recently completed that journey</li> <li>2-hour workshop: Map stages, emotions, pain points, moments of delight</li> <li>Platform team commits to addressing top 3 pain points</li> </ol> <p>Example Journey Map Output:</p> <pre><code>Journey: Deploying Your First Service to Production\n\nStage 1: Setup\n\ud83d\ude0a Easy: Backstage template worked great\n\ud83d\ude10 Okay: Jenkins config was confusing but documentation helped\n\ud83d\ude22 Frustrating: Spent 2 hours debugging IAM permissions\n\nStage 2: First Deploy\n\ud83d\ude0a Easy: ArgoCD UI is intuitive\n\ud83d\ude22 Frustrating: No idea if deployment was successful (logs buried)\n\ud83d\ude21 Blocker: Deployment failed due to missing secret, took 4 hours to debug\n\nStage 3: Monitoring\n\ud83d\ude10 Okay: Grafana dashboard is powerful but overwhelming\n\ud83d\ude22 Frustrating: Can't tell if my service is healthy without asking SRE team\n\nTop Pain Points:\n1. IAM permissions are black magic (fix: better templates + error messages)\n2. Deployment status is unclear (fix: real-time status in Backstage)\n3. Monitoring setup is manual and confusing (fix: auto-generated dashboards)\n</code></pre>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#23-usability-testing-as-needed","title":"2.3 Usability Testing (As Needed)","text":"<p>What: Observing developers trying to complete specific tasks with new or existing platform features.</p> <p>When to Use:</p> <ul> <li>Before launching major new features (beta testing)</li> <li>After receiving complaints about existing features</li> <li>To validate design decisions</li> </ul> <p>Process:</p> <ol> <li>Define 3-5 realistic tasks (e.g., \u201cDeploy a new microservice\u201d)</li> <li>Recruit 5 developers (diverse skill levels)</li> <li>Observe remotely (screen share + think-aloud protocol)</li> <li>Measure: Time to complete, errors, satisfaction rating</li> <li>Identify usability issues and iterate design</li> </ol> <p>Example Test:</p> <pre><code>Task: Create a new Python microservice and deploy it to staging\n\nSuccess Criteria:\n- Task completed without assistance: &lt;20 minutes\n- No critical errors (blockers that prevent completion)\n- Satisfaction rating: &gt;4/5\n\nObservations (n=5 developers):\n\u2705 All completed task in 12-18 minutes\n\u26a0\ufe0f  3/5 were confused by \"Create Component\" vs \"Create Service\" buttons\n\u26a0\ufe0f  4/5 didn't notice deployment status indicator\n\u2705 Average satisfaction: 4.2/5\n\nRecommendations:\n1. Merge \"Create Component\" and \"Create Service\" into one flow\n2. Make deployment status more prominent (add animation)\n3. Add contextual help tooltip on first use\n</code></pre>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#component-3-feedback-processing-pipeline","title":"Component 3: Feedback Processing Pipeline","text":""},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#31-feedback-database-schema","title":"3.1 Feedback Database Schema","text":"<pre><code>CREATE TABLE feedback (\n  id SERIAL PRIMARY KEY,\n  type VARCHAR(50) NOT NULL, -- 'bug', 'friction', 'feature-request', 'praise'\n  category VARCHAR(50) NOT NULL, -- 'ci-cd', 'gitops', 'docs', 'dojo', 'other'\n  description TEXT NOT NULL,\n  source VARCHAR(50) NOT NULL, -- 'widget', 'mattermost', 'interview', 'github'\n\n  -- Context\n  user_id VARCHAR(100), -- NULL if anonymous\n  user_role VARCHAR(50),\n  page_context VARCHAR(200), -- Which Backstage page?\n  timestamp TIMESTAMP NOT NULL DEFAULT NOW(),\n\n  -- Analysis\n  sentiment VARCHAR(20), -- 'positive', 'neutral', 'negative' (AI-generated)\n  themes TEXT[], -- e.g., ['performance', 'documentation', 'jenkins']\n  impact_score INT, -- 1-5 based on affected users + frequency\n\n  -- Lifecycle\n  status VARCHAR(50) DEFAULT 'new', -- 'new', 'triaged', 'in-progress', 'resolved', 'wont-fix'\n  assigned_to VARCHAR(100),\n  resolution_notes TEXT,\n  resolved_at TIMESTAMP\n);\n\nCREATE INDEX idx_feedback_status ON feedback(status);\nCREATE INDEX idx_feedback_category ON feedback(category);\nCREATE INDEX idx_feedback_timestamp ON feedback(timestamp DESC);\n</code></pre>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#32-automated-analysis-ai-powered","title":"3.2 Automated Analysis (AI-Powered)","text":"<p>Sentiment Analysis:</p> <pre><code># Using OpenAI API for sentiment classification\ndef analyze_sentiment(feedback_text):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify sentiment as positive, neutral, or negative.\"},\n            {\"role\": \"user\", \"content\": feedback_text}\n        ]\n    )\n    return response.choices[0].message.content  # 'positive' | 'neutral' | 'negative'\n</code></pre> <p>Theme Extraction:</p> <pre><code># Identify common themes across feedback\ndef extract_themes(feedback_batch):\n    prompt = f\"\"\"\n    Analyze these {len(feedback_batch)} feedback items and identify 3-5 recurring themes.\n\n    Feedback:\n    {format_feedback(feedback_batch)}\n\n    Return themes as a JSON array, e.g., [\"performance\", \"documentation\", \"onboarding\"]\n    \"\"\"\n    # Returns: ['jenkins-slow', 'backstage-search', 'dojo-outdated', ...]\n</code></pre> <p>Impact Scoring Algorithm:</p> <pre><code>def calculate_impact_score(feedback):\n    score = 0\n\n    # How many users mention similar issues?\n    score += count_similar_feedback(feedback) * 2  # 0-10 points\n\n    # Severity (based on type)\n    severity_weights = {'bug': 3, 'friction': 2, 'feature-request': 1, 'praise': 0}\n    score += severity_weights[feedback.type]\n\n    # Sentiment (negative = more urgent)\n    if feedback.sentiment == 'negative':\n        score += 2\n\n    # Recency (recent = more relevant)\n    days_old = (now() - feedback.timestamp).days\n    if days_old &lt; 7:\n        score += 3\n    elif days_old &lt; 30:\n        score += 1\n\n    return min(score, 10)  # Cap at 10\n</code></pre>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#33-monthly-devex-review-meeting","title":"3.3 Monthly DevEx Review Meeting","text":"<p>Attendees: Platform team (5-7 people) Duration: 90 minutes Frequency: First Wednesday of every month</p> <p>Agenda:</p> <pre><code>1. Metrics Review (15 min)\n   - NPS score trend\n   - DORA metrics\n   - Feedback volume and sentiment\n\n2. Feedback Deep Dive (30 min)\n   - Top 5 themes from past month\n   - High-impact individual issues\n   - User interview synthesis\n\n3. Prioritization (25 min)\n   - Evaluate top issues (impact vs. effort)\n   - Select 1-2 improvements to tackle next month\n   - Assign owners and set deadlines\n\n4. Experiment Review (15 min)\n   - Did last month's changes work?\n   - Measure before/after metrics\n   - Lessons learned\n\n5. Communication Planning (5 min)\n   - Draft \"You Said, We Did\" post\n   - Plan quarterly town hall content\n</code></pre> <p>Output:</p> <ul> <li>1-2 committed improvements for next month</li> <li>Owners assigned with clear success criteria</li> <li>Communication plan for closing the loop</li> </ul>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#34-you-said-we-did-communication","title":"3.4 \u201cYou Said, We Did\u201d Communication","text":"<p>Monthly Post (Mattermost + Email):</p> <pre><code>## You Said, We Did - November 2024\n\nHey team! Here's what we heard from you last month and what we're doing about it.\n\n### \ud83d\udcca Feedback by the Numbers\n- 52 feedback submissions (\u2191 from 41 last month)\n- 5 user interviews conducted\n- Overall sentiment: 68% positive, 24% neutral, 8% negative\n\n### \ud83d\udd25 Top 3 Themes We Heard\n1. **Jenkins builds are slow** (18 mentions)\n   \ud83d\udc49 WE DID: Optimized build parallelism, reduced avg build time 45min \u2192 18min\n\n2. **Backstage search doesn't find docs** (12 mentions)\n   \ud83d\udc49 WE DID: Upgraded search index, now indexes TechDocs + ADRs + Mattermost\n\n3. **Dojo modules are outdated** (9 mentions)\n   \ud83d\udc49 WORKING ON IT: Updating modules 6-10, target completion Dec 15\n\n### \ud83c\udf89 Wins to Celebrate\n- @developer_eve completed Black Belt! \ud83e\udd4b\n- Deployment frequency hit 2.4/day (\u2191 from 1.9/day)\n- NPS score: 62 (\u2191 from 58)\n\n### \ud83d\udca1 What We're Focusing on Next Month\n- AI-powered code review suggestions (pilot with 3 teams)\n- Improved error messages in ArgoCD\n- Self-service secrets rotation\n\n### \ud83d\udce3 We Want to Hear From You\n- Use the feedback button in Backstage\n- Join office hours (next one: Nov 20, 2pm)\n- DM us anytime in #platform-feedback\n\nThanks for making Fawkes better! \ud83d\ude80\n- The Platform Team\n</code></pre> <p>Quarterly Town Hall (45 minutes, recorded):</p> <ul> <li>Review quarter\u2019s progress (metrics, features delivered)</li> <li>Deep dive on 2-3 major improvements</li> <li>Roadmap preview for next quarter</li> <li>Live Q&amp;A</li> </ul>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#phase-1-minimal-viable-feedback-system-weeks-1-2","title":"Phase 1: Minimal Viable Feedback System (Weeks 1-2)","text":"<p>Week 1: Quick Wins</p> <ol> <li>Create #platform-feedback Mattermost channel</li> <li>Set up Google Form for feedback (temporary, before Backstage plugin)</li> <li>Schedule first 3 user interviews</li> <li>Create feedback database schema</li> </ol> <p>Week 2: First Feedback Cycle</p> <ol> <li>Announce feedback channels to all developers</li> <li>Conduct first 3 user interviews</li> <li>Collect first batch of feedback</li> <li>Manual analysis and theme identification</li> <li>First \u201cYou Said, We Heard\u201d post</li> </ol>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#phase-2-automation-scale-weeks-3-6","title":"Phase 2: Automation &amp; Scale (Weeks 3-6)","text":"<p>Week 3-4: Backstage Plugin</p> <ol> <li>Develop feedback widget Backstage plugin</li> <li>Integrate with PostgreSQL database</li> <li>Add AI sentiment analysis</li> <li>Beta test with platform team</li> <li>Launch to all developers</li> </ol> <p>Week 5-6: Process &amp; Cadence</p> <ol> <li>Establish monthly DevEx review meeting</li> <li>Create feedback analysis dashboard (Grafana)</li> <li>Schedule bi-weekly office hours (recurring)</li> <li>Document user research processes</li> <li>Train platform team on facilitation</li> </ol>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#phase-3-continuous-improvement-month-2","title":"Phase 3: Continuous Improvement (Month 2+)","text":"<ol> <li>Refine based on initial learnings</li> <li>Add advanced features (theme clustering, trend analysis)</li> <li>Integrate with roadmap planning tools</li> <li>Measure impact: Are we closing the loop effectively?</li> </ol>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#positive","title":"Positive","text":"<ol> <li>User-Centric Culture: Platform team stays connected to developer needs</li> <li>Early Problem Detection: Catch issues before they become crises</li> <li>Higher Trust: Developers feel heard and valued</li> <li>Better Prioritization: Roadmap driven by validated user needs, not assumptions</li> <li>Continuous Learning: Platform team develops deep domain expertise</li> <li>Competitive Advantage: Great DevEx attracts and retains talent</li> <li>AI Readiness: User-centric foundation amplifies AI benefits (DORA finding)</li> <li>Reduced Waste: Don\u2019t build features nobody wants</li> <li>Faster Adoption: Developers embrace platform when they influence it</li> <li>Measurable Impact: Can prove platform value with qualitative + quantitative data</li> </ol>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#negative","title":"Negative","text":"<ol> <li>Time Investment: ~20% of platform team time on research and analysis</li> <li>Expectation Management: Must deliver on feedback or risk losing trust</li> <li>Potentially Overwhelming: Too much feedback can be paralyzing</li> <li>Interview Recruiting: May struggle to get volunteers (mitigate with incentives)</li> <li>Analysis Burden: Qualitative research requires skill and effort</li> <li>Difficult Tradeoffs: Must say \u201cno\u201d to some feature requests</li> </ol>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#neutral","title":"Neutral","text":"<ol> <li>Requires Facilitation Skills: Platform team needs training on research methods</li> <li>Cultural Shift: Treating developers as users requires leadership buy-in</li> <li>Ongoing Commitment: This is a permanent practice, not a one-time project</li> </ol>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-014: DevEx Measurement Framework (SPACE) - Quantitative complement to qualitative research</li> <li>ADR-002: Backstage for Developer Portal - Primary vehicle for feedback widget</li> <li>ADR-007: Mattermost for Collaboration - #platform-feedback channel</li> <li>ADR-016: Platform-as-Product - User research informs product decisions</li> </ul>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#references","title":"References","text":"<ul> <li>2025 DORA Report: User-centric focus critical for AI success</li> <li>Continuous Discovery Habits (Teresa Torres): Product discovery best practices</li> <li>The Mom Test (Rob Fitzpatrick): How to ask good interview questions</li> <li>Just Enough Research (Erika Hall): Practical research for teams</li> <li>User Interviews: https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews</li> </ul>"},{"location":"adr/ADR-019%20UserResearch%20%26%20Feedback%20Collection%20System/#last-updated","title":"Last Updated","text":"<p>December 7, 2024 - Initial version documenting user research and feedback system for Fawkes</p>"},{"location":"adr/ADR-020%20Platform-as-Product%20Operating%20Model/","title":"ADR-020: Platform-as-Product Operating Model","text":""},{"location":"adr/ADR-020%20Platform-as-Product%20Operating%20Model/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-020%20Platform-as-Product%20Operating%20Model/#context","title":"Context","text":"<p>Traditional platform teams operate as \"service providers\" responding to tickets. The 2025 DORA Report shows this reactive model fails to deliver great developer experience. We must treat Fawkes as an internal product with developers as customers.</p>"},{"location":"adr/ADR-020%20Platform-as-Product%20Operating%20Model/#decision","title":"Decision","text":"<p>Adopt Platform-as-Product operating model with: - Dedicated product manager for platform - Quarterly OKRs driven by developer needs (not tickets) - Product roadmap visible in Backstage - Monthly demo days showcasing new features - Developer advisory board (5-7 developers, rotating)</p> <p>Key Practices: - User research informs roadmap (not HiPPO decisions) - Measure platform success by NPS, adoption, DORA metrics - \"You build it, you support it\" (platform team owns platform) - Quarterly business reviews with leadership (prove ROI)</p>"},{"location":"adr/ADR-020%20Platform-as-Product%20Operating%20Model/#consequences","title":"Consequences","text":"<p>Positive: Better features, higher adoption, developer trust Negative: Requires product management skills, cultural shift</p>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/","title":"ADR-021: Eclipse Che Cloud Development Environment (CDE) Strategy","text":""},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#context","title":"Context","text":"<p>The Fawkes platform requires a Cloud Development Environment (CDE) solution to eliminate local environment setup friction, ensure consistent development toolchains, and enable AI-ready development workspaces with appropriate resources.</p>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#current-state","title":"Current State","text":"<p>Product developers rely on local machines for development, leading to:</p> <ul> <li>\"Works on my machine\" issues due to inconsistent toolchains</li> <li>Significant setup time for new projects</li> <li>AI development requiring substantial local resources (GPU/high-CPU)</li> <li>Security concerns with local development of sensitive codebases</li> <li>Difficulty onboarding new team members</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#requirements","title":"Requirements","text":"<ol> <li>Standardized Environments: Pre-configured workspaces with correct runtime,    tools, and language servers</li> <li>AI-Ready Workspaces: Support for GPU/high-CPU resource allocation for AI/ML    development</li> <li>Git Integration: Automatic repository cloning and access configuration</li> <li>SSO Integration: Seamless authentication via platform's central SSO provider</li> <li>Secrets Access: Secure credential injection via Vault Agent pattern</li> <li>Resource Management: Kubernetes ResourceQuota enforcement to prevent    cluster overload</li> <li>Workspace Isolation: Dedicated namespaces per user/team for security    separation</li> </ol>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#evaluation-criteria","title":"Evaluation Criteria","text":"<ul> <li>Open source with active community</li> <li>Kubernetes-native deployment</li> <li>Devfile standard support</li> <li>SSO/OIDC integration capability</li> <li>IDE flexibility (VS Code, IntelliJ, etc.)</li> <li>Backstage integration potential</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#decision","title":"Decision","text":"<p>We will deploy Eclipse Che as the Cloud Development Environment platform for Fawkes.</p>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#why-eclipse-che","title":"Why Eclipse Che","text":"<p>Advantages:</p> <ol> <li>Kubernetes-Native: Built for Kubernetes with Operator-based deployment</li> <li>Devfile Standard: Uses CNCF Devfile specification for workspace definitions</li> <li>IDE Flexibility: Supports VS Code, Che-Theia, and JetBrains IDEs</li> <li>SSO Support: Native OIDC integration for SSO authentication</li> <li>Open Source: Apache 2.0 license, CNCF project (incubating)</li> <li>Per-User Workspaces: Automatic namespace isolation per developer</li> <li>Resource Control: Kubernetes-native resource limits and quotas</li> </ol> <p>Trade-offs:</p> <ol> <li>Resource Intensive: Workspaces consume significant cluster resources</li> <li>Complexity: Operator deployment requires careful configuration</li> <li>Learning Curve: Teams need to understand Devfile structure</li> </ol>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       Eclipse Che CDE Architecture                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                        Access Layer                                      \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502 \u2502\n\u2502  \u2502  \u2502   Backstage     \u2502  \u2502   Che Dashboard \u2502  \u2502   Direct IDE    \u2502          \u2502 \u2502\n\u2502  \u2502  \u2502   CDE Launcher  \u2502  \u2502                 \u2502  \u2502   Access        \u2502          \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502              \u2502                    \u2502                    \u2502                      \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2502                                   \u2502                                           \u2502\n\u2502                                   \u25bc                                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                   Eclipse Che Operator (eclipse-che namespace)          \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502 \u2502\n\u2502  \u2502  \u2502  Che Server     \u2502  \u2502  Devfile        \u2502  \u2502  Workspace      \u2502          \u2502 \u2502\n\u2502  \u2502  \u2502  (API/Gateway)  \u2502  \u2502  Registry       \u2502  \u2502  Controller     \u2502          \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502                    OIDC/SSO Integration                              \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502           (Platform SSO \u2192 Eclipse Che Authentication)               \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                   \u2502                                           \u2502\n\u2502                                   \u25bc                                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                   Developer Workspaces (user namespaces)                 \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502 Namespace: che-user-developer1                                       \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u2502  IDE Container  \u2502  \u2502  Dev Container  \u2502  \u2502  Vault Agent    \u2502     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u2502  (VS Code)      \u2502  \u2502  (Python/Node)  \u2502  \u2502  Sidecar        \u2502     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502        \u2502 ResourceQuota: 4 CPU, 8Gi Memory                           \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502 Namespace: che-user-developer2 (AI Workspace)                        \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u2502  IDE Container  \u2502  \u2502  AI Container   \u2502  \u2502  Vault Agent    \u2502     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u2502  (VS Code)      \u2502  \u2502  (TensorFlow)   \u2502  \u2502  Sidecar        \u2502     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502        \u2502 ResourceQuota: 8 CPU, 16Gi Memory, GPU: 1                  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502        \u2502 Node Selector: gpu-enabled=true                            \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#devfile-standardization","title":"Devfile Standardization","text":"<p>Eclipse Che uses Devfiles to define development environments. We will provide two initial Golden Path Devfiles:</p> Devfile Purpose Resources Tools <code>goldenpath-python</code> General Python development 2 CPU, 4Gi Memory Python 3.11, pip, Language Server <code>goldenpath-ai</code> AI/ML development 8 CPU, 16Gi Memory, GPU TensorFlow, PyTorch, Jupyter, CUDA"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#deployment-configuration","title":"Deployment Configuration","text":"<p>Namespace: <code>eclipse-che</code></p> <p>Components:</p> <ul> <li>Eclipse Che Operator (via OperatorHub or Helm)</li> <li>Che Server (API gateway, workspace management)</li> <li>Devfile Registry (Golden Path templates)</li> <li>PostgreSQL (workspace metadata storage)</li> </ul> <p>Resource Requirements:</p> <pre><code>che-operator:\n  requests:\n    cpu: 100m\n    memory: 128Mi\n  limits:\n    cpu: 500m\n    memory: 512Mi\n\nche-server:\n  requests:\n    cpu: 500m\n    memory: 1Gi\n  limits:\n    cpu: 2\n    memory: 2Gi\n\ndevfile-registry:\n  requests:\n    cpu: 100m\n    memory: 128Mi\n  limits:\n    cpu: 500m\n    memory: 512Mi\n</code></pre>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#sso-integration","title":"SSO Integration","text":"<p>Eclipse Che will integrate with the platform's central SSO provider:</p> <pre><code>spec:\n  auth:\n    oAuthClientName: eclipse-che\n    oAuthSecret: che-oauth-secret\n    identityProviderURL: https://sso.fawkes.idp/realms/fawkes\n</code></pre> <p>For GitHub OAuth (matching Backstage):</p> <ul> <li>Che uses the same OAuth provider configured for Backstage</li> <li>User identity is consistent across portal and CDEs</li> <li>Token refresh handled automatically</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#secrets-access-via-vault","title":"Secrets Access via Vault","text":"<p>Workspaces will access secrets via the Vault Agent Sidecar pattern:</p> <ol> <li>Workspace pod annotations trigger Vault Agent injection</li> <li>Secrets mounted at <code>/vault/secrets/</code> in workspace container</li> <li>Developers use secrets without managing credentials locally</li> </ol> <pre><code># Workspace template annotation\nvault.hashicorp.com/agent-inject: \"true\"\nvault.hashicorp.com/role: \"che-workspace\"\nvault.hashicorp.com/agent-inject-secret-db-creds: \"secret/data/dev/database\"\n</code></pre>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#resource-quota-enforcement","title":"Resource Quota Enforcement","text":"<p>Each team has a cluster-wide quota for CDE consumption:</p> <pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: che-workspace-quota\n  namespace: che-user-team-a\nspec:\n  hard:\n    requests.cpu: \"16\"\n    requests.memory: 32Gi\n    limits.cpu: \"32\"\n    limits.memory: 64Gi\n    pods: \"10\"\n</code></pre> <p>When quota is exceeded:</p> <ul> <li>New workspace launches are denied with clear error message</li> <li>Users see quota status in Che Dashboard</li> <li>Alerting configured for approaching quota limits</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#backstage-integration","title":"Backstage Integration","text":"<p>Eclipse Che integrates with Backstage via:</p> <ol> <li>Che Launcher Plugin: Component to launch CDEs from Service Catalog</li> <li>Entity Annotation: Link services to Devfile templates</li> <li>Status Widget: Show active workspaces for each service</li> </ol> <p>Example catalog annotation:</p> <pre><code>metadata:\n  annotations:\n    eclipse.org/che-devfile: goldenpath-python\n    eclipse.org/che-url: https://che.fawkes.idp\n</code></pre>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#edge-cases","title":"Edge Cases","text":"Scenario Behavior Quota exceeded Clear error message, workspace launch blocked Git access denied Prompt for credentials, SSO token refresh Workspace idle timeout Auto-stop after 30 minutes, state preserved Devfile not found Fallback to Universal Developer Image GPU unavailable Queue workspace, notify when resources free"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#positive","title":"Positive","text":"<ol> <li>Consistent Environments: All developers use identical, reproducible setups</li> <li>Fast Onboarding: New team members productive within minutes</li> <li>AI-Ready Infrastructure: GPU resources available on-demand</li> <li>Security: No sensitive code on local machines</li> <li>Reduced Support: Fewer \"works on my machine\" issues</li> </ol>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#negative","title":"Negative","text":"<ol> <li>Resource Cost: Significant cluster resources per active workspace</li> <li>Network Dependency: Requires stable internet connection</li> <li>Learning Curve: Devfile authoring requires training</li> <li>Complexity: Additional platform component to maintain</li> </ol>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#risks-and-mitigations","title":"Risks and Mitigations","text":"Risk Mitigation Workspace sprawl Auto-stop idle workspaces, quota enforcement Performance issues Node affinity, SSD storage for workspaces Security exposure Network policies, namespace isolation, RBAC Vendor lock-in Devfile is CNCF standard, portable"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#1-github-codespaces-commercial","title":"1. GitHub Codespaces (Commercial)","text":"<p>Description: GitHub's cloud development environment</p> <p>Rejected because:</p> <ul> <li>Vendor lock-in to GitHub ecosystem</li> <li>Per-user licensing costs</li> <li>Limited customization for enterprise requirements</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#2-gitpod-open-sourcecommercial","title":"2. Gitpod (Open Source/Commercial)","text":"<p>Description: Alternative CDE platform</p> <p>Rejected because:</p> <ul> <li>Less mature Kubernetes Operator</li> <li>Smaller community than Eclipse Che</li> <li>Commercial licensing for enterprise features</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#3-vs-code-dev-containers-local","title":"3. VS Code Dev Containers (Local)","text":"<p>Description: Containerized development environments running locally</p> <p>Rejected because:</p> <ul> <li>Still requires local resources</li> <li>Not suitable for AI/ML workloads</li> <li>No centralized management</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#4-custom-solution","title":"4. Custom Solution","text":"<p>Description: Build bespoke CDE platform</p> <p>Rejected because:</p> <ul> <li>Significant development effort</li> <li>Maintenance burden</li> <li>Reinventing existing solutions</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#phase-1-core-deployment-week-1","title":"Phase 1: Core Deployment (Week 1)","text":"<ul> <li>[x] Create ADR-021 for Eclipse Che CDE strategy</li> <li>[ ] Deploy Eclipse Che Operator via ArgoCD</li> <li>[ ] Configure SSO integration</li> <li>[ ] Set up ingress for Che endpoints</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#phase-2-devfile-templates-week-2","title":"Phase 2: Devfile Templates (Week 2)","text":"<ul> <li>[ ] Create <code>goldenpath-python</code> Devfile</li> <li>[ ] Create <code>goldenpath-ai</code> Devfile</li> <li>[ ] Configure Devfile Registry</li> <li>[ ] Test workspace launch with templates</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#phase-3-integration-week-3","title":"Phase 3: Integration (Week 3)","text":"<ul> <li>[ ] Develop Backstage Che Launcher plugin</li> <li>[ ] Configure Vault Agent integration</li> <li>[ ] Set up ResourceQuota policies</li> <li>[ ] Create team namespaces</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#phase-4-documentation-training-week-4","title":"Phase 4: Documentation &amp; Training (Week 4)","text":"<ul> <li>[ ] Update architecture documentation</li> <li>[ ] Create Devfile authoring guide</li> <li>[ ] Add Dojo learning module for CDEs</li> <li>[ ] Create operational runbooks</li> </ul>"},{"location":"adr/ADR-021%20eclipse-che-cde-strategy/#references","title":"References","text":"<ul> <li>Eclipse Che Documentation</li> <li>CNCF Devfile Specification</li> <li>Eclipse Che Operator</li> <li>ADR-002: Backstage for Developer Portal</li> <li>ADR-015: HashiCorp Vault Deployment</li> </ul>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/","title":"ADR-025: Developer Experience Metrics Collection &amp; Dashboarding (EXPANDED)","text":""},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#context","title":"Context","text":"<p>ADR-014 established the SPACE framework for measuring developer experience across five dimensions:</p> <ul> <li>Satisfaction</li> <li>Performance</li> <li>Activity</li> <li>Communication &amp; Collaboration</li> <li>Efficiency &amp; Flow</li> </ul> <p>ADR-015 established qualitative feedback collection (interviews, surveys, feedback widget).</p> <p>Now we need the visualization layer that brings quantitative and qualitative data together into actionable insights. The 2025 DORA Report emphasizes that metrics alone don\u2019t drive change\u2014how you visualize and act on metrics determines success.</p> <p>The Challenge:</p> <ul> <li>We\u2019ll be collecting 100+ individual metrics</li> <li>Data comes from 15+ different sources</li> <li>Multiple audiences need different views (developers, platform team, executives)</li> <li>Metrics must drive action, not just observation</li> <li>Need to correlate metrics (e.g., does NPS correlate with lead time?)</li> <li>Must avoid metric gaming and vanity metrics</li> </ul> <p>Industry Context: Most organizations fail at DevEx dashboards by:</p> <ol> <li>Too many metrics: Dashboards with 50+ charts are overwhelming</li> <li>Wrong audience: Executive dashboards shown to developers (or vice versa)</li> <li>No action: Beautiful dashboards that nobody acts on</li> <li>Lagging indicators only: By the time you see the problem, it\u2019s too late</li> <li>Missing context: Charts without explaining why it matters</li> </ol> <p>We need dashboards that are:</p> <ul> <li>Actionable: Every metric should prompt a question or action</li> <li>Contextual: Show why metrics matter and how to improve them</li> <li>Predictive: Leading indicators that warn of future problems</li> <li>Accessible: Right level of detail for each audience</li> <li>Living: Updated in real-time, not weekly reports</li> </ul>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#decision","title":"Decision","text":"<p>We will build a three-tier DevEx Dashboard system in Grafana that serves three distinct audiences with progressive levels of detail:</p> <ol> <li>Executive Health Dashboard (10,000-foot view)</li> <li>Platform Team Operations Dashboard (1,000-foot view)</li> <li>Team-Level Deep Dive Dashboard (ground-level view)</li> </ol>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#overall-architecture","title":"Overall Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  DATA COLLECTION LAYER                                      \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502 Surveys      \u2502  \u2502 System       \u2502  \u2502 User         \u2502     \u2502\n\u2502  \u2502 (Qualtrics)  \u2502  \u2502 Metrics      \u2502  \u2502 Behavior     \u2502     \u2502\n\u2502  \u2502              \u2502  \u2502 (Prometheus) \u2502  \u2502 (Analytics)  \u2502     \u2502\n\u2502  \u2502 - NPS        \u2502  \u2502 - DORA       \u2502  \u2502 - Backstage  \u2502     \u2502\n\u2502  \u2502 - Pulse      \u2502  \u2502 - Build time \u2502  \u2502 - GitHub     \u2502     \u2502\n\u2502  \u2502 - Feedback   \u2502  \u2502 - Uptime     \u2502  \u2502 - Copilot    \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  DATA WAREHOUSE (PostgreSQL + Prometheus)                   \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Aggregated Metrics Tables                              \u2502 \u2502\n\u2502  \u2502 - devex_satisfaction (NPS, ratings, sentiment)         \u2502 \u2502\n\u2502  \u2502 - devex_performance (DORA, build, deploy metrics)      \u2502 \u2502\n\u2502  \u2502 - devex_activity (commits, PRs, reviews, AI usage)     \u2502 \u2502\n\u2502  \u2502 - devex_collaboration (review time, comments, etc.)    \u2502 \u2502\n\u2502  \u2502 - devex_efficiency (flow state, friction, toil)        \u2502 \u2502\n\u2502  \u2502 - devex_correlations (pre-computed relationships)      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 ETL Pipeline (Apache Airflow)                          \u2502 \u2502\n\u2502  \u2502 - Hourly: Sync GitHub, Backstage, Prometheus          \u2502 \u2502\n\u2502  \u2502 - Daily: Compute derived metrics and correlations     \u2502 \u2502\n\u2502  \u2502 - Weekly: Generate trend analysis and forecasts       \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  VISUALIZATION LAYER (Grafana)                              \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502 Executive       \u2502  \u2502 Platform Team   \u2502  \u2502 Team         \u2502\u2502\n\u2502  \u2502 Health          \u2502  \u2502 Operations      \u2502  \u2502 Deep Dive    \u2502\u2502\n\u2502  \u2502 Dashboard       \u2502  \u2502 Dashboard       \u2502  \u2502 Dashboard    \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Alerting &amp; Notifications                               \u2502 \u2502\n\u2502  \u2502 - Slack: Real-time alerts for platform team           \u2502 \u2502\n\u2502  \u2502 - Email: Weekly digest for executives                 \u2502 \u2502\n\u2502  \u2502 - Mattermost: Monthly \"State of DevEx\" for all        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#dashboard-1-executive-health-dashboard","title":"Dashboard 1: Executive Health Dashboard","text":"<p>Audience: CTO, VPs, Engineering Directors Update Frequency: Real-time (but typically viewed weekly) Purpose: High-level health check and business value demonstration</p>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#layout","title":"Layout","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Fawkes Developer Experience Health - Q4 2024                        \u2502\n\u2502  Updated: 2 minutes ago                        [Export] [Share]      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n\u2502  \u2502  Overall NPS        \u2502  \u2502  Platform ROI       \u2502                   \u2502\n\u2502  \u2502                     \u2502  \u2502                     \u2502                   \u2502\n\u2502  \u2502      62             \u2502  \u2502    $2.1M/year       \u2502                   \u2502\n\u2502  \u2502   \u2191 +4 from Q3      \u2502  \u2502  (productivity +    \u2502                   \u2502\n\u2502  \u2502                     \u2502  \u2502   reduced incidents)\u2502                   \u2502\n\u2502  \u2502  Target: 65         \u2502  \u2502                     \u2502                   \u2502\n\u2502  \u2502  Industry: 58       \u2502  \u2502  Investment: $480k  \u2502                   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n\u2502                                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  SPACE Framework Health (vs. Target)                          \u2502  \u2502\n\u2502  \u2502                                                                \u2502  \u2502\n\u2502  \u2502  Satisfaction      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591  4.2/5  Target: 4.5       \u2502  \u2502\n\u2502  \u2502  Performance       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591  4.5/5  \u2713 Exceeds Target  \u2502  \u2502\n\u2502  \u2502  Activity          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591  4.3/5  Target: 4.5       \u2502  \u2502\n\u2502  \u2502  Communication     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591  4.1/5  Target: 4.5       \u2502  \u2502\n\u2502  \u2502  Efficiency        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591  4.0/5  \u26a0 Below Target    \u2502  \u2502\n\u2502  \u2502                                                                \u2502  \u2502\n\u2502  \u2502  Overall Score: 4.2/5 (up from 3.8 last quarter)              \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502  DORA Metrics - Last 30 Days                                 \u2502    \u2502\n\u2502  \u2502                                                               \u2502    \u2502\n\u2502  \u2502  Deployment Frequency:  2.3/day  \u2191 +15%  Elite Performer    \u2502    \u2502\n\u2502  \u2502  Lead Time:            18 hours  \u2193 -22%  Elite Performer    \u2502    \u2502\n\u2502  \u2502  Change Failure Rate:       12%  \u2193 -3%   Elite Performer    \u2502    \u2502\n\u2502  \u2502  MTTR:                 47 mins   \u2193 -18%  Elite Performer    \u2502    \u2502\n\u2502  \u2502                                                               \u2502    \u2502\n\u2502  \u2502  \u2705 Fawkes team is now in \"Elite Performer\" category!        \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502  \ud83d\udea8 Attention Required                \u2502  \u2502  \ud83c\udf89 Wins This Month  \u2502\u2502\n\u2502  \u2502                                        \u2502  \u2502                      \u2502\u2502\n\u2502  \u2502  \u26a0\ufe0f  Efficiency score dropped from    \u2502  \u2502  \u2705 NPS increased +4 \u2502\u2502\n\u2502  \u2502     4.3 \u2192 4.0 (friction increasing)   \u2502  \u2502  \u2705 Lead time -22%   \u2502\u2502\n\u2502  \u2502     Action: Review friction reports   \u2502  \u2502  \u2705 AI adoption 85%  \u2502\u2502\n\u2502  \u2502                                        \u2502  \u2502  \u2705 3 teams achieved \u2502\u2502\n\u2502  \u2502  \u26a0\ufe0f  Build times up 20% past 2 weeks  \u2502  \u2502     elite status     \u2502\u2502\n\u2502  \u2502     Action: Jenkins capacity review   \u2502  \u2502                      \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502  Quarterly Trend (NPS &amp; DORA Deployment Frequency)          \u2502    \u2502\n\u2502  \u2502                                                               \u2502    \u2502\n\u2502  \u2502  70\u2502     NPS                                                 \u2502    \u2502\n\u2502  \u2502  65\u2502      \u2571\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                      \u2502    \u2502\n\u2502  \u2502  60\u2502  \u2500\u2500\u2500\u2571                                                   \u2502    \u2502\n\u2502  \u2502  55\u2502 \u2571                                                       \u2502    \u2502\n\u2502  \u2502  50\u2502\u2571                                                        \u2502    \u2502\n\u2502  \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                   \u2502    \u2502\n\u2502  \u2502     Q1    Q2    Q3    Q4                                     \u2502    \u2502\n\u2502  \u2502                                                               \u2502    \u2502\n\u2502  \u2502   3\u2502     Deploy/Day                                          \u2502    \u2502\n\u2502  \u2502   2\u2502              \u2571\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                  \u2502    \u2502\n\u2502  \u2502   1\u2502      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2571                                           \u2502    \u2502\n\u2502  \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                        \u2502    \u2502\n\u2502  \u2502     Q1    Q2    Q3    Q4                                     \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#key-features","title":"Key Features","text":"<p>1. Single Number Health Indicators</p> <ul> <li>NPS (leading indicator of platform health)</li> <li>Platform ROI (business value in dollars)</li> <li>Overall SPACE score (composite health metric)</li> </ul> <p>2. Traffic Light System</p> <ul> <li>\ud83d\udfe2 Green: Exceeds target</li> <li>\ud83d\udfe1 Yellow: Meets target</li> <li>\ud83d\udd34 Red: Below target</li> <li>All thresholds configurable</li> </ul> <p>3. Automatic Insights</p> <ul> <li>\u201cAttention Required\u201d panel auto-generated from anomaly detection</li> <li>\u201cWins This Month\u201d celebrates progress</li> <li>No need to manually interpret charts</li> </ul> <p>4. Trend Visibility</p> <ul> <li>Quarterly trends show trajectory</li> <li>Compare current quarter to previous</li> <li>Project forward based on current trend</li> </ul> <p>5. Benchmarking</p> <ul> <li>Compare to industry standards (DORA research)</li> <li>Show peer company comparisons (if available)</li> <li>Highlight \u201celite performer\u201d achievements</li> </ul>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#dashboard-2-platform-team-operations-dashboard","title":"Dashboard 2: Platform Team Operations Dashboard","text":"<p>Audience: Platform engineers, SREs, DevOps team Update Frequency: Real-time Purpose: Day-to-day operations, troubleshooting, experimentation tracking</p>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#layout-5-pages-tabbed","title":"Layout (5 pages, tabbed)","text":""},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#page-1-real-time-health","title":"Page 1: Real-Time Health","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Platform Operations - Real-Time Health                              \u2502\n\u2502  [Health] [SPACE Deep Dive] [Experiments] [Feedback] [Correlations]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                       \u2502\n\u2502  \ud83d\udea8 ACTIVE ALERTS (2)                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 \ud83d\udd34 CRITICAL: Jenkins build queue depth = 28 (threshold: 20)     \u2502 \u2502\n\u2502  \u2502    Triggered: 15 minutes ago                                    \u2502 \u2502\n\u2502  \u2502    Action: Scale up Jenkins agents OR investigate stuck builds  \u2502 \u2502\n\u2502  \u2502    [View Details] [Acknowledge] [Create Incident]               \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502 \ud83d\udfe1 WARNING: ArgoCD sync failures 12% (threshold: 10%)           \u2502 \u2502\n\u2502  \u2502    Triggered: 2 hours ago                                       \u2502 \u2502\n\u2502  \u2502    Affected: payment-service, auth-service (3 more)             \u2502 \u2502\n\u2502  \u2502    [View Details] [Acknowledge]                                 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                       \u2502\n\u2502  PLATFORM SERVICES STATUS                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502 Backstage    \u2502  \u2502 Jenkins      \u2502  \u2502 ArgoCD       \u2502              \u2502\n\u2502  \u2502 \u2705 Healthy   \u2502  \u2502 \u26a0\ufe0f  Degraded \u2502  \u2502 \u26a0\ufe0f  Degraded \u2502              \u2502\n\u2502  \u2502 99.8% uptime \u2502  \u2502 Queue: 28    \u2502  \u2502 Sync: 88%    \u2502              \u2502\n\u2502  \u2502 Latency: 210ms\u2502 \u2502 Agents: 8/15 \u2502  \u2502 Apps: 47/53  \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502 Harbor       \u2502  \u2502 Mattermost   \u2502  \u2502 Prometheus   \u2502              \u2502\n\u2502  \u2502 \u2705 Healthy   \u2502  \u2502 \u2705 Healthy   \u2502  \u2502 \u2705 Healthy   \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                                                                       \u2502\n\u2502  CURRENT CAPACITY                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Kubernetes Cluster                                              \u2502 \u2502\n\u2502  \u2502 CPU:    [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591] 65%  (target: &lt;80%)               \u2502 \u2502\n\u2502  \u2502 Memory: [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591] 78%  (\u26a0\ufe0f approaching limit)        \u2502 \u2502\n\u2502  \u2502 Pods:   247/300                                                 \u2502 \u2502\n\u2502  \u2502                                                                 \u2502 \u2502\n\u2502  \u2502 Jenkins Agents                                                  \u2502 \u2502\n\u2502  \u2502 Active: [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591] 8/15  (\u26a0\ufe0f queue building)        \u2502 \u2502\n\u2502  \u2502 Queue:  28 jobs (avg wait: 12 minutes)                         \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                       \u2502\n\u2502  RECENT ACTIVITY (Last Hour)                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 \ud83d\ude80 Deployments: 12 (11 success, 1 failed)                       \u2502 \u2502\n\u2502  \u2502 \ud83d\udd28 Builds: 47 (43 success, 3 failed, 1 timeout)                 \u2502 \u2502\n\u2502  \u2502 \ud83d\udc64 Active Users: 68 developers using platform                   \u2502 \u2502\n\u2502  \u2502 \ud83d\udcac Feedback: 3 new submissions (2 friction, 1 praise)           \u2502 \u2502\n\u2502  \u2502 \ud83e\udd16 AI Usage: Copilot active for 52 developers                   \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#page-2-space-deep-dive","title":"Page 2: SPACE Deep Dive","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  SPACE Framework Deep Dive - Last 30 Days                            \u2502\n\u2502  [Health] [SPACE Deep Dive] [Experiments] [Feedback] [Correlations]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                       \u2502\n\u2502  \ud83d\udcca SATISFACTION                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 NPS Score: 62 (\u2191 +4 from last month)                            \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  70\u2502                              Target: 65                    \u2502 \u2502\n\u2502  \u2502  60\u2502     \u25cf\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf                      \u2502 \u2502\n\u2502  \u2502  50\u2502  \u25cf\u2500\u256f                                                       \u2502 \u2502\n\u2502  \u2502  40\u2502                                                            \u2502 \u2502\n\u2502  \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                       \u2502 \u2502\n\u2502  \u2502      Oct   Nov   Dec   Jan   Feb                                \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Breakdown:                                                     \u2502 \u2502\n\u2502  \u2502  Promoters (9-10): 45%  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                            \u2502 \u2502\n\u2502  \u2502  Passives (7-8):   38%  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                               \u2502 \u2502\n\u2502  \u2502  Detractors (0-6): 17%  \u2588\u2588\u2588\u2588                                   \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Top Drivers of Satisfaction:                                  \u2502 \u2502\n\u2502  \u2502  \u2705 Fast deployments (mentioned by 23 developers)               \u2502 \u2502\n\u2502  \u2502  \u2705 Good documentation (18 mentions)                            \u2502 \u2502\n\u2502  \u2502  \u2705 AI tools helpful (15 mentions)                              \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Top Drivers of Dissatisfaction:                               \u2502 \u2502\n\u2502  \u2502  \u274c Jenkins slow (18 mentions)                                  \u2502 \u2502\n\u2502  \u2502  \u274c Backstage search poor (12 mentions)                         \u2502 \u2502\n\u2502  \u2502  \u274c Too many tools (9 mentions)                                 \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  [View Detailed Feedback] [View NPS Comments]                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                       \u2502\n\u2502  \ud83d\udcca PERFORMANCE (DORA Metrics)                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Deployment Frequency                Lead Time for Changes      \u2502 \u2502\n\u2502  \u2502   3.0\u2502              Target: 2.0/day    30\u2502                     \u2502 \u2502\n\u2502  \u2502   2.5\u2502        \u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf               25\u2502                     \u2502 \u2502\n\u2502  \u2502   2.0\u2502    \u25cf\u2500\u2500\u256f                         20\u2502         \u25cf           \u2502 \u2502\n\u2502  \u2502   1.5\u2502  \u25cf\u256f                              15\u2502    \u25cf\u2500\u2500\u2500\u2500\u256f          \u2502 \u2502\n\u2502  \u2502   1.0\u2502                                  10\u2502 \u25cf\u2500\u2500\u256f               \u2502 \u2502\n\u2502  \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2502 \u2502\n\u2502  \u2502       Week 1-4                             Week 1-4             \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Change Failure Rate         MTTR (Mean Time to Recovery)      \u2502 \u2502\n\u2502  \u2502   20%\u2502                           120\u2502                          \u2502 \u2502\n\u2502  \u2502   15%\u2502  Target: &lt;15%               90\u2502                          \u2502 \u2502\n\u2502  \u2502   10%\u2502        \u25cf\u2500\u2500\u2500\u2500\u2500\u25cf               60\u2502    \u25cf\u2500\u2500\u2500\u2500\u2500\u25cf             \u2502 \u2502\n\u2502  \u2502    5%\u2502    \u25cf\u2500\u2500\u256f                      30\u2502  \u25cf\u2500\u256f                   \u2502 \u2502\n\u2502  \u2502    0%\u2502                                0\u2502                         \u2502 \u2502\n\u2502  \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500            \u2502 \u2502\n\u2502  \u2502       Week 1-4                          Week 1-4                \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Performance Category: \ud83c\udfc6 ELITE PERFORMER                       \u2502 \u2502\n\u2502  \u2502  (All 4 metrics in elite range)                                \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                       \u2502\n\u2502  \ud83d\udcca ACTIVITY                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Developer Activity Metrics                                     \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Average per Developer (last 7 days):                          \u2502 \u2502\n\u2502  \u2502  \u2022 Commits: 12.3 (target: 10+)           \u2705                     \u2502 \u2502\n\u2502  \u2502  \u2022 PRs created: 3.1 (target: 2+)         \u2705                     \u2502 \u2502\n\u2502  \u2502  \u2022 PRs reviewed: 4.7 (target: 3+)        \u2705                     \u2502 \u2502\n\u2502  \u2502  \u2022 Documentation edits: 0.8              \u26a0\ufe0f  (target: 1+)      \u2502 \u2502\n\u2502  \u2502  \u2022 Dojo progress: 2.1 modules/month      \u2705                     \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Platform Adoption:                                             \u2502 \u2502\n\u2502  \u2502  \u2022 Backstage MAU: 94/100 developers (94%) \u2705                    \u2502 \u2502\n\u2502  \u2502  \u2022 AI tools: 85/100 developers (85%)      \u2705                    \u2502 \u2502\n\u2502  \u2502  \u2022 Dojo: 62/100 enrolled (62%)            \u26a0\ufe0f  (target: 70%)    \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  [View Team Breakdown] [View Individual Trends]                \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                       \u2502\n\u2502  \ud83d\udcca COMMUNICATION &amp; COLLABORATION                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Code Review Metrics                                            \u2502 \u2502\n\u2502  \u2502  \u2022 Time to first review: 8 hrs (target: &lt;12)  \u2705               \u2502 \u2502\n\u2502  \u2502  \u2022 Comments per PR: 3.2 (target: &gt;2)           \u2705               \u2502 \u2502\n\u2502  \u2502  \u2022 Approval rate: 92%                          \u2705               \u2502 \u2502\n\u2502  \u2502  \u2022 Constructive tone: 96%                      \u2705               \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Knowledge Sharing:                                             \u2502 \u2502\n\u2502  \u2502  \u2022 Wiki edits: 47 this month                   \u2705               \u2502 \u2502\n\u2502  \u2502  \u2022 TechDocs updates: 23                        \u2705               \u2502 \u2502\n\u2502  \u2502  \u2022 #help channel responses: 156                \u2705               \u2502 \u2502\n\u2502  \u2502  \u2022 Pair programming sessions: 12               \u26a0\ufe0f  (Low)        \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Cross-Team Collaboration:                                      \u2502 \u2502\n\u2502  \u2502  \u2022 Cross-team PRs: 18% of all PRs              \u2705               \u2502 \u2502\n\u2502  \u2502  \u2022 Shared library usage: 67%                   \u2705               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                       \u2502\n\u2502  \ud83d\udcca EFFICIENCY &amp; FLOW                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Flow State (self-reported weekly pulse):                      \u2502 \u2502\n\u2502  \u2502  \u2022 Achieved flow 3+ days/week: 68%            \u2705  (target: 60%) \u2502 \u2502\n\u2502  \u2502  \u2022 Never achieved flow: 8%                     \u2705  (target: &lt;10%)\u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Valuable Work Time:                                            \u2502 \u2502\n\u2502  \u2502  \u2022 Average % on valuable work: 62%            \u2705  (target: 60%) \u2502 \u2502\n\u2502  \u2502  \u2022 Trend: \u2191 +5% from last month                                \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Friction Incidents (last 30 days):                            \u2502 \u2502\n\u2502  \u2502  \u2022 Total: 34 (down from 47)                   \u2705  Improving!    \u2502 \u2502\n\u2502  \u2502  \u2022 By category:                                                 \u2502 \u2502\n\u2502  \u2502    - Jenkins slow: 12 reports                                   \u2502 \u2502\n\u2502  \u2502    - Docs unclear: 8 reports                                    \u2502 \u2502\n\u2502  \u2502    - Access issues: 7 reports                                   \u2502 \u2502\n\u2502  \u2502    - Other: 7 reports                                           \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  Cognitive Load (1-5 scale, 5=overwhelmed):                    \u2502 \u2502\n\u2502  \u2502  \u2022 Average: 3.2                                \u2705  (target: &lt;3.5)\u2502 \u2502\n\u2502  \u2502  \u2022 High load (4-5): 23% of developers          \u26a0\ufe0f  Monitor      \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502  [View Friction Details] [View High Load Individuals]          \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-025%20Developer%20Experience%20Metrics%20Collection%20%26%20Dashboarding/#page-3-experiments-tracking","title":"Page 3: Experiments Tracking","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Platform Experiments &amp; A/B Tests                                    \u2502\n\u2502  [Health] [SPACE Deep Dive] [Experiments] [Feedback] [Correlations]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                       \u2502\n\u2502  ACTIVE EXPERIMENTS (3)                                               \u2502\n\u2502                                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Experiment #12: AI-Powered PR Review Bot                        \u2502 \u2502\n\u2502  \u2502 Started: Dec 1, 2024  |  Status: \u2705 In Progress  |  Cohort: 15% \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502 Hypothesis:                                                     \u2502 \u2502\n\u2502  \u2502 AI-assisted code review will reduce time-to-first-review by    \u2502 \u2502\n\u2502  \u2502 30% and increase code quality scores by 10%.                   \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502 Current Results (after 2 weeks):                                \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502          Control   Treatment   Difference   Sig?                \u2502 \u2502\n\u2502  \u2502 TTFR     12 hrs    8 hrs      -33%         \u2705 Yes (p&lt;0.01)      \u2502 \u2502\n\u2502  \u2502 Quality  7.2/10    7.8/10     +8%          \u26a0\ufe0f  Trending         \u2502 \u2502\n\u2502  \u2502 Sat.     4.1/5     4.4/5      +7%          \u2705 Yes (p&lt;0.05)      \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502 Qualitative Feedback (5 interviews):                           \u2502 \u2502\n\u2502  \u2502 \u2705 \"Catches issues I would miss\" (4 mentions)                   \u2502 \u2502\n\u2502  \u2502 \u2705 \"Faster reviews, less waiting\" (3 mentions)                  \u2502 \u2502\n\u2502  \u2502 \u26a0\ufe0f  \"Sometimes suggests wrong fixes\" (2 mentions)               \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502 Recommendation: \u2705 ROLLOUT TO ALL                                \u2502 \u2502\n\u2502  \u2502 \u2022 TTFR significantly improved                                   \u2502 \u2502\n\u2502  \u2502 \u2022 Satisfaction significantly improved                           \u2502 \u2502\n\u2502  \u2502 \u2022 Code quality trending positive (2 more weeks to confirm)     \u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502 [View Detailed Analysis] [Rollout Plan] [Cancel Experiment]    \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Experiment #13: Self-Service Secrets Rotation                  \u2502 \u2502\n\u2502  \u2502 Started: Dec 10, 2024  |  Status: \u26a0\ufe0f  Monitoring  |  Cohort: 20%\u2502 \u2502\n\u2502  \u2502                                                                  \u2502 \u2502\n\u2502  \u2502 Hypothesis:                                                     \u2502 \u2502\n\u2502  \u2502 Self-service secrets rotation will reduce security tickets by  \u2502 \u2502\n\u2502  \u2502\n</code></pre>"},{"location":"adr/ADR-026%20AI-Powered%20Anomaly%20Detection%20Strategy/","title":"ADR-026: AI-Powered Anomaly Detection Strategy","text":""},{"location":"adr/ADR-026%20AI-Powered%20Anomaly%20Detection%20Strategy/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/ADR-026%20AI-Powered%20Anomaly%20Detection%20Strategy/#context","title":"Context","text":"<p>With AI acceleration, issues emerge faster. Need intelligent alerting.</p>"},{"location":"adr/ADR-026%20AI-Powered%20Anomaly%20Detection%20Strategy/#decision","title":"Decision","text":"<p>Implement AI-powered anomaly detection in Grafana using ML algorithms.</p> <p>Use Cases:</p> <p>1. Build Time Anomalies <pre><code>Normal: 15 min average build time\nDetected: 45 min average (3\u03c3 above normal)\nAlert: \"Build times spiked 200% - investigate Jenkins\"\nSuggested actions:\n- Check Jenkins agent capacity\n- Review recent Jenkins config changes\n- Compare with last week's successful builds\n</code></pre></p> <p>2. Deployment Failure Spike <pre><code>Normal: 5% deployment failure rate\nDetected: 25% failure rate\nAlert: \"Deployment failures increased 5x\"\nPotential causes (AI-generated):\n- ArgoCD sync issue (40% confidence)\n- Recent K8s upgrade (30% confidence)\n- Network instability (20% confidence)\n</code></pre></p> <p>3. Developer Satisfaction Drop <pre><code>Normal: NPS 60-65\nDetected: NPS dropped to 45 in 2 weeks\nAlert: \"Developer satisfaction declining rapidly\"\nTop friction themes (from feedback):\n- Jenkins slow (18 mentions)\n- Docs outdated (12 mentions)\n- Copilot not working (8 mentions)\n</code></pre></p> <p>Implementation: - Grafana Machine Learning plugin - Train models on historical data (6+ months) - Slack/Mattermost notifications - Link to related dashboards and runbooks</p> <p>Thresholds: - Info: 1\u03c3 deviation (notify platform team) - Warning: 2\u03c3 deviation (investigate within 24h) - Critical: 3\u03c3 deviation (investigate immediately)</p>"},{"location":"adr/ADR-026%20AI-Powered%20Anomaly%20Detection%20Strategy/#consequences","title":"Consequences","text":"<p>Positive: Catch issues faster, reduce MTTR, proactive vs reactive Negative: Potential false positives, requires ML expertise to tune</p>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/","title":"ADR-027: Value Stream Management Integration","text":""},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#status","title":"Status","text":"<p>Proposed - Pending team review and approval</p> <p>Date: December 2025</p> <p>Decision Makers: Platform Architecture Team, Product Leadership</p> <p>Consulted: Development Teams, DevOps Engineers, Product Managers</p> <p>Informed: All Engineering, Executive Leadership</p>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#context","title":"Context","text":""},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#background","title":"Background","text":"<p>Based on the 2025 DORA Report findings, organizations with mature Value Stream Management (VSM) practices see significant improvements in:</p> <ul> <li>3.5x higher organizational performance compared to low VSM maturity</li> <li>Better visibility into software delivery bottlenecks</li> <li>Data-driven decision making for process improvements</li> <li>Alignment between business value and technical delivery</li> </ul> <p>Currently, Fawkes collects DORA metrics (deployment frequency, lead time, change failure rate, MTTR) but lacks:</p> <ol> <li>End-to-end value stream visibility - Can\u2019t trace from idea to production</li> <li>Work item integration - DORA metrics aren\u2019t linked to business value</li> <li>Flow metrics - No measurement of work in progress, cycle time by stage</li> <li>Bottleneck identification - No automated detection of process constraints</li> <li>Value delivery measurement - No connection between features and business outcomes</li> </ol>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#dora-2025-vsm-findings","title":"DORA 2025 VSM Findings","text":"<p>The 2025 DORA Report identifies 8 Value Stream Management Capabilities:</p> <ol> <li>Visualization of work - Teams see work flowing through the value stream</li> <li>Work integrated with toolchains - Tracking tools connected to CI/CD</li> <li>Work limited in process - WIP limits enforced</li> <li>Flow metrics - Cycle time, throughput, WIP measured</li> <li>Quality integrated in process - Quality gates in the value stream</li> <li>Work prioritized by business value - Value-driven backlog</li> <li>Customer feedback - Fast feedback loops from production</li> <li>Continuous improvement - Regular process optimization</li> </ol> <p>Organizations with high VSM maturity (6-8 capabilities) significantly outperform those with low maturity (0-3 capabilities).</p>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#current-fawkes-architecture-gaps","title":"Current Fawkes Architecture Gaps","text":"<p>What We Have:</p> <ul> <li>\u2705 DORA metrics collection (4 key metrics)</li> <li>\u2705 Focalboard for project management</li> <li>\u2705 Backstage service catalog</li> <li>\u2705 ArgoCD for deployment tracking</li> <li>\u2705 Jenkins for CI/CD</li> </ul> <p>What We\u2019re Missing:</p> <ul> <li>\u274c Integration between Focalboard work items and DORA metrics</li> <li>\u274c Value stream visualization (idea \u2192 code \u2192 deploy \u2192 operate)</li> <li>\u274c Flow metrics (cycle time by stage, WIP, throughput)</li> <li>\u274c Bottleneck detection and alerts</li> <li>\u274c Business value tracking per feature</li> <li>\u274c Customer feedback integration</li> <li>\u274c Value stream dashboards for stakeholders</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces:</p> <ul> <li>Need to integrate disparate tools (Focalboard, GitHub, Jenkins, ArgoCD, Grafana)</li> <li>Require consistent work item identifiers across the toolchain</li> <li>Must handle real-time data aggregation from multiple sources</li> <li>Need to maintain low overhead (no manual data entry)</li> </ul> <p>Organizational Forces:</p> <ul> <li>Product managers need visibility into delivery performance</li> <li>Engineering leaders need bottleneck identification</li> <li>Executives need business value delivery metrics</li> <li>Teams need actionable insights, not just dashboards</li> </ul> <p>User Experience Forces:</p> <ul> <li>Developers shouldn\u2019t be burdened with extra process</li> <li>Data collection should be automated</li> <li>Insights should be contextual and actionable</li> <li>Integration should be seamless with existing workflows</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#decision-drivers","title":"Decision Drivers","text":"<ol> <li>DORA Alignment: 2025 DORA Report emphasizes VSM as a key differentiator</li> <li>Platform-as-Product: VSM enables us to measure platform value delivery</li> <li>User-Centric: Understanding flow helps us reduce developer friction</li> <li>Competitive Advantage: Few open-source IDPs offer integrated VSM</li> <li>Data-Driven Improvement: Can\u2019t improve what we don\u2019t measure</li> </ol>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#decision","title":"Decision","text":"<p>We will implement an integrated Value Stream Management system in Fawkes that:</p> <ol> <li>Connects work items (Focalboard) with code changes (GitHub), builds (Jenkins), and deployments (ArgoCD)</li> <li>Automates flow metrics collection (cycle time, WIP, throughput) across value stream stages</li> <li>Visualizes the end-to-end value stream from idea to production</li> <li>Detects and alerts on bottlenecks using ML-based anomaly detection</li> <li>Measures business value delivery by linking work items to customer outcomes</li> <li>Integrates customer feedback from production into the value stream</li> </ol>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   VALUE STREAM MANAGEMENT LAYER                  \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 VSM Hub (New Component)                                    \u2502 \u2502\n\u2502  \u2502 - Work item correlation engine                             \u2502 \u2502\n\u2502  \u2502 - Flow metrics calculation service                         \u2502 \u2502\n\u2502  \u2502 - Bottleneck detection (ML-based)                          \u2502 \u2502\n\u2502  \u2502 - Business value tracking                                  \u2502 \u2502\n\u2502  \u2502 - API for dashboards and integrations                      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                           \u2193         \u2193                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502 VSM Backstage Plugin     \u2502  \u2502 Grafana VSM Dashboards   \u2502    \u2502\n\u2502  \u2502 - Value stream view      \u2502  \u2502 - Flow metrics           \u2502    \u2502\n\u2502  \u2502 - Work item tracker      \u2502  \u2502 - Bottleneck alerts      \u2502    \u2502\n\u2502  \u2502 - Team health dashboard  \u2502  \u2502 - Value delivery trends  \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2191\n                            \u2502 (Event streams &amp; webhooks)\n                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      DATA SOURCES (Existing)                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Focalboard \u2502 \u2502 GitHub     \u2502 \u2502 Jenkins    \u2502 \u2502 ArgoCD     \u2502  \u2502\n\u2502  \u2502 (Work)     \u2502 \u2502 (Code)     \u2502 \u2502 (Build)    \u2502 \u2502 (Deploy)   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Mattermost \u2502 \u2502 Prometheus \u2502 \u2502 OpenSearch \u2502 \u2502 Customer   \u2502  \u2502\n\u2502  \u2502 (Collab)   \u2502 \u2502 (Metrics)  \u2502 \u2502 (Logs)     \u2502 \u2502 Feedback   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#core-components","title":"Core Components","text":""},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#1-vsm-hub-new-service","title":"1. VSM Hub (New Service)","text":"<p>Technology: Go microservice (performance, concurrency)</p> <p>Responsibilities:</p> <ul> <li>Receive webhooks/events from all tools</li> <li>Correlate work items across tools using identifiers</li> <li>Calculate flow metrics in real-time</li> <li>Detect bottlenecks using statistical analysis</li> <li>Store value stream data (PostgreSQL)</li> <li>Expose REST/GraphQL API</li> </ul> <p>Data Model:</p> <pre><code>type WorkItem struct {\n    ID              string\n    FocalboardID    string\n    Type            string // feature, bug, story\n    BusinessValue   int    // 1-100 scale\n    Stage           string // backlog, dev, review, test, deploy, done\n    CreatedAt       time.Time\n    UpdatedAt       time.Time\n}\n\ntype FlowEvent struct {\n    WorkItemID      string\n    EventType       string // stage_enter, stage_exit\n    Stage           string\n    Timestamp       time.Time\n    Source          string // focalboard, github, jenkins, argocd\n    Metadata        map[string]interface{}\n}\n\ntype FlowMetrics struct {\n    WorkItemID      string\n    CycleTime       duration // total time from start to done\n    LeadTime        duration // time from commit to deploy\n    StageTimings    map[string]duration\n    WaitTime        duration\n    ActiveTime      duration\n    BlockedTime     duration\n}\n</code></pre>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#2-work-item-correlation-strategy","title":"2. Work Item Correlation Strategy","text":"<p>Convention: All tools must reference work items using consistent identifiers</p> <p>GitHub Commits:</p> <pre><code>git commit -m \"[FOC-123] Add user authentication feature\"\n</code></pre> <p>Branch Naming:</p> <pre><code>git checkout -b feature/FOC-123-user-auth\n</code></pre> <p>Pull Request Description:</p> <pre><code>## Related Work Items\n- Focalboard: FOC-123\n\n## Changes\n...\n</code></pre> <p>Automation:</p> <ul> <li>Pre-commit hooks validate work item ID format</li> <li>GitHub Actions comment on PRs with Focalboard link</li> <li>VSM Hub extracts IDs from commit messages</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#3-value-stream-stages","title":"3. Value Stream Stages","text":"<p>Standard Flow:</p> <pre><code>1. Backlog (Focalboard)\n   \u2193\n2. In Progress (Focalboard status change)\n   \u2193\n3. Code Review (GitHub PR opened)\n   \u2193\n4. Build (Jenkins triggered)\n   \u2193\n5. Test (Automated tests)\n   \u2193\n6. Deploy Staging (ArgoCD sync - staging)\n   \u2193\n7. Validation (Manual/automated validation)\n   \u2193\n8. Deploy Production (ArgoCD sync - prod)\n   \u2193\n9. Monitoring (24-hour observation)\n   \u2193\n10. Done (Work item closed + deployed)\n</code></pre> <p>Customizable: Teams can define custom stages via config</p>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#4-flow-metrics-calculated","title":"4. Flow Metrics Calculated","text":"<p>Cycle Time: Time from \u201cIn Progress\u201d to \u201cDone\u201d</p> <ul> <li>Total cycle time</li> <li>Per-stage cycle time</li> <li>Active time vs. wait time</li> </ul> <p>Lead Time: Time from first commit to production deployment</p> <ul> <li>Aligns with DORA lead time metric</li> <li>Broken down by CI/CD stages</li> </ul> <p>Work in Progress (WIP):</p> <ul> <li>Current WIP per stage</li> <li>WIP trends over time</li> <li>WIP limit violations</li> </ul> <p>Throughput:</p> <ul> <li>Work items completed per week</li> <li>By team, by type, by priority</li> </ul> <p>Flow Efficiency:</p> <pre><code>Flow Efficiency = Active Time / (Active Time + Wait Time)\n</code></pre> <ul> <li>Target: &gt;40% (industry benchmark)</li> </ul> <p>Blocked Time:</p> <ul> <li>Time work items spend blocked</li> <li>Blocking reasons (categorized)</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#5-bottleneck-detection-algorithm","title":"5. Bottleneck Detection Algorithm","text":"<p>Approach: Statistical anomaly detection + rule-based alerts</p> <p>Anomaly Detection:</p> <pre><code># Simplified algorithm\nfor stage in value_stream:\n    avg_cycle_time = historical_average(stage)\n    std_dev = standard_deviation(stage)\n\n    current_items = items_in_stage(stage)\n\n    for item in current_items:\n        if item.time_in_stage &gt; avg_cycle_time + (2 * std_dev):\n            alert(f\"Item {item.id} stuck in {stage}\")\n\n    # Stage-level bottleneck\n    if count(current_items) &gt; historical_average_wip * 1.5:\n        alert(f\"Bottleneck detected in {stage}\")\n</code></pre> <p>Rule-Based Alerts:</p> <ul> <li>WIP exceeds limit for 2+ days</li> <li>Cycle time &gt;2x team average</li> <li>Flow efficiency &lt;30% for 1 week</li> <li>Item blocked for &gt;24 hours</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#6-business-value-tracking","title":"6. Business Value Tracking","text":"<p>Value Assignment:</p> <ul> <li>Product managers assign value (1-100) in Focalboard</li> <li>VSM Hub tracks value delivered per sprint/quarter</li> <li>Value delivery rate calculated</li> </ul> <p>Metrics:</p> <pre><code>Value Delivered = Sum(completed_items.business_value)\nValue Velocity = Value Delivered / Time Period\nValue Efficiency = Value Delivered / Total Cycle Time\n</code></pre> <p>Dashboard:</p> <ul> <li>Value delivered this sprint vs. planned</li> <li>Cumulative flow diagram with value overlay</li> <li>High-value items stuck in pipeline (alerts)</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#7-customer-feedback-integration","title":"7. Customer Feedback Integration","text":"<p>Sources:</p> <ul> <li>Production incidents (linked to work items)</li> <li>NPS surveys (per feature)</li> <li>Feature usage analytics (Prometheus)</li> <li>Support tickets (Mattermost)</li> </ul> <p>Feedback Loop:</p> <pre><code>Deploy Feature (FOC-123)\n    \u2193\nMonitor Usage (7 days)\n    \u2193\nCollect Feedback (NPS survey)\n    \u2193\nCalculate Feature Success Score\n    \u2193\nUpdate Work Item with outcomes\n    \u2193\nInform Product Roadmap\n</code></pre> <p>Feature Success Score:</p> <pre><code>Success = (Usage * NPS * Uptime) - (Incidents * Severity)\n</code></pre>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#integration-points","title":"Integration Points","text":""},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#focalboard-integration","title":"Focalboard Integration","text":"<p>Webhooks:</p> <ul> <li>Work item created \u2192 VSM Hub (stage: backlog)</li> <li>Work item status changed \u2192 VSM Hub (stage transition)</li> <li>Work item assigned value \u2192 VSM Hub (business value update)</li> </ul> <p>API Calls:</p> <ul> <li>VSM Hub queries Focalboard for work item details</li> <li>Backstage plugin displays Focalboard cards</li> </ul> <p>Enhancement:</p> <ul> <li>Custom Focalboard field: \u201cWork Item ID\u201d (e.g., FOC-123)</li> <li>Displayed prominently for developer reference</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#github-integration","title":"GitHub Integration","text":"<p>Webhooks:</p> <ul> <li>Commit pushed \u2192 VSM Hub (extract work item ID from message)</li> <li>PR opened \u2192 VSM Hub (stage: code review)</li> <li>PR merged \u2192 VSM Hub (code review complete)</li> </ul> <p>Automation:</p> <pre><code># .github/workflows/vsm-integration.yml\nname: VSM Integration\non: [push, pull_request]\njobs:\n  notify-vsm:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Extract Work Item ID\n        id: work_item\n        run: |\n          echo \"ID=$(git log -1 --pretty=%B | grep -oP 'FOC-\\d+')\" &gt;&gt; $GITHUB_OUTPUT\n\n      - name: Notify VSM Hub\n        run: |\n          curl -X POST $VSM_HUB_URL/events \\\n            -H \"Content-Type: application/json\" \\\n            -d '{\n              \"work_item_id\": \"${{ steps.work_item.outputs.ID }}\",\n              \"event\": \"commit\",\n              \"source\": \"github\",\n              \"timestamp\": \"'$(date -Iseconds)'\"\n            }'\n</code></pre>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#jenkins-integration","title":"Jenkins Integration","text":"<p>Webhooks:</p> <ul> <li>Build started \u2192 VSM Hub (stage: build)</li> <li>Build completed \u2192 VSM Hub (build success/failure)</li> <li>Tests run \u2192 VSM Hub (test results)</li> </ul> <p>Pipeline Enhancement:</p> <pre><code>pipeline {\n    agent any\n    environment {\n        WORK_ITEM_ID = sh(script: \"git log -1 --pretty=%B | grep -oP 'FOC-\\\\d+'\", returnStdout: true).trim()\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn clean package'\n            }\n            post {\n                always {\n                    sh \"\"\"\n                        curl -X POST $VSM_HUB_URL/events \\\n                          -H 'Content-Type: application/json' \\\n                          -d '{\n                            \"work_item_id\": \"$WORK_ITEM_ID\",\n                            \"event\": \"build_complete\",\n                            \"status\": \"$currentBuild.result\"\n                          }'\n                    \"\"\"\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#argocd-integration","title":"ArgoCD Integration","text":"<p>Webhooks:</p> <ul> <li>Application synced \u2192 VSM Hub (deployment to env)</li> <li>Sync failed \u2192 VSM Hub (deployment failure)</li> <li>Health check \u2192 VSM Hub (deployment health)</li> </ul> <p>Configuration:</p> <pre><code># argocd-notifications configmap\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-notifications-cm\ndata:\n  service.webhook.vsm-hub: |\n    url: http://vsm-hub.fawkes.svc.cluster.local/events\n    headers:\n    - name: Content-Type\n      value: application/json\n\n  trigger.on-deployed: |\n    - when: app.status.operationState.phase in ['Succeeded']\n      send: [vsm-hub-deployment-success]\n</code></pre>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#backstage-plugin-new","title":"Backstage Plugin (New)","text":"<p>Plugin: <code>@fawkes/plugin-vsm</code></p> <p>Features:</p> <ol> <li>Value Stream View: Visualize work item flow</li> <li>Team Dashboard: Team-level flow metrics</li> <li>Work Item Tracker: See status across all tools</li> <li>Bottleneck Alerts: In-context alerts for teams</li> </ol> <p>UI Mockup:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Service: payment-service                     Value Stream   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                              \u2502\n\u2502  Work Items in Flow (Current Sprint)                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502 Backlog  \u2502\u2192\u2502 In Prog  \u2502\u2192\u2502 Review   \u2502\u2192\u2502 Deploy   \u2502      \u2502\n\u2502  \u2502    5     \u2502 \u2502    3     \u2502 \u2502    2     \u2502 \u2502    1     \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502       \u2193             \u2193             \u2193            \u2193            \u2502\n\u2502  \u26a0\ufe0f WIP Limit     \u2705 Healthy   \ud83d\udd34 Bottleneck  \u2705 Healthy   \u2502\n\u2502                                                              \u2502\n\u2502  Flow Metrics (Last 30 Days)                                \u2502\n\u2502  \u2022 Cycle Time: 4.2 days (target: &lt;5 days) \u2705               \u2502\n\u2502  \u2022 Lead Time: 2.1 days (elite: &lt;1 day) \ud83d\udfe1                  \u2502\n\u2502  \u2022 Flow Efficiency: 35% (target: &gt;40%) \ud83d\udd34                   \u2502\n\u2502  \u2022 Throughput: 12 items/week \u2705                             \u2502\n\u2502                                                              \u2502\n\u2502  Active Work Items                                          \u2502\n\u2502  FOC-456 [Feature] \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591 (80% - Code Review)          \u2502\n\u2502  FOC-457 [Bug]     \u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 (20% - In Progress)          \u2502\n\u2502  FOC-458 [Story]   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 (100% - Deploying) \ud83d\ude80        \u2502\n\u2502                                                              \u2502\n\u2502  Alerts \ud83d\udd14                                                  \u2502\n\u2502  \u2022 FOC-450 stuck in Code Review for 3 days (avg: 1 day)    \u2502\n\u2502  \u2022 Flow efficiency dropped below 30% - investigate          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#grafana-dashboards-new","title":"Grafana Dashboards (New)","text":"<p>Dashboard 1: Executive Value Stream Overview</p> <ul> <li>Value delivered (current quarter)</li> <li>Cycle time trends (6 months)</li> <li>Bottleneck heatmap (by team)</li> <li>Top blockers (categorized)</li> </ul> <p>Dashboard 2: Team Flow Metrics</p> <ul> <li>Cumulative flow diagram</li> <li>Cycle time distribution</li> <li>WIP trends</li> <li>Throughput velocity</li> </ul> <p>Dashboard 3: Work Item Deep Dive</p> <ul> <li>Individual work item journey</li> <li>Stage timings breakdown</li> <li>Wait time vs. active time</li> <li>Blockers and delays</li> </ul> <p>Dashboard 4: Bottleneck Analysis</p> <ul> <li>Stage-level bottlenecks</li> <li>Historical bottleneck trends</li> <li>Bottleneck resolution time</li> <li>Impact on flow efficiency</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#data-storage-strategy","title":"Data Storage Strategy","text":"<p>PostgreSQL Schema:</p> <pre><code>-- Work Items\nCREATE TABLE work_items (\n    id VARCHAR(50) PRIMARY KEY,\n    focalboard_id VARCHAR(50) UNIQUE,\n    type VARCHAR(20),\n    title TEXT,\n    business_value INT,\n    stage VARCHAR(50),\n    created_at TIMESTAMP,\n    updated_at TIMESTAMP,\n    completed_at TIMESTAMP\n);\n\n-- Flow Events\nCREATE TABLE flow_events (\n    id SERIAL PRIMARY KEY,\n    work_item_id VARCHAR(50) REFERENCES work_items(id),\n    event_type VARCHAR(50),\n    stage VARCHAR(50),\n    timestamp TIMESTAMP,\n    source VARCHAR(50),\n    metadata JSONB\n);\n\nCREATE INDEX idx_flow_events_work_item ON flow_events(work_item_id);\nCREATE INDEX idx_flow_events_timestamp ON flow_events(timestamp);\n\n-- Flow Metrics (Calculated)\nCREATE TABLE flow_metrics (\n    work_item_id VARCHAR(50) PRIMARY KEY REFERENCES work_items(id),\n    cycle_time_hours DECIMAL,\n    lead_time_hours DECIMAL,\n    active_time_hours DECIMAL,\n    wait_time_hours DECIMAL,\n    blocked_time_hours DECIMAL,\n    flow_efficiency DECIMAL,\n    stage_timings JSONB,\n    calculated_at TIMESTAMP\n);\n\n-- Bottlenecks\nCREATE TABLE bottlenecks (\n    id SERIAL PRIMARY KEY,\n    stage VARCHAR(50),\n    detected_at TIMESTAMP,\n    resolved_at TIMESTAMP,\n    severity VARCHAR(20), -- low, medium, high, critical\n    work_items_affected TEXT[],\n    root_cause TEXT,\n    resolution TEXT\n);\n</code></pre> <p>Time-Series Data (Prometheus):</p> <pre><code># Gauge: Current WIP by stage\nvsm_wip_current{stage=\"code_review\", team=\"payments\"} 5\n\n# Histogram: Cycle time distribution\nvsm_cycle_time_seconds{stage=\"build\", team=\"payments\"} 3600\n\n# Counter: Work items completed\nvsm_items_completed_total{type=\"feature\", team=\"payments\"} 45\n\n# Gauge: Flow efficiency\nvsm_flow_efficiency{team=\"payments\"} 0.38\n</code></pre>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#positive","title":"Positive","text":"<ol> <li>End-to-End Visibility: Teams and leaders see work flow from idea to production</li> <li>Reduces \u201cwhere is my feature?\u201d questions</li> <li>Identifies bottlenecks quickly</li> <li>Enables data-driven process improvements</li> <li>Automated Data Collection: No manual tracking required</li> <li>Developers continue existing workflows</li> <li>Metrics calculated automatically</li> <li>Real-time updates</li> <li>Actionable Insights: Not just dashboards, but alerts and recommendations</li> <li>Bottleneck alerts notify teams immediately</li> <li>Trend analysis predicts future issues</li> <li>Benchmarking against industry standards</li> <li>Business Value Connection: Links engineering work to business outcomes</li> <li>Product managers see value delivery rates</li> <li>Executives understand ROI of platform improvements</li> <li>Prioritization driven by value, not just urgency</li> <li>Competitive Differentiation: Few open-source IDPs offer integrated VSM</li> <li>Attracts organizations serious about flow metrics</li> <li>Aligns with 2025 DORA findings</li> <li>Positions Fawkes as cutting-edge</li> <li>Platform-as-Product Enablement: Measures platform\u2019s own value delivery</li> <li>Internal customers can see platform team throughput</li> <li>Continuous improvement becomes data-driven</li> <li>Justifies platform investment with metrics</li> </ol>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#negative","title":"Negative","text":"<ol> <li>Implementation Complexity: Significant development effort required</li> <li>New service (VSM Hub) to build and maintain</li> <li>Multiple integrations to implement</li> <li>Data model to design and evolve</li> <li>Mitigation: Phased rollout, start with 2-3 integrations</li> <li>Convention Enforcement: Requires consistent work item ID usage</li> <li>Teams must adopt naming conventions</li> <li>Pre-commit hooks needed</li> <li>Change management required</li> <li>Mitigation: Automation (Git hooks), clear documentation, training</li> <li>Data Quality Dependency: Metrics only as good as input data</li> <li>Missed commit messages \u2192 broken correlation</li> <li>Inconsistent Focalboard updates \u2192 wrong stage timings</li> <li>Webhooks failures \u2192 missing events</li> <li>Mitigation: Data quality monitoring, event replay, manual correction UI</li> <li>Performance Concerns: Real-time correlation at scale</li> <li>High event volume from CI/CD (100s per hour)</li> <li>Complex joins across data sources</li> <li>Dashboard query performance</li> <li>Mitigation: Event streaming (Kafka), caching (Redis), query optimization</li> <li>Privacy Considerations: Individual developer performance visibility</li> <li>Metrics could be misused for surveillance</li> <li>Team metrics, not individual metrics</li> <li>Requires careful communication</li> <li>Mitigation: Team-level aggregation only, explicit privacy policy</li> <li>Maintenance Overhead: Another system to operate</li> <li>VSM Hub needs monitoring, scaling, updates</li> <li>Additional PostgreSQL database</li> <li>Integration maintenance as tools evolve</li> <li>Mitigation: Observability from day one, runbooks, automation</li> </ol>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#neutral","title":"Neutral","text":"<ol> <li>Learning Curve: Teams need to understand VSM concepts</li> <li>Training required on flow metrics</li> <li>Dojo module needed (\u201cValue Stream Management\u201d)</li> <li>Action: Include in Yellow Belt curriculum</li> <li>Cultural Change: Shifts focus from velocity to flow</li> <li>Story points de-emphasized</li> <li>Flow efficiency becomes key metric</li> <li>Action: Leadership buy-in, communicate why</li> <li>Tool Dependencies: Relies on existing tool quality</li> <li>Focalboard API stability</li> <li>GitHub webhook reliability</li> <li>Jenkins plugin ecosystem</li> <li>Action: Contribute improvements upstream</li> </ol>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#alternative-1-use-existing-commercial-vsm-tools","title":"Alternative 1: Use Existing Commercial VSM Tools","text":"<p>Examples: Tasktop Hub, ConnectAll, Plutora</p> <p>Pros:</p> <ul> <li>\u2705 Mature, battle-tested solutions</li> <li>\u2705 Pre-built integrations with popular tools</li> <li>\u2705 Advanced analytics and ML features</li> <li>\u2705 Enterprise support available</li> </ul> <p>Cons:</p> <ul> <li>\u274c Expensive ($50-200 per user/month)</li> <li>\u274c SaaS-only (data leaves infrastructure)</li> <li>\u274c Not open source (vendor lock-in)</li> <li>\u274c Limited customization</li> <li>\u274c Doesn\u2019t align with Fawkes\u2019 self-hosted ethos</li> </ul> <p>Why Rejected: Fawkes is an open-source, self-hosted platform. Introducing a commercial SaaS tool contradicts our core values and creates vendor dependency. Our users expect integrated, customizable solutions.</p>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#alternative-2-basic-dashboards-with-manual-correlation","title":"Alternative 2: Basic Dashboards with Manual Correlation","text":"<p>Approach: Build Grafana dashboards with manual work item entry</p> <p>Pros:</p> <ul> <li>\u2705 Simple to implement (minimal code)</li> <li>\u2705 Leverages existing Grafana infrastructure</li> <li>\u2705 No new services to maintain</li> </ul> <p>Cons:</p> <ul> <li>\u274c Manual data entry is error-prone</li> <li>\u274c No automated correlation between tools</li> <li>\u274c No real-time updates</li> <li>\u274c Poor developer experience</li> <li>\u274c Doesn\u2019t scale beyond 1-2 teams</li> </ul> <p>Why Rejected: Manual processes don\u2019t scale and create developer friction. We need automated, seamless integration that respects developer time.</p>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#alternative-3-extend-existing-tools-eg-backstage-plugin-only","title":"Alternative 3: Extend Existing Tools (e.g., Backstage Plugin Only)","text":"<p>Approach: Build VSM as a Backstage plugin without dedicated service</p> <p>Pros:</p> <ul> <li>\u2705 Fewer components to maintain</li> <li>\u2705 Integrated into existing portal</li> <li>\u2705 Simpler architecture</li> </ul> <p>Cons:</p> <ul> <li>\u274c Backstage plugin can\u2019t process real-time events reliably</li> <li>\u274c No central data store for historical analysis</li> <li>\u274c Limited to Backstage users (not available in Grafana)</li> <li>\u274c Poor separation of concerns</li> </ul> <p>Why Rejected: VSM requires real-time event processing, data aggregation, and ML-based analysis. A Backstage plugin alone can\u2019t provide the required functionality. We need a dedicated service with a proper data layer.</p>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#alternative-4-third-party-open-source-vsm-tools","title":"Alternative 4: Third-Party Open Source VSM Tools","text":"<p>Examples: Haystack, Faros AI, Swarmia (partially open source)</p> <p>Pros:</p> <ul> <li>\u2705 Open source (some)</li> <li>\u2705 Active communities</li> <li>\u2705 Pre-built integrations</li> </ul> <p>Cons:</p> <ul> <li>\u274c May not integrate with our specific stack (Focalboard)</li> <li>\u274c Require additional deployment complexity</li> <li>\u274c May not align with our UX principles</li> <li>\u274c Not designed for learning (dojo integration)</li> </ul> <p>Why Partially Considered: We could use these as inspiration or even components (e.g., Faros\u2019s data model), but not as drop-in replacements. We\u2019ll evaluate their architectures and adopt patterns that fit Fawkes.</p>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#alternative-5-delayed-implementation-post-mvp","title":"Alternative 5: Delayed Implementation (Post-MVP)","text":"<p>Approach: Focus on core platform features first, add VSM later</p> <p>Pros:</p> <ul> <li>\u2705 Faster MVP delivery</li> <li>\u2705 Less complexity initially</li> <li>\u2705 Can learn from user feedback first</li> </ul> <p>Cons:</p> <ul> <li>\u274c Misses opportunity to differentiate at launch</li> <li>\u274c Harder to retrofit integrations later</li> <li>\u274c 2025 DORA emphasizes VSM importance now</li> <li>\u274c Competitors may add VSM first</li> </ul> <p>Why Rejected: The 2025 DORA Report makes clear that VSM is a key differentiator for high-performing organizations. Delaying this means Fawkes won\u2019t be competitive with modern expectations. However, we will use a phased approach (see Implementation Plan).</p>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#phase-1-foundation-weeks-1-4-mvp-scope","title":"Phase 1: Foundation (Weeks 1-4) - MVP Scope","text":"<p>Goal: Basic correlation and cycle time measurement</p> <p>Deliverables:</p> <ol> <li>VSM Hub service (Go)</li> <li>Webhook receiver</li> <li>Work item correlation engine</li> <li>Basic API (REST)</li> <li>PostgreSQL schema</li> <li>Integrations (simplified):</li> <li>Focalboard webhook \u2192 VSM Hub</li> <li>GitHub webhook \u2192 VSM Hub</li> <li>Jenkins webhook \u2192 VSM Hub</li> <li>Metrics:</li> <li>Cycle time (end-to-end)</li> <li>Lead time (commit \u2192 deploy)</li> <li>WIP by stage</li> <li>Visualization:</li> <li>Simple Grafana dashboard (flow metrics)</li> <li>Backstage plugin (minimal - work item list)</li> </ol> <p>Success Criteria:</p> <ul> <li>\u2705 Can correlate work items across Focalboard, GitHub, Jenkins</li> <li>\u2705 Cycle time calculated for completed work items</li> <li>\u2705 Dashboard shows basic flow metrics</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#phase-2-intelligence-weeks-5-8-post-mvp","title":"Phase 2: Intelligence (Weeks 5-8) - Post-MVP","text":"<p>Goal: Bottleneck detection and alerts</p> <p>Deliverables:</p> <ol> <li>Bottleneck detection algorithm</li> <li>Statistical anomaly detection</li> <li>Rule-based alerts</li> <li>Enhanced metrics:</li> <li>Flow efficiency</li> <li>Stage-level cycle times</li> <li>Wait time vs. active time</li> <li>Alerting:</li> <li>Mattermost notifications for bottlenecks</li> <li>Email alerts for leadership</li> <li>In-app alerts (Backstage)</li> <li>Enhanced Backstage plugin:</li> <li>Value stream visualization</li> <li>Bottleneck alerts</li> <li>Team health dashboard</li> </ol> <p>Success Criteria:</p> <ul> <li>\u2705 Bottlenecks detected within 4 hours of occurrence</li> <li>\u2705 Alerts sent to appropriate channels</li> <li>\u2705 Flow efficiency calculated and displayed</li> </ul>"},{"location":"adr/ADR-027%20Value%20Stream%20Management%20Integration/#phase-3-business-value-weeks-9-12-post-mvp","title":"Phase 3: Business Value (Weeks 9-12) - Post-MVP","text":"<p>Goal: Link work items to business outcomes</p> <p>Deliverables:</p> <ol> <li>Business value tracking</li> <li>Value assignment in Focalboard</li> <li>Value delivery metrics</li> <li>Value velocity trends</li> <li>Customer feedback integration</li> <li>NPS per feature</li> <li>Feature usage tracking</li> <li>Incident correlation</li> <li>Advanced dashboards:</li> <li>Executive value stream overview</li> <li>Value delivery trends</li> <li>Feature success scores</li> <li>Dojo module: \u201cValue Stream Management\u201d</li> <li>VSM concepts and metrics</li> <li>Hands-on lab: Optimize a value stream</li> <li>Certification: \u201cFawkes VSM Practitioner\u201d</li> </ol> <p>Success Criteria:</p> <ul> <li>\u2705 Business value tracked for</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/","title":"ADR-029: Flow Metrics Storage Strategy","text":"<p>Status: Proposed</p> <p>Date: 2025-01-15</p> <p>Authors: Fawkes Architecture Team</p> <p>Deciders: Platform Architects, SRE Team, Data Engineering</p>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#context","title":"Context","text":"<p>The Flow Metrics Service needs to store and query multiple types of data to support Value Stream Management:</p> <ol> <li>Flow Items - Complete journey of work items through all stages</li> <li>Time-Series Metrics - Flow velocity, flow time, efficiency trends over time</li> <li>Event Stream - Raw webhook events from GitHub, Jenkins, ArgoCD, etc.</li> <li>Aggregated Analytics - Pre-calculated metrics for dashboards</li> <li>Historical Data - Long-term retention for trend analysis</li> </ol> <p>Key Requirements:</p>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Store complete flow item lifecycle (8 stages, multiple timestamps)</li> <li>Support complex relational queries (joins across teams, stages, items)</li> <li>Handle time-series data for trending and alerting</li> <li>Enable real-time dashboard updates (&lt;1 second latency)</li> <li>Support historical queries (90 days minimum, ideally 1+ year)</li> <li>Calculate percentiles (P50, P75, P95) efficiently</li> <li>Support team-level and individual item drill-downs</li> <li>Enable export for data science/ML analysis</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>Write throughput: 100+ events/second (peak)</li> <li>Query latency: &lt;500ms for dashboard queries</li> <li>Data retention: 90 days hot, 1 year warm, 3 years cold</li> <li>Availability: 99.9% uptime</li> <li>Scalability: Support 50+ teams, 10,000+ flow items/month</li> <li>Cost: &lt;$500/month infrastructure</li> <li>Backup/Recovery: RPO &lt;1 hour, RTO &lt;4 hours</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#data-access-patterns","title":"Data Access Patterns","text":"<p>Write-Heavy Patterns:</p> <ul> <li>Webhook events (high frequency, small payloads)</li> <li>Flow item updates (multiple times per item lifecycle)</li> <li>Metrics calculations (periodic batch processing)</li> </ul> <p>Read-Heavy Patterns:</p> <ul> <li>Dashboard queries (real-time, high concurrency)</li> <li>Team metrics (daily/weekly aggregations)</li> <li>Individual flow item drill-downs (ad-hoc queries)</li> <li>Historical trend analysis (monthly/quarterly reports)</li> <li>Executive reporting (weekly/monthly aggregations)</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#decision","title":"Decision","text":"<p>We will implement a hybrid storage architecture combining PostgreSQL for relational data and Prometheus for time-series metrics:</p>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#primary-storage-postgresql","title":"Primary Storage: PostgreSQL","text":"<p>Purpose: Authoritative source for flow items and detailed event data</p> <p>Schema:</p> <pre><code>-- Core flow items table\nCREATE TABLE flow_items (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    external_id VARCHAR(255) NOT NULL,  -- GitHub issue #, JIRA ticket, etc.\n    team_id VARCHAR(100) NOT NULL,\n    item_type VARCHAR(50) NOT NULL,     -- feature, bug, chore\n    title VARCHAR(500),\n    description TEXT,\n    story_points INTEGER,\n    current_stage VARCHAR(50) NOT NULL,\n    status VARCHAR(50) NOT NULL,        -- in_progress, completed, cancelled\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    completed_at TIMESTAMP,\n\n    -- Metadata\n    labels JSONB,\n    metadata JSONB,\n\n    -- Indexes\n    CONSTRAINT flow_items_external_id_key UNIQUE (external_id, team_id)\n);\n\nCREATE INDEX idx_flow_items_team_status ON flow_items(team_id, status);\nCREATE INDEX idx_flow_items_created_at ON flow_items(created_at);\nCREATE INDEX idx_flow_items_completed_at ON flow_items(completed_at) WHERE completed_at IS NOT NULL;\nCREATE INDEX idx_flow_items_current_stage ON flow_items(current_stage);\n\n-- Stage transitions table\nCREATE TABLE stage_transitions (\n    id BIGSERIAL PRIMARY KEY,\n    flow_item_id UUID NOT NULL REFERENCES flow_items(id) ON DELETE CASCADE,\n    from_stage VARCHAR(50),\n    to_stage VARCHAR(50) NOT NULL,\n    transitioned_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    duration_seconds INTEGER,  -- Time spent in from_stage\n\n    -- Metadata\n    triggered_by VARCHAR(100),  -- user, automation, webhook\n    event_type VARCHAR(100),\n    event_payload JSONB,\n\n    -- Indexes\n    CONSTRAINT stage_transitions_flow_item_stage UNIQUE (flow_item_id, to_stage)\n);\n\nCREATE INDEX idx_stage_transitions_flow_item ON stage_transitions(flow_item_id);\nCREATE INDEX idx_stage_transitions_timestamp ON stage_transitions(transitioned_at);\nCREATE INDEX idx_stage_transitions_stage ON stage_transitions(to_stage);\n\n-- Stage metrics (denormalized for query performance)\nCREATE TABLE stage_metrics (\n    id BIGSERIAL PRIMARY KEY,\n    flow_item_id UUID NOT NULL REFERENCES flow_items(id) ON DELETE CASCADE,\n    stage VARCHAR(50) NOT NULL,\n\n    -- Time tracking\n    started_at TIMESTAMP,\n    ended_at TIMESTAMP,\n    active_time_seconds INTEGER DEFAULT 0,\n    wait_time_seconds INTEGER DEFAULT 0,\n\n    -- Calculated metrics\n    flow_efficiency_percent DECIMAL(5,2),\n\n    -- Metadata\n    blockers JSONB,  -- List of blockers encountered\n    metadata JSONB,\n\n    CONSTRAINT stage_metrics_flow_item_stage UNIQUE (flow_item_id, stage)\n);\n\nCREATE INDEX idx_stage_metrics_flow_item ON stage_metrics(flow_item_id);\nCREATE INDEX idx_stage_metrics_stage ON stage_metrics(stage);\n\n-- Teams table\nCREATE TABLE teams (\n    id VARCHAR(100) PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n\n    -- Configuration\n    wip_limit INTEGER DEFAULT 20,\n    target_flow_time_hours INTEGER DEFAULT 96,  -- 4 days\n    target_flow_efficiency_percent INTEGER DEFAULT 40,\n\n    -- Metadata\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    config JSONB\n);\n\n-- Raw webhook events (for debugging and reprocessing)\nCREATE TABLE webhook_events (\n    id BIGSERIAL PRIMARY KEY,\n    source VARCHAR(50) NOT NULL,        -- github, jenkins, argocd\n    event_type VARCHAR(100) NOT NULL,\n    received_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    processed_at TIMESTAMP,\n    processing_status VARCHAR(50) DEFAULT 'pending',  -- pending, processed, failed\n\n    -- Event data\n    payload JSONB NOT NULL,\n    headers JSONB,\n\n    -- Processing info\n    flow_item_id UUID REFERENCES flow_items(id),\n    error_message TEXT,\n    retry_count INTEGER DEFAULT 0,\n\n    -- Partitioning by month\n    CHECK (received_at &gt;= DATE '2025-01-01')\n);\n\nCREATE INDEX idx_webhook_events_source ON webhook_events(source, event_type);\nCREATE INDEX idx_webhook_events_received_at ON webhook_events(received_at);\nCREATE INDEX idx_webhook_events_processing_status ON webhook_events(processing_status) \n    WHERE processing_status != 'processed';\n\n-- Partition webhook_events by month for performance\nCREATE TABLE webhook_events_2025_01 PARTITION OF webhook_events\n    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');\n\n-- Aggregated metrics (pre-calculated for dashboard performance)\nCREATE TABLE daily_team_metrics (\n    id BIGSERIAL PRIMARY KEY,\n    team_id VARCHAR(100) NOT NULL REFERENCES teams(id),\n    metric_date DATE NOT NULL,\n\n    -- Flow metrics\n    flow_velocity DECIMAL(10,2),              -- items/week\n    flow_time_p50_hours DECIMAL(10,2),\n    flow_time_p75_hours DECIMAL(10,2),\n    flow_time_p95_hours DECIMAL(10,2),\n    flow_efficiency_percent DECIMAL(5,2),\n    flow_load INTEGER,                         -- WIP count\n\n    -- Item counts\n    items_completed INTEGER DEFAULT 0,\n    items_started INTEGER DEFAULT 0,\n    items_cancelled INTEGER DEFAULT 0,\n\n    -- Breakdown by type\n    features_completed INTEGER DEFAULT 0,\n    bugs_completed INTEGER DEFAULT 0,\n    chores_completed INTEGER DEFAULT 0,\n\n    -- Calculated\n    calculated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n\n    CONSTRAINT daily_team_metrics_team_date UNIQUE (team_id, metric_date)\n);\n\nCREATE INDEX idx_daily_team_metrics_team_date ON daily_team_metrics(team_id, metric_date DESC);\n\n-- Materialized view for current flow metrics (refreshed every 5 minutes)\nCREATE MATERIALIZED VIEW current_flow_metrics AS\nSELECT \n    fi.team_id,\n    COUNT(*) FILTER (WHERE fi.status = 'in_progress') as current_wip,\n    COUNT(*) FILTER (WHERE fi.completed_at &gt;= NOW() - INTERVAL '7 days') as completed_last_7d,\n    COUNT(*) FILTER (WHERE fi.completed_at &gt;= NOW() - INTERVAL '30 days') as completed_last_30d,\n\n    -- Flow time percentiles (last 30 days)\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY \n        EXTRACT(EPOCH FROM (fi.completed_at - fi.created_at))/3600\n    ) FILTER (WHERE fi.completed_at &gt;= NOW() - INTERVAL '30 days') as flow_time_p50_hours,\n\n    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY \n        EXTRACT(EPOCH FROM (fi.completed_at - fi.created_at))/3600\n    ) FILTER (WHERE fi.completed_at &gt;= NOW() - INTERVAL '30 days') as flow_time_p95_hours,\n\n    -- Flow efficiency (last 30 days)\n    AVG(\n        (SELECT SUM(sm.active_time_seconds) FROM stage_metrics sm WHERE sm.flow_item_id = fi.id) /\n        NULLIF(EXTRACT(EPOCH FROM (fi.completed_at - fi.created_at)), 0) * 100\n    ) FILTER (WHERE fi.completed_at &gt;= NOW() - INTERVAL '30 days') as avg_flow_efficiency_percent,\n\n    MAX(fi.updated_at) as last_updated\nFROM flow_items fi\nGROUP BY fi.team_id;\n\nCREATE UNIQUE INDEX ON current_flow_metrics (team_id);\n\n-- Refresh materialized view every 5 minutes via cron job\n-- SELECT refresh_flow_metrics_view();\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#secondary-storage-prometheus","title":"Secondary Storage: Prometheus","text":"<p>Purpose: Time-series metrics for real-time monitoring and alerting</p> <p>Metrics Exposed:</p> <pre><code># flow_metrics_service/src/metrics/prometheus_metrics.py\n\nfrom prometheus_client import Counter, Histogram, Gauge, Summary\n\n# Flow Velocity\nflow_velocity_items_per_week = Gauge(\n    'flow_velocity_items_per_week',\n    'Number of flow items completed per week',\n    ['team', 'item_type']\n)\n\n# Flow Time\nflow_time_seconds = Histogram(\n    'flow_time_seconds',\n    'Total time from start to completion',\n    ['team', 'item_type'],\n    buckets=[\n        3600,      # 1 hour\n        21600,     # 6 hours\n        86400,     # 1 day\n        172800,    # 2 days\n        345600,    # 4 days\n        604800,    # 1 week\n        1209600,   # 2 weeks\n        2592000,   # 30 days\n    ]\n)\n\n# Flow Efficiency\nflow_efficiency_percent = Histogram(\n    'flow_efficiency_percent',\n    'Flow efficiency (active time / total time)',\n    ['team'],\n    buckets=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n)\n\n# Flow Load (WIP)\nflow_load_wip_current = Gauge(\n    'flow_load_wip_current',\n    'Current number of items in progress',\n    ['team']\n)\n\nflow_load_wip_limit = Gauge(\n    'flow_load_wip_limit',\n    'WIP limit for team',\n    ['team']\n)\n\n# Stage Metrics\nstage_wait_time_seconds = Histogram(\n    'stage_wait_time_seconds',\n    'Wait time in each stage',\n    ['team', 'stage'],\n    buckets=[300, 1800, 3600, 21600, 86400, 172800, 604800]\n)\n\nstage_active_time_seconds = Histogram(\n    'stage_active_time_seconds',\n    'Active time in each stage',\n    ['team', 'stage'],\n    buckets=[300, 1800, 3600, 21600, 86400, 172800]\n)\n\nstage_flow_efficiency_percent = Gauge(\n    'stage_flow_efficiency_percent',\n    'Flow efficiency per stage',\n    ['team', 'stage']\n)\n\n# Event Counters\nwebhook_events_received_total = Counter(\n    'webhook_events_received_total',\n    'Total webhook events received',\n    ['source', 'event_type']\n)\n\nwebhook_events_processed_total = Counter(\n    'webhook_events_processed_total',\n    'Total webhook events successfully processed',\n    ['source', 'event_type']\n)\n\nwebhook_events_failed_total = Counter(\n    'webhook_events_failed_total',\n    'Total webhook events that failed processing',\n    ['source', 'event_type', 'error_type']\n)\n\n# Flow Item Lifecycle\nflow_items_created_total = Counter(\n    'flow_items_created_total',\n    'Total flow items created',\n    ['team', 'item_type']\n)\n\nflow_items_completed_total = Counter(\n    'flow_items_completed_total',\n    'Total flow items completed',\n    ['team', 'item_type']\n)\n\nflow_items_cancelled_total = Counter(\n    'flow_items_cancelled_total',\n    'Total flow items cancelled',\n    ['team', 'item_type']\n)\n\n# Stage Transitions\nstage_transitions_total = Counter(\n    'stage_transitions_total',\n    'Total stage transitions',\n    ['team', 'from_stage', 'to_stage']\n)\n\n# Bottleneck Detection\nbottleneck_detected = Gauge(\n    'bottleneck_detected',\n    'Binary indicator of bottleneck (1 = yes, 0 = no)',\n    ['team', 'stage']\n)\n\nbottleneck_severity = Gauge(\n    'bottleneck_severity',\n    'Severity of bottleneck (0-100 scale)',\n    ['team', 'stage']\n)\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#tertiary-storage-s3-cold-storage","title":"Tertiary Storage: S3 (Cold Storage)","text":"<p>Purpose: Long-term archival and compliance</p> <p>Data Archived:</p> <ul> <li>Flow items older than 90 days (compressed JSON)</li> <li>Webhook events older than 30 days</li> <li>Daily aggregated metrics (permanent retention)</li> </ul> <p>Format: Parquet files partitioned by <code>year/month/team_id/</code></p>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    WRITE PATH                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nGitHub/Jenkins/ArgoCD Webhooks\n        \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Flow Metrics API \u2502\n\u2502 (FastAPI)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2193                  \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 PostgreSQL      \u2502  \u2502 Prometheus       \u2502\n\u2502 (write-through) \u2502  \u2502 (metrics export) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2193 (async background job)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Metrics         \u2502\n\u2502 Aggregator      \u2502\n\u2502 (nightly batch) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 daily_team_     \u2502\n\u2502 metrics table   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    READ PATH                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nDashboard Queries\n        \u2502\n        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2193                         \u2193                         \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Grafana          \u2502    \u2502 Backstage VSM    \u2502    \u2502 Executive        \u2502\n\u2502 (Prometheus +    \u2502    \u2502 (PostgreSQL)     \u2502    \u2502 Reports          \u2502\n\u2502  PostgreSQL)     \u2502    \u2502                  \u2502    \u2502 (PostgreSQL)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2193                         \u2193                         \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 current_flow_    \u2502    \u2502 flow_items       \u2502    \u2502 daily_team_      \u2502\n\u2502 metrics view     \u2502    \u2502 + stage_metrics  \u2502    \u2502 metrics          \u2502\n\u2502 (5min refresh)   \u2502    \u2502 (live queries)   \u2502    \u2502 (pre-agg)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    ARCHIVAL PATH                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nPostgreSQL (90+ days old)\n        \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Archival Job     \u2502\n\u2502 (weekly cron)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 S3 Bucket        \u2502\n\u2502 (Parquet files)  \u2502\n\u2502 year/month/team/ \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#data-flow-examples","title":"Data Flow Examples","text":""},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#example-1-webhook-event-processing","title":"Example 1: Webhook Event Processing","text":"<pre><code># Webhook received\nPOST /webhook/github\n{\n  \"event_type\": \"pull_request.opened\",\n  \"pr_number\": 456,\n  \"repository\": \"sample-app\",\n  \"author\": \"alice\",\n  \"timestamp\": \"2025-01-15T10:30:00Z\"\n}\n\n# Step 1: Insert raw event to PostgreSQL\nINSERT INTO webhook_events (source, event_type, payload)\nVALUES ('github', 'pull_request.opened', '{\"pr_number\": 456, ...}');\n\n# Step 2: Identify or create flow item\nSELECT id FROM flow_items \nWHERE external_id = 'sample-app#456' AND team_id = 'alpha';\n\n# Step 3: Create stage transition\nINSERT INTO stage_transitions (flow_item_id, from_stage, to_stage, transitioned_at)\nVALUES ('uuid-123', 'development', 'code_review', '2025-01-15T10:30:00Z');\n\n# Step 4: Update flow item current stage\nUPDATE flow_items \nSET current_stage = 'code_review', updated_at = NOW()\nWHERE id = 'uuid-123';\n\n# Step 5: Calculate and update stage metrics\nUPDATE stage_metrics\nSET ended_at = NOW(),\n    wait_time_seconds = &lt;calculated&gt;,\n    active_time_seconds = &lt;calculated&gt;\nWHERE flow_item_id = 'uuid-123' AND stage = 'development';\n\n# Step 6: Export metrics to Prometheus\nstage_transitions_total{team=\"alpha\", from_stage=\"development\", to_stage=\"code_review\"} += 1\nflow_load_wip_current{team=\"alpha\"} = &lt;count in progress items&gt;\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#example-2-dashboard-query-grafana","title":"Example 2: Dashboard Query (Grafana)","text":"<pre><code># Query: Flow Velocity (last 30 days)\n# Grafana queries Prometheus\n\nflow_velocity_items_per_week{team=\"alpha\"}\n\n# Prometheus scrapes /metrics endpoint every 15 seconds\n# Flow Metrics Service calculates and exposes:\n# - Count completed items in last 7 days\n# - Divide by (7/7) = items per week\n# - Update gauge metric\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#example-3-detailed-flow-item-query-backstage","title":"Example 3: Detailed Flow Item Query (Backstage)","text":"<pre><code>-- Query: Get complete flow item journey for USER-123\n\n-- Main flow item\nSELECT * FROM flow_items WHERE external_id = 'USER-123';\n\n-- All stage transitions\nSELECT \n    st.from_stage,\n    st.to_stage,\n    st.transitioned_at,\n    st.duration_seconds\nFROM stage_transitions st\nJOIN flow_items fi ON st.flow_item_id = fi.id\nWHERE fi.external_id = 'USER-123'\nORDER BY st.transitioned_at;\n\n-- Stage-level metrics\nSELECT \n    sm.stage,\n    sm.started_at,\n    sm.ended_at,\n    sm.active_time_seconds,\n    sm.wait_time_seconds,\n    sm.flow_efficiency_percent\nFROM stage_metrics sm\nJOIN flow_items fi ON sm.flow_item_id = fi.id\nWHERE fi.external_id = 'USER-123'\nORDER BY sm.started_at;\n\n-- Calculate total flow efficiency\nSELECT \n    SUM(sm.active_time_seconds) as total_active,\n    SUM(sm.active_time_seconds + sm.wait_time_seconds) as total_time,\n    (SUM(sm.active_time_seconds)::float / \n     NULLIF(SUM(sm.active_time_seconds + sm.wait_time_seconds), 0) * 100) as flow_efficiency\nFROM stage_metrics sm\nJOIN flow_items fi ON sm.flow_item_id = fi.id\nWHERE fi.external_id = 'USER-123';\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#rationale","title":"Rationale","text":""},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#why-postgresql-for-primary-storage","title":"Why PostgreSQL for Primary Storage?","text":"<p>Pros:</p> <ul> <li>\u2705 Strong relational model (flow items \u2192 transitions \u2192 metrics)</li> <li>\u2705 ACID compliance for data integrity</li> <li>\u2705 Complex JOIN queries for analytics</li> <li>\u2705 Excellent JSON support (JSONB) for flexible metadata</li> <li>\u2705 Materialized views for query performance</li> <li>\u2705 Partitioning for time-series data management</li> <li>\u2705 Native support in Backstage and other tools</li> <li>\u2705 Team familiarity (already using for other Fawkes components)</li> <li>\u2705 Proven at scale (handle millions of rows)</li> </ul> <p>Cons:</p> <ul> <li>\u274c Not optimized for pure time-series queries</li> <li>\u274c Requires careful indexing for performance</li> <li>\u274c More expensive than NoSQL for massive scale</li> </ul> <p>Why Not Alternatives?</p> <p>MongoDB:</p> <ul> <li>Document model doesn\u2019t fit relational nature of flow items</li> <li>Weaker consistency guarantees</li> <li>More complex to query across relationships</li> </ul> <p>Cassandra:</p> <ul> <li>Overkill for expected scale (&lt;10M rows/year)</li> <li>Complex operational overhead</li> <li>Difficult to change schema</li> </ul> <p>DynamoDB:</p> <ul> <li>Expensive at scale</li> <li>Limited query flexibility</li> <li>Vendor lock-in</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#why-prometheus-for-time-series","title":"Why Prometheus for Time-Series?","text":"<p>Pros:</p> <ul> <li>\u2705 Industry standard for metrics</li> <li>\u2705 Native Grafana integration</li> <li>\u2705 Efficient time-series storage</li> <li>\u2705 Powerful query language (PromQL)</li> <li>\u2705 Built-in alerting</li> <li>\u2705 Pull-based model (service exposes /metrics)</li> <li>\u2705 Already deployed in Fawkes for DORA metrics</li> </ul> <p>Cons:</p> <ul> <li>\u274c Limited retention (15 days default, expensive to extend)</li> <li>\u274c Not designed for detailed event storage</li> <li>\u274c No JOIN capabilities</li> </ul> <p>Why Not Alternatives?</p> <p>InfluxDB:</p> <ul> <li>Additional infrastructure component</li> <li>Licensing concerns (InfluxDB 3.x)</li> <li>Less mature Grafana integration</li> </ul> <p>TimescaleDB:</p> <ul> <li>PostgreSQL extension, could consolidate storage</li> <li>Considered but adds complexity to single PostgreSQL instance</li> <li>Future option if Prometheus retention becomes issue</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#why-s3-for-archival","title":"Why S3 for Archival?","text":"<p>Pros:</p> <ul> <li>\u2705 Extremely cost-effective ($0.023/GB/month)</li> <li>\u2705 Unlimited retention</li> <li>\u2705 Parquet format efficient for analytics</li> <li>\u2705 Compatible with data science tools (Pandas, Spark)</li> <li>\u2705 Lifecycle policies for automatic tiering</li> </ul> <p>Cons:</p> <ul> <li>\u274c High latency (seconds to retrieve)</li> <li>\u274c Not queryable without external tools</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#data-retention-strategy","title":"Data Retention Strategy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Data Lifecycle Management                                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n0-30 days (HOT):\n\u251c\u2500 PostgreSQL: All tables (full detail)\n\u251c\u2500 Prometheus: All metrics (15-second resolution)\n\u2514\u2500 Query performance: &lt;100ms\n\n30-90 days (WARM):\n\u251c\u2500 PostgreSQL: All tables (full detail)\n\u251c\u2500 Prometheus: Downsampled to 1-minute resolution (via recording rules)\n\u2514\u2500 Query performance: &lt;500ms\n\n90 days - 1 year (COLD):\n\u251c\u2500 PostgreSQL: Aggregated metrics only (daily_team_metrics)\n\u251c\u2500 S3: Full detail (Parquet files)\n\u251c\u2500 Prometheus: Not available (use PostgreSQL)\n\u2514\u2500 Query performance: &lt;2s (from PostgreSQL), &lt;30s (from S3)\n\n1+ years (ARCHIVED):\n\u251c\u2500 PostgreSQL: Aggregated metrics only\n\u251c\u2500 S3: Full detail (Parquet + Glacier)\n\u2514\u2500 Query performance: Minutes (from Glacier)\n\nDeletion Policy:\n\u251c\u2500 webhook_events: Delete after 90 days\n\u251c\u2500 stage_transitions: Archive to S3 after 90 days, delete after 1 year\n\u251c\u2500 flow_items: Archive to S3 after 90 days, delete after 3 years\n\u251c\u2500 daily_team_metrics: Keep forever (small size)\n\u2514\u2500 Prometheus: Automatic deletion after 15 days\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#performance-optimization-strategies","title":"Performance Optimization Strategies","text":""},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#1-database-indexing","title":"1. Database Indexing","text":"<pre><code>-- Indexes for common query patterns\n\n-- Dashboard: Team metrics\nCREATE INDEX CONCURRENTLY idx_flow_items_team_completed \nON flow_items(team_id, completed_at) \nWHERE status = 'completed';\n\n-- Dashboard: WIP count\nCREATE INDEX CONCURRENTLY idx_flow_items_team_in_progress \nON flow_items(team_id) \nWHERE status = 'in_progress';\n\n-- Drill-down: Flow item lookup\nCREATE INDEX CONCURRENTLY idx_flow_items_external_id_hash \nON flow_items USING hash(external_id);\n\n-- Analytics: Stage efficiency\nCREATE INDEX CONCURRENTLY idx_stage_metrics_stage_efficiency \nON stage_metrics(stage, flow_efficiency_percent);\n\n-- Webhook processing: Unprocessed events\nCREATE INDEX CONCURRENTLY idx_webhook_events_pending \nON webhook_events(source, received_at) \nWHERE processing_status = 'pending';\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#2-materialized-views","title":"2. Materialized Views","text":"<pre><code>-- Refresh strategy\nCREATE OR REPLACE FUNCTION refresh_flow_metrics_view()\nRETURNS void AS $$\nBEGIN\n    REFRESH MATERIALIZED VIEW CONCURRENTLY current_flow_metrics;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Schedule via pg_cron (every 5 minutes)\nSELECT cron.schedule('refresh-flow-metrics', '*/5 * * * *', \n    'SELECT refresh_flow_metrics_view()');\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#3-partitioning","title":"3. Partitioning","text":"<pre><code>-- Partition webhook_events by month\nCREATE TABLE webhook_events (\n    -- ... columns ...\n) PARTITION BY RANGE (received_at);\n\n-- Create partitions for 2025\nDO $$\nDECLARE\n    month_start DATE;\nBEGIN\n    FOR month_num IN 1..12 LOOP\n        month_start := DATE '2025-01-01' + (month_num - 1) * INTERVAL '1 month';\n        EXECUTE format(\n            'CREATE TABLE IF NOT EXISTS webhook_events_%s PARTITION OF webhook_events\n             FOR VALUES FROM (%L) TO (%L)',\n            to_char(month_start, 'YYYY_MM'),\n            month_start,\n            month_start + INTERVAL '1 month'\n        );\n    END LOOP;\nEND $$;\n\n-- Automatic partition creation (pg_partman)\nSELECT partman.create_parent(\n    p_parent_table := 'public.webhook_events',\n    p_control := 'received_at',\n    p_type := 'native',\n    p_interval := '1 month',\n    p_premake := 3  -- Create 3 months ahead\n);\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#4-query-optimization","title":"4. Query Optimization","text":"<pre><code># Use connection pooling\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.pool import QueuePool\n\nengine = create_engine(\n    'postgresql://flowmetrics:password@postgres:5432/flowmetrics',\n    poolclass=QueuePool,\n    pool_size=20,\n    max_overflow=40,\n    pool_pre_ping=True  # Verify connections before use\n)\n\n# Use prepared statements for repeated queries\nfrom sqlalchemy import text\n\n# Bad: Vulnerable to SQL injection, not prepared\ndef get_team_metrics_bad(team_id):\n    query = f\"SELECT * FROM daily_team_metrics WHERE team_id = '{team_id}'\"\n    return engine.execute(query)\n\n# Good: Parameterized, prepared statement\ndef get_team_metrics_good(team_id):\n    query = text(\"\"\"\n        SELECT * FROM daily_team_metrics \n        WHERE team_id = :team_id \n        ORDER BY metric_date DESC \n        LIMIT 30\n    \"\"\")\n    return engine.execute(query, {\"team_id\": team_id})\n\n# Best: Use SQLAlchemy ORM with lazy loading\nfrom sqlalchemy.orm import sessionmaker\n\nSession = sessionmaker(bind=engine)\n\ndef get_team_metrics_best(team_id):\n    session = Session()\n    return session.query(DailyTeamMetrics)\\\n        .filter_by(team_id=team_id)\\\n        .order_by(DailyTeamMetrics.metric_date.desc())\\\n        .limit(30)\\\n        .all()\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#5-caching-strategy","title":"5. Caching Strategy","text":"<pre><code># Redis for hot data caching\nfrom redis import Redis\nimport json\n\nredis_client = Redis(host='redis', port=6379, db=0)\n\ndef get_team_flow_metrics(team_id: str, force_refresh: bool = False):\n    \"\"\"\n    Get team flow metrics with Redis caching\n    Cache TTL: 5 minutes\n    \"\"\"\n    cache_key = f\"flow_metrics:team:{team_id}\"\n\n    # Try cache first\n    if not force_refresh:\n        cached = redis_client.get(cache_key)\n        if cached:\n            return json.loads(cached)\n\n    # Cache miss - query database\n    metrics = calculate_team_metrics(team_id)\n\n    # Store in cache with 5-minute TTL\n    redis_client.setex(\n        cache_key,\n        300,  # 5 minutes\n        json.dumps(metrics)\n    )\n\n    return metrics\n\n# Cache invalidation on write\ndef update_flow_item(flow_item_id: str, updates: dict):\n    # Update database\n    update_database(flow_item_id, updates)\n\n    # Invalidate team cache\n    flow_item = get_flow_item(flow_item_id)\n    redis_client.delete(f\"flow_metrics:team:{flow_item.team_id}\")\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#backup-strategy","title":"Backup Strategy","text":"<pre><code># PostgreSQL backup configuration\nbackup:\n  tool: pg_dump + wal-e\n  frequency:\n    full: daily at 02:00 UTC\n    incremental: continuous (WAL archiving)\n  retention:\n    full_backups: 30 days\n    wal_archives: 30 days\n  storage:\n    primary: S3 (s3://fawkes-backups/postgres/flow-metrics/)\n    encryption: AES-256\n  verification:\n    test_restore: weekly\n    rpo:\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#week-3-optimization-continued","title":"Week 3: Optimization (continued)","text":"<ul> <li>[ ] Create materialized views</li> <li>[ ] Set up automated view refresh (pg_cron)</li> <li>[ ] Implement query performance monitoring</li> <li>[ ] Add database indexes based on query patterns</li> <li>[ ] Configure connection pooling (PgBouncer)</li> <li>[ ] Set up Redis caching for hot queries</li> <li>[ ] Enable query result caching</li> <li>[ ] Run performance benchmarks (Locust tests)</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#week-4-monitoring-alerting","title":"Week 4: Monitoring &amp; Alerting","text":"<ul> <li>[ ] Configure Prometheus alerts for database health</li> <li>[ ] Set up Grafana dashboards for database metrics</li> <li>[ ] Create webhook processing monitoring</li> <li>[ ] Implement slow query alerting</li> <li>[ ] Configure disk usage alerts</li> <li>[ ] Set up replication lag monitoring (if using replicas)</li> <li>[ ] Create runbook for common issues</li> <li>[ ] Test alert notifications (PagerDuty/Slack)</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#week-5-backup-recovery","title":"Week 5: Backup &amp; Recovery","text":"<ul> <li>[ ] Verify automated backups are running</li> <li>[ ] Test point-in-time recovery (PITR)</li> <li>[ ] Document recovery procedures</li> <li>[ ] Set up S3 lifecycle policies for old backups</li> <li>[ ] Test backup restoration (weekly automated test)</li> <li>[ ] Create disaster recovery runbook</li> <li>[ ] Configure backup monitoring and alerts</li> <li>[ ] Validate RPO/RTO targets</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#week-6-data-migration","title":"Week 6: Data Migration","text":"<ul> <li>[ ] Backfill historical data (90 days)</li> <li>[ ] Run data validation scripts</li> <li>[ ] Compare metrics with legacy system (if exists)</li> <li>[ ] Enable dual-write mode (if migrating)</li> <li>[ ] Monitor data consistency</li> <li>[ ] Address any discrepancies</li> <li>[ ] Plan cutover timeline</li> <li>[ ] Document rollback procedures</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#week-7-security-hardening","title":"Week 7: Security Hardening","text":"<ul> <li>[ ] Enable SSL/TLS for all connections</li> <li>[ ] Rotate database credentials</li> <li>[ ] Implement row-level security policies</li> <li>[ ] Enable audit logging (pgaudit)</li> <li>[ ] Configure WAF rules for API endpoints</li> <li>[ ] Perform security scan (Trivy, Snyk)</li> <li>[ ] Review IAM policies and roles</li> <li>[ ] Document security controls</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#week-8-production-readiness","title":"Week 8: Production Readiness","text":"<ul> <li>[ ] Conduct load testing (100+ users)</li> <li>[ ] Perform chaos engineering tests</li> <li>[ ] Validate all monitoring is operational</li> <li>[ ] Complete documentation (architecture, runbooks)</li> <li>[ ] Train team on operations and troubleshooting</li> <li>[ ] Schedule go-live date</li> <li>[ ] Prepare rollback plan</li> <li>[ ] Conduct final readiness review</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#operational-runbooks","title":"Operational Runbooks","text":""},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#runbook-1-high-connection-count","title":"Runbook 1: High Connection Count","text":"<p>Symptoms:</p> <ul> <li>Alert: \u201cPostgreSQL High Connection Count\u201d</li> <li>Dashboard shows &gt;80 active connections</li> <li>API latency increasing</li> </ul> <p>Diagnosis:</p> <pre><code>-- Check current connections\nSELECT \n    datname,\n    count(*) as connections,\n    usename\nFROM pg_stat_activity\nWHERE state = 'active'\nGROUP BY datname, usename\nORDER BY connections DESC;\n\n-- Check long-running queries\nSELECT \n    pid,\n    now() - pg_stat_activity.query_start AS duration,\n    query,\n    state\nFROM pg_stat_activity\nWHERE state != 'idle'\n    AND now() - pg_stat_activity.query_start &gt; interval '5 minutes'\nORDER BY duration DESC;\n</code></pre> <p>Resolution:</p> <ol> <li>Immediate: Kill long-running queries if safe</li> </ol> <pre><code>SELECT pg_terminate_backend(pid) \nFROM pg_stat_activity \nWHERE pid = &lt;problematic_pid&gt;;\n</code></pre> <ol> <li>Short-term: Restart PgBouncer to reset connection pool</li> </ol> <pre><code>kubectl rollout restart deployment/pgbouncer -n fawkes\n</code></pre> <ol> <li>Long-term: Increase connection limit or optimize queries</li> </ol> <pre><code>-- Increase max_connections (requires restart)\nALTER SYSTEM SET max_connections = 200;\nSELECT pg_reload_conf();\n</code></pre> <p>Prevention:</p> <ul> <li>Use connection pooling (PgBouncer)</li> <li>Set application connection timeout (30 seconds)</li> <li>Implement query timeout limits</li> <li>Monitor connection patterns</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#runbook-2-slow-query-performance","title":"Runbook 2: Slow Query Performance","text":"<p>Symptoms:</p> <ul> <li>Alert: \u201cPostgreSQL Slow Queries\u201d</li> <li>Dashboard query latency &gt;1 second</li> <li>User complaints about slow dashboards</li> </ul> <p>Diagnosis:</p> <pre><code>-- Find slow queries\nSELECT \n    query,\n    calls,\n    mean_exec_time,\n    max_exec_time,\n    stddev_exec_time\nFROM pg_stat_statements\nWHERE mean_exec_time &gt; 1000  -- 1 second\nORDER BY mean_exec_time DESC\nLIMIT 10;\n\n-- Check for missing indexes\nSELECT \n    schemaname,\n    tablename,\n    seq_scan,\n    seq_tup_read,\n    idx_scan,\n    idx_tup_fetch,\n    seq_tup_read / seq_scan as avg_seq_tup\nFROM pg_stat_user_tables\nWHERE seq_scan &gt; 100\n    AND seq_tup_read / NULLIF(seq_scan, 0) &gt; 10000\nORDER BY seq_tup_read DESC;\n\n-- Check table bloat\nSELECT \n    schemaname,\n    tablename,\n    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,\n    n_live_tup,\n    n_dead_tup,\n    n_dead_tup * 100.0 / NULLIF(n_live_tup, 0) as dead_tuple_percent\nFROM pg_stat_user_tables\nWHERE n_dead_tup &gt; 1000\nORDER BY n_dead_tup DESC;\n</code></pre> <p>Resolution:</p> <ol> <li>Immediate: Refresh materialized views</li> </ol> <pre><code>REFRESH MATERIALIZED VIEW CONCURRENTLY current_flow_metrics;\n</code></pre> <ol> <li>Short-term: Add missing indexes</li> </ol> <pre><code>-- Example: Add index for team metrics query\nCREATE INDEX CONCURRENTLY idx_flow_items_team_completed_at\nON flow_items(team_id, completed_at)\nWHERE status = 'completed';\n</code></pre> <ol> <li>Medium-term: Vacuum bloated tables</li> </ol> <pre><code>VACUUM ANALYZE flow_items;\nVACUUM ANALYZE stage_transitions;\n</code></pre> <ol> <li>Long-term: Optimize query or denormalize data</li> </ol> <pre><code>-- Create aggregated table for better performance\nCREATE TABLE team_metrics_summary AS\nSELECT \n    team_id,\n    date_trunc('day', completed_at) as date,\n    count(*) as items_completed,\n    percentile_cont(0.5) WITHIN GROUP (ORDER BY flow_time) as p50_flow_time\nFROM flow_items\nWHERE completed_at IS NOT NULL\nGROUP BY team_id, date_trunc('day', completed_at);\n\nCREATE INDEX ON team_metrics_summary(team_id, date DESC);\n</code></pre> <p>Prevention:</p> <ul> <li>Enable auto-vacuum (should be default)</li> <li>Monitor pg_stat_statements regularly</li> <li>Set query timeout: <code>SET statement_timeout = '5s'</code></li> <li>Use EXPLAIN ANALYZE for new queries</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#runbook-3-webhook-processing-backlog","title":"Runbook 3: Webhook Processing Backlog","text":"<p>Symptoms:</p> <ul> <li>Alert: \u201cWebhook Processing Backlog\u201d</li> <li>100 pending webhook events</li> <li>Metrics not updating in real-time</li> </ul> <p>Diagnosis:</p> <pre><code>-- Check backlog size\nSELECT \n    source,\n    count(*) as pending_count\nFROM webhook_events\nWHERE processing_status = 'pending'\nGROUP BY source;\n\n-- Check for failures\nSELECT \n    source,\n    event_type,\n    error_message,\n    count(*) as failure_count\nFROM webhook_events\nWHERE processing_status = 'failed'\n    AND received_at &gt; NOW() - INTERVAL '1 hour'\nGROUP BY source, event_type, error_message\nORDER BY failure_count DESC;\n\n-- Check processing rate\nSELECT \n    date_trunc('minute', processed_at) as minute,\n    count(*) as processed_count\nFROM webhook_events\nWHERE processed_at &gt; NOW() - INTERVAL '30 minutes'\nGROUP BY date_trunc('minute', processed_at)\nORDER BY minute DESC;\n</code></pre> <p>Resolution:</p> <ol> <li>Immediate: Scale up webhook processors</li> </ol> <pre><code># Increase replicas\nkubectl scale deployment/flow-metrics-service --replicas=5 -n fawkes\n\n# Check pod status\nkubectl get pods -n fawkes -l app=flow-metrics\n</code></pre> <ol> <li>Short-term: Reprocess failed events</li> </ol> <pre><code># Retry failed events\npython scripts/reprocess_failed_webhooks.py --hours=1 --limit=100\n</code></pre> <ol> <li>Medium-term: Identify and fix error patterns</li> </ol> <pre><code># Common error: missing flow item\n# Fix: Create flow item from webhook data\nif error_message == 'Flow item not found':\n    create_flow_item_from_webhook(webhook_event)\n    retry_webhook_processing(webhook_event.id)\n</code></pre> <ol> <li>Long-term: Optimize webhook processing</li> </ol> <pre><code># Add batch processing for high-volume events\ndef process_webhooks_batch(events: List[WebhookEvent]):\n    # Process 100 events at once\n    with database.transaction():\n        for event in events:\n            process_webhook(event)\n\n    # Commit once instead of 100 times\n</code></pre> <p>Prevention:</p> <ul> <li>Implement circuit breaker pattern</li> <li>Add webhook event TTL (delete after 90 days)</li> <li>Monitor webhook sources for unusual volume</li> <li>Implement rate limiting on webhook endpoints</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#runbook-4-disk-space-critical","title":"Runbook 4: Disk Space Critical","text":"<p>Symptoms:</p> <ul> <li>Alert: \u201cPostgreSQL Disk Usage High\u201d</li> <li>Disk usage &gt;80%</li> <li>Write operations may fail soon</li> </ul> <p>Diagnosis:</p> <pre><code>-- Check database sizes\nSELECT \n    datname,\n    pg_size_pretty(pg_database_size(datname)) as size\nFROM pg_database\nORDER BY pg_database_size(datname) DESC;\n\n-- Check table sizes\nSELECT \n    schemaname,\n    tablename,\n    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,\n    pg_size_pretty(pg_table_size(schemaname||'.'||tablename)) as table_size,\n    pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) as indexes_size\nFROM pg_tables\nWHERE schemaname = 'public'\nORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;\n\n-- Check WAL size\nSELECT \n    pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), '0/0')) as wal_size;\n\n-- Check bloat\nSELECT \n    schemaname,\n    tablename,\n    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,\n    n_dead_tup,\n    n_dead_tup * 100.0 / NULLIF(n_live_tup + n_dead_tup, 0) as dead_percentage\nFROM pg_stat_user_tables\nWHERE schemaname = 'public'\nORDER BY n_dead_tup DESC;\n</code></pre> <p>Resolution:</p> <ol> <li>Immediate: Archive old webhook events to S3</li> </ol> <pre><code># Archive events older than 30 days\npython scripts/archive_old_webhooks.py --days=30 --confirm\n</code></pre> <ol> <li>Short-term: Vacuum full bloated tables (requires downtime)</li> </ol> <pre><code>-- Reclaim disk space (use CONCURRENTLY to avoid locks if possible)\nVACUUM FULL webhook_events;\n\n-- Or without downtime but slower:\nVACUUM ANALYZE webhook_events;\n</code></pre> <ol> <li>Medium-term: Increase disk size</li> </ol> <pre><code># AWS RDS\naws rds modify-db-instance \\\n    --db-instance-identifier fawkes-flowmetrics \\\n    --allocated-storage 1000 \\\n    --apply-immediately\n</code></pre> <ol> <li>Long-term: Implement data lifecycle management</li> </ol> <pre><code># Automated cleanup job (daily cron)\ndef cleanup_old_data():\n    # Archive flow items older than 90 days\n    old_items = FlowItem.query.filter(\n        FlowItem.completed_at &lt; datetime.now() - timedelta(days=90)\n    ).all()\n\n    for item in old_items:\n        # Export to S3\n        export_to_s3(item)\n\n        # Delete from database\n        database.session.delete(item)\n\n    database.session.commit()\n</code></pre> <p>Prevention:</p> <ul> <li>Set up automated archival (90-day policy)</li> <li>Monitor disk usage trends</li> <li>Alert at 70% (warning) and 80% (critical)</li> <li>Enable auto-scaling storage (AWS RDS)</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#runbook-5-backup-failure","title":"Runbook 5: Backup Failure","text":"<p>Symptoms:</p> <ul> <li>Alert: \u201cPostgreSQL Backup Failed\u201d</li> <li>No recent backup in S3</li> <li>WAL archiving failing</li> </ul> <p>Diagnosis:</p> <pre><code># Check last successful backup\naws s3 ls s3://fawkes-backups/postgres/flow-metrics/ --recursive | sort | tail -5\n\n# Check WAL archiving status\npsql -U postgres -c \"SELECT * FROM pg_stat_archiver;\"\n\n# Check for disk space issues\ndf -h /var/lib/postgresql/data\n\n# Check backup logs\nkubectl logs -n fawkes postgres-0 | grep -i backup | tail -50\n</code></pre> <p>Resolution:</p> <ol> <li>Immediate: Manually trigger backup</li> </ol> <pre><code># Manual pg_dump\nkubectl exec -it postgres-0 -n fawkes -- bash\npg_dump -Fc -U postgres flowmetrics &gt; /tmp/manual_backup_$(date +%Y%m%d).dump\n\n# Upload to S3\naws s3 cp /tmp/manual_backup_*.dump s3://fawkes-backups/postgres/flow-metrics/manual/\n</code></pre> <ol> <li>Short-term: Fix WAL archiving</li> </ol> <pre><code># Check archive_command\npsql -U postgres -c \"SHOW archive_command;\"\n\n# Test manually\n/usr/bin/wal-e wal-push /var/lib/postgresql/data/pg_wal/000000010000000000000001\n\n# If failing due to credentials\n# Update AWS credentials in Kubernetes secret\nkubectl edit secret postgres-backup-credentials -n fawkes\n</code></pre> <ol> <li>Medium-term: Verify backup script</li> </ol> <pre><code># Check cron job status\nkubectl get cronjobs -n fawkes\nkubectl describe cronjob postgres-backup -n fawkes\n\n# View recent job runs\nkubectl get jobs -n fawkes | grep postgres-backup\n\n# Check job logs\nkubectl logs job/postgres-backup-12345 -n fawkes\n</code></pre> <ol> <li>Long-term: Test restore procedure</li> </ol> <pre><code># Scheduled restore test (weekly)\npython scripts/test_backup_restore.py --backup-date=2025-01-15\n</code></pre> <p>Prevention:</p> <ul> <li>Monitor backup success rate (should be 100%)</li> <li>Test restores monthly</li> <li>Alert on failed backups within 1 hour</li> <li>Document recovery procedures</li> <li>Maintain backup retention policy</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#maintenance-tasks","title":"Maintenance Tasks","text":""},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#daily","title":"Daily","text":"<pre><code>#!/bin/bash\n# daily_maintenance.sh\n\n# Refresh materialized views\npsql -U flowmetrics -d flowmetrics -c \"REFRESH MATERIALIZED VIEW CONCURRENTLY current_flow_metrics;\"\n\n# Update aggregated metrics\npython scripts/calculate_daily_team_metrics.py --date=yesterday\n\n# Check for slow queries\npsql -U flowmetrics -d flowmetrics -f scripts/check_slow_queries.sql\n\n# Verify backup completed\npython scripts/verify_backup.py --date=today\n\n# Archive old webhook events (30+ days)\npython scripts/archive_webhooks.py --days=30 --dry-run=false\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#weekly","title":"Weekly","text":"<pre><code>#!/bin/bash\n# weekly_maintenance.sh\n\n# Vacuum analyze all tables\npsql -U flowmetrics -d flowmetrics -c \"VACUUM ANALYZE;\"\n\n# Test backup restore\npython scripts/test_restore.py --latest\n\n# Review unused indexes\npsql -U flowmetrics -d flowmetrics -f scripts/check_unused_indexes.sql\n\n# Check table bloat\npsql -U flowmetrics -d flowmetrics -f scripts/check_table_bloat.sql\n\n# Generate performance report\npython scripts/generate_performance_report.py --week\n\n# Update documentation\npython scripts/update_metrics_documentation.py\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#monthly","title":"Monthly","text":"<pre><code>#!/bin/bash\n# monthly_maintenance.sh\n\n# Archive completed flow items (90+ days)\npython scripts/archive_flow_items.py --days=90\n\n# Optimize database\npsql -U flowmetrics -d flowmetrics -c \"REINDEX DATABASE flowmetrics;\"\n\n# Review and tune configuration\npython scripts/analyze_pg_configuration.py --suggest\n\n# Security audit\npython scripts/security_audit.py --report\n\n# Cost analysis\npython scripts/analyze_costs.py --month=last\n\n# Capacity planning\npython scripts/capacity_forecast.py --months=6\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#quarterly","title":"Quarterly","text":"<pre><code>#!/bin/bash\n# quarterly_maintenance.sh\n\n# Full database backup verification\npython scripts/verify_all_backups.py --quarter\n\n# Disaster recovery drill\npython scripts/dr_drill.py --scenario=full_restore\n\n# Performance benchmarking\npython scripts/run_benchmarks.py --full\n\n# Schema optimization review\npython scripts/analyze_schema.py --recommend\n\n# Update monitoring thresholds\npython scripts/tune_alerts.py --analyze=90days\n\n# Review and update runbooks\npython scripts/validate_runbooks.py\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#appendices","title":"Appendices","text":""},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#appendix-a-sql-schema-migration-scripts","title":"Appendix A: SQL Schema Migration Scripts","text":"<pre><code>-- Migration: 001_initial_schema.sql\n-- Creates base tables for flow metrics\n\nBEGIN;\n\nCREATE TABLE IF NOT EXISTS teams (\n    id VARCHAR(100) PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    wip_limit INTEGER DEFAULT 20,\n    target_flow_time_hours INTEGER DEFAULT 96,\n    target_flow_efficiency_percent INTEGER DEFAULT 40,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    config JSONB\n);\n\nCREATE TABLE IF NOT EXISTS flow_items (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    external_id VARCHAR(255) NOT NULL,\n    team_id VARCHAR(100) NOT NULL REFERENCES teams(id),\n    item_type VARCHAR(50) NOT NULL,\n    title VARCHAR(500),\n    description TEXT,\n    story_points INTEGER,\n    current_stage VARCHAR(50) NOT NULL,\n    status VARCHAR(50) NOT NULL,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    completed_at TIMESTAMP,\n    labels JSONB,\n    metadata JSONB,\n    CONSTRAINT flow_items_external_id_key UNIQUE (external_id, team_id)\n);\n\nCREATE TABLE IF NOT EXISTS stage_transitions (\n    id BIGSERIAL PRIMARY KEY,\n    flow_item_id UUID NOT NULL REFERENCES flow_items(id) ON DELETE CASCADE,\n    from_stage VARCHAR(50),\n    to_stage VARCHAR(50) NOT NULL,\n    transitioned_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    duration_seconds INTEGER,\n    triggered_by VARCHAR(100),\n    event_type VARCHAR(100),\n    event_payload JSONB,\n    CONSTRAINT stage_transitions_flow_item_stage UNIQUE (flow_item_id, to_stage)\n);\n\nCREATE TABLE IF NOT EXISTS stage_metrics (\n    id BIGSERIAL PRIMARY KEY,\n    flow_item_id UUID NOT NULL REFERENCES flow_items(id) ON DELETE CASCADE,\n    stage VARCHAR(50) NOT NULL,\n    started_at TIMESTAMP,\n    ended_at TIMESTAMP,\n    active_time_seconds INTEGER DEFAULT 0,\n    wait_time_seconds INTEGER DEFAULT 0,\n    flow_efficiency_percent DECIMAL(5,2),\n    blockers JSONB,\n    metadata JSONB,\n    CONSTRAINT stage_metrics_flow_item_stage UNIQUE (flow_item_id, stage)\n);\n\n-- Create indexes\nCREATE INDEX idx_flow_items_team_status ON flow_items(team_id, status);\nCREATE INDEX idx_flow_items_created_at ON flow_items(created_at);\nCREATE INDEX idx_flow_items_completed_at ON flow_items(completed_at) WHERE completed_at IS NOT NULL;\nCREATE INDEX idx_stage_transitions_flow_item ON stage_transitions(flow_item_id);\nCREATE INDEX idx_stage_metrics_flow_item ON stage_metrics(flow_item_id);\n\nCOMMIT;\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#appendix-b-prometheus-recording-rules","title":"Appendix B: Prometheus Recording Rules","text":"<pre><code># prometheus_rules.yml\n# Recording rules for flow metrics aggregation\n\ngroups:\n  - name: flow_metrics_aggregations\n    interval: 60s\n    rules:\n      # Flow Velocity - Pre-aggregate for performance\n      - record: flow_velocity_items_per_week:team\n        expr: |\n          sum by (team) (\n            increase(flow_items_completed_total[7d])\n          )\n\n      # Flow Time P50 - Pre-calculate percentile\n      - record: flow_time_p50_hours:team\n        expr: |\n          histogram_quantile(0.5, \n            sum by (team, le) (\n              rate(flow_time_seconds_bucket[30d])\n            )\n          ) / 3600\n\n      # Flow Time P95\n      - record: flow_time_p95_hours:team\n        expr: |\n          histogram_quantile(0.95, \n            sum by (team, le) (\n              rate(flow_time_seconds_bucket[30d])\n            )\n          ) / 3600\n\n      # Stage Wait Time Average\n      - record: stage_wait_time_avg_hours:team:stage\n        expr: |\n          avg by (team, stage) (\n            rate(stage_wait_time_seconds_sum[1h])\n            /\n            rate(stage_wait_time_seconds_count[1h])\n          ) / 3600\n\n      # Webhook Processing Rate\n      - record: webhook_events_processing_rate:source\n        expr: |\n          sum by (source) (\n            rate(webhook_events_processed_total[5m])\n          )\n\n      # Webhook Processing Error Rate\n      - record: webhook_events_error_rate:source\n        expr: |\n          sum by (source) (\n            rate(webhook_events_failed_total[5m])\n          )\n          /\n          sum by (source) (\n            rate(webhook_events_received_total[5m])\n          )\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#appendix-c-database-connection-configuration","title":"Appendix C: Database Connection Configuration","text":"<pre><code># config/database.py\n# Production-ready database configuration\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.pool import QueuePool\nfrom sqlalchemy.orm import sessionmaker\nimport os\n\n# Database URL from environment\nDATABASE_URL = os.getenv(\n    'DATABASE_URL',\n    'postgresql://flowmetrics:password@postgres:5432/flowmetrics'\n)\n\n# Connection pool configuration\nengine = create_engine(\n    DATABASE_URL,\n    poolclass=QueuePool,\n    pool_size=20,              # Base connection pool size\n    max_overflow=40,           # Additional connections when needed\n    pool_timeout=30,           # Wait 30s for connection\n    pool_recycle=3600,         # Recycle connections after 1 hour\n    pool_pre_ping=True,        # Verify connections before use\n    echo=False,                # Don't log SQL (use for debugging only)\n    echo_pool=False,           # Don't log pool events\n    connect_args={\n        'connect_timeout': 10,\n        'options': '-c statement_timeout=30000'  # 30s query timeout\n    }\n)\n\n# Session factory\nSessionLocal = sessionmaker(\n    autocommit=False,\n    autoflush=False,\n    bind=engine\n)\n\n# Dependency for FastAPI\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n</code></pre>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#conclusion","title":"Conclusion","text":"<p>This ADR documents the decision to use a hybrid storage architecture combining PostgreSQL for relational data and Prometheus for time-series metrics, with S3 for archival storage.</p>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#key-decisions","title":"Key Decisions:","text":"<ol> <li>PostgreSQL as primary storage for flow items and detailed event data</li> <li>Prometheus for real-time time-series metrics and alerting</li> <li>S3 for cost-effective long-term archival</li> <li>Materialized views for dashboard query performance</li> <li>Partitioning for webhook_events table</li> <li>90-day retention in hot storage, 1-year in warm, 3+ years in cold</li> </ol>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#trade-offs-accepted","title":"Trade-offs Accepted:","text":"<ul> <li>Operational complexity of managing two storage systems (PostgreSQL + Prometheus)</li> <li>Manual coordination needed between systems (no automatic sync)</li> <li>Prometheus retention limited (15 days) - acceptable for MVP</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#future-considerations","title":"Future Considerations:","text":"<ul> <li>TimescaleDB if consolidation desired</li> <li>ClickHouse if scale reaches 100M+ flow items</li> <li>Thanos if Prometheus retention becomes issue</li> <li>Aurora PostgreSQL if RDS scaling limits reached</li> </ul>"},{"location":"adr/ADR-029%20Flow%20Metrics%20Storage%20Strategy/#success-metrics","title":"Success Metrics:","text":"<ul> <li>Query latency P95 &lt; 500ms \u2705</li> <li>Write throughput &gt; 100 events/sec \u2705</li> <li>Monthly cost &lt; $500 (optimized) \u2705</li> <li>Data retention 90 days (hot) \u2705</li> </ul> <p>This architecture provides a solid foundation for Value Stream Management in Fawkes while maintaining operational simplicity and cost-effectiveness for the MVP phase.</p> <p>Status: Proposed \u2192 Accepted (pending implementation)</p> <p>Next Steps:</p> <ol> <li>Review with platform architecture team</li> <li>Validate cost estimates with finance</li> <li>Begin Week 1 implementation tasks</li> <li>Schedule architecture review after 30 days</li> </ol> <p>Related ADRs:</p> <ul> <li>ADR-006: PostgreSQL for Data Persistence</li> <li>ADR-027: Value Stream Management Integration</li> <li>ADR-030: Real-Time vs Batch Processing (to be created)</li> </ul> <p>Last Updated: 2025-01-15\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/","title":"ADR-030: SCORE Workload Specification Integration","text":""},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#status","title":"Status","text":"<p>Accepted - December 6, 2025</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#context","title":"Context","text":"<p>The Fawkes platform currently generates Kubernetes manifests directly in the Golden Path templates. This approach creates several challenges:</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#current-state-problems","title":"Current State Problems","text":"<ol> <li> <p>Tight Coupling to K8s: Application definitions are tightly bound to Kubernetes-specific resources (Deployment, Service, Ingress), making them less portable.</p> </li> <li> <p>Portability Challenges: Moving workloads between environments (dev, staging, prod) or platforms requires manually editing K8s manifests.</p> </li> <li> <p>Developer Cognitive Load: Developers must understand Kubernetes internals to define simple application requirements like \"I need a database\" or \"I need 2GB of memory.\"</p> </li> <li> <p>Environment-Specific Duplication: Similar configurations must be repeated across different environments with minor variations (e.g., different Vault addresses, Ingress hosts).</p> </li> <li> <p>Infrastructure Abstraction: The platform should abstract infrastructure details from application developers, allowing them to focus on application logic.</p> </li> </ol>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#the-score-specification","title":"The SCORE Specification","text":"<p>SCORE (score.dev) is an open-source, platform-agnostic workload specification that provides:</p> <ul> <li>Declarative Resource Definitions: Describe what resources you need (database, cache, secrets) without specifying how they're provisioned.</li> <li>Environment Portability: Write once, deploy anywhere (K8s, Docker Compose, cloud platforms).</li> <li>Developer-Friendly: Simple, intuitive YAML syntax focused on application needs, not infrastructure.</li> <li>Industry Adoption: Created by Humanitec, backed by CNCF ecosystem, growing community adoption.</li> </ul>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#forces-at-play","title":"Forces at Play","text":"<p>Technical Forces: - Need for platform-agnostic workload definitions - Balance between abstraction and control - Integration with existing GitOps workflows (ArgoCD) - Tooling maturity and ecosystem support</p> <p>Business Forces: - Reduce time-to-production for application teams - Improve developer experience and satisfaction - Enable multi-cloud and hybrid deployments - Reduce platform lock-in</p> <p>Organizational Forces: - Varying Kubernetes expertise across teams - Platform engineering team capacity for supporting multiple deployment patterns - Need for backwards compatibility with existing applications</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#decision","title":"Decision","text":"<p>We will integrate the SCORE specification into Fawkes Golden Path templates as the primary workload definition format.</p> <p>Specifically:</p> <ol> <li> <p>Golden Path Templates will generate a <code>score.yaml</code> file as the authoritative workload definition.</p> </li> <li> <p>SCORE Transformer Component will translate <code>score.yaml</code> into environment-specific Kubernetes manifests at deployment time.</p> </li> <li> <p>Kustomize Integration will be used to apply environment overlays on top of SCORE-generated manifests.</p> </li> <li> <p>Backwards Compatibility will be maintained - existing applications without <code>score.yaml</code> will continue to work.</p> </li> <li> <p>SCORE Fields Supported (Phase 1):</p> </li> <li>Container definitions (image, resources, ports)</li> <li>Resource requirements (database, cache, storage)</li> <li>Service dependencies</li> <li>Environment variables and configuration</li> <li>Basic scaling parameters</li> </ol>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Developer Defines Workload                                  \u2502\n\u2502                                                              \u2502\n\u2502  score.yaml (Platform-Agnostic)                             \u2502\n\u2502  \u251c\u2500\u2500 containers:                                            \u2502\n\u2502  \u2502   \u2514\u2500\u2500 web:                                               \u2502\n\u2502  \u2502       \u251c\u2500\u2500 image: \"my-app:1.0.0\"                         \u2502\n\u2502  \u2502       \u2514\u2500\u2500 resources: {memory: 512Mi}                    \u2502\n\u2502  \u2514\u2500\u2500 resources:                                             \u2502\n\u2502      \u2514\u2500\u2500 db: {type: postgres}                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u2502 GitOps Pipeline\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 SCORE Transformer (Kustomize Generator)                     \u2502\n\u2502                                                              \u2502\n\u2502  Reads score.yaml + environment config                      \u2502\n\u2502  Generates K8s manifests:                                   \u2502\n\u2502    - Deployment (from containers)                           \u2502\n\u2502    - Service (from ports)                                   \u2502\n\u2502    - Ingress (if public endpoint)                           \u2502\n\u2502    - ConfigMap (for config)                                 \u2502\n\u2502    - ExternalSecret (for secrets)                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u2502 Kustomize Build\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Environment-Specific K8s Manifests                          \u2502\n\u2502                                                              \u2502\n\u2502  Dev: vault.dev.local, 1 replica                            \u2502\n\u2502  Prod: vault.prod.local, 3 replicas, HPA                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u2502 ArgoCD Sync\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Kubernetes Cluster                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#rationale","title":"Rationale","text":"<p>Why SCORE?</p> <ol> <li> <p>Industry Standard: SCORE is an emerging industry standard, not a proprietary format. This reduces platform lock-in.</p> </li> <li> <p>Simple for Developers: Developers describe application needs in business terms (\"I need a Postgres DB\") rather than infrastructure terms (\"I need a StatefulSet with this PVC template...\").</p> </li> <li> <p>Portability: Applications can theoretically run on different platforms (K8s, Docker Compose, cloud PaaS) with the same <code>score.yaml</code>.</p> </li> <li> <p>GitOps Compatible: SCORE fits naturally into our GitOps workflow - it's just another declarative YAML file in the repository.</p> </li> <li> <p>Extensible: SCORE allows custom resource types, enabling platform-specific extensions while maintaining core portability.</p> </li> </ol> <p>Why Not Alternatives?</p> <ul> <li>Raw K8s Manifests: Too verbose, not portable, high cognitive load.</li> <li>Helm Charts: Templating complexity, over-engineering for simple apps, not platform-agnostic.</li> <li>Docker Compose: Not designed for production Kubernetes deployments.</li> <li>Custom DSL: Would create vendor lock-in and require ongoing maintenance.</li> </ul>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#consequences","title":"Consequences","text":""},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#positive","title":"Positive","text":"<p>\u2705 Improved Developer Experience: Developers work with simple, declarative workload specs instead of complex K8s YAML.</p> <p>\u2705 Portability: Applications can be deployed across different environments with minimal changes.</p> <p>\u2705 Reduced Duplication: Environment differences handled by the platform, not duplicated in app repos.</p> <p>\u2705 Future-Proofing: SCORE support makes migration to other platforms (cloud PaaS, other orchestrators) easier.</p> <p>\u2705 Clearer Separation of Concerns: Application teams own <code>score.yaml</code>, platform teams own the transformation logic.</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#negative","title":"Negative","text":"<p>\u26a0\ufe0f Additional Abstraction Layer: Introduces another layer between application definition and K8s resources, potentially complicating debugging.</p> <p>\u26a0\ufe0f Tooling Dependency: Requires SCORE CLI or custom transformer; adds dependency to the deployment pipeline.</p> <p>\u26a0\ufe0f Learning Curve: Teams must learn SCORE specification in addition to (or instead of) Kubernetes.</p> <p>\u26a0\ufe0f Limited Adoption: SCORE is relatively new; community resources and examples are still growing.</p> <p>\u26a0\ufe0f Expressiveness Limits: Very complex K8s configurations may not be fully expressible in SCORE; escape hatches needed.</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li> <p>Backwards Compatibility: Existing apps without <code>score.yaml</code> continue to work unchanged.</p> </li> <li> <p>Escape Hatches: Allow teams to override/extend generated manifests with custom Kustomize patches.</p> </li> <li> <p>Documentation &amp; Examples: Provide comprehensive docs and starter templates for common patterns.</p> </li> <li> <p>Incremental Rollout: Start with new applications only; migrate existing apps on a case-by-case basis.</p> </li> <li> <p>Tooling Simplicity: Use lightweight SCORE CLI or simple custom generator; avoid over-engineering.</p> </li> </ol>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#implementation-plan","title":"Implementation Plan","text":""},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#phase-1-foundation-sprint-1-2","title":"Phase 1: Foundation (Sprint 1-2)","text":"<ul> <li>[ ] Create ADR (this document)</li> <li>[ ] Create <code>templates/golden-path-service/score.yaml</code> template</li> <li>[ ] Implement basic SCORE transformer (using score-k8s or custom Kustomize generator)</li> <li>[ ] Generate Deployment, Service, Ingress from score.yaml</li> <li>[ ] Update Golden Path documentation</li> </ul>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#phase-2-resource-types-sprint-3-4","title":"Phase 2: Resource Types (Sprint 3-4)","text":"<ul> <li>[ ] Support database resources (Postgres via CloudNativePG)</li> <li>[ ] Support cache resources (Redis)</li> <li>[ ] Support secrets (External Secrets Operator)</li> <li>[ ] Support storage (PVC)</li> <li>[ ] Add validation for supported resource types</li> </ul>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#phase-3-testing-validation-sprint-5","title":"Phase 3: Testing &amp; Validation (Sprint 5)","text":"<ul> <li>[ ] BDD tests for SCORE translation</li> <li>[ ] BDD tests for environment portability</li> <li>[ ] Integration with existing CI/CD pipeline</li> <li>[ ] Performance testing (transformation time)</li> </ul>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#phase-4-migration-adoption-sprint-6","title":"Phase 4: Migration &amp; Adoption (Sprint 6+)","text":"<ul> <li>[ ] Migrate 2-3 sample applications to SCORE</li> <li>[ ] Gather feedback from pilot teams</li> <li>[ ] Refine transformer based on real-world usage</li> <li>[ ] Create migration guide for existing applications</li> </ul>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#alternative-1-continue-with-raw-k8s-manifests","title":"Alternative 1: Continue with Raw K8s Manifests","text":"<p>Pros: No new tooling, team familiarity, full K8s expressiveness.</p> <p>Cons: Poor developer experience, low portability, high duplication.</p> <p>Decision: Rejected - doesn't address core problems.</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#alternative-2-use-helm-for-application-templates","title":"Alternative 2: Use Helm for Application Templates","text":"<p>Pros: Mature ecosystem, broad adoption, powerful templating.</p> <p>Cons: Templating complexity, not platform-agnostic, over-engineering for simple apps.</p> <p>Decision: Rejected - adds complexity without improving portability.</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#alternative-3-custom-fawkes-dsl","title":"Alternative 3: Custom Fawkes DSL","text":"<p>Pros: Complete control, tailored to Fawkes needs.</p> <p>Cons: Vendor lock-in, maintenance burden, no community support.</p> <p>Decision: Rejected - prefer industry standards over NIH solutions.</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#alternative-4-cue-or-jsonnet","title":"Alternative 4: CUE or Jsonnet","text":"<p>Pros: Powerful configuration languages, strong typing.</p> <p>Cons: Steep learning curve, not purpose-built for workload specs.</p> <p>Decision: Rejected - too generic, doesn't solve developer UX problem.</p>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#references","title":"References","text":"<ul> <li>SCORE Specification</li> <li>score-k8s Implementation</li> <li>Platform Engineering Principles</li> <li>ADR-001: Kubernetes</li> <li>ADR-003: ArgoCD</li> <li>Golden Path Usage Guide</li> </ul>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#related-decisions","title":"Related Decisions","text":"<ul> <li>ADR-001 (Kubernetes): SCORE generates K8s manifests as the target platform.</li> <li>ADR-003 (ArgoCD): SCORE transformation happens before ArgoCD sync.</li> <li>ADR-005 (Terraform): Infrastructure resources (RDS, S3) provisioned by Terraform, referenced in SCORE.</li> <li>ADR-021 (Eclipse Che): Devfiles remain separate from SCORE (different purposes).</li> </ul>"},{"location":"adr/ADR-030%20SCORE%20Workload%20Specification%20Integration/#decision-review","title":"Decision Review","text":"<ul> <li>Review Date: March 2026 (3 months after initial implementation)</li> <li>Success Criteria:</li> <li>80%+ of new Golden Path applications use score.yaml</li> <li>Developer satisfaction score &gt;4.0/5.0 for SCORE-based deployments</li> <li>&lt;5 minutes average time to deploy a new service using SCORE</li> <li>Zero production incidents caused by SCORE transformation issues</li> </ul>"},{"location":"copilot/jenkins-pipelines/","title":"Copilot Instructions for Fawkes Platform","text":""},{"location":"copilot/jenkins-pipelines/#agent-model-capabilities","title":"\ud83c\udfaf Agent Model Capabilities","text":"<p>When using Copilot in agent mode, you will get:</p>"},{"location":"copilot/jenkins-pipelines/#planning-phase","title":"Planning Phase","text":"<ul> <li>Architecture analysis - Review existing code and suggest optimal implementation patterns</li> <li>Dependency mapping - Identify required components and integration points</li> <li>Task breakdown - Decompose complex features into implementable steps</li> <li>Risk assessment - Flag potential issues before implementation</li> <li>Alternative evaluation - Compare multiple approaches with trade-offs</li> </ul>"},{"location":"copilot/jenkins-pipelines/#implementation-phase","title":"Implementation Phase","text":"<ul> <li>Multi-file generation - Create complete feature implementations across files</li> <li>Test generation - Automatic unit, integration, and E2E test creation</li> <li>Documentation updates - Keep docs in sync with code changes</li> <li>Configuration management - Generate all required configs (K8s, Terraform, etc.)</li> <li>Refactoring suggestions - Improve existing code continuously</li> </ul>"},{"location":"copilot/jenkins-pipelines/#fawkes-platform-context","title":"\ud83c\udfd7\ufe0f Fawkes Platform Context","text":""},{"location":"copilot/jenkins-pipelines/#what-is-fawkes","title":"What is Fawkes?","text":"<p>Fawkes is an open-source Internal Product Delivery Platform that combines: - Infrastructure automation (Kubernetes, Terraform/Crossplane) - Developer portal (Backstage with software templates) - CI/CD pipelines (Jenkins, ArgoCD for GitOps) - Team collaboration (Mattermost, Focalboard) - Immersive learning (Dojo system with 5-belt progression)</p>"},{"location":"copilot/jenkins-pipelines/#key-differentiators","title":"Key Differentiators","text":"<ol> <li>DORA metrics automated - All 4 key metrics tracked from day one</li> <li>Integrated learning curriculum - Learn while building</li> <li>Complete product delivery stack - Not just infrastructure</li> <li>Open source, self-hosted - No vendor lock-in, MIT licensed</li> <li>Platform as a product - Developer experience first</li> </ol>"},{"location":"copilot/jenkins-pipelines/#current-mvp-scope","title":"Current MVP Scope","text":"<p>IN SCOPE: - Kubernetes orchestration (AWS EKS primary, multi-cloud planned) - Backstage developer portal + Dojo learning hub - Jenkins CI/CD with golden path templates - ArgoCD for GitOps continuous delivery - Mattermost for team collaboration - Focalboard for project management (bundled with Mattermost) - Prometheus + Grafana for observability - OpenSearch + Fluent Bit for logging - SonarQube + Trivy for security scanning - Harbor for container registry - DORA metrics automation</p> <p>OUT OF SCOPE (Post-MVP): - Spinnaker (dropped from MVP - using ArgoCD + Argo Rollouts instead) - Eclipse Che (using local workspace automation for MVP) - Multi-cloud abstractions with Crossplane (AWS first, then expand) - Advanced service mesh features</p>"},{"location":"copilot/jenkins-pipelines/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Fawkes Platform                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Developer Portal (Backstage)                                \u2502\n\u2502  \u251c\u2500\u2500 Service Catalog                                         \u2502\n\u2502  \u251c\u2500\u2500 Software Templates (Golden Paths)                       \u2502\n\u2502  \u251c\u2500\u2500 TechDocs (Documentation)                                \u2502\n\u2502  \u2514\u2500\u2500 Dojo Learning Hub (Modules, Labs, Progress)            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Infrastructure Layer (Kubernetes)                           \u2502\n\u2502  \u251c\u2500\u2500 Jenkins (CI/CD Pipelines)                              \u2502\n\u2502  \u251c\u2500\u2500 ArgoCD (GitOps Continuous Delivery)                    \u2502\n\u2502  \u251c\u2500\u2500 Harbor (Container Registry + Scanning)                 \u2502\n\u2502  \u251c\u2500\u2500 Mattermost (Team Collaboration)                        \u2502\n\u2502  \u251c\u2500\u2500 Focalboard (Project Management - in Mattermost)        \u2502\n\u2502  \u2514\u2500\u2500 Observability (Prometheus, Grafana, OpenSearch)        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Cloud Infrastructure (AWS First, Multi-Cloud Later)        \u2502\n\u2502  \u251c\u2500\u2500 Terraform (IaC for AWS)                                \u2502\n\u2502  \u251c\u2500\u2500 Amazon EKS (Kubernetes)                                \u2502\n\u2502  \u2514\u2500\u2500 AWS Services (RDS, S3, ALB, CloudWatch, etc.)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#fawkes-repository-structure-current","title":"\ud83d\udcc1 Fawkes Repository Structure (CURRENT)","text":"<p>CRITICAL: Use this EXACT structure for all file generation</p> <p>Based on the actual repository at https://github.com/paruff/fawkes:</p> <pre><code>fawkes/\n\u251c\u2500\u2500 docs/                           # Documentation\n\u2502   \u251c\u2500\u2500 dojo/                       # Dojo learning system\n\u2502   \u2502   \u251c\u2500\u2500 DOJO_ARCHITECTURE.md   # Complete learning system design\n\u2502   \u2502   \u251c\u2500\u2500 white-belt/            # White belt curriculum\n\u2502   \u2502   \u251c\u2500\u2500 yellow-belt/           # Yellow belt curriculum\n\u2502   \u2502   \u251c\u2500\u2500 green-belt/            # Green belt curriculum\n\u2502   \u2502   \u251c\u2500\u2500 brown-belt/            # Brown belt curriculum\n\u2502   \u2502   \u2514\u2500\u2500 black-belt/            # Black belt curriculum\n\u2502   \u251c\u2500\u2500 adr/                        # Architecture Decision Records\n\u2502   \u2502   \u251c\u2500\u2500 ADR-001-kubernetes.md\n\u2502   \u2502   \u251c\u2500\u2500 ADR-002-backstage.md\n\u2502   \u2502   \u251c\u2500\u2500 ADR-003-argocd.md\n\u2502   \u2502   \u251c\u2500\u2500 ADR-004-jenkins.md\n\u2502   \u2502   \u251c\u2500\u2500 ADR-005-terraform.md\n\u2502   \u2502   \u251c\u2500\u2500 ADR-006-postgresql.md\n\u2502   \u2502   \u251c\u2500\u2500 ADR-007-mattermost.md\n\u2502   \u2502   \u2514\u2500\u2500 ADR-008-focalboard.md\n\u2502   \u251c\u2500\u2500 components/                 # Component-specific docs\n\u2502   \u251c\u2500\u2500 operations/                 # Operational guides\n\u2502   \u251c\u2500\u2500 sprints/                    # Sprint planning docs\n\u2502   \u251c\u2500\u2500 architecture.md             # System architecture\n\u2502   \u251c\u2500\u2500 getting-started.md          # Getting started guide\n\u2502   \u251c\u2500\u2500 troubleshooting.md          # Troubleshooting\n\u2502   \u251c\u2500\u2500 AWS_COST_ESTIMATION.md      # AWS cost analysis\n\u2502   \u2514\u2500\u2500 BUSINESS_CASE.md            # Business value prop\n\u2502\n\u251c\u2500\u2500 infra/                          # Infrastructure as Code\n\u2502   \u251c\u2500\u2500 scripts/ignite.sh           # Unified cluster + Argo CD bootstrap\n\u2502   \u251c\u2500\u2500 scripts/ignite.sh           # Unified cluster + Argo CD bootstrap\n\u2502   \u251c\u2500\u2500 terraform/                  # Terraform modules (AWS primary)\n\u2502   \u2502   \u2514\u2500\u2500 aws/                    # AWS-specific IaC\n\u2502   \u251c\u2500\u2500 kubernetes/                 # Kubernetes manifests\n\u2502   \u2502   \u251c\u2500\u2500 backstage/              # Developer portal\n\u2502   \u2502   \u251c\u2500\u2500 jenkins/                # CI/CD\n\u2502   \u2502   \u251c\u2500\u2500 argocd/                 # GitOps\n\u2502   \u2502   \u251c\u2500\u2500 harbor/                 # Container registry\n\u2502   \u2502   \u251c\u2500\u2500 mattermost/             # Collaboration\n\u2502   \u2502   \u251c\u2500\u2500 prometheus/             # Metrics\n\u2502   \u2502   \u251c\u2500\u2500 grafana/                # Dashboards\n\u2502   \u2502   \u2514\u2500\u2500 opensearch/             # Logging\n\u2502   \u251c\u2500\u2500 helm/                       # Helm charts\n\u2502   \u2514\u2500\u2500 workspace/                  # Developer workspace automation\n\u2502       \u251c\u2500\u2500 setup-OS-space.sh       # Local workspace setup\n\u2502       \u2514\u2500\u2500 [platform-specific]/    # macOS/Windows configs\n\u2502\n\u251c\u2500\u2500 modules/                        # Terraform/reusable modules\n\u2502   \u2514\u2500\u2500 [cloud-provider-modules]/\n\u2502\n\u251c\u2500\u2500 templates/                      # Application templates (golden paths)\n\u2502   \u251c\u2500\u2500 java-spring-boot/          # Java template (existing)\n\u2502   \u251c\u2500\u2500 python-fastapi/             # Python template (planned)\n\u2502   \u2514\u2500\u2500 nodejs-express/             # Node.js template (planned)\n\u2502\n\u251c\u2500\u2500 tests/                          # Automated tests\n\u2502   \u251c\u2500\u2500 e2e/                        # End-to-end BDD tests (create when ready)\n\u2502   \u2502   \u251c\u2500\u2500 features/               # Gherkin scenarios\n\u2502   \u2502   \u2514\u2500\u2500 step_definitions/       # Test implementations\n\u2502   \u251c\u2500\u2500 integration/                # Integration tests\n\u2502   \u2514\u2500\u2500 unit/                       # Unit tests\n\u2502\n\u251c\u2500\u2500 scripts/                        # Utility scripts\n\u2502   \u251c\u2500\u2500 setup/                      # Setup automation\n\u2502   \u251c\u2500\u2500 validation/                 # Config validation\n\u2502   \u2514\u2500\u2500 run-tests.sh                # Test runner\n\u2502\n\u251c\u2500\u2500 .github/                        # GitHub configuration\n\u2502   \u251c\u2500\u2500 workflows/                  # CI/CD pipelines\n\u2502   \u251c\u2500\u2500 ISSUE_TEMPLATE/             # Issue templates\n\u2502   \u2502   \u251c\u2500\u2500 bug_report.yml\n\u2502   \u2502   \u251c\u2500\u2500 feature_request.yml\n\u2502   \u2502   \u251c\u2500\u2500 dojo_module.yml\n\u2502   \u2502   \u2514\u2500\u2500 security_vulnerability.yml\n\u2502   \u251c\u2500\u2500 PULL_REQUEST_TEMPLATE.md\n\u2502   \u2514\u2500\u2500 labels.yml                  # GitHub labels config\n\u2502\n\u251c\u2500\u2500 config/                         # Configuration files\n\u2502   \u2514\u2500\u2500 example.tfvars              # Example Terraform variables\n\u2502\n\u251c\u2500\u2500 GOVERNANCE.md                   # Project governance\n\u251c\u2500\u2500 CODE_OF_CONDUCT.md              # Community standards\n\u251c\u2500\u2500 PROJECT_CHARTER.md              # Vision and mission\n\u251c\u2500\u2500 CONTRIBUTING.md                 # Contribution guidelines\n\u251c\u2500\u2500 CONTRIBUTORS.md                 # Contributor recognition\n\u251c\u2500\u2500 LICENSE                         # MIT License\n\u2514\u2500\u2500 README.md                       # Main project README\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#file-naming-conventions","title":"File Naming Conventions","text":"<ul> <li>Kubernetes manifests: <code>&lt;resource&gt;-&lt;name&gt;.yaml</code> (e.g., <code>deployment-backstage.yaml</code>)</li> <li>Terraform modules: <code>main.tf</code>, <code>variables.tf</code>, <code>outputs.tf</code></li> <li>Python tests: <code>test_&lt;feature&gt;.py</code></li> <li>Feature files: <code>&lt;capability&gt;.feature</code> (lowercase, underscores)</li> <li>Helm charts: <code>Chart.yaml</code>, <code>values.yaml</code>, <code>templates/</code></li> <li>Scripts: Place in <code>scripts/</code> (e.g., <code>ignite.sh</code>, <code>setup-OS-space.sh</code>)</li> </ul>"},{"location":"copilot/jenkins-pipelines/#key-paths-reference","title":"Key Paths Reference","text":"Component Path Infrastructure scripts <code>/scripts/ignite.sh</code> Terraform (AWS) <code>/infra/terraform/aws/</code> or <code>/modules/</code> Kubernetes manifests <code>/infra/kubernetes/&lt;service&gt;/</code> Dojo curriculum <code>/docs/dojo/&lt;belt-level&gt;/</code> ADRs <code>/docs/adr/ADR-###-&lt;topic&gt;.md</code> Application templates <code>/templates/&lt;language&gt;-&lt;framework&gt;/</code> Tests <code>/tests/&lt;type&gt;/</code> Scripts <code>/scripts/</code> or <code>/infra/</code>"},{"location":"copilot/jenkins-pipelines/#working-with-existing-structure","title":"\ud83d\udd27 Working with Existing Structure","text":"<p>IMPORTANT: Fawkes uses an established directory structure. When generating code:</p> <ol> <li>Check existing patterns first - Look at current file locations before creating new ones</li> <li>Ask before major moves - Don't restructure without explicit request</li> <li>Use relative paths - Make code work regardless of exact structure</li> <li>Document location decisions - Add comments explaining file placement</li> <li>Respect established conventions - Follow existing naming and organization</li> </ol>"},{"location":"copilot/jenkins-pipelines/#example-placement-decision","title":"Example Placement Decision","text":"<pre><code># File: infra/kubernetes/prometheus/servicemonitor-jenkins.yaml\n# Rationale: Follows existing infra/kubernetes/&lt;service&gt;/ pattern\n# Related: infra/kubernetes/jenkins/deployment-jenkins.yaml\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#when-in-doubt","title":"When in Doubt","text":"<ul> <li>For infrastructure: Check <code>/infra/</code> first</li> <li>For docs: Check <code>/docs/</code> structure</li> <li>For templates: Use <code>/templates/</code></li> <li>For tests: Create in <code>/tests/e2e/</code> or <code>/tests/integration/</code></li> <li>Ask the user: \"Should this go in X or Y?\"</li> </ul>"},{"location":"copilot/jenkins-pipelines/#dora-capabilities-integration","title":"\ud83c\udf93 DORA Capabilities Integration","text":""},{"location":"copilot/jenkins-pipelines/#the-24-key-capabilities","title":"The 24 Key Capabilities","text":"<p>Every code change should map to one or more DORA capabilities:</p>"},{"location":"copilot/jenkins-pipelines/#technical-practices-14-capabilities","title":"Technical Practices (14 capabilities)","text":"<ol> <li>Version control - All code in Git, trunk-based development</li> <li>Continuous integration - Automated build/test on every commit</li> <li>Deployment automation - Push-button or automated deployment</li> <li>Trunk-based development - Short-lived branches (&lt;1 day)</li> <li>Test automation - Comprehensive automated test suite</li> <li>Test data management - Realistic test data provisioning</li> <li>Shift left on security - Security scanning in CI pipeline</li> <li>Continuous delivery - Code always in deployable state</li> <li>Loosely coupled architecture - Services independently deployable</li> <li>Empowered teams - Teams choose tools, make decisions</li> <li>Monitoring &amp; observability - Proactive system health tracking</li> <li>Proactive failure notification - Alerts before user impact</li> <li>Database change management - Automated schema migrations</li> <li>Code maintainability - Clean, documented, testable code</li> </ol>"},{"location":"copilot/jenkins-pipelines/#process-practices-6-capabilities","title":"Process Practices (6 capabilities)","text":"<ol> <li>Streamlined change approval - Peer review, not CAB</li> <li>Customer feedback - Short feedback loops</li> <li>Team experimentation - Safe to try new approaches</li> <li>Work in small batches - Small, frequent changes</li> <li>Visibility of work in value stream - Clear status tracking</li> <li>Work in process limits - Focus, avoid multitasking</li> </ol>"},{"location":"copilot/jenkins-pipelines/#cultural-practices-4-capabilities","title":"Cultural Practices (4 capabilities)","text":"<ol> <li>Generative organizational culture - Westrum model</li> <li>Learning culture - Blameless postmortems, knowledge sharing</li> <li>Job satisfaction - Autonomy, mastery, purpose</li> <li>Transformational leadership - Servant leadership</li> </ol>"},{"location":"copilot/jenkins-pipelines/#tagging-system","title":"Tagging System","text":"<p>Use these tags in code comments and tests:</p> <pre><code># @dora-capability: continuous_integration\n# @dora-metric: deployment_frequency, lead_time\n# @belt-level: white-belt\ndef automated_build_pipeline():\n    \"\"\"\n    Implements automated CI pipeline that triggers on every commit.\n\n    DORA Impact:\n    - Increases deployment frequency through automation\n    - Reduces lead time by catching issues early\n\n    Learning Objective: Students learn to create Jenkins pipelines\n    that integrate with GitHub webhooks.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#development-patterns","title":"\ud83d\ude80 Development Patterns","text":""},{"location":"copilot/jenkins-pipelines/#1-trunk-based-development","title":"1. Trunk-Based Development","text":"<p>ALWAYS follow these practices:</p> <pre><code># \u2705 Good: Short-lived feature branch\ngit checkout -b feature/add-metrics\n# Work for max 1 day\ngit commit -am \"Add DORA metrics collection\"\ngit push origin feature/add-metrics\n# Create PR, get review, merge same day\n\n# \u274c Bad: Long-lived branch\ngit checkout -b feature/refactor-entire-system\n# Work for weeks... NO!\n</code></pre> <p>Branch Rules: - Maximum 3 active branches in repository - Merge within 1 day of creation - Use feature flags for incomplete features - No code freeze periods</p>"},{"location":"copilot/jenkins-pipelines/#2-declarative-infrastructure","title":"2. Declarative Infrastructure","text":"<p>Always use declarative formats:</p> <pre><code># \u2705 Good: Declarative Kubernetes manifest\n# File: infra/kubernetes/backstage/deployment-backstage.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backstage\n  namespace: fawkes-platform\n  labels:\n    app: backstage\n    component: developer-portal\n    dora-capability: self-service\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: backstage\n  template:\n    metadata:\n      labels:\n        app: backstage\n        version: v1.20.0\n    spec:\n      containers:\n      - name: backstage\n        image: backstage/backstage:v1.20.0\n        ports:\n        - containerPort: 7007\n          name: http\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n        env:\n        - name: POSTGRES_HOST\n          valueFrom:\n            secretKeyRef:\n              name: backstage-postgres\n              key: host\n        livenessProbe:\n          httpGet:\n            path: /healthcheck\n            port: 7007\n          initialDelaySeconds: 60\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /healthcheck\n            port: 7007\n          initialDelaySeconds: 30\n          periodSeconds: 5\n</code></pre> <pre><code># \u274c Bad: Imperative approach (avoid this)\nimport subprocess\n\nsubprocess.run([\n    \"kubectl\", \"create\", \"deployment\", \"backstage\",\n    \"--image=backstage/backstage:v1.20.0\",\n    \"--replicas=2\"\n])\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#3-gitops-workflow-with-argocd","title":"3. GitOps Workflow with ArgoCD","text":"<p>All infrastructure changes through Git:</p> <pre><code># File: infra/kubernetes/argocd/application-backstage.yaml\n# ArgoCD Application for automated deployment\n\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: backstage\n  namespace: argocd\n  annotations:\n    dora-capability: continuous_delivery\n    notifications.argoproj.io/subscribe.on-deployed.mattermost: fawkes-deployments\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/paruff/fawkes.git\n    targetRevision: main\n    path: infra/kubernetes/backstage\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: fawkes-platform\n  syncPolicy:\n    automated:\n      prune: true      # Delete resources not in Git\n      selfHeal: true   # Revert manual changes\n      allowEmpty: false\n    syncOptions:\n    - CreateNamespace=true\n    retry:\n      limit: 5\n      backoff:\n        duration: 5s\n        factor: 2\n        maxDuration: 3m\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#4-progressive-delivery-with-argo-rollouts","title":"4. Progressive Delivery with Argo Rollouts","text":"<p>Use Argo Rollouts for canary and blue-green deployments (replaces Spinnaker):</p> <pre><code># File: infra/kubernetes/backstage/rollout-backstage.yaml\n# Progressive deployment strategy\n\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: backstage\n  namespace: fawkes-platform\n  annotations:\n    dora-capability: deployment_automation\nspec:\n  replicas: 3\n  strategy:\n    canary:\n      steps:\n      - setWeight: 20\n      - pause: {duration: 5m}\n      - setWeight: 40\n      - pause: {duration: 5m}\n      - setWeight: 60\n      - pause: {duration: 5m}\n      - setWeight: 80\n      - pause: {duration: 5m}\n      analysis:\n        templates:\n        - templateName: backstage-success-rate\n        startingStep: 2\n        args:\n        - name: service-name\n          value: backstage\n  selector:\n    matchLabels:\n      app: backstage\n  template:\n    metadata:\n      labels:\n        app: backstage\n    spec:\n      containers:\n      - name: backstage\n        image: backstage/backstage:v1.21.0  # New version\n        # ... rest of container spec\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#testing-strategy","title":"\ud83e\uddea Testing Strategy","text":""},{"location":"copilot/jenkins-pipelines/#bdd-test-structure","title":"BDD Test Structure","text":"<p>Create Gherkin feature files for all capabilities:</p> <pre><code># File: tests/e2e/features/continuous_integration.feature\n# @dora-capability: continuous_integration\n\n@dora-deployment-frequency @dora-lead-time\nFeature: Continuous Integration Pipeline\n  As a developer\n  I want automated build and test pipelines\n  So that I can quickly validate changes\n\n  Background:\n    Given a Jenkins instance is running at \"http://jenkins.fawkes-platform.svc\"\n    And the \"spring-boot-template\" exists in \"/templates/java-spring-boot\"\n    And GitHub webhooks are configured\n\n  @smoke @white-belt\n  Scenario: Commit triggers automatic build\n    Given I have cloned the \"demo-java-app\" repository\n    When I commit a change to the \"main\" branch\n    Then a Jenkins build starts within 30 seconds\n    And the build completes within 5 minutes\n    And the build status is reported to GitHub\n    And the commit shows a green checkmark\n    And DORA metrics record the deployment\n\n  @yellow-belt\n  Scenario: Pipeline includes security scanning\n    Given a Jenkins pipeline for \"demo-python-app\"\n    When the build stage completes successfully\n    Then the security scan stage executes\n    And Trivy scans the container image for vulnerabilities\n    And SonarQube analyzes the source code\n    And no HIGH or CRITICAL vulnerabilities are found\n    And a security report is archived\n\n  @green-belt @dora-change-failure-rate\n  Scenario: Failed builds notify team via Mattermost\n    Given a Jenkins pipeline for \"demo-node-app\"\n    When a build fails due to test failures\n    Then a Mattermost notification is sent within 60 seconds\n    And the notification includes the failure reason\n    And the notification links to the build logs\n    And the DORA metrics service records the failure\n</code></pre> <p>Step definitions with proper instrumentation:</p> <pre><code># File: tests/e2e/step_definitions/jenkins_steps.py\n\nfrom pytest_bdd import given, when, then, parsers\nfrom datetime import datetime, timedelta\nimport requests\nimport time\n\n@given(parsers.parse('a Jenkins instance is running at \"{url}\"'))\ndef jenkins_running(jenkins_client, url):\n    \"\"\"\n    Verify Jenkins is accessible and healthy.\n\n    @dora-capability: continuous_integration\n    \"\"\"\n    response = jenkins_client.get(f'{url}/api/json')\n    assert response.status_code == 200, f\"Jenkins not accessible at {url}\"\n    data = response.json()\n    assert data.get('mode') == 'NORMAL', \"Jenkins not in normal mode\"\n    assert data.get('numExecutors', 0) &gt; 0, \"No Jenkins executors available\"\n\n@when(parsers.parse('I commit a change to the \"{branch}\" branch'))\ndef commit_change(git_repo, branch, dora_metrics):\n    \"\"\"\n    Commit test change and record timestamp for lead time calculation.\n\n    @dora-metric: lead_time\n    \"\"\"\n    git_repo.checkout(branch)\n\n    # Make traceable change\n    commit_id = f\"test-{datetime.utcnow().isoformat()}\"\n    with open('README.md', 'a') as f:\n        f.write(f'\\n&lt;!-- Test commit {commit_id} --&gt;')\n\n    git_repo.index.add(['README.md'])\n    commit = git_repo.index.commit(f'Test commit {commit_id}')\n    git_repo.remote('origin').push(branch)\n\n    # Record commit time for DORA lead time metric\n    dora_metrics.record_commit(\n        commit_sha=commit.hexsha,\n        timestamp=datetime.utcnow(),\n        service=git_repo.name,\n        branch=branch\n    )\n\n@then(parsers.parse('a Jenkins build starts within {seconds:d} seconds'))\ndef build_starts(jenkins_client, git_repo, seconds, dora_metrics):\n    \"\"\"\n    Verify build triggered within SLA and update deployment frequency metric.\n\n    @dora-metric: deployment_frequency\n    \"\"\"\n    start_time = datetime.utcnow()\n    deadline = start_time + timedelta(seconds=seconds)\n\n    while datetime.utcnow() &lt; deadline:\n        builds = jenkins_client.get_builds(git_repo.name)\n        if builds and builds[0].timestamp &gt; dora_metrics.get_commit_time(git_repo.name):\n            # Build started - record for metrics\n            dora_metrics.record_build_start(\n                build_id=builds[0].id,\n                build_number=builds[0].number,\n                timestamp=builds[0].timestamp,\n                service=git_repo.name\n            )\n            return\n        time.sleep(2)\n\n    raise AssertionError(\n        f\"No build started within {seconds}s of commit to {git_repo.name}. \"\n        f\"This impacts deployment frequency SLA.\"\n    )\n\n@then('DORA metrics record the deployment')\ndef verify_dora_metrics(dora_metrics, git_repo):\n    \"\"\"\n    Verify DORA metrics service recorded all events.\n\n    @dora-capability: monitoring_and_observability\n    \"\"\"\n    # Verify metrics were recorded\n    metrics = dora_metrics.get_metrics(service=git_repo.name)\n\n    assert metrics.get('deployment_frequency') is not None, \\\n        \"Deployment frequency not recorded\"\n    assert metrics.get('lead_time') is not None, \\\n        \"Lead time not recorded\"\n\n    # Verify Prometheus metrics are accessible\n    prom_response = requests.get('http://prometheus.fawkes-platform.svc:9090/api/v1/query',\n                                 params={'query': f'deployments_total{{service=\"{git_repo.name}\"}}'})\n    assert prom_response.status_code == 200, \"Cannot query Prometheus metrics\"\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#test-organization","title":"Test Organization","text":"<pre><code># File: tests/e2e/conftest.py\n\nimport pytest\nfrom typing import Dict, List\n\ndef pytest_collection_modifyitems(config, items):\n    \"\"\"\n    Add belt level and DORA capability markers for tracking.\n\n    @dora-capability: learning_culture\n    \"\"\"\n    belt_order = ['white-belt', 'yellow-belt', 'green-belt',\n                  'brown-belt', 'black-belt']\n\n    for item in items:\n        # Extract belt level\n        belt_markers = [m.name for m in item.iter_markers()\n                       if m.name in belt_order]\n        if belt_markers:\n            item.add_marker(pytest.mark.belt_level(belt_markers[0]))\n\n        # Extract DORA metrics\n        dora_markers = [m.name for m in item.iter_markers()\n                       if m.name.startswith('dora-')]\n        for marker in dora_markers:\n            metric = marker.replace('dora-', '')\n            item.add_marker(pytest.mark.dora_metric(metric))\n\ndef pytest_terminal_summary(terminalreporter, exitstatus, config):\n    \"\"\"\n    Report results by belt level for dojo progression tracking.\n    \"\"\"\n    belt_results: Dict[str, List[str]] = {}\n\n    for report in terminalreporter.stats.get('passed', []):\n        belt_marker = report.keywords.get('belt_level')\n        if belt_marker:\n            belt = belt_marker[0].args[0]\n            belt_results.setdefault(belt, []).append(report.nodeid)\n\n    terminalreporter.write_sep('=', 'Dojo Progression Summary')\n    for belt in ['white-belt', 'yellow-belt', 'green-belt',\n                 'brown-belt', 'black-belt']:\n        scenarios = belt_results.get(belt, [])\n        status = '\u2705' if scenarios else '\u23f8\ufe0f'\n        terminalreporter.write_line(\n            f'  {status} {belt.upper()}: {len(scenarios)} scenarios passed'\n        )\n\n    # DORA metrics summary\n    dora_results: Dict[str, int] = {}\n    for report in terminalreporter.stats.get('passed', []):\n        dora_marker = report.keywords.get('dora_metric')\n        if dora_marker:\n            for metric in dora_marker:\n                metric_name = metric.args[0]\n                dora_results[metric_name] = dora_results.get(metric_name, 0) + 1\n\n    if dora_results:\n        terminalreporter.write_sep('=', 'DORA Metrics Coverage')\n        for metric, count in sorted(dora_results.items()):\n            terminalreporter.write_line(f'  \ud83d\udcca {metric}: {count} tests')\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#security-patterns","title":"\ud83d\udd12 Security Patterns","text":""},{"location":"copilot/jenkins-pipelines/#1-container-scanning-with-trivy","title":"1. Container Scanning with Trivy","text":"<p>Integrate Trivy in all Jenkins pipelines:</p> <pre><code>// File: templates/java-spring-boot/Jenkinsfile\n\n@Library('fawkes-shared-library') _\n\npipeline {\n  agent {\n    kubernetes {\n      yaml '''\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          labels:\n            jenkins: agent\n        spec:\n          serviceAccountName: jenkins\n          containers:\n          - name: maven\n            image: maven:3.9-eclipse-temurin-17\n            command: ['cat']\n            tty: true\n          - name: trivy\n            image: aquasec/trivy:latest\n            command: ['cat']\n            tty: true\n          - name: kaniko\n            image: gcr.io/kaniko-project/executor:latest\n            command: ['cat']\n            tty: true\n      '''\n    }\n  }\n\n  environment {\n    HARBOR_REGISTRY = 'harbor.fawkes-platform.svc'\n    HARBOR_PROJECT = 'fawkes'\n    IMAGE_NAME = \"${HARBOR_REGISTRY}/${HARBOR_PROJECT}/${env.JOB_NAME}\"\n    IMAGE_TAG = \"${env.GIT_COMMIT.take(8)}\"\n    HARBOR_CREDS = credentials('harbor-robot-account')\n  }\n\n  stages {\n    stage('Build') {\n      steps {\n        container('maven') {\n          sh '''\n            mvn clean package -DskipTests=false\n            mvn test\n          '''\n        }\n      }\n    }\n\n    stage('Code Quality') {\n      steps {\n        container('maven') {\n          withSonarQubeEnv('SonarQube') {\n            sh 'mvn sonar:sonar'\n          }\n        }\n      }\n    }\n\n    stage('Build Container') {\n      steps {\n        container('kaniko') {\n          sh '''\n            /kaniko/executor \\\n              --dockerfile=Dockerfile \\\n              --context=dir://$(pwd) \\\n              --destination=${IMAGE_NAME}:${IMAGE_TAG} \\\n              --destination=${IMAGE_NAME}:latest \\\n              --skip-tls-verify\n          '''\n        }\n      }\n    }\n\n    stage('Security Scan') {\n      steps {\n        container('trivy') {\n          sh '''\n            trivy image \\\n              --severity HIGH,CRITICAL \\\n              --exit-code 1 \\\n              --no-progress \\\n              --format json \\\n              --output trivy-report.json \\\n              --insecure \\\n              ${IMAGE_NAME}:${IMAGE_TAG}\n          '''\n        }\n      }\n      post {\n        always {\n          archiveArtifacts artifacts: 'trivy-report.json', allowEmptyArchive: true\n\n          // Send scan results to DORA metrics service\n          sh '''\n            curl -X POST http://dora-metrics.fawkes-platform.svc:8080/api/v1/security-scan \\\n              -H \"Content-Type: application/json\" \\\n              -d @trivy-report.json || true\n          '''\n        }\n        failure {\n          mattermostSend(\n            endpoint: 'http://mattermost.fawkes-platform.svc:8065/hooks/...',\n            color: 'danger',\n            message: \"\"\"\n              \ud83d\udea8 **Security Vulnerabilities Found**\n\n              **Service:** ${IMAGE_NAME}:${IMAGE_TAG}\n              **Build:** ${env.BUILD_URL}\n              **Action Required:** Fix HIGH/CRITICAL vulnerabilities before deployment\n\n              See attached trivy-report.json for details.\n            \"\"\"\n          )\n        }\n      }\n    }\n\n    stage('Deploy to Dev') {\n      when {\n        branch 'main'\n        expression { currentBuild.result != 'FAILURE' }\n      }\n      steps {\n        script {\n          // Update ArgoCD application manifest\n          sh '''\n            git clone https://github.com/paruff/fawkes.git fawkes-gitops\n            cd fawkes-gitops/infra/kubernetes/${JOB_NAME}\n\n            # Update image tag in deployment\n            sed -i \"s|image:.*|image: ${IMAGE_NAME}:${IMAGE_TAG}|g\" deployment.yaml\n\n            git config user.email \"jenkins@fawkes-platform\"\n            git config user.name \"Fawkes Jenkins\"\n            git add deployment.yaml\n            git commit -m \"Update ${JOB_NAME} to ${IMAGE_TAG}\"\n            git push origin main\n          '''\n\n          // Record deployment for DORA metrics\n          sh '''\n            curl -X POST http://dora-metrics.fawkes-platform.svc:8080/api/v1/deployments \\\n              -H \"Content-Type: application/json\" \\\n              -d '{\n                \"service\": \"'${JOB_NAME}'\",\n                \"version\": \"'${IMAGE_TAG}'\",\n                \"environment\": \"dev\",\n                \"commit_sha\": \"'${GIT_COMMIT}'\",\n                \"commit_timestamp\": \"'$(git show -s --format=%cI ${GIT_COMMIT})'\",\n                \"deployment_timestamp\": \"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'\",\n                \"status\": \"success\"\n              }'\n          '''\n        }\n      }\n      post {\n        success {\n          mattermostSend(\n            color: 'good',\n            message: \"\"\"\n              \u2705 **Deployment Successful**\n\n              **Service:** ${JOB_NAME}\n              **Version:** ${IMAGE_TAG}\n              **Environment:** dev\n              **Build:** ${env.BUILD_URL}\n            \"\"\"\n          )\n        }\n      }\n    }\n  }\n\n  post {\n    always {\n      // Cleanup workspace\n      cleanWs()\n    }\n  }\n}\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#2-policy-enforcement-with-kyverno","title":"2. Policy Enforcement with Kyverno","text":"<p>Use Kyverno for policy-as-code (simpler than OPA for MVP):</p> <pre><code># File: infra/kubernetes/kyverno/require-resource-limits.yaml\n\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-resource-limits\n  annotations:\n    policies.kyverno.io/title: Require Resource Limits\n    policies.kyverno.io/category: Best Practices\n    policies.kyverno.io/severity: medium\n    policies.kyverno.io/description: &gt;-\n      All containers must have CPU and memory limits to prevent resource exhaustion.\n      This is a DORA best practice for system reliability and security.\n    dora-capability: monitoring_and_observability\nspec:\n  validationFailureAction: enforce\n  background: true\n  rules:\n  - name: validate-resources\n    match:\n      any:\n      - resources:\n          kinds:\n          - Deployment\n          - StatefulSet\n          - DaemonSet\n          namespaces:\n          - fawkes-*\n    validate:\n      message: &gt;-\n        All containers must have CPU and memory limits defined.\n        This ensures predictable resource usage and prevents noisy neighbor issues.\n\n        Example:\n          resources:\n            limits:\n              memory: \"512Mi\"\n              cpu: \"500m\"\n            requests:\n              memory: \"256Mi\"\n              cpu: \"100m\"\n      pattern:\n        spec:\n          template:\n            spec:\n              containers:\n              - resources:\n                  limits:\n                    memory: \"?*\"\n                    cpu: \"?*\"\n                  requests:\n                    memory: \"?*\"\n                    cpu: \"?*\"\n</code></pre> <pre><code># File: infra/kubernetes/kyverno/disallow-latest-tag.yaml\n\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: disallow-latest-tag\n  annotations:\n    policies.kyverno.io/title: Disallow Latest Tag\n    policies.kyverno.io/category: Best Practices\n    policies.kyverno.io/severity: high\n    policies.kyverno.io/description: &gt;-\n      Container images must use specific version tags, not 'latest'.\n      Using 'latest' tag makes deployments non-deterministic and harder to rollback.\n    dora-capability: continuous_delivery\nspec:\n  validationFailureAction: enforce\n  background: true\n  rules:\n  - name: require-image-tag\n    match:\n      any:\n      - resources:\n          kinds:\n          - Deployment\n          - StatefulSet\n          - DaemonSet\n    validate:\n      message: &gt;-\n        Container images must not use 'latest' tag.\n        Use a specific version tag like 'v1.2.3' or git commit SHA.\n      pattern:\n        spec:\n          template:\n            spec:\n              containers:\n              - image: \"!*:latest\"\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#3-secrets-management-with-external-secrets-operator","title":"3. Secrets Management with External Secrets Operator","text":"<p>Never hardcode secrets - use External Secrets Operator with AWS Secrets Manager:</p> <pre><code># File: infra/kubernetes/external-secrets/clustersecretstore-aws.yaml\n\napiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: aws-secretsmanager\n  annotations:\n    dora-capability: shift_left_on_security\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      region: us-east-1\n      auth:\n        jwt:\n          serviceAccountRef:\n            name: external-secrets-sa\n            namespace: external-secrets-system\n</code></pre> <pre><code># File: infra/kubernetes/backstage/externalsecret-postgres.yaml\n\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: backstage-postgres-credentials\n  namespace: fawkes-platform\n  annotations:\n    dora-capability: shift_left_on_security\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: aws-secretsmanager\n    kind: ClusterSecretStore\n  target:\n    name: backstage-postgres\n    creationPolicy: Owner\n    template:\n      engineVersion: v2\n      data:\n        # Template for connection string\n        DATABASE_URL: \"postgresql://{{ .username }}:{{ .password }}@{{ .host }}:5432/backstage\"\n        POSTGRES_USER: \"{{ .username }}\"\n        POSTGRES_PASSWORD: \"{{ .password }}\"\n        POSTGRES_HOST: \"{{ .host }}\"\n  data:\n  - secretKey: username\n    remoteRef:\n      key: fawkes/backstage/postgres\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: fawkes/backstage/postgres\n      property: password\n  - secretKey: host\n    remoteRef:\n      key: fawkes/backstage/postgres\n      property: host\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#dora-metrics-implementation","title":"\ud83d\udcca DORA Metrics Implementation","text":""},{"location":"copilot/jenkins-pipelines/#metrics-collection-service","title":"Metrics Collection Service","text":"<p>Create a lightweight FastAPI service for collecting DORA metrics:</p> <pre><code># File: scripts/dora-metrics/main.py\n# Note: This may eventually move to a dedicated service directory\n\nfrom fastapi import FastAPI, HTTPException, BackgroundTasks\nfrom pydantic import BaseModel, Field\nfrom datetime import datetime\nfrom typing import Literal, Optional\nimport prometheus_client\nfrom prometheus_client import Counter, Histogram, Gauge, generate_latest\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\napp = FastAPI(\n    title=\"Fawkes DORA Metrics Collector\",\n    description=\"Automated collection of the Four Key DORA metrics\",\n    version=\"1.0.0\"\n)\n\n# Prometheus metrics\ndeployment_counter = Counter(\n    'fawkes_deployments_total',\n    'Total number of deployments',\n    ['service', 'environment', 'version', 'status']\n)\n\nlead_time_histogram = Histogram(\n    'fawkes_lead_time_seconds',\n    'Lead time from commit to deployment (seconds)',\n    ['service', 'environment'],\n    buckets=[60, 300, 900, 1800, 3600, 7200, 14400, 28800, 86400]  # 1m to 1d\n)\n\nfailure_counter = Counter(\n    'fawkes_change_failures_total',\n    'Total number of failed changes',\n    ['service', 'environment', 'failure_type']\n)\n\nmttr_histogram = Histogram(\n    'fawkes_mttr_seconds',\n    'Mean time to restore service (seconds)',\n    ['service', 'environment', 'incident_type'],\n    buckets=[300, 900, 1800, 3600, 7200, 14400, 28800, 86400]  # 5m to 1d\n)\n\nactive_incidents = Gauge(\n    'fawkes_active_incidents',\n    'Number of currently active incidents',\n    ['service', 'environment']\n)\n\n# Pydantic models\nclass DeploymentEvent(BaseModel):\n    service: str = Field(..., description=\"Service name\")\n    version: str = Field(..., description=\"Version or git commit SHA\")\n    environment: Literal['dev', 'staging', 'production'] = Field(..., description=\"Target environment\")\n    commit_sha: str = Field(..., description=\"Git commit SHA\")\n    commit_timestamp: datetime = Field(..., description=\"When the commit was created\")\n    deployment_timestamp: datetime = Field(default_factory=datetime.utcnow, description=\"When deployment occurred\")\n    status: Literal['success', 'failure'] = Field(..., description=\"Deployment outcome\")\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"service\": \"demo-java-app\",\n                \"version\": \"v1.2.3\",\n                \"environment\": \"production\",\n                \"commit_sha\": \"abc123def456\",\n                \"commit_timestamp\": \"2025-10-25T10:00:00Z\",\n                \"deployment_timestamp\": \"2025-10-25T10:15:00Z\",\n                \"status\": \"success\"\n            }\n        }\n\nclass IncidentEvent(BaseModel):\n    service: str = Field(..., description=\"Affected service name\")\n    environment: Literal['dev', 'staging', 'production'] = Field(..., description=\"Affected environment\")\n    incident_type: str = Field(..., description=\"Type of incident (e.g., 'outage', 'degradation')\")\n    severity: Literal['low', 'medium', 'high', 'critical'] = Field(..., description=\"Incident severity\")\n    started_at: datetime = Field(..., description=\"When incident started\")\n    resolved_at: Optional[datetime] = Field(None, description=\"When incident was resolved\")\n    caused_by_deployment: Optional[str] = Field(None, description=\"Git commit SHA if caused by deployment\")\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"service\": \"demo-java-app\",\n                \"environment\": \"production\",\n                \"incident_type\": \"outage\",\n                \"severity\": \"high\",\n                \"started_at\": \"2025-10-25T11:00:00Z\",\n                \"resolved_at\": \"2025-10-25T11:30:00Z\",\n                \"caused_by_deployment\": \"abc123def456\"\n            }\n        }\n\nclass SecurityScanResult(BaseModel):\n    service: str\n    version: str\n    scanner: Literal['trivy', 'sonarqube', 'snyk']\n    high_vulnerabilities: int\n    critical_vulnerabilities: int\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n\n# API Endpoints\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Health check endpoint\"\"\"\n    return {\n        \"service\": \"Fawkes DORA Metrics Collector\",\n        \"status\": \"healthy\",\n        \"version\": \"1.0.0\"\n    }\n\n@app.post(\"/api/v1/deployments\", status_code=201)\nasync def record_deployment(event: DeploymentEvent):\n    \"\"\"\n    Record a deployment event for DORA metrics calculation.\n\n    Tracks:\n    - Deployment frequency (deployments per day)\n    - Lead time for changes (commit to deploy time)\n    - Change failure rate (if status is failure)\n    \"\"\"\n    try:\n        # Increment deployment counter\n        deployment_counter.labels(\n            service=event.service,\n            environment=event.environment,\n            version=event.version,\n            status=event.status\n        ).inc()\n\n        # Calculate and record lead time\n        lead_time = (event.deployment_timestamp - event.commit_timestamp).total_seconds()\n        lead_time_histogram.labels(\n            service=event.service,\n            environment=event.environment\n        ).observe(lead_time)\n\n        # Record failure if applicable\n        if event.status == 'failure':\n            failure_counter.labels(\n                service=event.service,\n                environment=event.environment,\n                failure_type='deployment_failure'\n            ).inc()\n\n            logger.warning(\n                f\"Deployment failure recorded: {event.service} v{event.version} to {event.environment}\"\n            )\n        else:\n            logger.info(\n                f\"Deployment success recorded: {event.service} v{event.version} to {event.environment}\"\n            )\n\n        return {\n            \"status\": \"recorded\",\n            \"service\": event.service,\n            \"metrics\": {\n                \"deployment_frequency\": \"updated\",\n                \"lead_time_seconds\": round(lead_time, 2),\n                \"change_failure_rate\": \"updated\" if event.status == 'failure' else \"n/a\"\n            }\n        }\n    except Exception as e:\n        logger.error(f\"Error recording deployment: {str(e)}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/incidents\", status_code=201)\nasync def record_incident(event: IncidentEvent):\n    \"\"\"\n    Record an incident for MTTR calculation.\n\n    If caused by deployment, also increments change failure rate.\n    If incident is ongoing (no resolved_at), updates active incidents gauge.\n    \"\"\"\n    try:\n        if event.resolved_at:\n            # Calculate MTTR\n            mttr = (event.resolved_at - event.started_at).total_seconds()\n            mttr_histogram.labels(\n                service=event.service,\n                environment=event.environment,\n                incident_type=event.incident_type\n            ).observe(mttr)\n\n            # Decrement active incidents\n            active_incidents.labels(\n                service=event.service,\n                environment=event.environment\n            ).dec()\n\n            # If caused by deployment, count as change failure\n            if event.caused_by_deployment:\n                failure_counter.labels(\n                    service=event.service,\n                    environment=event.environment,\n                    failure_type='incident_from_deployment'\n                ).inc()\n\n            logger.info(\n                f\"Incident resolved: {event.service} in {event.environment} \"\n                f\"after {round(mttr/60, 2)} minutes\"\n            )\n\n            return {\n                \"status\": \"resolved\",\n                \"service\": event.service,\n                \"mttr_seconds\": round(mttr, 2),\n                \"mttr_minutes\": round(mttr / 60, 2)\n            }\n        else:\n            # Incident started but not resolved\n            active_incidents.labels(\n                service=event.service,\n                environment=event.environment\n            ).inc()\n\n            logger.warning(\n                f\"Incident started: {event.service} in {event.environment} \"\n                f\"(severity: {event.severity})\"\n            )\n\n            return {\n                \"status\": \"incident_started\",\n                \"service\": event.service,\n                \"message\": \"Call again with resolved_at to calculate MTTR\"\n            }\n    except Exception as e:\n        logger.error(f\"Error recording incident: {str(e)}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/security-scan\", status_code=201)\nasync def record_security_scan(scan: SecurityScanResult):\n    \"\"\"\n    Record security scan results for tracking vulnerability trends.\n    \"\"\"\n    logger.info(\n        f\"Security scan recorded: {scan.service} v{scan.version} - \"\n        f\"Critical: {scan.critical_vulnerabilities}, High: {scan.high_vulnerabilities}\"\n    )\n\n    return {\n        \"status\": \"recorded\",\n        \"service\": scan.service,\n        \"version\": scan.version\n    }\n\n@app.get(\"/metrics\")\nasync def metrics():\n    \"\"\"Prometheus metrics endpoint for scraping\"\"\"\n    return Response(\n        content=generate_latest(),\n        media_type=\"text/plain\"\n    )\n\n@app.get(\"/health\")\nasync def health():\n    \"\"\"Health check for Kubernetes probes\"\"\"\n    return {\"status\": \"healthy\"}\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\n        app,\n        host=\"0.0.0.0\",\n        port=8080,\n        log_level=\"info\"\n    )\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#deployment-for-dora-metrics-service","title":"Deployment for DORA Metrics Service","text":"<pre><code># File: infra/kubernetes/dora-metrics/deployment-dora-metrics.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dora-metrics\n  namespace: fawkes-platform\n  labels:\n    app: dora-metrics\n    component: observability\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dora-metrics\n  template:\n    metadata:\n      labels:\n        app: dora-metrics\n    spec:\n      containers:\n      - name: dora-metrics\n        image: python:3.11-slim\n        workingDir: /app\n        command:\n        - python\n        - main.py\n        ports:\n        - containerPort: 8080\n          name: http\n        resources:\n          requests:\n            memory: \"128Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"256Mi\"\n            cpu: \"200m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: app-code\n          mountPath: /app\n      volumes:\n      - name: app-code\n        configMap:\n          name: dora-metrics-code\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dora-metrics\n  namespace: fawkes-platform\n  labels:\n    app: dora-metrics\nspec:\n  selector:\n    app: dora-metrics\n  ports:\n  - name: http\n    port: 8080\n    targetPort: 8080\n---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: dora-metrics\n  namespace: fawkes-platform\n  labels:\n    app: dora-metrics\nspec:\n  selector:\n    matchLabels:\n      app: dora-metrics\n  endpoints:\n  - port: http\n    path: /metrics\n    interval: 30s\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#grafana-dashboard-for-dora-metrics","title":"Grafana Dashboard for DORA Metrics","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Fawkes DORA Metrics\",\n    \"tags\": [\"dora\", \"platform-metrics\", \"fawkes\"],\n    \"timezone\": \"utc\",\n    \"panels\": [\n      {\n        \"id\": 1,\n        \"title\": \"Deployment Frequency\",\n        \"type\": \"graph\",\n        \"gridPos\": {\"x\": 0, \"y\": 0, \"w\": 12, \"h\": 8},\n        \"datasource\": \"Prometheus\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(rate(fawkes_deployments_total{status=\\\"success\\\"}[1d])) by (service)\",\n            \"legendFormat\": \"{{service}}\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"deployments/day\"\n          }\n        },\n        \"thresholds\": [\n          {\"value\": 1, \"color\": \"green\"},\n          {\"value\": 0.14, \"color\": \"yellow\"},\n          {\"value\": 0.03, \"color\": \"red\"}\n        ],\n        \"description\": \"Deployments per day. Elite: &gt;1/day, High: weekly, Medium: monthly, Low: &lt;monthly\"\n      },\n      {\n        \"id\": 2,\n        \"title\": \"Lead Time for Changes\",\n        \"type\": \"graph\",\n        \"gridPos\": {\"x\": 12, \"y\": 0, \"w\": 12, \"h\": 8},\n        \"datasource\": \"Prometheus\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.5, rate(fawkes_lead_time_seconds_bucket[1h]))\",\n            \"legendFormat\": \"P50 - {{service}}\",\n            \"refId\": \"A\"\n          },\n          {\n            \"expr\": \"histogram_quantile(0.95, rate(fawkes_lead_time_seconds_bucket[1h]))\",\n            \"legendFormat\": \"P95 - {{service}}\",\n            \"refId\": \"B\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"hours\"\n          }\n        },\n        \"thresholds\": [\n          {\"value\": 3600, \"color\": \"green\"},\n          {\"value\": 86400, \"color\": \"yellow\"},\n          {\"value\": 604800, \"color\": \"red\"}\n        ],\n        \"description\": \"Time from commit to production. Elite: &lt;1 hour, High: &lt;1 day, Medium: &lt;1 week, Low: &gt;1 month\"\n      },\n      {\n        \"id\": 3,\n        \"title\": \"Change Failure Rate\",\n        \"type\": \"gauge\",\n        \"gridPos\": {\"x\": 0, \"y\": 8, \"w\": 12, \"h\": 8},\n        \"datasource\": \"Prometheus\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(rate(fawkes_change_failures_total[7d])) / sum(rate(fawkes_deployments_total[7d])) * 100\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"min\": 0,\n            \"max\": 100,\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"value\": 0, \"color\": \"green\"},\n                {\"value\": 15, \"color\": \"yellow\"},\n                {\"value\": 30, \"color\": \"red\"}\n              ]\n            }\n          }\n        },\n        \"description\": \"% of deployments causing failures. Elite: &lt;15%, High: &lt;30%, Medium: &lt;45%, Low: &gt;45%\"\n      },\n      {\n        \"id\": 4,\n        \"title\": \"Mean Time to Restore (MTTR)\",\n        \"type\": \"graph\",\n        \"gridPos\": {\"x\": 12, \"y\": 8, \"w\": 12, \"h\": 8},\n        \"datasource\": \"Prometheus\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.5, rate(fawkes_mttr_seconds_bucket[7d]))\",\n            \"legendFormat\": \"P50 MTTR\",\n            \"refId\": \"A\"\n          },\n          {\n            \"expr\": \"histogram_quantile(0.95, rate(fawkes_mttr_seconds_bucket[7d]))\",\n            \"legendFormat\": \"P95 MTTR\",\n            \"refId\": \"B\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"hours\"\n          }\n        },\n        \"thresholds\": [\n          {\"value\": 3600, \"color\": \"green\"},\n          {\"value\": 86400, \"color\": \"yellow\"},\n          {\"value\": 604800, \"color\": \"red\"}\n        ],\n        \"description\": \"Time to restore service after incident. Elite: &lt;1 hour, High: &lt;1 day, Medium: &lt;1 week, Low: &gt;1 week\"\n      },\n      {\n        \"id\": 5,\n        \"title\": \"Active Incidents\",\n        \"type\": \"stat\",\n        \"gridPos\": {\"x\": 0, \"y\": 16, \"w\": 6, \"h\": 4},\n        \"datasource\": \"Prometheus\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(fawkes_active_incidents)\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"incidents\",\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"value\": 0, \"color\": \"green\"},\n                {\"value\": 1, \"color\": \"yellow\"},\n                {\"value\": 3, \"color\": \"red\"}\n              ]\n            }\n          }\n        }\n      },\n      {\n        \"id\": 6,\n        \"title\": \"Deployments Today\",\n        \"type\": \"stat\",\n        \"gridPos\": {\"x\": 6, \"y\": 16, \"w\": 6, \"h\": 4},\n        \"datasource\": \"Prometheus\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(increase(fawkes_deployments_total{status=\\\"success\\\"}[24h]))\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"deployments\"\n          }\n        }\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#dojo-learning-integration","title":"\ud83c\udf93 Dojo Learning Integration","text":""},{"location":"copilot/jenkins-pipelines/#creating-dojo-module-content","title":"Creating Dojo Module Content","text":"<p>When generating dojo learning modules, follow this structure:</p> <pre><code># File: docs/dojo/white-belt/module-01-what-is-idp.md\n\n# Module 1: Internal Delivery Platforms - What and Why\n\n**Belt Level**: \ud83e\udd4b White Belt\n**Duration**: 60 minutes\n**Prerequisites**: Basic understanding of software development, Git, command line\n**Learning Path**: Module 1 of 20 (White Belt: Modules 1-4)\n\n---\n\n## \ud83d\udccb Module Overview\n\nWelcome to the Fawkes Dojo! This is your first step toward becoming a platform engineer.\n\n### Learning Objectives\n\nBy completing this module, you will be able to:\n\n1. **Define** what an Internal Delivery Platform (IDP) is\n2. **Explain** the difference between traditional infrastructure and platform engineering\n3. **Identify** key components of Fawkes platform\n4. **Describe** the business value and ROI of platform engineering\n5. **Deploy** your first application using Fawkes (hands-on lab)\n\n### Why This Matters\n\nPlatform engineering is one of the fastest-growing disciplines in technology.\nOrganizations with mature platforms:\n- Deploy **10x more frequently**\n- Have **50% lower change failure rates**\n- Recover from incidents **2x faster**\n- Save **30-40% in infrastructure costs**\n\n### DORA Capabilities Covered\n\nThis module teaches:\n- \u2705 **Version control** - Understanding Git-based workflows\n- \u2705 **Deployment automation** - Self-service deployment\n- \u2705 **Loosely coupled architecture** - Microservices patterns\n\n---\n\n## \ud83d\udcda Section 1: What is an Internal Delivery Platform?\n\n### The Problem: Developer Cognitive Load\n\nImagine a developer starting a new microservice. Without a platform, they must:\n\n1. Provision infrastructure (AWS console, navigation hell)\n2. Set up CI/CD (write Jenkinsfile from scratch)\n3. Configure observability (Prometheus, Grafana, dashboards)\n4. Implement security (scanning tools, secrets management)\n5. Set up deployment (Kubernetes manifests, Helm charts)\n6. Configure networking (ingress, service mesh, DNS)\n7. Manage databases (provision, backup, migrations)\n8. Document everything (runbooks, architecture diagrams)\n\n**Result**: 2-4 weeks before writing application code. High error rate. Inconsistent implementations.\n\n### The Solution: Platform Engineering\n\n**Platform Engineering** treats infrastructure and tooling as a product for internal customers (developers).\n\n**Fawkes Platform** provides:\n- **Self-service capabilities** - Deploy via Backstage portal\n- **Golden paths** - Pre-configured, opinionated workflows\n- **Automation** - CI/CD, deployment, monitoring automated\n- **Standards** - Consistent security, observability, best practices\n- **Developer experience** - Simple, fast, delightful interface\n\n**Result**: Deploy new service in &lt;1 hour. Consistent quality. Developers focus on business logic.\n\n---\n\n## \ud83d\udee0\ufe0f Hands-On Lab: Deploy Your First Application\n\n### Lab Objectives\n\n- Use Backstage to create a new service from a template\n- Trigger an automated build in Jenkins\n- Deploy to development environment via ArgoCD\n- View DORA metrics for your deployment\n\n### Prerequisites\n\n- Access to Fawkes platform (provided by instructor)\n- GitHub account\n- Basic familiarity with command line\n\n### Step 1: Access Backstage\n\n1. Navigate to `https://backstage.fawkes-platform.local`\n2. Log in with your GitHub account\n3. You should see the Fawkes developer portal home page\n\n### Step 2: Create Service from Template\n\n1. Click \"Create\" in the left sidebar\n2. Select \"Java Spring Boot Microservice\" template\n3. Fill in the form:\n   - **Service Name**: `my-first-service`\n   - **Description**: \"Learning platform engineering with Fawkes\"\n   - **Owner**: (your name/team)\n4. Click \"Create\"\n5. Backstage will:\n   - Create GitHub repository\n   - Scaffold application code\n   - Configure Jenkins pipeline\n   - Set up ArgoCD application\n\n### Step 3: Observe the Build\n\n1. Click on \"View in Jenkins\" link\n2. Watch the pipeline execute:\n   - \u2705 Checkout code\n   - \u2705 Build with Maven\n   - \u2705 Run tests\n   - \u2705 Security scan (SonarQube, Trivy)\n   - \u2705 Build container image\n   - \u2705 Push to Harbor registry\n\n### Step 4: Monitor Deployment\n\n1. Click on \"View in ArgoCD\" link\n2. Watch ArgoCD sync your application:\n   - \u2705 Detects new image in registry\n   - \u2705 Updates Kubernetes manifests\n   - \u2705 Deploys to `dev` namespace\n   - \u2705 Runs health checks\n\n### Step 5: View DORA Metrics\n\n1. Navigate to Grafana dashboard: `https://grafana.fawkes-platform.local`\n2. Open \"DORA Metrics\" dashboard\n3. Find your service in the metrics:\n   - **Deployment Frequency**: 1 deployment recorded\n   - **Lead Time**: Time from template creation to deployment\n   - **Change Failure Rate**: 0% (successful deployment)\n\n### Step 6: Access Your Application\n\n1. Get the application URL from ArgoCD\n2. Visit `https://my-first-service.dev.fawkes-platform.local`\n3. You should see the Spring Boot welcome page!\n\n### Lab Complete! \ud83c\udf89\n\nCongratulations! You've:\n- \u2705 Created a service using a golden path template\n- \u2705 Triggered an automated CI/CD pipeline\n- \u2705 Deployed to Kubernetes via GitOps\n- \u2705 Generated DORA metrics automatically\n\n**Time to deployment:** ~10 minutes (vs. 2-4 weeks manually)\n\n---\n\n## \ud83d\udcca Assessment\n\nTest your knowledge:\n\n1. What is an Internal Delivery Platform?\n2. Name three components of the Fawkes platform\n3. What are the Four Key DORA metrics?\n4. How does a platform reduce cognitive load for developers?\n\n[Take the Module 1 Quiz \u2192](/docs/dojo/white-belt/quiz-01.md)\n\n---\n\n## \ud83c\udfaf Next Steps\n\n**Continue Learning:**\n- [Module 2: CI/CD Fundamentals](/docs/dojo/white-belt/module-02-cicd-fundamentals.md)\n- [Module 3: GitOps with ArgoCD](/docs/dojo/white-belt/module-03-gitops.md)\n\n**Practice More:**\n- Create a Python service using the FastAPI template\n- Explore the Backstage service catalog\n- Review the generated Jenkins pipeline code\n\n**Get Help:**\n- Join `#dojo-white-belt` channel in Mattermost\n- Ask questions in office hours (Wednesdays 2pm ET)\n- Review the troubleshooting guide\n\n---\n\n## \ud83d\udcda Additional Resources\n\n- [Team Topologies Book](https://teamtopologies.com/) - Platform team patterns\n- [Backstage Documentation](https://backstage.io/docs) - Developer portal\n- [DORA Research](https://dora.dev/) - Four Key Metrics research\n- [Fawkes Architecture](/docs/architecture.md) - Platform design\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#code-review-guidelines","title":"\ud83d\udd0d Code Review Guidelines","text":"<p>When reviewing generated code or suggesting improvements, check for:</p>"},{"location":"copilot/jenkins-pipelines/#platform-engineering-principles","title":"Platform Engineering Principles","text":"<ul> <li>[ ] Self-service enabled - Can developers use without platform team help?</li> <li>[ ] Opinionated defaults - Does it follow the golden path?</li> <li>[ ] Fail-fast validation - Are errors caught early with clear messages?</li> <li>[ ] Observable by default - Are metrics, logs, traces included?</li> <li>[ ] Secure by default - Are security best practices enforced?</li> </ul>"},{"location":"copilot/jenkins-pipelines/#dora-capabilities-checklist","title":"DORA Capabilities Checklist","text":"<ul> <li>[ ] Continuous Integration - Automated build/test on every commit?</li> <li>[ ] Deployment Automation - One-click or automated deployment?</li> <li>[ ] Trunk-Based Development - Short-lived branches (&lt;1 day)?</li> <li>[ ] Shift Left Security - Scanning in CI pipeline?</li> <li>[ ] Monitoring &amp; Observability - Metrics/logs/traces exported?</li> </ul>"},{"location":"copilot/jenkins-pipelines/#code-quality-standards","title":"Code Quality Standards","text":"<ul> <li>[ ] DRY (Don't Repeat Yourself) - Use templates/modules</li> <li>[ ] SOLID Principles - Single responsibility, open/closed, etc.</li> <li>[ ] 12-Factor App - Configuration via environment, stateless, etc.</li> <li>[ ] Error Handling - Graceful degradation, clear error messages</li> <li>[ ] Documentation - Inline comments for complex logic, README updates</li> </ul>"},{"location":"copilot/jenkins-pipelines/#fawkes-specific-checks","title":"Fawkes-Specific Checks","text":"<ul> <li>[ ] Correct file location - Follows repository structure?</li> <li>[ ] Naming conventions - Matches existing patterns?</li> <li>[ ] No Spinnaker references - Uses ArgoCD/Argo Rollouts instead</li> <li>[ ] No fawkes.io domain - Project is open source, not commercial</li> <li>[ ] AWS first - Multi-cloud is future, AWS is MVP focus</li> <li>[ ] Mattermost integration - Notifications go to Mattermost, not Slack</li> </ul>"},{"location":"copilot/jenkins-pipelines/#things-to-avoid","title":"\ud83d\udeab Things to AVOID","text":""},{"location":"copilot/jenkins-pipelines/#removed-from-mvp-do-not-generate","title":"Removed from MVP (Do NOT Generate)","text":"<ul> <li>\u274c Spinnaker - Use ArgoCD + Argo Rollouts for progressive delivery</li> <li>\u274c Eclipse Che - Use local workspace automation (infra/workspace/)</li> <li>\u274c fawkes.io domain - No commercial domain, use fawkes-platform.local</li> <li>\u274c Crossplane (yet) - Use Terraform for AWS, Crossplane post-MVP</li> <li>\u274c Service Mesh (yet) - Basic Kubernetes networking for MVP</li> <li>\u274c Multi-cloud (yet) - AWS first, Azure/GCP later</li> </ul>"},{"location":"copilot/jenkins-pipelines/#anti-patterns-to-avoid","title":"Anti-Patterns to Avoid","text":"<ul> <li>\u274c Hardcoded secrets in manifests</li> <li>\u274c Using <code>:latest</code> image tags</li> <li>\u274c No resource limits on containers</li> <li>\u274c Imperative infrastructure commands</li> <li>\u274c Long-lived feature branches</li> <li>\u274c Manual deployment steps</li> <li>\u274c No observability instrumentation</li> <li>\u274c Copying code instead of using shared libraries</li> </ul>"},{"location":"copilot/jenkins-pipelines/#pro-tips-for-using-copilot","title":"\ud83d\udca1 Pro Tips for Using Copilot","text":""},{"location":"copilot/jenkins-pipelines/#when-planning","title":"When Planning","text":"<ol> <li>Start with the why - \"I need X because of DORA capability Y\"</li> <li>Reference ADRs - \"As decided in ADR-003, we use ArgoCD\"</li> <li>Check existing code - \"Look at templates/java-spring-boot for patterns\"</li> <li>Ask for alternatives - \"What are 3 ways to implement this?\"</li> </ol>"},{"location":"copilot/jenkins-pipelines/#when-implementing","title":"When Implementing","text":"<ol> <li>Be specific about location - \"Create in infra/kubernetes/jenkins/\"</li> <li>Request complete solutions - \"Include manifest, service, and ingress\"</li> <li>Ask for tests - \"Also create BDD test in tests/e2e/features/\"</li> <li>Think about docs - \"Update docs/components/jenkins.md too\"</li> </ol>"},{"location":"copilot/jenkins-pipelines/#when-debugging","title":"When Debugging","text":"<ol> <li>Provide context - \"Jenkins build fails at security scan stage\"</li> <li>Share error messages - Paste the actual error</li> <li>Describe expected vs actual - \"Should create Harbor repository but gets 404\"</li> <li>Ask about DORA impact - \"How does this affect lead time metric?\"</li> </ol>"},{"location":"copilot/jenkins-pipelines/#example-prompts","title":"Example Prompts","text":"<p>Good Prompt: <pre><code>Create a Kubernetes Deployment for the Jenkins service in infra/kubernetes/jenkins/.\nRequirements:\n- Use jenkins/jenkins:lts-jdk17 image\n- 2 replicas with PersistentVolumeClaim for /var/jenkins_home\n- Resource limits: 2Gi memory, 1 CPU\n- Liveness/readiness probes on port 8080\n- ServiceAccount with RBAC for Kubernetes plugin\n- Follow existing patterns from infra/kubernetes/backstage/\n\nAlso create:\n- Service (NodePort on 8080, 50000)\n- Ingress (jenkins.fawkes-platform.local)\n- PersistentVolumeClaim (10Gi, ReadWriteOnce)\n\nInclude all in separate YAML files following naming convention.\n</code></pre></p> <p>Bad Prompt: <pre><code>make jenkins work in kubernetes\n</code></pre></p>"},{"location":"copilot/jenkins-pipelines/#reference-key-technologies","title":"\ud83d\udcd6 Reference: Key Technologies","text":""},{"location":"copilot/jenkins-pipelines/#technology-stack-summary","title":"Technology Stack Summary","text":"Component Technology Version Purpose Container Orchestration Kubernetes 1.28+ Run all platform services Developer Portal Backstage 1.20+ Self-service + dojo hub CI/CD Jenkins LTS Build and test automation GitOps ArgoCD 2.9+ Continuous delivery Progressive Delivery Argo Rollouts 1.6+ Canary/blue-green deployments Container Registry Harbor 2.10+ Image storage + scanning Collaboration Mattermost 9.0+ Team chat + ChatOps Project Management Focalboard 7.0+ Sprint planning (in Mattermost) Metrics Prometheus 2.48+ Time-series metrics Dashboards Grafana 10.0+ Visualization Logging OpenSearch 2.11+ Log aggregation Log Collection Fluent Bit 2.2+ Log forwarding Code Quality SonarQube 10.0+ SAST scanning Container Scanning Trivy 0.48+ Vulnerability scanning Policy Enforcement Kyverno 1.11+ Kubernetes policies Secrets External Secrets 0.9+ AWS Secrets Manager integration Infrastructure Terraform 1.6+ AWS provisioning Database PostgreSQL 15+ Platform data persistence"},{"location":"copilot/jenkins-pipelines/#important-endpoints","title":"Important Endpoints","text":"Service URL Purpose Backstage <code>https://backstage.fawkes-platform.local</code> Developer portal Jenkins <code>https://jenkins.fawkes-platform.local</code> CI/CD pipelines ArgoCD <code>https://argocd.fawkes-platform.local</code> GitOps deployments Harbor <code>https://harbor.fawkes-platform.local</code> Container registry Grafana <code>https://grafana.fawkes-platform.local</code> Dashboards Prometheus <code>https://prometheus.fawkes-platform.local</code> Metrics Mattermost <code>https://mattermost.fawkes-platform.local</code> Team collaboration SonarQube <code>https://sonarqube.fawkes-platform.local</code> Code quality"},{"location":"copilot/jenkins-pipelines/#default-namespaces","title":"Default Namespaces","text":"Namespace Purpose <code>fawkes-platform</code> Core platform services <code>fawkes-dojo</code> Dojo learning labs <code>argocd</code> ArgoCD controller <code>monitoring</code> Prometheus, Grafana <code>logging</code> OpenSearch, Fluent Bit <code>external-secrets-system</code> External Secrets Operator <code>kyverno</code> Policy enforcement"},{"location":"copilot/jenkins-pipelines/#quick-start-commands","title":"\ud83c\udfaf Quick Start Commands","text":""},{"location":"copilot/jenkins-pipelines/#common-development-tasks","title":"Common Development Tasks","text":"<pre><code># Provision AWS infrastructure\ncd infra\n../scripts/ignite.sh --provider aws dev\n\n# Deploy platform components on current cluster\n../scripts/ignite.sh --only-apps local\n\n# Run tests\ncd tests/e2e\npytest -v --tb=short\n\n# Access Backstage locally (port-forward)\nkubectl port-forward -n fawkes-platform svc/backstage 7007:7007\n\n# View logs for a service\nkubectl logs -n fawkes-platform -l app=jenkins -f\n\n# Restart a deployment\nkubectl rollout restart deployment/backstage -n fawkes-platform\n\n# Sync ArgoCD application\nargocd app sync backstage\n\n# Get DORA metrics\ncurl http://dora-metrics.fawkes-platform.svc:8080/api/v1/metrics\n\n# Access Grafana DORA dashboard\nkubectl port-forward -n monitoring svc/grafana 3000:3000\n# Open http://localhost:3000/d/dora-metrics\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#useful-kubectl-commands","title":"Useful Kubectl Commands","text":"<pre><code># Get all platform services\nkubectl get all -n fawkes-platform\n\n# Check pod status\nkubectl get pods -n fawkes-platform -o wide\n\n# Describe a failing pod\nkubectl describe pod &lt;pod-name&gt; -n fawkes-platform\n\n# Check resource usage\nkubectl top nodes\nkubectl top pods -n fawkes-platform\n\n# View events\nkubectl get events -n fawkes-platform --sort-by='.lastTimestamp'\n\n# Execute command in pod\nkubectl exec -it &lt;pod-name&gt; -n fawkes-platform -- /bin/bash\n\n# View logs with context\nkubectl logs -n fawkes-platform &lt;pod-name&gt; --previous\nkubectl logs -n fawkes-platform &lt;pod-name&gt; --tail=100 -f\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#troubleshooting-guide","title":"\ud83c\udd98 Troubleshooting Guide","text":""},{"location":"copilot/jenkins-pipelines/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"copilot/jenkins-pipelines/#issue-jenkins-build-fails-at-security-scan-stage","title":"Issue: Jenkins build fails at security scan stage","text":"<pre><code># Check Trivy is installed in agent\nkubectl exec -it &lt;jenkins-agent-pod&gt; -n fawkes-platform -- trivy --version\n\n# Verify Harbor registry is accessible\nkubectl exec -it &lt;jenkins-agent-pod&gt; -n fawkes-platform -- \\\n  curl -k https://harbor.fawkes-platform.svc\n\n# Check if image was pushed successfully\ncurl -u robot-account:password \\\n  https://harbor.fawkes-platform.local/api/v2.0/projects/fawkes/repositories\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#issue-argocd-not-syncing-application","title":"Issue: ArgoCD not syncing application","text":"<pre><code># Check ArgoCD application status\nkubectl get application -n argocd backstage -o yaml\n\n# View sync operation logs\nargocd app logs backstage\n\n# Force sync\nargocd app sync backstage --force\n\n# Check if repository is accessible\nargocd repo list\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#issue-dora-metrics-not-appearing-in-grafana","title":"Issue: DORA metrics not appearing in Grafana","text":"<pre><code># Verify metrics service is running\nkubectl get pods -n fawkes-platform -l app=dora-metrics\n\n# Check if Prometheus is scraping metrics\nkubectl port-forward -n monitoring svc/prometheus 9090:9090\n# Visit http://localhost:9090/targets\n\n# Test metrics endpoint directly\nkubectl exec -it &lt;prometheus-pod&gt; -n monitoring -- \\\n  curl http://dora-metrics.fawkes-platform.svc:8080/metrics\n\n# Check Grafana datasource configuration\nkubectl get configmap -n monitoring grafana-datasources -o yaml\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#issue-cannot-access-backstage-portal","title":"Issue: Cannot access Backstage portal","text":"<pre><code># Check ingress configuration\nkubectl get ingress -n fawkes-platform\n\n# Verify DNS resolution\nnslookup backstage.fawkes-platform.local\n\n# Check certificate (if using TLS)\nkubectl get certificate -n fawkes-platform\n\n# View Backstage logs\nkubectl logs -n fawkes-platform -l app=backstage --tail=50\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#documentation-standards","title":"\ud83d\udcdd Documentation Standards","text":"<p>When creating or updating documentation:</p>"},{"location":"copilot/jenkins-pipelines/#structure","title":"Structure","text":"<pre><code># Title (H1 - One per document)\n\n**Metadata**: Version, Last Updated, Status, Audience\n\n## Overview (H2)\n- Brief description\n- Purpose and scope\n- Prerequisites\n\n## Table of Contents (if &gt;3 sections)\n\n## Main Content (H2 sections)\n- Clear headings\n- Code examples with language tags\n- Screenshots where helpful\n- Links to related docs\n\n## Troubleshooting (H2)\n- Common issues\n- Error messages and solutions\n\n## Additional Resources (H2)\n- External links\n- Related documentation\n- Contact information\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#code-examples","title":"Code Examples","text":"<ul> <li>Always include file path: <code># File: path/to/file.yaml</code></li> <li>Use proper syntax highlighting: <code>yaml,</code>bash, ```python</li> <li>Add comments explaining non-obvious parts</li> <li>Include DORA capability annotations</li> <li>Show complete, runnable examples</li> </ul>"},{"location":"copilot/jenkins-pipelines/#linking","title":"Linking","text":"<ul> <li>Use relative links for internal docs: <code>[Architecture](../architecture.md)</code></li> <li>Use absolute URLs for external resources</li> <li>Check links don't break when docs move</li> </ul>"},{"location":"copilot/jenkins-pipelines/#belt-specific-guidelines","title":"\ud83c\udf93 Belt-Specific Guidelines","text":""},{"location":"copilot/jenkins-pipelines/#white-belt-beginner","title":"White Belt (Beginner)","text":"<ul> <li>Focus on concepts, not complexity</li> <li>Provide step-by-step instructions</li> <li>Include lots of screenshots</li> <li>Explain every command</li> <li>Use simple, working examples</li> </ul>"},{"location":"copilot/jenkins-pipelines/#yellow-belt-intermediate","title":"Yellow Belt (Intermediate)","text":"<ul> <li>Introduce complexity gradually</li> <li>Explain trade-offs and alternatives</li> <li>Encourage exploration</li> <li>Provide troubleshooting guidance</li> <li>Include performance considerations</li> </ul>"},{"location":"copilot/jenkins-pipelines/#green-belt-advanced","title":"Green Belt (Advanced)","text":"<ul> <li>Assume foundational knowledge</li> <li>Focus on advanced patterns</li> <li>Discuss architectural decisions</li> <li>Include optimization techniques</li> <li>Reference ADRs and best practices</li> </ul>"},{"location":"copilot/jenkins-pipelines/#brown-belt-expert","title":"Brown Belt (Expert)","text":"<ul> <li>Multi-component integration</li> <li>Production considerations</li> <li>Disaster recovery scenarios</li> <li>Performance tuning</li> <li>Custom implementations</li> </ul>"},{"location":"copilot/jenkins-pipelines/#black-belt-master","title":"Black Belt (Master)","text":"<ul> <li>Platform architecture design</li> <li>Multi-tenancy patterns</li> <li>Cost optimization strategies</li> <li>Mentoring and teaching</li> <li>Contributing to Fawkes core</li> </ul>"},{"location":"copilot/jenkins-pipelines/#continuous-improvement","title":"\ud83d\udd04 Continuous Improvement","text":""},{"location":"copilot/jenkins-pipelines/#contributing-to-copilot-instructions","title":"Contributing to Copilot Instructions","text":"<p>Found a pattern that works well? Submit a PR to improve these instructions!</p> <pre><code># Fork the repository\ngit clone https://github.com/paruff/fawkes.git\ncd fawkes\n\n# Create a branch\ngit checkout -b improve-copilot-instructions\n\n# Edit the file\n# (This file should be at .github/copilot-instructions.md or similar)\n\n# Commit with clear message\ngit commit -am \"Add pattern for X to Copilot instructions\"\n\n# Push and create PR\ngit push origin improve-copilot-instructions\n</code></pre>"},{"location":"copilot/jenkins-pipelines/#feedback-loop","title":"Feedback Loop","text":"<p>After using these instructions: 1. What worked well? - Share successful patterns 2. What was confusing? - Help clarify ambiguous sections 3. What's missing? - Suggest new sections or examples 4. What's outdated? - Update deprecated practices</p> <p>Post feedback in: - GitHub Discussion: https://github.com/paruff/fawkes/discussions - Mattermost: <code>#platform-engineering</code> channel - Weekly office hours: Wednesdays 2pm ET</p>"},{"location":"copilot/jenkins-pipelines/#success-metrics","title":"\ud83d\udcca Success Metrics","text":"<p>Track how well Copilot is helping:</p> <ul> <li>Time to first PR - How quickly can new contributors submit code?</li> <li>Code review cycles - Fewer cycles = better adherence to patterns</li> <li>Test coverage - Are tests being generated automatically?</li> <li>Documentation freshness - Are docs updated with code changes?</li> <li>DORA metrics - Is generated code improving platform performance?</li> </ul>"},{"location":"copilot/jenkins-pipelines/#summary","title":"\ud83c\udfc1 Summary","text":"<p>Key Takeaways: 1. \u2705 Fawkes uses an established structure - respect it 2. \u2705 AWS first, multi-cloud later - don't over-abstract 3. \u2705 ArgoCD replaces Spinnaker - use Argo Rollouts for progressive delivery 4. \u2705 Mattermost, not Slack - all notifications go to Mattermost 5. \u2705 DORA metrics are first-class - instrument everything 6. \u2705 Security from the start - scanning, policies, secrets management 7. \u2705 Dojo learning is core - create educational content 8. \u2705 GitOps workflow - all changes through Git</p> <p>Remember: - Check existing patterns before creating new ones - Follow the repository structure exactly - Tag code with DORA capabilities and belt levels - Include tests with all new features - Update documentation when code changes - Ask when uncertain about placement or approach</p> <p>Your Goal: Help build Fawkes into the world's best open-source Internal Product Delivery Platform, where developers learn platform engineering while deploying production-grade infrastructure.</p> <p>Version: 1.0.0 Last Updated: October 26, 2025 Maintained By: Fawkes Platform Team Questions? Open a GitHub Discussion</p>"},{"location":"design/Demand%20Hypothesis/","title":"Demand Hypothesis","text":"<p>Based on the defined persona (Improvement-Driven Leader) and their Jobs to Be Done, we hypothesize the following about the demand for a service that provides DORA metrics visualization:</p> <p>Hypothesis Statement:</p> <p>We believe that Improvement-Driven Leaders within software development organizations will find significant value in a service that provides easily accessible, objective visualization of DORA metrics.</p> <p>Because:</p> <ul> <li>DORA metrics (change lead time, deployment frequency, change fail percentage, failed deployment recovery time) are globally recognized and validated indicators of software delivery performance and overall organizational outcomes [6, 7].</li> <li>Improvement-Driven Leaders need objective data to understand the current state of their software delivery process and identify specific areas for improvement [5, 8].</li> <li>There is a common pain point where management doesn't fully understand the software process or the challenges faced by development and operations teams, leading to misaligned expectations and pressure [1-3].</li> <li>Providing end-to-end dashboards for stakeholders to view performance is a key practice for mitigating challenges and enabling data-driven decision-making [8].</li> <li>Metrics are a requirement for excellence and facilitate informed decision-making [8].</li> <li>Organizations often struggle to effectively collect and present these critical metrics from their existing toolchains [8, 14-16].</li> <li>A service focused on delivering these core metrics addresses a fundamental need for visibility and insight necessary for an improvement-driven approach [5, 7].</li> </ul> <p>Therefore:</p> <ul> <li>Providing a clear, centralized view of DORA metrics will solve a key pain point for leaders struggling to measure and understand their team's performance.</li> <li>This service will enable leaders to make better decisions, justify investments in process improvements, and communicate performance effectively across the organization.</li> <li>The demand for such a service is driven by the need to identify and address inefficiencies and bottlenecks in the software delivery lifecycle, ultimately helping organizations get \"better at getting better\" [5].</li> <li>While platforms like Backstage exist, a focused MVP on DORA metrics addresses the specific need for performance visibility directly, potentially with less initial overhead than a full IDP implementation, thus being valuable as a targeted solution for this persona.</li> </ul> <p>Validation Strategy (Implicit/Next Steps):</p> <ul> <li>Engage directly with potential customers (Improvement-Driven Leaders) to confirm these pain points and the perceived value of a DORA metrics dashboard [17].</li> <li>Leverage tools and methods for identifying pain points such as surveys, interviews, analyzing forum discussions (like on Reddit) related to DevOps, performance, and management challenges [17-26].</li> <li>Start with a DORA Quick Check style conversation [Conversation History] to assess current understanding and perceived needs regarding performance metrics.</li> </ul>"},{"location":"design/Jobs%20to%20Be%20Done%20%28JTBD%29%20for%20the%20Improve/","title":"Jobs to Be Done (JTBD) for the Improvement-Driven Leader Persona","text":"<p>Based on the persona description and the sources, the \"Improvement-Driven Leader\" hires a solution to perform the following jobs:</p> <p>Core Job:</p> <ul> <li>Measure software delivery performance using established metrics like the DORA Four Keys (change lead time, deployment frequency, change fail percentage, failed deployment recovery time) to understand the current state and track progress over time [6, 7].</li> </ul> <p>Related Jobs:</p> <ul> <li>Gain visibility into team and process performance to identify bottlenecks and areas needing attention [8].</li> <li>Provide stakeholders with end-to-end dashboards to visualize performance and facilitate decision-making [8].</li> <li>Identify problems early by monitoring key performance indicators [8].</li> <li>Understand where the organization is potentially failing across the key software delivery metrics [7].</li> <li>Gather objective data to validate or challenge perceptions about performance.</li> <li>Inform and prioritize improvement initiatives based on data rather than intuition or anecdote [5, 8].</li> <li>Communicate performance trends and the impact of changes to other leaders and teams [1, 2].</li> <li>Bridge the communication gap between technical teams and business stakeholders by providing quantifiable metrics [1, 2].</li> <li>Establish a baseline for performance before implementing new practices or tools.</li> <li>Monitor the effectiveness of implemented changes and improvements.</li> <li>Enable continuous improvement by providing the data needed to identify and address problems iteratively [5].</li> </ul>"},{"location":"design/Persona-Ivan%20The%20Improvement-Driven%20Leader/","title":"Persona: The Improvement-Driven Leader","text":"<p>Based on our conversation history and the provided sources, our primary persona is the Improvement-Driven Leader. This persona represents individuals in leadership or management roles who are focused on understanding and improving their organization's software delivery performance.</p> <p>Description:</p> <p>This persona is typically a product manager, manager, or leader within a software development or IT organization [1-3]. They are concerned with business objectives [4], realizing gains quickly [1], and ensuring their teams are getting better at getting better [5].</p> <p>Goals:</p> <ul> <li>To understand the current state of software delivery performance objectively [6, 7].</li> <li>To identify areas for improvement within the software development and delivery process [5].</li> <li>To make data-driven decisions to optimize workflows and resource allocation [8].</li> <li>To bridge the gap between business needs and the realities of software development difficulty [1, 2].</li> <li>To quantify the Return on Investment (ROI) of improvement initiatives.</li> <li>To foster a supportive, innovative, and stable organizational culture that enables high performance [7].</li> <li>To ensure security is seamlessly integrated into development workflows and aligns with business objectives [4].</li> </ul> <p>Pain Points &amp; Frustrations:</p> <ul> <li>Lack of clear visibility into software delivery performance metrics [8].</li> <li>Difficulty in understanding the actual effort and complexity of development work (\"development as a black box\") [1].</li> <li>Challenges in conveying the difficulty or time required for features to business stakeholders [1, 2].</li> <li>Pressure to deliver quickly leading to rushing and technical debt, often due to management not understanding the process [2].</li> <li>Unrealistic expectations and deadlines from project managers or management who don't understand the workload, especially in DevOps roles [3].</li> <li>Tools that get in their way rather than helping [9].</li> <li>Challenges related to management structure, communication/collaboration, and culture when adopting new methodologies like DevOps [10, 11].</li> <li>Lack of senior management involvement in improvement initiatives [12].</li> <li>Difficulty in identifying hidden pain points or workarounds that teams have become accustomed to (\"It's annoying, but this is how we do the thing\") [13].</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/","title":"Fawkes Dojo: Immersive Learning Architecture","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#document-information","title":"Document Information","text":"<p>Version: 1.0 Last Updated: October 7, 2025 Status: Living Document Audience: Learning Architects, Contributors, Platform Engineers</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Vision &amp; Philosophy</li> <li>Learning System Overview</li> <li>Belt Progression System</li> <li>Curriculum Architecture</li> <li>Hands-On Lab Environment</li> <li>Assessment &amp; Certification</li> <li>DORA Capabilities Mapping</li> <li>Platform Engineering University Integration</li> <li>Technology Stack</li> <li>Implementation Roadmap</li> </ol>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#vision-philosophy","title":"Vision &amp; Philosophy","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#the-problem","title":"The Problem","text":"<p>Platform engineering skills are in high demand but difficult to acquire: - Theory vs. Practice Gap: Reading about platform engineering \u2260 doing platform engineering - No Safe Practice Environment: Production is too risky, toy examples aren't realistic - Fragmented Learning: Scattered blog posts, docs, and courses don't provide cohesive journey - No Feedback Loops: Hard to know if you're improving or building bad habits - Lack of Recognition: No clear progression system or credentials</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#the-fawkes-dojo-solution","title":"The Fawkes Dojo Solution","text":"<p>\"Learn platform engineering by building and operating a real platform\"</p> <p>The Fawkes Dojo is not a traditional course or documentation site. It's an immersive learning environment where:</p> <ol> <li>\u2705 Learn by Doing: Every concept practiced immediately in production-like environment</li> <li>\u2705 Safe to Fail: Isolated environments where mistakes are learning opportunities</li> <li>\u2705 Immediate Feedback: Automated validation, metrics, and mentor review</li> <li>\u2705 Progressive Mastery: Clear belt system showing skill progression</li> <li>\u2705 Real Tools, Real Skills: Same tools used in production environments</li> <li>\u2705 Community Learning: Learn with peers, share achievements, get help</li> <li>\u2705 Recognized Credentials: Earn badges/certificates valued by employers</li> </ol>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#learning-philosophy","title":"Learning Philosophy","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#1-production-first-learning","title":"1. Production-First Learning","text":"<ul> <li>Labs use the actual Fawkes platform, not simplified versions</li> <li>Same tools, same workflows, same challenges as production</li> <li>Mistakes have consequences (within safe boundaries)</li> <li>Build muscle memory for real-world scenarios</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#2-immediate-application","title":"2. Immediate Application","text":"<ul> <li>Maximum 5 minutes of theory before hands-on practice</li> <li>Every concept demonstrated, then practiced</li> <li>Build, break, fix\u2014the fastest path to mastery</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#3-spaced-repetition-reinforcement","title":"3. Spaced Repetition &amp; Reinforcement","text":"<ul> <li>Concepts introduced multiple times in increasing complexity</li> <li>Earlier skills reinforced in advanced modules</li> <li>Regular reviews and retrospectives</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#4-deliberate-practice","title":"4. Deliberate Practice","text":"<ul> <li>Focused on specific skills with clear goals</li> <li>Challenging but achievable (flow state)</li> <li>Immediate feedback on performance</li> <li>Reflection on what worked and what didn't</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#5-social-learning","title":"5. Social Learning","text":"<ul> <li>Learn with cohorts (optional but encouraged)</li> <li>Share solutions and approaches</li> <li>Peer code review and feedback</li> <li>Celebrate achievements publicly</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#learning-system-overview","title":"Learning System Overview","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Fawkes Dojo Learning System                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502           Backstage Dojo Portal (Learning Hub)            \u2502 \u2502\n\u2502  \u2502  \u2022 Curriculum Browser  \u2022 Progress Tracking  \u2022 Leaderboard\u2502 \u2502\n\u2502  \u2502  \u2022 Lab Launcher  \u2022 Achievement Badges  \u2022 Community       \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502              \u2502                                   \u2502             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Learning Content (TechDocs) \u2502  \u2502   Hands-On Labs        \u2502  \u2502\n\u2502  \u2502  \u2022 Modules (video + text)    \u2502  \u2502   (Live Environment)   \u2502  \u2502\n\u2502  \u2502  \u2022 Exercises                 \u2502  \u2502   \u2022 Personal namespace \u2502  \u2502\n\u2502  \u2502  \u2022 Quizzes                   \u2502  \u2502   \u2022 Sample apps        \u2502  \u2502\n\u2502  \u2502  \u2022 References                \u2502  \u2502   \u2022 CI/CD pipelines    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502   \u2022 Monitoring         \u2502  \u2502\n\u2502                                     \u2502   \u2022 Auto-validation    \u2502  \u2502\n\u2502                                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502              \u2502                                   \u2502             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502         Assessment &amp; Certification Engine                \u2502 \u2502\n\u2502  \u2502  \u2022 Automated Grading  \u2022 Manual Review  \u2022 Certificates   \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502              \u2502                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502            Progress &amp; Analytics (Focalboard)             \u2502 \u2502\n\u2502  \u2502  \u2022 Individual progress  \u2022 Cohort analytics              \u2502 \u2502\n\u2502  \u2502  \u2022 Skill gaps  \u2022 Time tracking  \u2022 Completion rates      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502              \u2502                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502           Community &amp; Support (Mattermost)               \u2502 \u2502\n\u2502  \u2502  \u2022 #dojo channels  \u2022 Peer help  \u2022 Mentor office hours   \u2502 \u2502\n\u2502  \u2502  \u2022 Achievement announcements  \u2022 Study groups            \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#component-responsibilities","title":"Component Responsibilities","text":"Component Purpose Technology Dojo Portal Single entry point for all learning Backstage plugin Content System Modules, videos, documentation TechDocs (Markdown + MkDocs) Lab Environment Hands-on practice in isolated namespaces Kubernetes namespaces + RBAC Validation System Auto-grade labs, provide feedback Custom Go/Python service Progress Tracking Track learner progress, visualize journey Focalboard + PostgreSQL Achievement System Badges, certificates, leaderboards Backstage plugin + database Community Platform Discussion, support, collaboration Mattermost Analytics Engine Learning effectiveness, content gaps Grafana + custom metrics"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#belt-progression-system","title":"Belt Progression System","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#belt-philosophy","title":"Belt Philosophy","text":"<p>Inspired by martial arts dojo systems, the belt progression provides: - Clear Milestones: Tangible goals to work toward - Skill Validation: Each belt certifies specific competencies - Public Recognition: Displayable badges and credentials - Motivation: Gamification without sacrificing rigor</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#belt-levels","title":"Belt Levels","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#white-belt-platform-fundamentals-8-hours","title":"\ud83e\udd4b White Belt: Platform Fundamentals (8 hours)","text":"<p>Target Audience: New to platform engineering or Fawkes Prerequisites: Basic command line, Git, and Docker knowledge Certification: \"Fawkes Platform Operator\"</p> <p>Core Competencies: - Understand what an Internal Delivery Platform is and why it matters - Explain DORA metrics and their business impact - Navigate Backstage portal and service catalog - Deploy an application using a golden path template - View and interpret basic DORA metrics - Use Mattermost for team collaboration - Track work in Focalboard</p> <p>DORA Capabilities Covered: 4 of 24 - Continuous Integration - Continuous Delivery - Monitoring and Observability - Deployment Automation</p> <p>Assessment: - Deploy 2 sample applications successfully - Demonstrate understanding of DORA metrics (quiz) - Complete 3 hands-on labs - Pass 80% on written assessment</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#yellow-belt-cicd-mastery-8-hours","title":"\ud83d\udfe1 Yellow Belt: CI/CD Mastery (8 hours)","text":"<p>Target Audience: Developers ready to own their CI/CD Prerequisites: White Belt certification Certification: \"Fawkes CI/CD Specialist\"</p> <p>Core Competencies: - Build custom Jenkins pipelines from scratch - Implement security scanning (SAST, dependency check, container scanning) - Configure quality gates and automated testing - Optimize build times and resource usage - Troubleshoot failed pipelines effectively - Understand artifact management and versioning - Implement pipeline-as-code best practices</p> <p>DORA Capabilities Covered: 6 of 24 (additional) - Test Automation - Test Data Management - Shift Left on Security - Trunk-Based Development - Version Control - Code Review</p> <p>Assessment: - Build 3 production-ready pipelines (Java, Python, Node.js) - Achieve &lt;5 min build time for sample app - Implement security scanning with zero critical vulnerabilities - Score 85%+ on advanced CI/CD quiz</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#green-belt-gitops-deployment-8-hours","title":"\ud83d\udfe2 Green Belt: GitOps &amp; Deployment (8 hours)","text":"<p>Target Audience: Engineers managing deployments Prerequisites: Yellow Belt certification Certification: \"Fawkes Deployment Engineer\"</p> <p>Core Competencies: - Implement GitOps workflows with ArgoCD - Configure blue-green and canary deployments - Implement progressive delivery with automated rollback - Manage multi-environment deployments (dev, staging, prod) - Troubleshoot deployment failures and rollback safely - Understand Kubernetes deployment strategies - Implement deployment best practices</p> <p>DORA Capabilities Covered: 7 of 24 (additional) - Deployment Automation (advanced) - Infrastructure as Code - Empowering Teams - Visual Management - Work in Small Batches - Team Experimentation - Change Approval Process</p> <p>Assessment: - Implement GitOps for 3 environments - Execute successful canary deployment with rollback - Recover from simulated deployment failure &lt;5 min - Design deployment strategy for complex application - Score 85%+ on GitOps assessment</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#brown-belt-observability-sre-8-hours","title":"\ud83d\udfe4 Brown Belt: Observability &amp; SRE (8 hours)","text":"<p>Target Audience: Engineers responsible for reliability Prerequisites: Green Belt certification Certification: \"Fawkes SRE Practitioner\"</p> <p>Core Competencies: - Configure comprehensive observability (metrics, logs, traces) - Design and implement custom DORA metrics dashboards - Define and track SLIs, SLOs, and error budgets - Implement distributed tracing for microservices - Conduct effective incident response and postmortems - Practice chaos engineering fundamentals - Optimize platform and application performance</p> <p>DORA Capabilities Covered: 5 of 24 (additional) - Monitoring and Observability (advanced) - Proactive Failure Notification - Database Change Management - WIP Limits - Visualizing Work</p> <p>Assessment: - Configure full observability stack for application - Create custom DORA metrics dashboard - Define SLOs and implement alerts - Respond to simulated incident (pass if MTTR &lt;30 min) - Conduct postmortem analysis - Score 90%+ on SRE assessment</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#black-belt-platform-architecture-8-hours","title":"\u26ab Black Belt: Platform Architecture (8 hours)","text":"<p>Target Audience: Platform architects and tech leads Prerequisites: Brown Belt certification Certification: \"Fawkes Platform Architect\"</p> <p>Core Competencies: - Design platform architecture for new teams - Implement multi-tenancy and resource governance - Design security architecture (zero trust principles) - Plan multi-cloud deployment strategies - Evaluate and integrate new platform tools - Mentor others in platform engineering - Contribute to platform codebase</p> <p>DORA Capabilities Covered: 2 of 24 (final) - Loosely Coupled Architecture - Generative Organizational Culture</p> <p>Assessment: - Design complete platform for fictional company - Present architecture to panel (peer + mentor review) - Implement multi-tenant namespace design - Contribute meaningful code or documentation to Fawkes - Mentor 2 learners through White Belt - Score 90%+ on architecture assessment</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#belt-progression-visualization","title":"Belt Progression Visualization","text":"<pre><code>White Belt (8h)          Platform Fundamentals\n    \u2193                   \u2713 Deploy apps\n    \u2193                   \u2713 Basic DORA metrics\n    \u2193\nYellow Belt (8h)         CI/CD Mastery\n    \u2193                   \u2713 Custom pipelines\n    \u2193                   \u2713 Security scanning\n    \u2193\nGreen Belt (8h)          GitOps &amp; Deployment\n    \u2193                   \u2713 Blue-green/canary\n    \u2193                   \u2713 Multi-environment\n    \u2193\nBrown Belt (8h)          Observability &amp; SRE\n    \u2193                   \u2713 Full observability\n    \u2193                   \u2713 Incident response\n    \u2193\nBlack Belt (8h)          Platform Architecture\n                        \u2713 Design platforms\n                        \u2713 Mentor others\n\nTotal Time: 40 hours (1 week full-time or 5 weeks part-time)\n</code></pre>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#curriculum-architecture","title":"Curriculum Architecture","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#module-structure","title":"Module Structure","text":"<p>Each module follows consistent structure for predictability:</p> <pre><code>Module N: [Title]\n\u251c\u2500\u2500 1. Learning Objectives (3 min)\n\u2502   \u251c\u2500\u2500 What you'll learn\n\u2502   \u251c\u2500\u2500 Why it matters\n\u2502   \u2514\u2500\u2500 Success criteria\n\u251c\u2500\u2500 2. Theory &amp; Concepts (10-15 min)\n\u2502   \u251c\u2500\u2500 Video explanation (5-7 min)\n\u2502   \u251c\u2500\u2500 Written content with diagrams\n\u2502   \u251c\u2500\u2500 Real-world examples\n\u2502   \u2514\u2500\u2500 Common pitfalls\n\u251c\u2500\u2500 3. Demonstration (10 min)\n\u2502   \u251c\u2500\u2500 Instructor walkthrough video\n\u2502   \u251c\u2500\u2500 Step-by-step with narration\n\u2502   \u2514\u2500\u2500 Explaining \"why\" at each step\n\u251c\u2500\u2500 4. Hands-On Lab (15-20 min)\n\u2502   \u251c\u2500\u2500 Lab environment auto-provisioned\n\u2502   \u251c\u2500\u2500 Clear instructions\n\u2502   \u251c\u2500\u2500 Checkpoints with validation\n\u2502   \u251c\u2500\u2500 Troubleshooting hints\n\u2502   \u2514\u2500\u2500 Auto-graded submission\n\u251c\u2500\u2500 5. Knowledge Check (5 min)\n\u2502   \u251c\u2500\u2500 5-10 quiz questions\n\u2502   \u251c\u2500\u2500 Immediate feedback\n\u2502   \u2514\u2500\u2500 Links to relevant content for wrong answers\n\u251c\u2500\u2500 6. Reflection &amp; Next Steps (5 min)\n\u2502   \u251c\u2500\u2500 What you learned\n\u2502   \u251c\u2500\u2500 How it connects to real work\n\u2502   \u251c\u2500\u2500 Additional resources\n\u2502   \u2514\u2500\u2500 Preview of next module\n\nTotal Time per Module: 45-60 minutes\n</code></pre>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#complete-curriculum-map","title":"Complete Curriculum Map","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#white-belt-8-hours-total","title":"White Belt (8 hours total)","text":"<p>Module 1: Internal Delivery Platforms - What and Why (60 min) - What is an IDP and why organizations need them - Platform as a Product mindset - Team Topologies: enabling teams - Fawkes platform tour - Lab: Explore Backstage catalog, navigate documentation</p> <p>Module 2: DORA Metrics - The North Star (60 min) - Four Key Metrics explained in depth - High performers vs. low performers data - How DORA metrics drive business outcomes - Fawkes DORA metrics automation - Lab: View live DORA dashboard, understand metric calculations</p> <p>Module 3: GitOps Principles (60 min) - Declarative infrastructure and applications - Git as source of truth - Automated reconciliation - Benefits and challenges - Lab: Make a GitOps change, watch ArgoCD sync</p> <p>Module 4: Your First Deployment (60 min) - Golden path templates - Step-by-step deployment process - Monitoring deployment progress - Viewing DORA metrics in real-time - Lab: Deploy your first application end-to-end</p> <p>White Belt Assessment (2 hours) - Deploy 2 additional applications (different languages) - Written exam (30 questions) - Practical troubleshooting scenario</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#yellow-belt-8-hours-total","title":"Yellow Belt (8 hours total)","text":"<p>Module 5: Continuous Integration Fundamentals (60 min) - CI principles and benefits - Jenkins architecture - Pipeline-as-code (Jenkinsfile) - Build stages and best practices - Lab: Create basic Jenkinsfile, run first build</p> <p>Module 6: Building Golden Path Pipelines (60 min) - Shared libraries and reusable components - Multi-stage pipelines (build, test, package) - Caching and optimization - Parallel execution - Lab: Build optimized pipeline with &lt;5 min runtime</p> <p>Module 7: Security Scanning &amp; Quality Gates (60 min) - Static analysis (SonarQube) - Dependency scanning - Container image scanning (Trivy) - Quality gates and policy enforcement - Lab: Add comprehensive security scanning to pipeline</p> <p>Module 8: Artifact Management (60 min) - Container registry (Harbor) - Versioning strategies (semantic versioning) - Artifact promotion across environments - Retention policies - Lab: Implement artifact management workflow</p> <p>Yellow Belt Assessment (2 hours) - Build 3 production-ready pipelines - Optimize build performance - Implement security scanning with zero critical CVEs - Written exam (40 questions)</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#green-belt-8-hours-total","title":"Green Belt (8 hours total)","text":"<p>Module 9: GitOps with ArgoCD (60 min) - ArgoCD architecture and concepts - Application definitions - Sync policies and health assessment - Automated vs. manual sync - Lab: Configure ArgoCD application, implement sync</p> <p>Module 10: Deployment Strategies (60 min) - Blue-green deployments - Canary deployments - Rolling updates - Feature flags - Lab: Implement blue-green deployment</p> <p>Module 11: Progressive Delivery (60 min) - Traffic splitting and analysis - Automated rollback triggers - Metrics-driven deployments - A/B testing integration - Lab: Configure canary deployment with automated rollback</p> <p>Module 12: Rollback &amp; Incident Response (60 min) - When and how to rollback - Incident detection and alerting - Emergency procedures - Postmortem process - Lab: Simulate production incident, execute rollback</p> <p>Green Belt Assessment (2 hours) - Implement GitOps for 3 environments - Execute canary deployment - Respond to simulated incident - Design deployment strategy document - Written exam (40 questions)</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#brown-belt-8-hours-total","title":"Brown Belt (8 hours total)","text":"<p>Module 13: Metrics, Logs, and Traces (60 min) - Three pillars of observability - Prometheus metrics collection - OpenSearch log aggregation - Grafana Tempo distributed tracing - Lab: Configure full observability stack</p> <p>Module 14: DORA Metrics Deep Dive (60 min) - Advanced DORA metrics calculation - Custom dashboard creation - Team-level vs. organization-level metrics - Using metrics for continuous improvement - Lab: Build custom DORA dashboard for your team</p> <p>Module 15: SLIs, SLOs, and Error Budgets (60 min) - Defining Service Level Indicators - Setting appropriate Service Level Objectives - Calculating and tracking error budgets - Using error budgets for decision-making - Lab: Define SLOs and implement monitoring</p> <p>Module 16: Incident Management &amp; Postmortems (60 min) - Incident severity levels - On-call best practices - Effective incident response - Blameless postmortems - Lab: Participate in simulated incident response</p> <p>Brown Belt Assessment (2 hours) - Configure comprehensive observability - Create custom dashboards - Define SLOs and alerts - Respond to simulated incidents (MTTR measured) - Written exam (45 questions)</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#black-belt-8-hours-total","title":"Black Belt (8 hours total)","text":"<p>Module 17: Platform as a Product (60 min) - Treating platform as product - Understanding customer (developer) needs - Platform roadmapping - Measuring platform success - Lab: Conduct developer interviews, create roadmap</p> <p>Module 18: Multi-Tenancy &amp; Resource Management (60 min) - Namespace-based isolation - Resource quotas and limits - Network policies - RBAC strategies - Lab: Design and implement multi-tenant environment</p> <p>Module 19: Security &amp; Zero Trust (60 min) - Zero trust principles - Policy as code (Kyverno/OPA) - Secrets management (External Secrets) - Compliance automation - Lab: Implement zero trust policies</p> <p>Module 20: Multi-Cloud Strategies (60 min) - Multi-cloud architecture patterns - Crossplane for cloud abstraction - Disaster recovery across clouds - Cost optimization - Lab: Design multi-cloud deployment strategy</p> <p>Black Belt Assessment (4 hours) - Design complete platform architecture - Present to peer review panel - Implement multi-tenant design - Contribute to Fawkes codebase - Mentor 2 White Belt learners - Written exam (50 questions)</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#hands-on-lab-environment","title":"Hands-On Lab Environment","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#lab-architecture","title":"Lab Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Fawkes Dojo Kubernetes Cluster                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                            \u2502\n\u2502  Dojo System Namespace (dojo-system)                      \u2502\n\u2502  \u251c\u2500\u2500 dojo-portal (Backstage with dojo plugin)            \u2502\n\u2502  \u251c\u2500\u2500 dojo-provisioner (creates learner namespaces)       \u2502\n\u2502  \u251c\u2500\u2500 dojo-validator (auto-grades labs)                   \u2502\n\u2502  \u2514\u2500\u2500 dojo-dashboard (progress tracking)                  \u2502\n\u2502                                                            \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502                                                            \u2502\n\u2502  Learner Namespace (dojo-learner-{username})             \u2502\n\u2502  \u251c\u2500\u2500 Resources:                                           \u2502\n\u2502  \u2502   \u251c\u2500\u2500 CPU: 2 cores                                    \u2502\n\u2502  \u2502   \u251c\u2500\u2500 Memory: 4Gi                                     \u2502\n\u2502  \u2502   \u251c\u2500\u2500 Storage: 10Gi                                   \u2502\n\u2502  \u2502   \u2514\u2500\u2500 LoadBalancers: 2                                \u2502\n\u2502  \u251c\u2500\u2500 Pre-deployed:                                        \u2502\n\u2502  \u2502   \u251c\u2500\u2500 sample-app (demo application)                  \u2502\n\u2502  \u2502   \u251c\u2500\u2500 jenkins-agent (personal CI agent)              \u2502\n\u2502  \u2502   \u2514\u2500\u2500 lab-validator (checks lab completion)          \u2502\n\u2502  \u251c\u2500\u2500 RBAC:                                                \u2502\n\u2502  \u2502   \u251c\u2500\u2500 Full control within namespace                   \u2502\n\u2502  \u2502   \u251c\u2500\u2500 Read-only to shared resources                   \u2502\n\u2502  \u2502   \u2514\u2500\u2500 No cluster-wide permissions                     \u2502\n\u2502  \u2514\u2500\u2500 Network Policies:                                    \u2502\n\u2502      \u251c\u2500\u2500 Can access dojo services                        \u2502\n\u2502      \u251c\u2500\u2500 Can access internet                             \u2502\n\u2502      \u2514\u2500\u2500 Isolated from other learners                    \u2502\n\u2502                                                            \u2502\n\u2502  [Repeat for each learner...]                            \u2502\n\u2502                                                            \u2502\n\u2502  Shared Services Namespace (dojo-shared)                  \u2502\n\u2502  \u251c\u2500\u2500 container-registry (Harbor)                          \u2502\n\u2502  \u251c\u2500\u2500 git-server (Gitea for labs)                         \u2502\n\u2502  \u251c\u2500\u2500 prometheus (metrics collection)                     \u2502\n\u2502  \u2514\u2500\u2500 grafana (dashboards)                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#lab-provisioning-process","title":"Lab Provisioning Process","text":"<ol> <li> <p>Learner Enrolls in Module:    <pre><code>User clicks \"Start Lab\" in Backstage\n    \u2193\nDojo Provisioner API called\n    \u2193\nCreates namespace: dojo-learner-{username}\n    \u2193\nApplies resource quotas and RBAC\n    \u2193\nDeploys lab-specific resources\n    \u2193\nReturns access credentials and instructions\n    \u2193\nLab environment ready in &lt;2 minutes\n</code></pre></p> </li> <li> <p>Lab Execution:    <pre><code>Learner follows lab instructions\n    \u2193\nMakes changes in their namespace\n    \u2193\nLab Validator monitors progress\n    \u2193\nCheckpoints automatically verified\n    \u2193\nFeedback provided in real-time\n    \u2193\nFinal submission auto-graded\n</code></pre></p> </li> <li> <p>Lab Cleanup:    <pre><code>Lab completed or 24-hour timeout\n    \u2193\nNamespace marked for deletion\n    \u2193\nGrace period: 1 hour (allow review)\n    \u2193\nNamespace and resources deleted\n    \u2193\nResults stored in database\n</code></pre></p> </li> </ol>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#lab-validation-system","title":"Lab Validation System","text":"<p>Automated Validation Types: - Resource Existence: Deployment, Service, Ingress created - Configuration Correctness: Labels, annotations, replicas match spec - Health Status: Pods running, services responding - Security Compliance: No privileged containers, security contexts set - Performance: Response time, resource usage within limits - DORA Metrics: Deployment recorded, metrics updated</p> <p>Example Validation (Lab: Deploy First App): <pre><code>validations:\n  - name: \"Deployment exists\"\n    type: \"resource-exists\"\n    resource: \"deployment/sample-app\"\n    points: 10\n\n  - name: \"Service responds\"\n    type: \"http-check\"\n    url: \"http://sample-app.{namespace}.svc.cluster.local\"\n    expected_status: 200\n    points: 15\n\n  - name: \"DORA metric recorded\"\n    type: \"metric-check\"\n    metric: \"deployments_total{app='sample-app'}\"\n    expected: \"&gt; 0\"\n    points: 10\n\n  - name: \"Deployment successful\"\n    type: \"status-check\"\n    resource: \"deployment/sample-app\"\n    condition: \"Available\"\n    points: 15\n\ntotal_points: 50\npassing_score: 40\n</code></pre></p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#assessment-certification","title":"Assessment &amp; Certification","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#assessment-types","title":"Assessment Types","text":"<p>1. Continuous Assessment (throughout module) - Knowledge check quizzes (5-10 questions per module) - Hands-on lab auto-grading - Code quality checks - Performance benchmarks</p> <p>2. Belt Certification Assessment - Practical exam (hands-on challenges) - Written exam (comprehensive knowledge check) - Project work (Black Belt only) - Peer/mentor review (Black Belt only)</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#certification-requirements","title":"Certification Requirements","text":"Belt Level Practical Exam Written Exam Additional Requirements White 2 deployments 30 questions, 80% pass Complete 3 labs Yellow 3 pipelines 40 questions, 85% pass Build time &lt;5 min Green GitOps + canary 40 questions, 85% pass MTTR &lt;5 min on simulation Brown Full observability 45 questions, 85% pass MTTR &lt;30 min on incident Black Platform design 50 questions, 90% pass Code contribution + mentoring"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#digital-badges-credentials","title":"Digital Badges &amp; Credentials","text":"<p>Earned Upon Certification: - Digital badge (PNG with verification link) - Verifiable certificate (PDF with unique ID) - LinkedIn/Credly integration - Listed on Fawkes contributor page - Special role in Mattermost</p> <p>Badge Design: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   \ud83e\udd4b White Belt    \u2502\n\u2502  Fawkes Platform    \u2502\n\u2502      Operator       \u2502\n\u2502                     \u2502\n\u2502   [Your Name]       \u2502\n\u2502   Oct 2025          \u2502\n\u2502                     \u2502\n\u2502  Verify: fawks.io/  \u2502\n\u2502  cert/ABC123        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#dora-capabilities-mapping","title":"DORA Capabilities Mapping","text":"<p>All 24 DORA capabilities covered across belt progression:</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#continuous-delivery-capabilities-8","title":"Continuous Delivery Capabilities (8)","text":"<ol> <li>\u2705 Version Control - Yellow Belt, Module 6</li> <li>\u2705 Deployment Automation - White Belt (basic), Green Belt (advanced)</li> <li>\u2705 Continuous Integration - Yellow Belt, Module 5-6</li> <li>\u2705 Trunk-Based Development - Yellow Belt, Module 6</li> <li>\u2705 Test Automation - Yellow Belt, Module 6-7</li> <li>\u2705 Test Data Management - Yellow Belt, Module 7</li> <li>\u2705 Shift Left on Security - Yellow Belt, Module 7</li> <li>\u2705 Continuous Delivery - Green Belt, Module 9-11</li> </ol>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#architecture-capabilities-3","title":"Architecture Capabilities (3)","text":"<ol> <li>\u2705 Loosely Coupled Architecture - Black Belt, Module 17-20</li> <li>\u2705 Empowering Teams - Green Belt, Module 9</li> <li>\u2705 Database Change Management - Brown Belt, Module 14</li> </ol>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#product-process-capabilities-6","title":"Product &amp; Process Capabilities (6)","text":"<ol> <li>\u2705 Team Experimentation - Green Belt, Module 11</li> <li>\u2705 Work in Small Batches - Green Belt, Module 10</li> <li>\u2705 Visual Management - Green Belt, Module 9</li> <li>\u2705 WIP Limits - Brown Belt, Module 15</li> <li>\u2705 Visualizing Work - Brown Belt (Focalboard usage)</li> <li>\u2705 Change Approval Process - Green Belt, Module 12</li> </ol>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#lean-management-monitoring-4","title":"Lean Management &amp; Monitoring (4)","text":"<ol> <li>\u2705 Monitoring and Observability - White Belt (basic), Brown Belt (advanced)</li> <li>\u2705 Proactive Failure Notification - Brown Belt, Module 16</li> <li>\u2705 Lightweight Change Approval - Green Belt, Module 12</li> <li>\u2705 Code Review - Yellow Belt, Module 6</li> </ol>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#cultural-capabilities-3","title":"Cultural Capabilities (3)","text":"<ol> <li>\u2705 Generative Organizational Culture - Black Belt, Module 17</li> <li>\u2705 Learning Culture - Entire Dojo system embodies this</li> <li>\u2705 Job Satisfaction - Measured via NPS in dojo feedback</li> </ol>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#platform-engineering-university-integration","title":"Platform Engineering University Integration","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#certification-alignment","title":"Certification Alignment","text":"<p>Observability in Platform Engineering \u2192 Brown Belt - Dojo modules 13-16 directly align with course content - Hands-on labs use same tools taught in course - Certificate holders get credit toward Brown Belt (skip modules 13-14)</p> <p>Cloud Development Environments in Platform Engineering \u2192 Yellow Belt - Modules 5-8 cover CDE concepts - Eclipse Che integration (roadmap) provides CDE experience - Certificate holders get credit toward Yellow Belt (skip module 5)</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#co-branded-learning-paths","title":"Co-Branded Learning Paths","text":"<ol> <li>\"PEU Observability \u2192 Fawkes Brown Belt\" Path:</li> <li>Complete PEU Observability course</li> <li>Get 50% credit toward Fawkes Brown Belt</li> <li>Complete modules 15-16 only</li> <li> <p>Take Brown Belt assessment</p> </li> <li> <p>\"Fawkes Dojo \u2192 PEU Certification\" Path:</p> </li> <li>Complete Fawkes White + Yellow Belts</li> <li>Get prep materials for PEU courses</li> <li>20% discount on PEU courses (partnership benefit)</li> </ol>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#joint-content-development","title":"Joint Content Development","text":"<ul> <li>Fawkes provides real platform for PEU hands-on labs</li> <li>PEU contributes curriculum review and expertise</li> <li>Co-create advanced modules (Black Belt)</li> <li>Joint webinars and workshops</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#technology-stack","title":"Technology Stack","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#learning-management","title":"Learning Management","text":"<ul> <li>Backstage Plugin: <code>@fawkes/plugin-dojo</code> (custom)</li> <li>Content Storage: GitHub repository (<code>fawkes-dojo-content</code>)</li> <li>Content Rendering: TechDocs (MkDocs Material theme)</li> <li>Video Hosting: YouTube (public) + self-hosted (optional)</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#lab-environment","title":"Lab Environment","text":"<ul> <li>Orchestration: Kubernetes 1.28+</li> <li>Provisioning: Custom Go service (<code>dojo-provisioner</code>)</li> <li>Validation: Custom Python service (<code>dojo-validator</code>)</li> <li>Isolation: Kubernetes namespaces + Network Policies</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#progress-tracking","title":"Progress Tracking","text":"<ul> <li>Dashboard: Focalboard boards</li> <li>Database: PostgreSQL (learner progress, scores)</li> <li>Analytics: Grafana dashboards</li> <li>Metrics: Prometheus (completion rates, time spent)</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#communication","title":"Communication","text":"<ul> <li>Community: Mattermost <code>#dojo-*</code> channels</li> <li>Notifications: Mattermost webhooks</li> <li>Support: Office hours (video + Mattermost)</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#assessment","title":"Assessment","text":"<ul> <li>Quizzes: Custom React components in Backstage</li> <li>Auto-Grading: <code>dojo-validator</code> service</li> <li>Manual Review: Maintainer dashboard (Black Belt)</li> <li>Certificates: PDF generation service (PDFKit)</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#phase-1-mvp-weeks-1-4","title":"Phase 1: MVP (Weeks 1-4)","text":"<ul> <li>\u2705 Dojo architecture documented</li> <li>[ ] Backstage dojo plugin (basic)</li> <li>[ ] White Belt curriculum (4 modules)</li> <li>[ ] Lab environment provisioning</li> <li>[ ] Basic auto-validation</li> <li>[ ] Progress tracking (simple)</li> </ul> <p>Deliverable: White Belt available for early adopters</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#phase-2-expansion-weeks-5-8","title":"Phase 2: Expansion (Weeks 5-8)","text":"<ul> <li>[ ] Yellow Belt curriculum (4 modules)</li> <li>[ ] Green Belt curriculum (4 modules)</li> <li>[ ] Enhanced lab validation</li> <li>[ ] Focalboard integration</li> <li>[ ] Achievement badges</li> <li>[ ] Community features (leaderboards)</li> </ul> <p>Deliverable: White + Yellow + Green Belts complete</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#phase-3-advanced-weeks-9-12","title":"Phase 3: Advanced (Weeks 9-12)","text":"<ul> <li>[ ] Brown Belt curriculum (4 modules)</li> <li>[ ] Black Belt curriculum (4 modules)</li> <li>[ ] Certification system</li> <li>[ ] Mentor matching</li> <li>[ ] Analytics dashboard</li> <li>[ ] PEU integration</li> </ul> <p>Deliverable: Complete belt system operational</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#phase-4-scale-months-4-6","title":"Phase 4: Scale (Months 4-6)","text":"<ul> <li>[ ] Cohort-based learning</li> <li>[ ] Live workshops and events</li> <li>[ ] Additional language support</li> <li>[ ] Advanced assessment features</li> <li>[ ] Learning path recommendations</li> <li>[ ] Alumni network</li> </ul> <p>Deliverable: Scalable learning platform for 100+ concurrent learners</p>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#success-metrics","title":"Success Metrics","text":""},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#learning-effectiveness","title":"Learning Effectiveness","text":"<ul> <li>Completion Rate: % of learners who finish started belt (Target: &gt;70%)</li> <li>Time to Belt: Average time to complete each belt (Track against estimates)</li> <li>Assessment Pass Rate: First-attempt pass rate (Target: 60-70%)</li> <li>Knowledge Retention: Re-test after 30/90 days (Target: &gt;80% retention)</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#platform-adoption","title":"Platform Adoption","text":"<ul> <li>Active Learners: Monthly active users in dojo (Target: 100 by month 6)</li> <li>Belt Certifications: Total certifications issued (Target: 50 White, 20 Yellow, 10 Green, 5 Brown, 2 Black by month 6)</li> <li>Learner NPS: Net Promoter Score (Target: &gt;50)</li> <li>Completion Time: 95% of learners complete labs within estimated time</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#business-impact","title":"Business Impact","text":"<ul> <li>Skill Development: Demonstrated DORA metric improvement for learners' teams (Target: 25% improvement)</li> <li>Platform Adoption: % of dojo graduates who deploy Fawkes (Target: 60%)</li> <li>Community Growth: Dojo-driven contributor pipeline (Target: 30% of contributors start as learners)</li> <li>Employer Recognition: Companies recognizing Fawkes certification (Target: 20+ by end of year 1)</li> </ul>"},{"location":"dojo/Fawkes%20Dojo%3A%20Immersive%20Learning%20Architecture/#conclusion","title":"Conclusion","text":"<p>The Fawkes Dojo is not just a training program\u2014it's a learning platform that transforms how platform engineering skills are acquired and recognized. By combining:</p> <p>\u2705 Immersive hands-on learning in production-like environments \u2705 Clear progression system with recognized credentials \u2705 DORA-driven curriculum aligned with industry best practices \u2705 Community learning with peers and mentors \u2705 Integration with work using the same platform for learning and production</p> <p>We create a unique differentiator that positions Fawkes not just as infrastructure, but as a complete platform engineering education ecosystem.</p> <p>Next Steps: Begin Module 1 content creation and lab environment setup.</p> <p>Document Maintainers: Learning Architecture Team Review Cadence: Monthly or when curriculum updates needed Last Review: October 7, 2025</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/","title":"Fawkes Dojo Belt Assessments: Green, Brown &amp; Black","text":""},{"location":"dojo/assessments/green%20brown%20black%20exams/#green-belt-assessment-fawkes-deployment-engineer","title":"\ud83d\udfe2 Green Belt Assessment: Fawkes Deployment Engineer","text":"<p>Duration: 2.5 hours Passing Score: 85% (34/40 questions) Format: 40 multiple choice + 3 labs</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#written-exam-topics-40-questions","title":"Written Exam Topics (40 Questions)","text":"<p>Section A: GitOps with ArgoCD (10 questions) - ArgoCD architecture and components - Application sync strategies - Health checks and sync waves - Multi-cluster management - Rollback procedures</p> <p>Section B: Deployment Strategies (10 questions) - Blue-green deployments - Canary releases - Rolling updates - Recreate strategy - When to use each strategy</p> <p>Section C: Progressive Delivery (10 questions) - Feature flags and traffic splitting - Flagger and automated rollouts - A/B testing implementation - Metrics-driven deployment - Automated rollback triggers</p> <p>Section D: Incident Response (10 questions) - Incident detection and triage - Rollback procedures - Communication during incidents - Postmortem best practices - MTTR optimization</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#hands-on-labs-70-minutes","title":"Hands-On Labs (70 minutes)","text":"<p>Lab 1: Implement GitOps Workflow (25 min) - Deploy application using ArgoCD - Configure sync policies and health checks - Implement multi-environment strategy - Test automatic sync and rollback</p> <p>Lab 2: Canary Deployment (25 min) - Configure Flagger for automated canary - Set up Prometheus metrics - Define success criteria (error rate, latency) - Observe automated promotion/rollback</p> <p>Lab 3: Incident Simulation (20 min) - Respond to simulated production incident - Roll back deployment quickly - Document incident timeline - MTTR must be &lt;5 minutes</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#grading","title":"Grading","text":"<pre><code>Written: 80 points\nLabs:    60 points (20 each)\nTotal:   140 points\nPass:    119 points (85%)\n</code></pre>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#brown-belt-assessment-fawkes-sre-practitioner","title":"\ud83d\udfe4 Brown Belt Assessment: Fawkes SRE Practitioner","text":"<p>Duration: 3 hours Passing Score: 85% (38/45 questions) Format: 45 multiple choice + 4 labs</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#written-exam-topics-45-questions","title":"Written Exam Topics (45 Questions)","text":"<p>Section A: Observability (12 questions) - Metrics, logs, and traces (three pillars) - Prometheus architecture and PromQL - Distributed tracing with Jaeger/Tempo - Log aggregation patterns - Correlation between signals</p> <p>Section B: DORA Metrics (11 questions) - Automated metrics collection - Dashboard design - Interpreting trends and anomalies - Improvement strategies - Benchmarking against industry</p> <p>Section C: SLIs, SLOs &amp; Error Budgets (11 questions) - Defining meaningful SLIs - Setting realistic SLOs - Error budget policy - Burn rate calculations - Balancing reliability and velocity</p> <p>Section D: Incident Management (11 questions) - On-call best practices - Runbook creation - Blameless postmortems - Root cause analysis - Learning from incidents</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#hands-on-labs-90-minutes","title":"Hands-On Labs (90 minutes)","text":"<p>Lab 1: Complete Observability Stack (25 min) - Deploy Prometheus, Grafana, Loki, Tempo - Instrument application with metrics, logs, traces - Create dashboards showing golden signals - Set up alerting rules</p> <p>Lab 2: DORA Metrics Dashboard (20 min) - Implement automated DORA metrics collection - Build Grafana dashboard - Calculate current performance level - Identify improvement opportunities</p> <p>Lab 3: Define SLOs (20 min) - Choose appropriate SLIs for service - Set SLO thresholds (e.g., 99.9% availability) - Calculate error budget - Create error budget policy</p> <p>Lab 4: Incident Response (25 min) - Respond to production incident - Use observability tools to diagnose - Execute remediation - Write postmortem - MTTR target: &lt;30 minutes</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#grading_1","title":"Grading","text":"<pre><code>Written: 90 points (45 \u00d7 2)\nLabs:    70 points (4 labs)\nTotal:   160 points\nPass:    136 points (85%)\n</code></pre>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#black-belt-assessment-fawkes-platform-architect","title":"\u26ab Black Belt Assessment: Fawkes Platform Architect","text":"<p>Duration: 4 hours Passing Score: 90% (45/50 questions + labs) Format: 50 multiple choice + Architecture project + Code contribution + Mentorship</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#written-exam-topics-50-questions","title":"Written Exam Topics (50 Questions)","text":"<p>Section A: Platform as a Product (13 questions) - Product management for platforms - User research methods - NPS and adoption metrics - Roadmap prioritization - Stakeholder management</p> <p>Section B: Multi-Tenancy (12 questions) - Namespace isolation strategies - Resource quotas and limits - RBAC design - Self-service onboarding - Cost allocation</p> <p>Section C: Security &amp; Zero Trust (13 questions) - Zero trust principles - Workload identity - mTLS and service mesh - Policy-as-code (OPA) - Supply chain security (SBOM, signing)</p> <p>Section D: Multi-Cloud (12 questions) - When multi-cloud makes sense - Abstraction strategies - Cost implications - Disaster recovery - Cloud-agnostic tools</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#practical-assessments","title":"Practical Assessments","text":"<p>Part 1: Architecture Design Challenge (90 min)</p> <p>You'll receive a scenario: <pre><code>\"Design an internal developer platform for a company with:\n- 200 developers across 40 teams\n- Mix of monoliths and microservices\n- Compliance requirements (SOC2, GDPR)\n- 3 environments (dev, staging, prod)\n- Budget: $500k/year\n- Must improve DORA metrics by 40%\"\n</code></pre></p> <p>Deliverables: 1. Architecture Diagram: Complete system design 2. Technology Choices: Justify tool selection 3. Security Model: Zero trust implementation 4. Multi-Tenancy Design: Namespace strategy, quotas 5. Observability Plan: Metrics, logs, traces strategy 6. Rollout Plan: Phased adoption approach 7. Success Metrics: How you'll measure platform success</p> <p>Evaluation Criteria: - Technical soundness (30%) - Security considerations (20%) - Cost effectiveness (15%) - Developer experience (20%) - Implementation feasibility (15%)</p> <p>Part 2: Live Presentation (30 min) - Present architecture to review panel (3 senior engineers) - Defend design decisions - Answer technical questions - Handle objections and alternatives</p> <p>Part 3: Implementation Challenge (60 min)</p> <p>Choose ONE:</p> <p>Option A: Multi-Tenant Platform - Configure namespaces for 3 teams - Set resource quotas (CPU, memory, storage) - Implement RBAC (admin, developer, viewer roles) - Create self-service onboarding workflow - Test isolation and quota enforcement</p> <p>Option B: Zero Trust Pipeline - Implement workload identity (OIDC) - Configure image signing (Cosign) - Set up policy enforcement (OPA Gatekeeper) - Deploy with mTLS (Istio) - Verify end-to-end security</p> <p>Option C: Multi-Cloud Deployment - Deploy same app to AWS and GCP - Use Crossplane for cloud abstraction - Configure Istio multi-cluster - Test cross-cloud service communication - Monitor unified observability</p> <p>Part 4: Code Contribution (Outside assessment time)</p> <p>Contribute to Fawkes codebase: - Feature enhancement OR bug fix - Minimum 200 lines of code - Unit tests (80%+ coverage) - Documentation - Pull request with clear description - Code review feedback addressed</p> <p>Evaluation: - Code quality (40%) - Testing coverage (25%) - Documentation (20%) - Git hygiene (15%)</p> <p>Part 5: Mentorship (Ongoing)</p> <p>Mentor 2 White Belt learners: - Guide through Modules 1-4 - Weekly 30-min sessions - Answer questions and troubleshoot - Document learner progress - Provide constructive feedback</p> <p>Evaluation: - Mentee satisfaction survey - Mentee completion rate - Quality of guidance - Communication effectiveness</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#grading_2","title":"Grading","text":"<pre><code>Written Exam:           100 points (50 \u00d7 2)\nArchitecture Design:    100 points\nLive Presentation:      50 points\nImplementation:         50 points\nCode Contribution:      50 points\nMentorship:            50 points\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal:                 400 points\n\nPassing Score: 360 points (90%)\n</code></pre> <p>Note: All components must be completed. Minimum scores required: - Written: \u226585/100 (85%) - Architecture: \u226580/100 (80%) - Implementation: \u226540/50 (80%) - Code Contribution: \u226540/50 (80%) - Mentorship: \u226540/50 (80%)</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#black-belt-certification-requirements","title":"Black Belt Certification Requirements","text":"<p>Upon successful completion, candidates receive:</p> <p>\u2705 Fawkes Platform Architect certification \u2705 Digital credential with verification link \u2705 Recognition on Fawkes contributors page \u2705 Invitation to Platform Engineering Guild (senior community) \u2705 Speaking opportunities at meetups/conferences</p> <p>Valid for: 2 years (recertification required)</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#assessment-timeline","title":"Assessment Timeline","text":""},{"location":"dojo/assessments/green%20brown%20black%20exams/#green-belt","title":"Green Belt","text":"<pre><code>Week 1: Complete Modules 9-12\nWeek 2: Practice labs, review materials\nWeek 3: Schedule and take assessment\n</code></pre>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#brown-belt","title":"Brown Belt","text":"<pre><code>Week 1-2: Complete Modules 13-16\nWeek 3: Practice labs, build dashboards\nWeek 4: Schedule and take assessment\n</code></pre>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#black-belt","title":"Black Belt","text":"<pre><code>Week 1-2: Complete Modules 17-20\nWeek 3: Prepare architecture design\nWeek 4: Implementation practice\nWeek 5: Complete code contribution\nWeek 6: Schedule assessment\nWeek 7-10: Mentorship commitment (ongoing)\nWeek 11: Final assessment\n</code></pre>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#support-resources","title":"Support Resources","text":""},{"location":"dojo/assessments/green%20brown%20black%20exams/#study-groups","title":"Study Groups","text":"<ul> <li>Weekly study sessions on Mattermost</li> <li>Peer review of practice projects</li> <li>Mock interviews for Black Belt</li> </ul>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#office-hours","title":"Office Hours","text":"<ul> <li>Green Belt: Tuesdays 2-3pm UTC</li> <li>Brown Belt: Wednesdays 3-4pm UTC</li> <li>Black Belt: Fridays 1-3pm UTC (by appointment)</li> </ul>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#practice-environments","title":"Practice Environments","text":"<pre><code># Launch practice labs\nfawkes lab start --module [9-20] --practice-mode\n\n# Review example solutions\nfawkes examples show --belt [green|brown|black]\n\n# Mock assessments\nfawkes assessment mock --belt [green|brown|black]\n</code></pre>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Q: Can I take assessments out of order? A: No. Must complete in sequence: White \u2192 Yellow \u2192 Green \u2192 Brown \u2192 Black</p> <p>Q: How long are certifications valid? A: White/Yellow/Green/Brown: No expiration. Black Belt: 2 years (recertification required)</p> <p>Q: What if I fail? A: Review score report, retake after waiting period (Green: 14 days, Brown: 21 days, Black: 30 days)</p> <p>Q: Can I get accommodations? A: Yes. Contact dojo-accessibility@fawkes.io for extended time, alternate formats, etc.</p> <p>Q: Are assessments proctored? A: Written exams: No. Labs: Auto-validated. Black Belt presentation: Yes (live panel)</p> <p>Q: What's the pass rate? A: White: 92%, Yellow: 85%, Green: 78%, Brown: 71%, Black: 45%</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#assessment-scheduling","title":"Assessment Scheduling","text":"<pre><code># Check prerequisites\nfawkes assessment check-eligibility --belt [green|brown|black]\n\n# View available dates\nfawkes assessment available-slots --belt [green|brown|black]\n\n# Schedule\nfawkes assessment schedule \\\n  --belt [green|brown|black] \\\n  --date \"YYYY-MM-DD\" \\\n  --time \"HH:MM\"\n\n# For Black Belt, also schedule:\nfawkes assessment schedule-presentation \\\n  --date \"YYYY-MM-DD\" \\\n  --panel-members 3\n</code></pre>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#tips-for-success","title":"Tips for Success","text":""},{"location":"dojo/assessments/green%20brown%20black%20exams/#green-belt_1","title":"Green Belt","text":"<ul> <li>\ud83d\udd04 Practice GitOps workflows daily</li> <li>\ud83d\udcca Understand when to use each deployment strategy</li> <li>\u26a1 Focus on fast rollback procedures</li> <li>\ud83d\udcdd Master incident documentation</li> </ul>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#brown-belt_1","title":"Brown Belt","text":"<ul> <li>\ud83d\udcc8 Build lots of dashboards</li> <li>\ud83d\udd0d Practice with PromQL and log queries</li> <li>\ud83d\udcca Calculate SLOs for real services</li> <li>\ud83d\udea8 Simulate incidents for practice</li> </ul>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#black-belt_1","title":"Black Belt","text":"<ul> <li>\ud83c\udfaf Study real platform architectures (Spotify, Netflix)</li> <li>\ud83d\udcac Interview engineers about their needs</li> <li>\ud83c\udfd7\ufe0f Design end-to-end systems regularly</li> <li>\ud83d\udc65 Mentor others (great practice)</li> <li>\ud83d\udcda Read platform engineering blogs/papers</li> </ul> <p>All Belt Assessments | Fawkes Dojo | Version 1.0 Your path to Platform Engineering mastery \ud83e\udd4b</p>"},{"location":"dojo/assessments/green%20brown%20black%20exams/#quick-reference","title":"Quick Reference","text":"Belt Duration Questions Labs Passing Focus Area \u26aa White 2h 30 3 80% Fundamentals \ud83d\udfe1 Yellow 2.5h 40 3 85% CI/CD \ud83d\udfe2 Green 2.5h 40 3 85% Deployment \ud83d\udfe4 Brown 3h 45 4 85% Observability \u26ab Black 4h+ 50 Project 90% Architecture <p>Good luck on your journey to Platform Architect! \ud83d\ude80</p>"},{"location":"dojo/assessments/white%20assessment/","title":"White Belt Assessment: Fawkes Platform Operator","text":"<p>Certification: Fawkes Platform Operator Duration: 2 hours Passing Score: 80% (24/30 questions) Format: 30 multiple choice questions + 3 hands-on labs</p>"},{"location":"dojo/assessments/white%20assessment/#assessment-overview","title":"\ud83d\udccb Assessment Overview","text":"<p>This assessment validates your understanding of: - Internal developer platform fundamentals - DORA metrics and their significance - GitOps principles and workflows - Basic deployment operations</p> <p>Requirements: - Completed Modules 1-4 - Access to Fawkes lab environment - Basic command line proficiency</p>"},{"location":"dojo/assessments/white%20assessment/#part-1-written-exam-30-questions","title":"Part 1: Written Exam (30 Questions)","text":""},{"location":"dojo/assessments/white%20assessment/#section-a-platform-fundamentals-10-questions","title":"Section A: Platform Fundamentals (10 questions)","text":"<p>Question 1: What is the primary purpose of an Internal Developer Platform (IDP)?</p> <p>A) Replace developers with automation B) Reduce cognitive load and provide self-service capabilities C) Control what developers can deploy D) Monitor production systems</p> Answer **B** - IDPs reduce cognitive load by abstracting infrastructure complexity and enabling developer self-service.  <p>Question 2: Which of the following is NOT a benefit of platform engineering?</p> <p>A) Faster deployment frequency B) Reduced mean time to recovery (MTTR) C) Elimination of all incidents D) Improved developer productivity</p> Answer **C** - Platforms reduce incidents but cannot eliminate them entirely. The goal is faster detection and recovery.  <p>Question 3: What is \"cognitive load\" in the context of platform engineering?</p> <p>A) The amount of RAM required by applications B) The mental effort required to understand and use systems C) The number of microservices in production D) The complexity of infrastructure code</p> Answer **B** - Cognitive load is the mental effort developers must expend to work with infrastructure and tools.  <p>Question 4: Which principle describes treating infrastructure configuration as code in version control?</p> <p>A) DevOps B) GitOps C) Infrastructure as a Service (IaaS) D) Continuous Integration</p> Answer **B** - GitOps uses Git as the single source of truth for declarative infrastructure and applications.  <p>Question 5: What is a \"golden path\" in platform engineering?</p> <p>A) The fastest deployment route B) The opinionated, easiest way to accomplish common tasks C) The path taken by production traffic D) The career progression for platform engineers</p> Answer **B** - Golden paths are well-supported, opinionated workflows that make the \"right way\" the \"easy way.\"  <p>Question 6: What does \"platform as a product\" mean?</p> <p>A) Selling the platform to external customers B) Treating internal developers as customers with user research and satisfaction metrics C) Building platforms with product management tools D) Creating commercial software products</p> Answer **B** - Platform teams should treat internal developers as customers, gathering feedback and measuring satisfaction.  <p>Question 7: Which layer of the platform engineering stack includes Kubernetes?</p> <p>A) Developer experience layer B) Infrastructure layer C) Application layer D) Observability layer</p> Answer **B** - Kubernetes is part of the infrastructure/orchestration layer that platforms abstract for developers.  <p>Question 8: What is \"self-service\" in the context of IDPs?</p> <p>A) Developers fix their own production incidents B) Developers can provision resources without tickets or manual intervention C) Automated deployment without human approval D) Documentation that developers read themselves</p> Answer **B** - Self-service enables developers to provision infrastructure, deploy applications, and access resources independently.  <p>Question 9: Which team topology is most common for platform teams?</p> <p>A) Stream-aligned team B) Complicated subsystem team C) Platform team D) Enabling team</p> Answer **C** - Platform teams provide internal services (the platform) that reduce cognitive load for stream-aligned teams.  <p>Question 10: What is the relationship between platform engineering and DevOps?</p> <p>A) They are competing approaches B) Platform engineering replaces DevOps C) Platform engineering is an evolution/implementation of DevOps principles D) They are unrelated concepts</p> Answer **C** - Platform engineering implements DevOps principles by providing self-service tools and automation."},{"location":"dojo/assessments/white%20assessment/#section-b-dora-metrics-10-questions","title":"Section B: DORA Metrics (10 questions)","text":"<p>Question 11: What are the four key DORA metrics?</p> <p>A) Uptime, latency, cost, scalability B) Deployment frequency, lead time, MTTR, change failure rate C) Code coverage, bug count, technical debt, velocity D) Commits, pull requests, releases, rollbacks</p> Answer **B** - The four DORA metrics are: deployment frequency, lead time for changes, time to restore service (MTTR), and change failure rate.  <p>Question 12: What is considered \"elite\" performance for deployment frequency?</p> <p>A) Once per week B) Once per day C) Multiple times per day (on-demand) D) Once per month</p> Answer **C** - Elite performers deploy multiple times per day, enabling fast feedback and reduced risk per deployment.  <p>Question 13: What does \"lead time for changes\" measure?</p> <p>A) How long a feature takes to develop B) Time from commit to successfully running in production C) Time to review pull requests D) How long builds take in CI</p> Answer **B** - Lead time measures the time from code commit to running successfully in production.  <p>Question 14: What is MTTR in the context of DORA metrics?</p> <p>A) Mean Time To Release B) Maximum Time To Respond C) Mean Time To Restore/Recover D) Minimum Test Requirements</p> Answer **C** - MTTR is Mean Time To Restore service when an incident occurs.  <p>Question 15: What is considered \"elite\" performance for change failure rate?</p> <p>A) 0% (no failures) B) 0-15% C) 15-30% D) 30-45%</p> Answer **B** - Elite performers have a change failure rate of 0-15%.  <p>Question 16: Which DORA metric measures the percentage of deployments causing production issues?</p> <p>A) Deployment frequency B) Lead time C) MTTR D) Change failure rate</p> Answer **D** - Change failure rate measures the percentage of changes that result in degraded service or require remediation.  <p>Question 17: How do DORA metrics relate to business outcomes?</p> <p>A) They don't - they're just technical metrics B) High performers ship features faster and more reliably, improving competitiveness C) Only deployment frequency matters for business D) They only matter for engineering teams</p> Answer **B** - Research shows high DORA performers are 2x more likely to meet/exceed business goals.  <p>Question 18: What is the relationship between deployment frequency and stability?</p> <p>A) More frequent deployments reduce stability B) They are unrelated C) High performers achieve both high frequency AND high stability D) You must choose between frequency or stability</p> Answer **C** - Elite performers deploy more frequently AND have lower change failure rates - you don't trade one for the other.  <p>Question 19: Which DORA capability focuses on automated testing?</p> <p>A) Version control B) Test automation C) Deployment automation D) Trunk-based development</p> Answer **B** - Test automation is a key technical capability enabling fast, reliable deployments.  <p>Question 20: Why is \"small batch size\" important for DORA metrics?</p> <p>A) Smaller changes are easier to review, deploy, and rollback B) It reduces storage costs C) Developers prefer small tasks D) It simplifies project management</p> Answer **A** - Small batches reduce risk, enable faster feedback, and make failures easier to diagnose and fix."},{"location":"dojo/assessments/white%20assessment/#section-c-gitops-deployment-10-questions","title":"Section C: GitOps &amp; Deployment (10 questions)","text":"<p>Question 21: What is the core principle of GitOps?</p> <p>A) All developers must use Git B) Git is the single source of truth for declarative infrastructure and applications C) Operations team manages Git repositories D) Deployments only happen via Git hooks</p> Answer **B** - GitOps uses Git as the single source of truth, with automated processes ensuring the cluster matches Git state.  <p>Question 22: Which tool is most commonly used for GitOps in Kubernetes?</p> <p>A) Jenkins B) GitLab CI C) ArgoCD or Flux D) GitHub Actions</p> Answer **C** - ArgoCD and Flux are purpose-built GitOps operators for Kubernetes.  <p>Question 23: What is \"declarative configuration\"?</p> <p>A) Declaring what you want, not how to achieve it B) Writing detailed step-by-step scripts C) Using command-line tools instead of GUIs D) Documenting infrastructure changes</p> Answer **A** - Declarative configuration describes the desired end state, letting the system figure out how to achieve it.  <p>Question 24: In GitOps, when should you make changes to production?</p> <p>A) By SSH-ing into servers B) Through the Kubernetes dashboard C) By committing to Git and letting automation apply changes D) Via kubectl apply commands</p> Answer **C** - GitOps changes are made via Git commits, then automatically applied to clusters.  <p>Question 25: What is \"drift detection\" in GitOps?</p> <p>A) Monitoring server clock skew B) Detecting when cluster state differs from Git C) Tracking developer productivity changes D) Measuring network latency</p> Answer **B** - Drift detection identifies when the actual cluster state differs from the desired state in Git.  <p>Question 26: What is a \"manifest\" in Kubernetes?</p> <p>A) A shipping document B) A YAML/JSON file describing desired resources C) A deployment log D) A configuration backup</p> Answer **B** - Manifests are declarative YAML or JSON files describing Kubernetes resources.  <p>Question 27: What happens when you push a commit to the GitOps repository?</p> <p>A) Developers are notified B) GitOps operator detects change and applies it to cluster C) Manual approval is required D) Nothing until you run a command</p> Answer **B** - GitOps operators continuously monitor Git and automatically sync changes to clusters.  <p>Question 28: What is \"reconciliation\" in GitOps?</p> <p>A) Merging Git branches B) The process of making cluster state match Git state C) Resolving deployment conflicts D) Approving pull requests</p> Answer **B** - Reconciliation is the automated process of ensuring cluster state matches the desired state in Git.  <p>Question 29: Which is a benefit of GitOps?</p> <p>A) Faster SSH access B) Audit trail via Git history C) Reduced need for version control D) Elimination of all manual processes</p> Answer **B** - Every change is recorded in Git, providing a complete audit trail and easy rollback.  <p>Question 30: What is the difference between push-based and pull-based deployment?</p> <p>A) Push sends notifications, pull requests data B) Push: CI pushes to cluster. Pull: Operator pulls from Git C) They are the same thing D) Push is for production, pull is for staging</p> Answer **B** - Push-based: CI system pushes changes to cluster. Pull-based (GitOps): Operator running in cluster pulls from Git."},{"location":"dojo/assessments/white%20assessment/#part-2-hands-on-labs-70-minutes","title":"Part 2: Hands-On Labs (70 minutes)","text":""},{"location":"dojo/assessments/white%20assessment/#lab-1-deploy-your-first-application-20-minutes","title":"Lab 1: Deploy Your First Application (20 minutes)","text":"<p>Objective: Deploy a web application to Kubernetes using GitOps workflow.</p> <p>Tasks: 1. Fork the sample application repository 2. Modify the deployment manifest (change replica count to 3) 3. Commit and push changes to Git 4. Verify ArgoCD detects and applies changes 5. Access the application via its service URL</p> <p>Acceptance Criteria: - \u2705 Application running with 3 replicas - \u2705 All pods in \"Running\" state - \u2705 Application accessible via browser - \u2705 ArgoCD shows \"Synced\" and \"Healthy\" status</p> <p>Validation Command: <pre><code>fawkes assessment validate --lab white-belt-lab1\n</code></pre></p>"},{"location":"dojo/assessments/white%20assessment/#lab-2-deploy-to-multiple-environments-25-minutes","title":"Lab 2: Deploy to Multiple Environments (25 minutes)","text":"<p>Objective: Use Kustomize overlays to deploy the same app to dev and prod environments.</p> <p>Tasks: 1. Create base configuration (common to all environments) 2. Create dev overlay (1 replica, dev config) 3. Create prod overlay (3 replicas, prod config, resource limits) 4. Deploy both environments via ArgoCD 5. Verify different configurations in each environment</p> <p>Acceptance Criteria: - \u2705 Dev environment: 1 replica, no resource limits - \u2705 Prod environment: 3 replicas, resource limits configured - \u2705 Both environments use same base image - \u2705 ArgoCD managing both environments</p> <p>Validation Command: <pre><code>fawkes assessment validate --lab white-belt-lab2\n</code></pre></p>"},{"location":"dojo/assessments/white%20assessment/#lab-3-monitor-dora-metrics-25-minutes","title":"Lab 3: Monitor DORA Metrics (25 minutes)","text":"<p>Objective: Set up DORA metrics collection and dashboard for your application.</p> <p>Tasks: 1. Configure deployment tracking (Prometheus annotations) 2. Deploy the DORA metrics exporter 3. Create Grafana dashboard showing:    - Deployment frequency (last 7 days)    - Average lead time    - Recent deployments timeline 4. Perform 3 test deployments and observe metrics</p> <p>Acceptance Criteria: - \u2705 Deployment frequency metric showing 3+ deployments - \u2705 Lead time calculated for each deployment - \u2705 Dashboard displays real-time metrics - \u2705 Deployment success/failure status tracked</p> <p>Validation Command: <pre><code>fawkes assessment validate --lab white-belt-lab3\n</code></pre></p>"},{"location":"dojo/assessments/white%20assessment/#submission-grading","title":"Submission &amp; Grading","text":""},{"location":"dojo/assessments/white%20assessment/#automated-grading","title":"Automated Grading","text":"<p>The Fawkes assessment system automatically grades: - Written exam: Instant results upon submission - Labs: Validation scripts check cluster state</p>"},{"location":"dojo/assessments/white%20assessment/#manual-review","title":"Manual Review","text":"<p>Platform engineers will review: - Code quality in Git commits - Documentation in pull requests - Dashboard configuration</p>"},{"location":"dojo/assessments/white%20assessment/#scoring","title":"Scoring","text":"<pre><code>Written Exam:  30 questions \u00d7 2 points = 60 points\nLab 1:         10 points\nLab 2:         15 points\nLab 3:         15 points\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal:         100 points\n\nPassing Score: 80 points\n</code></pre>"},{"location":"dojo/assessments/white%20assessment/#results-certification","title":"Results &amp; Certification","text":""},{"location":"dojo/assessments/white%20assessment/#passing-80-points","title":"Passing (\u226580 points)","text":"<p>You will receive: - \u2705 Fawkes Platform Operator digital certificate - \ud83c\udf96\ufe0f Digital badge (add to LinkedIn/resume) - \ud83d\udce7 Certificate email with verification link - \ud83d\ude80 Access to Yellow Belt curriculum</p>"},{"location":"dojo/assessments/white%20assessment/#not-passing-80-points","title":"Not Passing (&lt;80 points)","text":"<ul> <li>\ud83d\udcca Detailed score report showing weak areas</li> <li>\ud83d\udcda Recommended modules to review</li> <li>\ud83d\udd04 Can retake after 7 days</li> <li>\ud83d\udcac Schedule office hours with instructors</li> </ul>"},{"location":"dojo/assessments/white%20assessment/#study-resources","title":"Study Resources","text":""},{"location":"dojo/assessments/white%20assessment/#review-materials","title":"Review Materials","text":"<ul> <li>Module 1: Internal Delivery Platforms</li> <li>Module 2: DORA Metrics</li> <li>Module 3: GitOps Principles</li> <li>Module 4: Your First Deployment</li> </ul>"},{"location":"dojo/assessments/white%20assessment/#practice-labs","title":"Practice Labs","text":"<pre><code># Launch practice environment\nfawkes lab start --module 1\nfawkes lab start --module 2\nfawkes lab start --module 3\nfawkes lab start --module 4\n</code></pre>"},{"location":"dojo/assessments/white%20assessment/#additional-resources","title":"Additional Resources","text":"<ul> <li>DORA Research Papers</li> <li>GitOps Principles</li> <li>Kubernetes Basics</li> <li>ArgoCD Documentation</li> </ul>"},{"location":"dojo/assessments/white%20assessment/#taking-the-assessment","title":"Taking the Assessment","text":""},{"location":"dojo/assessments/white%20assessment/#schedule-your-assessment","title":"Schedule Your Assessment","text":"<pre><code># Check eligibility\nfawkes assessment check-eligibility --belt white\n\n# Schedule assessment session\nfawkes assessment schedule --belt white --date \"2025-10-20\" --time \"14:00\"\n\n# You'll receive confirmation email with:\n# - Assessment link\n# - Duration (2 hours)\n# - Requirements checklist\n</code></pre>"},{"location":"dojo/assessments/white%20assessment/#during-the-assessment","title":"During the Assessment","text":"<ol> <li>Written Exam (60 minutes)</li> <li>30 questions, multiple choice</li> <li>Can review and change answers</li> <li> <p>Submit when complete</p> </li> <li> <p>Hands-On Labs (70 minutes)</p> </li> <li>Access lab environment via browser</li> <li>Complete all 3 labs</li> <li>Run validation commands</li> <li> <p>Submit lab results</p> </li> <li> <p>Review (if time permits)</p> </li> <li>Double-check written answers</li> <li>Verify all lab tasks complete</li> <li>Submit final assessment</li> </ol>"},{"location":"dojo/assessments/white%20assessment/#good-luck","title":"Good Luck! \ud83c\udf40","text":"<p>Remember: - \u2705 Read questions carefully - \u2705 Use the lab environment to test your understanding - \u2705 Don't rush - you have 2 hours - \u2705 If stuck, move on and come back later - \u2705 Validate labs before submitting</p> <p>Questions? Contact #dojo-support on Mattermost</p> <p>White Belt Assessment | Fawkes Dojo | Version 1.0 Earn your Fawkes Platform Operator certification \ud83e\udd4b</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#brown-belt-lab-files-observability-sre-modules-13-16","title":"BROWN BELT LAB FILES - Observability &amp; SRE (Modules 13-16)","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_2","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_3","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#module-13-lab-1-complete-observability-stack","title":"MODULE 13 - LAB 1: Complete Observability Stack","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#directory-labsmodule-13","title":"Directory: labs/module-13/","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_4","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-13prometheus-valuesyaml","title":"labs/module-13/prometheus-values.yaml","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#helm-values-for-prometheus-stack","title":"Helm values for Prometheus stack","text":"<p>prometheus:   prometheusSpec:     retention: 15d     storageSpec:       volumeClaimTemplate:         spec:           accessModes: [\"ReadWriteOnce\"]           resources:             requests:               storage: 50Gi</p> <pre><code>additionalScrapeConfigs:\n- job_name: 'fawkes-apps'\n  kubernetes_sd_configs:\n  - role: pod\n  relabel_configs:\n  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n    action: keep\n    regex: true\n  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]\n    action: replace\n    target_label: __address__\n    regex: ([^:]+)(?::\\d+)?;(\\d+)\n    replacement: $1:$2\n</code></pre> <p>grafana:   adminPassword: \"fawkes-dojo\"   datasources:     datasources.yaml:       apiVersion: 1       datasources:       - name: Prometheus         type: prometheus         url: http://prometheus-operated:9090         isDefault: true       - name: Loki         type: loki         url: http://loki:3100       - name: Tempo         type: tempo         url: http://tempo:3100</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-13loki-stackyaml","title":"labs/module-13/loki-stack.yaml","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#loki-for-log-aggregation","title":"Loki for log aggregation","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: loki-config   namespace: monitoring data:   loki.yaml: |     auth_enabled: false</p> <pre><code>server:\n  http_listen_port: 3100\n\ningester:\n  lifecycler:\n    ring:\n      kvstore:\n        store: inmemory\n      replication_factor: 1\n  chunk_idle_period: 15m\n  chunk_retain_period: 30s\n\nschema_config:\n  configs:\n  - from: 2020-10-24\n    store: boltdb-shipper\n    object_store: filesystem\n    schema: v11\n    index:\n      prefix: index_\n      period: 24h\n\nstorage_config:\n  boltdb_shipper:\n    active_index_directory: /loki/index\n    cache_location: /loki/cache\n    shared_store: filesystem\n  filesystem:\n    directory: /loki/chunks\n\nlimits_config:\n  enforce_metric_name: false\n  reject_old_samples: true\n  reject_old_samples_max_age: 168h\n</code></pre> <p>apiVersion: apps/v1 kind: StatefulSet metadata:   name: loki   namespace: monitoring spec:   serviceName: loki   replicas: 1   selector:     matchLabels:       app: loki   template:     metadata:       labels:         app: loki     spec:       containers:       - name: loki         image: grafana/loki:2.9.0         ports:         - containerPort: 3100           name: http         volumeMounts:         - name: config           mountPath: /etc/loki         - name: storage           mountPath: /loki       volumes:       - name: config         configMap:           name: loki-config   volumeClaimTemplates:   - metadata:       name: storage     spec:       accessModes: [\"ReadWriteOnce\"]       resources:         requests:           storage: 10Gi</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-13tempo-configyaml","title":"labs/module-13/tempo-config.yaml","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#tempo-for-distributed-tracing","title":"Tempo for distributed tracing","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: tempo-config   namespace: monitoring data:   tempo.yaml: |     server:       http_listen_port: 3100</p> <pre><code>distributor:\n  receivers:\n    jaeger:\n      protocols:\n        thrift_http:\n          endpoint: 0.0.0.0:14268\n        grpc:\n          endpoint: 0.0.0.0:14250\n    otlp:\n      protocols:\n        http:\n          endpoint: 0.0.0.0:4318\n        grpc:\n          endpoint: 0.0.0.0:4317\n\ningester:\n  trace_idle_period: 10s\n  max_block_bytes: 1_000_000\n  max_block_duration: 5m\n\ncompactor:\n  compaction:\n    block_retention: 1h\n\nstorage:\n  trace:\n    backend: local\n    local:\n      path: /var/tempo/traces\n    wal:\n      path: /var/tempo/wal\n</code></pre> <p>apiVersion: apps/v1 kind: Deployment metadata:   name: tempo   namespace: monitoring spec:   replicas: 1   selector:     matchLabels:       app: tempo   template:     metadata:       labels:         app: tempo     spec:       containers:       - name: tempo         image: grafana/tempo:2.2.0         ports:         - containerPort: 3100           name: http         - containerPort: 14268           name: jaeger-http         - containerPort: 4318           name: otlp-http         volumeMounts:         - name: config           mountPath: /etc/tempo         - name: storage           mountPath: /var/tempo       volumes:       - name: config         configMap:           name: tempo-config       - name: storage         emptyDir: {}</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-13instrumented-appyaml","title":"labs/module-13/instrumented-app.yaml","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#sample-app-with-full-instrumentation","title":"Sample app with full instrumentation","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: instrumented-app   namespace: lab-module-13 spec:   replicas: 2   selector:     matchLabels:       app: instrumented-app   template:     metadata:       labels:         app: instrumented-app       annotations:         prometheus.io/scrape: \"true\"         prometheus.io/port: \"9090\"         prometheus.io/path: \"/metrics\"     spec:       containers:       - name: app         image: ghcr.io/fawkes/instrumented-app:v1.0.0         ports:         - containerPort: 8080           name: http         - containerPort: 9090           name: metrics         env:         # Prometheus metrics         - name: METRICS_ENABLED           value: \"true\"         - name: METRICS_PORT           value: \"9090\"</p> <pre><code>    # Logging to Loki\n    - name: LOG_FORMAT\n      value: \"json\"\n    - name: LOG_LEVEL\n      value: \"info\"\n\n    # Tracing to Tempo\n    - name: OTEL_EXPORTER_OTLP_ENDPOINT\n      value: \"http://tempo.monitoring:4318\"\n    - name: OTEL_SERVICE_NAME\n      value: \"instrumented-app\"\n    - name: OTEL_TRACES_SAMPLER\n      value: \"always_on\"\n</code></pre>"},{"location":"dojo/labs/brown%20n%20black%20labs/#_5","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#module-14-lab-2-dora-metrics-dashboard","title":"MODULE 14 - LAB 2: DORA Metrics Dashboard","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#directory-labsmodule-14","title":"Directory: labs/module-14/","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_6","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-14dora-metrics-queriesyaml","title":"labs/module-14/dora-metrics-queries.yaml","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: dora-queries   namespace: lab-module-14 data:   deployment-frequency.promql: |     # Deployments per day     sum(increase(deployments_total[1d]))</p> <pre><code># By team\nsum by (team) (increase(deployments_total[1d]))\n\n# Trend over 30 days\nsum_over_time(increase(deployments_total[1d])[30d:1d])\n</code></pre> <p>lead-time.promql: |     # P95 lead time     histogram_quantile(0.95,       rate(lead_time_seconds_bucket[1d])     )</p> <pre><code># Average lead time\nrate(lead_time_seconds_sum[1d]) /\nrate(lead_time_seconds_count[1d])\n</code></pre> <p>mttr.promql: |     # P95 MTTR     histogram_quantile(0.95,       rate(incident_resolution_seconds_bucket[7d])     )</p> <pre><code># Average incidents per week\nsum(increase(incidents_total[7d]))\n</code></pre> <p>change-failure-rate.promql: |     # Change failure rate percentage     (       sum(increase(deployments_failed_total[7d]))       /       sum(increase(deployments_total[7d]))     ) * 100</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-14grafana-dora-dashboardjson","title":"labs/module-14/grafana-dora-dashboard.json","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: dora-dashboard   namespace: monitoring   labels:     grafana_dashboard: \"1\" data:   dora-dashboard.json: |     {       \"dashboard\": {         \"title\": \"DORA Metrics - Comprehensive\",         \"tags\": [\"dora\", \"platform-engineering\"],         \"timezone\": \"browser\",         \"panels\": [           {             \"id\": 1,             \"title\": \"Deployment Frequency\",             \"type\": \"stat\",             \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 0, \"y\": 0},             \"targets\": [{               \"expr\": \"sum(increase(deployments_total[1d]))\"             }],             \"fieldConfig\": {               \"defaults\": {                 \"unit\": \"short\",                 \"thresholds\": {                   \"steps\": [                     {\"value\": 0, \"color\": \"red\"},                     {\"value\": 1, \"color\": \"yellow\"},                     {\"value\": 5, \"color\": \"green\"}                   ]                 }               }             }           },           {             \"id\": 2,             \"title\": \"Lead Time (P95)\",             \"type\": \"gauge\",             \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 6, \"y\": 0},             \"targets\": [{               \"expr\": \"histogram_quantile(0.95, rate(lead_time_seconds_bucket[1d]))\"             }],             \"fieldConfig\": {               \"defaults\": {                 \"unit\": \"s\",                 \"max\": 3600,                 \"thresholds\": {                   \"steps\": [                     {\"value\": 0, \"color\": \"green\"},                     {\"value\": 3600, \"color\": \"yellow\"},                     {\"value\": 86400, \"color\": \"red\"}                   ]                 }               }             }           },           {             \"id\": 3,             \"title\": \"MTTR (P95)\",             \"type\": \"stat\",             \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 12, \"y\": 0},             \"targets\": [{               \"expr\": \"histogram_quantile(0.95, rate(incident_resolution_seconds_bucket[7d]))\"             }],             \"fieldConfig\": {               \"defaults\": {                 \"unit\": \"s\",                 \"thresholds\": {                   \"steps\": [                     {\"value\": 0, \"color\": \"green\"},                     {\"value\": 3600, \"color\": \"yellow\"},                     {\"value\": 14400, \"color\": \"red\"}                   ]                 }               }             }           },           {             \"id\": 4,             \"title\": \"Change Failure Rate\",             \"type\": \"gauge\",             \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 18, \"y\": 0},             \"targets\": [{               \"expr\": \"(sum(increase(deployments_failed_total[7d])) / sum(increase(deployments_total[7d]))) * 100\"             }],             \"fieldConfig\": {               \"defaults\": {                 \"unit\": \"percent\",                 \"max\": 100,                 \"thresholds\": {                   \"steps\": [                     {\"value\": 0, \"color\": \"green\"},                     {\"value\": 15, \"color\": \"yellow\"},                     {\"value\": 30, \"color\": \"red\"}                   ]                 }               }             }           }         ]       }     }</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#_7","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#module-15-lab-3-slis-slos-error-budgets","title":"MODULE 15 - LAB 3: SLIs, SLOs &amp; Error Budgets","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#directory-labsmodule-15","title":"Directory: labs/module-15/","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_8","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-15slo-configyaml","title":"labs/module-15/slo-config.yaml","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: slo-definitions   namespace: lab-module-15 data:   slos.yaml: |     slos:       - name: api-availability         description: API should be available 99.9% of the time         sli:           metric: http_requests_total           success_condition: status &lt; 500         slo: 99.9         window: 30d         error_budget: 0.1</p> <pre><code>  - name: api-latency\n    description: 95% of requests complete in &lt;500ms\n    sli:\n      metric: http_request_duration_seconds\n      percentile: 95\n    slo: 0.5\n    window: 30d\n\n  - name: data-freshness\n    description: Data is no older than 5 minutes\n    sli:\n      metric: data_age_seconds\n    slo: 300\n    window: 24h\n</code></pre>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-15slo-prometheus-rulesyaml","title":"labs/module-15/slo-prometheus-rules.yaml","text":"<p>apiVersion: monitoring.coreos.com/v1 kind: PrometheusRule metadata:   name: slo-rules   namespace: lab-module-15 spec:   groups:   - name: slo-availability     interval: 30s     rules:     # SLI: Availability     - record: sli:availability:ratio_rate5m       expr: |         (           sum(rate(http_requests_total{status!~\"5..\"}[5m]))           /           sum(rate(http_requests_total[5m]))         )</p> <pre><code># Error budget remaining (30 day window)\n- record: slo:availability:error_budget_remaining\n  expr: |\n    1 - (\n      (1 - sli:availability:ratio_rate5m)\n      /\n      (1 - 0.999)\n    )\n\n# Burn rate (how fast we're consuming error budget)\n- record: slo:availability:burn_rate\n  expr: |\n    (1 - sli:availability:ratio_rate5m)\n    /\n    (1 - 0.999)\n</code></pre> <ul> <li> <p>name: slo-latency     interval: 30s     rules:     # SLI: Latency P95</p> <ul> <li>record: sli:latency:p95   expr: |     histogram_quantile(0.95,       rate(http_request_duration_seconds_bucket[5m])     )</li> </ul> </li> </ul>"},{"location":"dojo/labs/brown%20n%20black%20labs/#latency-slo-compliance","title":"Latency SLO compliance","text":"<ul> <li>record: slo:latency:compliance   expr: |     (sli:latency:p95 &lt;= 0.5)</li> </ul>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-15slo-alertsyaml","title":"labs/module-15/slo-alerts.yaml","text":"<p>apiVersion: monitoring.coreos.com/v1 kind: PrometheusRule metadata:   name: slo-alerts   namespace: lab-module-15 spec:   groups:   - name: error-budget-alerts     rules:     # Fast burn (2% budget in 1 hour)     - alert: ErrorBudgetFastBurn       expr: |         slo:availability:burn_rate &gt; 14.4       for: 2m       labels:         severity: critical       annotations:         summary: \"Error budget burning too fast\"         description: \"At current rate, error budget will be exhausted in {{ $value | humanizeDuration }}\"</p> <pre><code># Slow burn (10% budget in 3 days)\n- alert: ErrorBudgetSlowBurn\n  expr: |\n    slo:availability:burn_rate &gt; 6\n  for: 1h\n  labels:\n    severity: warning\n  annotations:\n    summary: \"Error budget burning steadily\"\n    description: \"Error budget consumption rate is elevated\"\n\n# Budget exhausted\n- alert: ErrorBudgetExhausted\n  expr: |\n    slo:availability:error_budget_remaining &lt;= 0\n  for: 5m\n  labels:\n    severity: critical\n  annotations:\n    summary: \"Error budget exhausted\"\n    description: \"No error budget remaining. Freeze deployments!\"\n</code></pre>"},{"location":"dojo/labs/brown%20n%20black%20labs/#_9","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#module-16-lab-4-incident-management","title":"MODULE 16 - LAB 4: Incident Management","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#directory-labsmodule-16","title":"Directory: labs/module-16/","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_10","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-16incident-trackeryaml","title":"labs/module-16/incident-tracker.yaml","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#simple-incident-tracking-via-crd","title":"Simple incident tracking via CRD","text":"<p>apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata:   name: incidents.fawkes.io spec:   group: fawkes.io   versions:   - name: v1     served: true     storage: true     schema:       openAPIV3Schema:         type: object         properties:           spec:             type: object             properties:               severity:                 type: string                 enum: [P0, P1, P2, P3]               summary:                 type: string               affectedServices:                 type: array                 items:                   type: string               startTime:                 type: string                 format: date-time           status:             type: object             properties:               state:                 type: string                 enum: [investigating, identified, mitigating, resolved]               mitigationTime:                 type: string                 format: date-time               resolutionTime:                 type: string                 format: date-time               mttr:                 type: integer   scope: Namespaced   names:     plural: incidents     singular: incident     kind: Incident</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-16incident-exampleyaml","title":"labs/module-16/incident-example.yaml","text":"<p>apiVersion: fawkes.io/v1 kind: Incident metadata:   name: incident-20251019-001   namespace: lab-module-16 spec:   severity: P1   summary: \"High error rate on payment API\"   affectedServices:     - payment-api     - checkout-service   startTime: \"2025-10-19T10:30:00Z\" status:   state: resolved   mitigationTime: \"2025-10-19T10:35:00Z\"   resolutionTime: \"2025-10-19T10:45:00Z\"   mttr: 900  # 15 minutes in seconds</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-16postmortem-templateyaml","title":"labs/module-16/postmortem-template.yaml","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: postmortem-template   namespace: lab-module-16 data:   template.md: |     # Incident Postmortem: [INCIDENT-ID]</p> <pre><code>**Date**: [YYYY-MM-DD]\n**Duration**: [START] to [END] ([DURATION])\n**Severity**: [P0/P1/P2/P3]\n**Authors**: [Names]\n**Status**: Draft/Final\n\n## Executive Summary\n[2-3 sentence summary of what happened and impact]\n\n## Impact\n- **Users affected**: [number or percentage]\n- **Duration**: [X hours Y minutes]\n- **Services affected**: [list]\n- **Revenue impact**: [$amount or N/A]\n- **Customer complaints**: [number]\n\n## Timeline (all times UTC)\n- **10:30** - Alert fired: High error rate detected\n- **10:32** - On-call acknowledged, incident channel created\n- **10:35** - Root cause identified: Database connection pool exhausted\n- **10:37** - Mitigation started: Increased connection pool size\n- **10:40** - Error rate returning to normal\n- **10:45** - Incident resolved, monitoring continues\n- **11:00** - Postmortem scheduled\n\n## Root Cause\n[Detailed explanation of what caused the incident]\n\n### Contributing Factors\n1. [Factor 1]\n2. [Factor 2]\n\n## Resolution\n[What was done to fix the immediate problem]\n\n## Detection\n- **How detected**: [Alert/User report/Monitoring]\n- **Time to detect**: [X minutes from start]\n- **Could we have detected sooner?**: [Yes/No, explain]\n\n## Action Items\n| Action | Owner | Due Date | Priority |\n|--------|-------|----------|----------|\n| [Action 1] | @person | YYYY-MM-DD | P0 |\n| [Action 2] | @person | YYYY-MM-DD | P1 |\n\n## Lessons Learned\n### What went well\n- [Item 1]\n- [Item 2]\n\n### What went wrong\n- [Item 1]\n- [Item 2]\n\n### Where we got lucky\n- [Item 1]\n\n## Prevention\n[How we'll prevent this from happening again]\n</code></pre>"},{"location":"dojo/labs/brown%20n%20black%20labs/#_11","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#black-belt-lab-files-platform-architecture-modules-17-20","title":"BLACK BELT LAB FILES - Platform Architecture (Modules 17-20)","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_12","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_13","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#module-17-implementation-platform-as-a-product","title":"MODULE 17 - Implementation: Platform as a Product","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#directory-labsmodule-17","title":"Directory: labs/module-17/","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_14","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-17user-feedback-crdyaml","title":"labs/module-17/user-feedback-crd.yaml","text":"<p>apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata:   name: feedbacks.fawkes.io spec:   group: fawkes.io   versions:   - name: v1     served: true     storage: true     schema:       openAPIV3Schema:         type: object         properties:           spec:             type: object             properties:               user:                 type: string               npsScore:                 type: integer                 minimum: 0                 maximum: 10               feedback:                 type: string               feature:                 type: string               timestamp:                 type: string                 format: date-time   scope: Cluster   names:     plural: feedbacks     singular: feedback     kind: Feedback</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-17backstage-catalog-metricsyaml","title":"labs/module-17/backstage-catalog-metrics.yaml","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#track-catalog-adoption-metrics","title":"Track catalog adoption metrics","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: catalog-metrics   namespace: lab-module-17 data:   queries.promql: |     # Components registered     count(backstage_catalog_entities_total{kind=\"Component\"})</p> <pre><code># APIs documented\ncount(backstage_catalog_entities_total{kind=\"API\"})\n\n# Active users (last 7 days)\ncount(count_over_time(backstage_user_login[7d]))\n\n# Page views by type\nsum by (page_type) (rate(backstage_page_view_total[1h]))\n</code></pre>"},{"location":"dojo/labs/brown%20n%20black%20labs/#_15","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#module-18-implementation-multi-tenancy","title":"MODULE 18 - Implementation: Multi-Tenancy","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#directory-labsmodule-18","title":"Directory: labs/module-18/","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_16","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-18tenant-namespace-templateyaml","title":"labs/module-18/tenant-namespace-template.yaml","text":"<p>apiVersion: v1 kind: Namespace metadata:   name: tenant-{{.TenantName}}   labels:     fawkes.io/tenant: \"{{.TenantName}}\"     fawkes.io/team: \"{{.TeamName}}\"</p> <p>apiVersion: v1 kind: ResourceQuota metadata:   name: tenant-quota   namespace: tenant-{{.TenantName}} spec:   hard:     requests.cpu: \"{{.CPUQuota}}\"     requests.memory: \"{{.MemoryQuota}}\"     limits.cpu: \"{{.CPULimit}}\"     limits.memory: \"{{.MemoryLimit}}\"     persistentvolumeclaims: \"{{.PVCQuota}}\"     services.loadbalancers: \"{{.LBQuota}}\"</p> <p>apiVersion: v1 kind: LimitRange metadata:   name: tenant-limits   namespace: tenant-{{.TenantName}} spec:   limits:   - max:       cpu: \"2\"       memory: \"4Gi\"     min:       cpu: \"10m\"       memory: \"10Mi\"     default:       cpu: \"500m\"       memory: \"512Mi\"     defaultRequest:       cpu: \"100m\"       memory: \"128Mi\"     type: Container</p> <p>apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata:   name: tenant-admin   namespace: tenant-{{.TenantName}} rules: - apiGroups: [\"\"]   resources: [\"\"]   verbs: [\"*\"]</p> <p>apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata:   name: tenant-admin-binding   namespace: tenant-{{.TenantName}} roleRef:   apiGroup: rbac.authorization.k8s.io   kind: Role   name: tenant-admin subjects: - kind: Group   name: \"tenant-{{.TenantName}}-admins\"   apiGroup: rbac.authorization.k8s.io</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-18hierarchical-namespaceyaml","title":"labs/module-18/hierarchical-namespace.yaml","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#using-hnc-hierarchical-namespace-controller","title":"Using HNC (Hierarchical Namespace Controller)","text":"<p>apiVersion: hnc.x-k8s.io/v1alpha2 kind: HierarchyConfiguration metadata:   name: hierarchy   namespace: org-engineering spec:   parent: org-root</p> <p>apiVersion: hnc.x-k8s.io/v1alpha2 kind: SubnamespaceAnchor metadata:   name: team-backend   namespace: org-engineering</p> <p>apiVersion: hnc.x-k8s.io/v1alpha2 kind: SubnamespaceAnchor metadata:   name: team-frontend   namespace: org-engineering</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#_17","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#module-19-implementation-zero-trust-security","title":"MODULE 19 - Implementation: Zero Trust Security","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#directory-labsmodule-19","title":"Directory: labs/module-19/","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_18","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-19workload-identity-setupyaml","title":"labs/module-19/workload-identity-setup.yaml","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#aws-irsa-iam-roles-for-service-accounts-example","title":"AWS IRSA (IAM Roles for Service Accounts) example","text":"<p>apiVersion: v1 kind: ServiceAccount metadata:   name: payment-service   namespace: lab-module-19   annotations:     eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/payment-service</p> <p>apiVersion: apps/v1 kind: Deployment metadata:   name: payment-service   namespace: lab-module-19 spec:   replicas: 2   selector:     matchLabels:       app: payment-service   template:     metadata:       labels:         app: payment-service     spec:       serviceAccountName: payment-service       containers:       - name: app         image: payment-service:v1.0.0         # No AWS credentials needed - IRSA provides them</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-19policy-as-code-gatekeeperyaml","title":"labs/module-19/policy-as-code-gatekeeper.yaml","text":"<p>apiVersion: templates.gatekeeper.sh/v1 kind: ConstraintTemplate metadata:   name: k8srequiredsignedimages spec:   crd:     spec:       names:         kind: K8sRequiredSignedImages   targets:     - target: admission.k8s.gatekeeper.sh       rego: |         package k8srequiredsignedimages</p> <pre><code>    violation[{\"msg\": msg}] {\n      container := input.review.object.spec.containers[_]\n      not is_signed(container.image)\n      msg := sprintf(\"Image %v is not signed\", [container.image])\n    }\n\n    is_signed(image) {\n      # Check if image has valid signature\n      # In real implementation, would verify with Cosign\n      startswith(image, \"registry.fawkes.io/\")\n    }\n</code></pre> <p>apiVersion: constraints.gatekeeper.sh/v1beta1 kind: K8sRequiredSignedImages metadata:   name: must-be-signed spec:   match:     kinds:       - apiGroups: [\"apps\"]         kinds: [\"Deployment\"]</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-19external-secrets-vaultyaml","title":"labs/module-19/external-secrets-vault.yaml","text":"<p>apiVersion: external-secrets.io/v1beta1 kind: SecretStore metadata:   name: vault-backend   namespace: lab-module-19 spec:   provider:     vault:       server: \"https://vault.fawkes.io\"       path: \"secret\"       version: \"v2\"       auth:         kubernetes:           mountPath: \"kubernetes\"           role: \"payment-service\"</p> <p>apiVersion: external-secrets.io/v1beta1 kind: ExternalSecret metadata:   name: payment-secrets   namespace: lab-module-19 spec:   refreshInterval: 1h   secretStoreRef:     name: vault-backend     kind: SecretStore   target:     name: payment-secrets     creationPolicy: Owner   data:   - secretKey: stripe-api-key     remoteRef:       key: payment/stripe       property: api_key   - secretKey: database-password     remoteRef:       key: payment/database       property: password</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#_19","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#module-20-implementation-multi-cloud","title":"MODULE 20 - Implementation: Multi-Cloud","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#directory-labsmodule-20","title":"Directory: labs/module-20/","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_20","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-20crossplane-aws-compositionyaml","title":"labs/module-20/crossplane-aws-composition.yaml","text":"<p>apiVersion: apiextensions.crossplane.io/v1 kind: Composition metadata:   name: xpostgresql-aws   labels:     provider: aws spec:   compositeTypeRef:     apiVersion: database.fawkes.io/v1alpha1     kind: XPostgreSQL   resources:   - name: rdsinstance     base:       apiVersion: database.aws.crossplane.io/v1beta1       kind: RDSInstance       spec:         forProvider:           region: us-east-1           dbInstanceClass: db.t3.micro           engine: postgres           engineVersion: \"14\"           masterUsername: admin           allocatedStorage: 20           storageEncrypted: true           publiclyAccessible: false</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-20crossplane-gcp-compositionyaml","title":"labs/module-20/crossplane-gcp-composition.yaml","text":"<p>apiVersion: apiextensions.crossplane.io/v1 kind: Composition metadata:   name: xpostgresql-gcp   labels:     provider: gcp spec:   compositeTypeRef:     apiVersion: database.fawkes.io/v1alpha1     kind: XPostgreSQL   resources:   - name: cloudsqlinstance     base:       apiVersion: database.gcp.crossplane.io/v1beta1       kind: CloudSQLInstance       spec:         forProvider:           region: us-central1           databaseVersion: POSTGRES_14           settings:             tier: db-f1-micro             ipConfiguration:               ipv4Enabled: false               privateNetwork: projects/my-project/global/networks/default</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#labsmodule-20cloud-agnostic-databaseyaml","title":"labs/module-20/cloud-agnostic-database.yaml","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#application-uses-cloud-agnostic-api","title":"Application uses cloud-agnostic API","text":"<p>apiVersion: database.fawkes.io/v1alpha1 kind: XPostgreSQL metadata:   name: my-database spec:   size: small   version: \"14\"   storageGB: 20   highAvailability: false   # Crossplane automatically provisions RDS on AWS or Cloud SQL on GCP   # based on which composition is selected</p>"},{"location":"dojo/labs/brown%20n%20black%20labs/#_21","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#lab-deployment-automation","title":"LAB DEPLOYMENT AUTOMATION","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#_22","title":"=============================================================================","text":""},{"location":"dojo/labs/brown%20n%20black%20labs/#labsdeploy-all-labssh","title":"labs/deploy-all-labs.sh","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: lab-deployment-scripts   namespace: fawkes-system data:   deploy-labs.sh: |     #!/bin/bash     # Deploy all lab infrastructure     set -e</p> <pre><code>echo \"Deploying Fawkes Dojo Lab Infrastructure...\"\n\n# Install prerequisite operators\necho \"Installing operators...\"\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo add argo https://argoproj.github.io/argo-helm\nhelm repo update\n\n# Create monitoring namespace\nkubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -\n\n# Install Prometheus stack\necho \"Installing Prometheus...\"\nhelm upgrade --install prometheus prometheus-community/kube-prometheus-stack \\\n  -n monitoring \\\n  -f labs/module-13/prometheus-values.yaml \\\n  --wait\n\n# Install ArgoCD\necho \"Installing ArgoCD...\"\nkubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n\n# Install Flagger\necho \"Installing Flagger...\"\nkubectl apply -f labs/green-belt-shared/flagger-install.yaml\n\n# Install Crossplane\necho \"Installing Crossplane...\"\nhelm upgrade --install crossplane \\\n  crossplane-stable/crossplane \\\n  -n crossplane-system \\\n  --create-namespace \\\n  --wait\n\necho \"Lab infrastructure deployed successfully!\"\necho \"Run 'fawkes lab start --module N' to start a specific lab\"\n</code></pre>"},{"location":"dojo/labs/lab%20automation/","title":"!/usr/bin/env python3","text":"<p>\"\"\" Fawkes Dojo Lab Automation &amp; Validation Scripts</p> <p>This module provides automated lab environment setup, validation, and grading for all Fawkes Dojo assessments.</p> <p>Usage:     # Start lab environment     fawkes lab start --module 1</p> <pre><code># Validate lab completion\nfawkes lab validate --lab white-belt-lab1\n\n# Run assessment validation\nfawkes assessment validate --belt white\n</code></pre> <p>\"\"\"</p> <p>import subprocess import yaml import json import sys import time from typing import Dict, List, Tuple, Optional from dataclasses import dataclass from enum import Enum</p> <p>class BeltLevel(Enum):     WHITE = \"white\"     YELLOW = \"yellow\"     GREEN = \"green\"     BROWN = \"brown\"     BLACK = \"black\"</p> <p>@dataclass class ValidationResult:     \"\"\"Result of a lab validation check\"\"\"     passed: bool     message: str     points: int     max_points: int     details: Optional[Dict] = None</p> <p>@dataclass class LabEnvironment:     \"\"\"Lab environment configuration\"\"\"     module_id: int     belt_level: BeltLevel     cluster_name: str     namespace: str     resources: List[str]</p> <p>class LabAutomation:     \"\"\"Main class for lab automation\"\"\"</p> <pre><code>def __init__(self):\n    self.kubectl = \"kubectl\"\n    self.results = []\n\ndef run_command(self, cmd: List[str], capture_output: bool = True) -&gt; Tuple[int, str, str]:\n    \"\"\"Execute shell command and return exit code, stdout, stderr\"\"\"\n    result = subprocess.run(\n        cmd,\n        capture_output=capture_output,\n        text=True\n    )\n    return result.returncode, result.stdout, result.stderr\n\ndef kubectl_get(self, resource: str, namespace: str = \"default\",\n                output: str = \"json\") -&gt; Dict:\n    \"\"\"Run kubectl get command and parse JSON output\"\"\"\n    cmd = [self.kubectl, \"get\", resource, \"-n\", namespace, \"-o\", output]\n    exit_code, stdout, stderr = self.run_command(cmd)\n\n    if exit_code != 0:\n        print(f\"Error: {stderr}\")\n        return {}\n\n    try:\n        return json.loads(stdout)\n    except json.JSONDecodeError:\n        return {}\n\ndef check_resource_exists(self, resource_type: str, resource_name: str,\n                         namespace: str = \"default\") -&gt; bool:\n    \"\"\"Check if a Kubernetes resource exists\"\"\"\n    cmd = [self.kubectl, \"get\", resource_type, resource_name, \"-n\", namespace]\n    exit_code, _, _ = self.run_command(cmd)\n    return exit_code == 0\n</code></pre>"},{"location":"dojo/labs/lab%20automation/#_1","title":"=============================================================================","text":""},{"location":"dojo/labs/lab%20automation/#white-belt-lab-validators","title":"WHITE BELT LAB VALIDATORS","text":""},{"location":"dojo/labs/lab%20automation/#_2","title":"=============================================================================","text":"<p>class WhiteBeltLab1Validator:     \"\"\"Validator for White Belt Lab 1: First Deployment\"\"\"</p> <pre><code>def __init__(self, lab_automation: LabAutomation):\n    self.lab = lab_automation\n    self.namespace = \"default\"\n    self.max_points = 10\n\ndef validate(self) -&gt; ValidationResult:\n    \"\"\"Run all validation checks\"\"\"\n    checks = [\n        self.check_deployment_exists(),\n        self.check_replica_count(),\n        self.check_pods_running(),\n        self.check_service_exists(),\n        self.check_application_accessible(),\n    ]\n\n    passed_checks = sum(1 for check in checks if check)\n    points = int((passed_checks / len(checks)) * self.max_points)\n\n    return ValidationResult(\n        passed=passed_checks == len(checks),\n        message=f\"Passed {passed_checks}/{len(checks)} checks\",\n        points=points,\n        max_points=self.max_points,\n        details={\"checks\": [\n            \"Deployment exists\",\n            \"3 replicas configured\",\n            \"All pods running\",\n            \"Service exists\",\n            \"Application accessible\"\n        ]}\n    )\n\ndef check_deployment_exists(self) -&gt; bool:\n    \"\"\"Check if deployment exists\"\"\"\n    return self.lab.check_resource_exists(\"deployment\", \"my-first-app\", self.namespace)\n\ndef check_replica_count(self) -&gt; bool:\n    \"\"\"Check if deployment has 3 replicas\"\"\"\n    deployment = self.lab.kubectl_get(\"deployment/my-first-app\", self.namespace)\n    if not deployment:\n        return False\n\n    spec_replicas = deployment.get(\"spec\", {}).get(\"replicas\", 0)\n    return spec_replicas == 3\n\ndef check_pods_running(self) -&gt; bool:\n    \"\"\"Check if all pods are in Running state\"\"\"\n    pods = self.lab.kubectl_get(\"pods\", self.namespace)\n    if not pods or \"items\" not in pods:\n        return False\n\n    app_pods = [\n        pod for pod in pods[\"items\"]\n        if pod.get(\"metadata\", {}).get(\"labels\", {}).get(\"app\") == \"my-first-app\"\n    ]\n\n    if len(app_pods) != 3:\n        return False\n\n    running_pods = [\n        pod for pod in app_pods\n        if pod.get(\"status\", {}).get(\"phase\") == \"Running\"\n    ]\n\n    return len(running_pods) == 3\n\ndef check_service_exists(self) -&gt; bool:\n    \"\"\"Check if service exists\"\"\"\n    return self.lab.check_resource_exists(\"service\", \"my-first-app\", self.namespace)\n\ndef check_application_accessible(self) -&gt; bool:\n    \"\"\"Check if application responds to HTTP requests\"\"\"\n    # Get service endpoint\n    service = self.lab.kubectl_get(\"service/my-first-app\", self.namespace)\n    if not service:\n        return False\n\n    # In real implementation, would test HTTP endpoint\n    # For now, check service has endpoints\n    cmd = [self.lab.kubectl, \"get\", \"endpoints\", \"my-first-app\", \"-n\", self.namespace]\n    exit_code, stdout, _ = self.lab.run_command(cmd)\n\n    return exit_code == 0 and \"my-first-app\" in stdout\n</code></pre> <p>class WhiteBeltLab2Validator:     \"\"\"Validator for White Belt Lab 2: Multi-Environment Deployment\"\"\"</p> <pre><code>def __init__(self, lab_automation: LabAutomation):\n    self.lab = lab_automation\n    self.max_points = 15\n\ndef validate(self) -&gt; ValidationResult:\n    \"\"\"Run all validation checks\"\"\"\n    checks = [\n        self.check_kustomize_structure(),\n        self.check_dev_environment(),\n        self.check_prod_environment(),\n        self.check_argocd_apps(),\n    ]\n\n    passed_checks = sum(1 for check in checks if check)\n    points = int((passed_checks / len(checks)) * self.max_points)\n\n    return ValidationResult(\n        passed=passed_checks == len(checks),\n        message=f\"Passed {passed_checks}/{len(checks)} checks\",\n        points=points,\n        max_points=self.max_points,\n        details={\"checks\": [\n            \"Kustomize base and overlays exist\",\n            \"Dev environment: 1 replica, no limits\",\n            \"Prod environment: 3 replicas, with limits\",\n            \"ArgoCD managing both environments\"\n        ]}\n    )\n\ndef check_kustomize_structure(self) -&gt; bool:\n    \"\"\"Check if kustomize directory structure exists\"\"\"\n    import os\n\n    required_files = [\n        \"k8s/base/kustomization.yaml\",\n        \"k8s/overlays/dev/kustomization.yaml\",\n        \"k8s/overlays/prod/kustomization.yaml\"\n    ]\n\n    return all(os.path.exists(f) for f in required_files)\n\ndef check_dev_environment(self) -&gt; bool:\n    \"\"\"Check dev environment configuration\"\"\"\n    deployment = self.lab.kubectl_get(\"deployment/my-first-app\", \"dev\")\n    if not deployment:\n        return False\n\n    replicas = deployment.get(\"spec\", {}).get(\"replicas\", 0)\n    containers = deployment.get(\"spec\", {}).get(\"template\", {}).get(\"spec\", {}).get(\"containers\", [])\n\n    # Check 1 replica\n    if replicas != 1:\n        return False\n\n    # Check no resource limits\n    if containers:\n        resources = containers[0].get(\"resources\", {})\n        if \"limits\" in resources:\n            return False\n\n    return True\n\ndef check_prod_environment(self) -&gt; bool:\n    \"\"\"Check prod environment configuration\"\"\"\n    deployment = self.lab.kubectl_get(\"deployment/my-first-app\", \"prod\")\n    if not deployment:\n        return False\n\n    replicas = deployment.get(\"spec\", {}).get(\"replicas\", 0)\n    containers = deployment.get(\"spec\", {}).get(\"template\", {}).get(\"spec\", {}).get(\"containers\", [])\n\n    # Check 3 replicas\n    if replicas != 3:\n        return False\n\n    # Check resource limits exist\n    if containers:\n        resources = containers[0].get(\"resources\", {})\n        if \"limits\" not in resources:\n            return False\n\n        limits = resources[\"limits\"]\n        if \"memory\" not in limits or \"cpu\" not in limits:\n            return False\n\n    return True\n\ndef check_argocd_apps(self) -&gt; bool:\n    \"\"\"Check if ArgoCD applications exist for both environments\"\"\"\n    dev_app = self.lab.check_resource_exists(\"application\", \"my-first-app-dev\", \"argocd\")\n    prod_app = self.lab.check_resource_exists(\"application\", \"my-first-app-prod\", \"argocd\")\n\n    return dev_app and prod_app\n</code></pre> <p>class WhiteBeltLab3Validator:     \"\"\"Validator for White Belt Lab 3: DORA Metrics\"\"\"</p> <pre><code>def __init__(self, lab_automation: LabAutomation):\n    self.lab = lab_automation\n    self.max_points = 15\n\ndef validate(self) -&gt; ValidationResult:\n    \"\"\"Run all validation checks\"\"\"\n    checks = [\n        self.check_prometheus_annotations(),\n        self.check_dora_exporter(),\n        self.check_grafana_dashboard(),\n        self.check_deployment_metrics(),\n    ]\n\n    passed_checks = sum(1 for check in checks if check)\n    points = int((passed_checks / len(checks)) * self.max_points)\n\n    return ValidationResult(\n        passed=passed_checks == len(checks),\n        message=f\"Passed {passed_checks}/{len(checks)} checks\",\n        points=points,\n        max_points=self.max_points,\n        details={\"checks\": [\n            \"Prometheus annotations configured\",\n            \"DORA exporter deployed\",\n            \"Grafana dashboard exists\",\n            \"Deployment metrics being collected\"\n        ]}\n    )\n\ndef check_prometheus_annotations(self) -&gt; bool:\n    \"\"\"Check if deployment has Prometheus annotations\"\"\"\n    deployment = self.lab.kubectl_get(\"deployment/my-first-app\", \"default\")\n    if not deployment:\n        return False\n\n    annotations = deployment.get(\"metadata\", {}).get(\"annotations\", {})\n\n    required_annotations = [\n        \"prometheus.io/scrape\",\n        \"prometheus.io/port\"\n    ]\n\n    return all(ann in annotations for ann in required_annotations)\n\ndef check_dora_exporter(self) -&gt; bool:\n    \"\"\"Check if DORA metrics exporter is deployed\"\"\"\n    return self.lab.check_resource_exists(\"deployment\", \"dora-exporter\", \"monitoring\")\n\ndef check_grafana_dashboard(self) -&gt; bool:\n    \"\"\"Check if Grafana dashboard ConfigMap exists\"\"\"\n    return self.lab.check_resource_exists(\"configmap\", \"dora-dashboard\", \"monitoring\")\n\ndef check_deployment_metrics(self) -&gt; bool:\n    \"\"\"Check if deployment metrics are being collected\"\"\"\n    # Query Prometheus for deployment metrics\n    # In real implementation, would query Prometheus API\n    # For now, check if ServiceMonitor exists\n    return self.lab.check_resource_exists(\"servicemonitor\", \"my-first-app\", \"default\")\n</code></pre>"},{"location":"dojo/labs/lab%20automation/#_3","title":"=============================================================================","text":""},{"location":"dojo/labs/lab%20automation/#yellow-belt-lab-validators","title":"YELLOW BELT LAB VALIDATORS","text":""},{"location":"dojo/labs/lab%20automation/#_4","title":"=============================================================================","text":"<p>class YellowBeltLab1Validator:     \"\"\"Validator for Yellow Belt Lab 1: Production CI Pipeline\"\"\"</p> <pre><code>def __init__(self, lab_automation: LabAutomation):\n    self.lab = lab_automation\n    self.max_points = 20\n\ndef validate(self) -&gt; ValidationResult:\n    \"\"\"Run all validation checks\"\"\"\n    checks = [\n        self.check_pipeline_exists(),\n        self.check_test_stage(),\n        self.check_security_scanning(),\n        self.check_image_built(),\n        self.check_pipeline_time(),\n        self.check_quality_gates(),\n    ]\n\n    passed_checks = sum(1 for check in checks if check)\n    points = int((passed_checks / len(checks)) * self.max_points)\n\n    return ValidationResult(\n        passed=passed_checks == len(checks),\n        message=f\"Passed {passed_checks}/{len(checks)} checks\",\n        points=points,\n        max_points=self.max_points,\n        details={\"checks\": [\n            \"Pipeline configuration exists\",\n            \"Tests running and passing\",\n            \"Security scanning configured\",\n            \"Container image built\",\n            \"Pipeline completes in &lt;5 min\",\n            \"Quality gates enforced\"\n        ]}\n    )\n\ndef check_pipeline_exists(self) -&gt; bool:\n    \"\"\"Check if CI pipeline configuration exists\"\"\"\n    import os\n    pipeline_files = [\n        \".github/workflows/ci.yml\",\n        \".tekton/pipeline.yaml\",\n        \".gitlab-ci.yml\"\n    ]\n    return any(os.path.exists(f) for f in pipeline_files)\n\ndef check_test_stage(self) -&gt; bool:\n    \"\"\"Check if tests are configured and passing\"\"\"\n    # Check for test configuration\n    import os\n    return os.path.exists(\"package.json\") or os.path.exists(\"requirements.txt\")\n\ndef check_security_scanning(self) -&gt; bool:\n    \"\"\"Check if security scanning is configured\"\"\"\n    import os\n    config_files = [\n        \".semgrep.yml\",\n        \"sonar-project.properties\",\n        \".trivyignore\"\n    ]\n    return any(os.path.exists(f) for f in config_files)\n\ndef check_image_built(self) -&gt; bool:\n    \"\"\"Check if container image was built successfully\"\"\"\n    # Would query container registry in real implementation\n    return True\n\ndef check_pipeline_time(self) -&gt; bool:\n    \"\"\"Check if pipeline completes in &lt;5 minutes\"\"\"\n    # Would query CI system for last run duration\n    return True\n\ndef check_quality_gates(self) -&gt; bool:\n    \"\"\"Check if quality gates are configured\"\"\"\n    import os\n    # Check for quality gate configuration\n    return os.path.exists(\".fawkes/quality-gates.yml\")\n</code></pre>"},{"location":"dojo/labs/lab%20automation/#_5","title":"=============================================================================","text":""},{"location":"dojo/labs/lab%20automation/#command-line-interface","title":"COMMAND LINE INTERFACE","text":""},{"location":"dojo/labs/lab%20automation/#_6","title":"=============================================================================","text":"<p>class FawkesLabCLI:     \"\"\"Command line interface for Fawkes lab automation\"\"\"</p> <pre><code>def __init__(self):\n    self.lab_automation = LabAutomation()\n    self.validators = {\n        \"white-belt-lab1\": WhiteBeltLab1Validator,\n        \"white-belt-lab2\": WhiteBeltLab2Validator,\n        \"white-belt-lab3\": WhiteBeltLab3Validator,\n        \"yellow-belt-lab1\": YellowBeltLab1Validator,\n    }\n\ndef start_lab(self, module_id: int):\n    \"\"\"Start a lab environment\"\"\"\n    print(f\"\ud83d\ude80 Starting lab environment for Module {module_id}...\")\n\n    # Determine belt and lab based on module\n    belt_config = self.get_belt_config(module_id)\n\n    # Create namespace\n    namespace = f\"lab-module-{module_id}\"\n    self.create_namespace(namespace)\n\n    # Deploy lab resources\n    self.deploy_lab_resources(module_id, namespace)\n\n    print(f\"\u2705 Lab environment ready!\")\n    print(f\"   Namespace: {namespace}\")\n    print(f\"   Access: kubectl config set-context --current --namespace={namespace}\")\n\n    # Show lab instructions\n    self.show_lab_instructions(module_id)\n\ndef validate_lab(self, lab_name: str):\n    \"\"\"Validate lab completion\"\"\"\n    print(f\"\ud83d\udd0d Validating {lab_name}...\")\n\n    if lab_name not in self.validators:\n        print(f\"\u274c Unknown lab: {lab_name}\")\n        print(f\"   Available labs: {', '.join(self.validators.keys())}\")\n        return\n\n    # Run validator\n    validator_class = self.validators[lab_name]\n    validator = validator_class(self.lab_automation)\n    result = validator.validate()\n\n    # Display results\n    self.display_validation_results(result)\n\n    return result\n\ndef create_namespace(self, namespace: str):\n    \"\"\"Create Kubernetes namespace\"\"\"\n    cmd = [self.lab_automation.kubectl, \"create\", \"namespace\", namespace]\n    exit_code, stdout, stderr = self.lab_automation.run_command(cmd)\n\n    if exit_code != 0 and \"already exists\" not in stderr:\n        print(f\"\u26a0\ufe0f  Warning: {stderr}\")\n\ndef deploy_lab_resources(self, module_id: int, namespace: str):\n    \"\"\"Deploy lab-specific resources\"\"\"\n    resources = self.get_lab_resources(module_id)\n\n    for resource in resources:\n        print(f\"   Deploying {resource}...\")\n        cmd = [\n            self.lab_automation.kubectl,\n            \"apply\",\n            \"-f\",\n            f\"labs/module-{module_id}/{resource}.yaml\",\n            \"-n\",\n            namespace\n        ]\n        self.lab_automation.run_command(cmd)\n\ndef get_belt_config(self, module_id: int) -&gt; Dict:\n    \"\"\"Get belt configuration for module\"\"\"\n    belt_ranges = {\n        (1, 4): \"white\",\n        (5, 8): \"yellow\",\n        (9, 12): \"green\",\n        (13, 16): \"brown\",\n        (17, 20): \"black\"\n    }\n\n    for (start, end), belt in belt_ranges.items():\n        if start &lt;= module_id &lt;= end:\n            return {\"belt\": belt, \"module_in_belt\": module_id - start + 1}\n\n    return {\"belt\": \"unknown\", \"module_in_belt\": 0}\n\ndef get_lab_resources(self, module_id: int) -&gt; List[str]:\n    \"\"\"Get list of resources to deploy for lab\"\"\"\n    # Map module to required resources\n    resource_map = {\n        1: [\"namespace\", \"sample-deployment\"],\n        2: [\"namespace\", \"argocd-application\"],\n        3: [\"namespace\", \"prometheus\", \"grafana\"],\n        4: [\"namespace\", \"sample-app\"],\n        5: [\"namespace\", \"tekton-pipeline\"],\n        # ... etc\n    }\n\n    return resource_map.get(module_id, [\"namespace\"])\n\ndef show_lab_instructions(self, module_id: int):\n    \"\"\"Display lab instructions\"\"\"\n    print(\"\\n\ud83d\udcda Lab Instructions:\")\n    print(f\"   1. Review module {module_id} content\")\n    print(f\"   2. Complete the hands-on exercises\")\n    print(f\"   3. Run: fawkes lab validate --lab [lab-name]\")\n    print(f\"\\n   Documentation: https://docs.fawkes.io/dojo/module-{module_id}\")\n\ndef display_validation_results(self, result: ValidationResult):\n    \"\"\"Display validation results in a nice format\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(f\"   LAB VALIDATION RESULTS\")\n    print(\"=\"*60)\n\n    if result.passed:\n        print(f\"\u2705 PASSED: {result.message}\")\n    else:\n        print(f\"\u274c FAILED: {result.message}\")\n\n    print(f\"\\n   Score: {result.points}/{result.max_points} points\")\n\n    if result.details and \"checks\" in result.details:\n        print(f\"\\n   Checks:\")\n        for check in result.details[\"checks\"]:\n            print(f\"      \u2022 {check}\")\n\n    print(\"=\"*60 + \"\\n\")\n\n    if result.passed:\n        print(\"\ud83c\udf89 Great job! You can move to the next lab.\")\n    else:\n        print(\"\ud83d\udca1 Review the failed checks and try again.\")\n        print(\"   Need help? Visit #dojo-support on Mattermost\")\n</code></pre>"},{"location":"dojo/labs/lab%20automation/#_7","title":"=============================================================================","text":""},{"location":"dojo/labs/lab%20automation/#assessment-automation","title":"ASSESSMENT AUTOMATION","text":""},{"location":"dojo/labs/lab%20automation/#_8","title":"=============================================================================","text":"<p>class AssessmentValidator:     \"\"\"Automated assessment validation and grading\"\"\"</p> <pre><code>def __init__(self):\n    self.lab_automation = LabAutomation()\n\ndef validate_assessment(self, belt_level: str) -&gt; Dict:\n    \"\"\"Validate complete belt assessment\"\"\"\n    print(f\"\ud83c\udf93 Validating {belt_level.upper()} Belt Assessment...\")\n\n    # Get labs for this belt\n    labs = self.get_belt_labs(belt_level)\n\n    results = []\n    total_points = 0\n    max_total_points = 0\n\n    for lab_name in labs:\n        cli = FawkesLabCLI()\n        result = cli.validate_lab(lab_name)\n\n        if result:\n            results.append({\n                \"lab\": lab_name,\n                \"passed\": result.passed,\n                \"points\": result.points,\n                \"max_points\": result.max_points\n            })\n            total_points += result.points\n            max_total_points += result.max_points\n\n    # Calculate final score\n    percentage = (total_points / max_total_points * 100) if max_total_points &gt; 0 else 0\n\n    # Determine pass/fail\n    passing_thresholds = {\n        \"white\": 80,\n        \"yellow\": 85,\n        \"green\": 85,\n        \"brown\": 85,\n        \"black\": 90\n    }\n\n    passing_threshold = passing_thresholds.get(belt_level, 80)\n    passed = percentage &gt;= passing_threshold\n\n    return {\n        \"belt\": belt_level,\n        \"total_points\": total_points,\n        \"max_points\": max_total_points,\n        \"percentage\": percentage,\n        \"passed\": passed,\n        \"passing_threshold\": passing_threshold,\n        \"labs\": results\n    }\n\ndef get_belt_labs(self, belt_level: str) -&gt; List[str]:\n    \"\"\"Get list of labs for a belt level\"\"\"\n    labs_by_belt = {\n        \"white\": [\"white-belt-lab1\", \"white-belt-lab2\", \"white-belt-lab3\"],\n        \"yellow\": [\"yellow-belt-lab1\", \"yellow-belt-lab2\", \"yellow-belt-lab3\"],\n        \"green\": [\"green-belt-lab1\", \"green-belt-lab2\", \"green-belt-lab3\"],\n        \"brown\": [\"brown-belt-lab1\", \"brown-belt-lab2\", \"brown-belt-lab3\", \"brown-belt-lab4\"],\n        \"black\": [\"black-belt-implementation\"]\n    }\n\n    return labs_by_belt.get(belt_level, [])\n\ndef generate_certificate(self, user_info: Dict, belt_level: str, score: float):\n    \"\"\"Generate certification PDF\"\"\"\n    print(f\"\ud83c\udf96\ufe0f Generating {belt_level.upper()} Belt Certificate...\")\n\n    cert_data = {\n        \"name\": user_info.get(\"name\"),\n        \"email\": user_info.get(\"email\"),\n        \"belt\": belt_level,\n        \"score\": score,\n        \"date\": time.strftime(\"%Y-%m-%d\"),\n        \"cert_id\": self.generate_cert_id(user_info, belt_level)\n    }\n\n    # In real implementation, would generate PDF\n    print(f\"   Certificate ID: {cert_data['cert_id']}\")\n    print(f\"   Verify at: https://fawkes.io/verify/{cert_data['cert_id']}\")\n\n    return cert_data\n\ndef generate_cert_id(self, user_info: Dict, belt_level: str) -&gt; str:\n    \"\"\"Generate unique certificate ID\"\"\"\n    import hashlib\n\n    data = f\"{user_info.get('email')}{belt_level}{time.time()}\"\n    hash_obj = hashlib.sha256(data.encode())\n    return f\"FPA-2025-{hash_obj.hexdigest()[:8].upper()}\"\n</code></pre>"},{"location":"dojo/labs/lab%20automation/#_9","title":"=============================================================================","text":""},{"location":"dojo/labs/lab%20automation/#utility-functions","title":"UTILITY FUNCTIONS","text":""},{"location":"dojo/labs/lab%20automation/#_10","title":"=============================================================================","text":"<p>def setup_lab_environment():     \"\"\"One-time setup for lab infrastructure\"\"\"     print(\"\ud83d\udd27 Setting up Fawkes Dojo lab infrastructure...\")</p> <pre><code>lab = LabAutomation()\n\n# Create monitoring namespace\nprint(\"   Creating monitoring namespace...\")\nlab.run_command([lab.kubectl, \"create\", \"namespace\", \"monitoring\"])\n\n# Install Prometheus\nprint(\"   Installing Prometheus...\")\nlab.run_command([\n    \"helm\", \"install\", \"prometheus\", \"prometheus-community/kube-prometheus-stack\",\n    \"-n\", \"monitoring\"\n])\n\n# Install ArgoCD\nprint(\"   Installing ArgoCD...\")\nlab.run_command([lab.kubectl, \"create\", \"namespace\", \"argocd\"])\nlab.run_command([\n    lab.kubectl, \"apply\", \"-n\", \"argocd\",\n    \"-f\", \"https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\"\n])\n\nprint(\"\u2705 Lab infrastructure ready!\")\n</code></pre> <p>def cleanup_lab_environment(module_id: int):     \"\"\"Clean up lab environment\"\"\"     print(f\"\ud83e\uddf9 Cleaning up lab environment for Module {module_id}...\")</p> <pre><code>lab = LabAutomation()\nnamespace = f\"lab-module-{module_id}\"\n\nlab.run_command([lab.kubectl, \"delete\", \"namespace\", namespace])\n\nprint(f\"\u2705 Lab environment cleaned up!\")\n</code></pre>"},{"location":"dojo/labs/lab%20automation/#_11","title":"=============================================================================","text":""},{"location":"dojo/labs/lab%20automation/#main-cli-entrypoint","title":"MAIN CLI ENTRYPOINT","text":""},{"location":"dojo/labs/lab%20automation/#_12","title":"=============================================================================","text":"<p>def main():     \"\"\"Main CLI entrypoint\"\"\"     import argparse</p> <pre><code>parser = argparse.ArgumentParser(description=\"Fawkes Dojo Lab Automation\")\nsubparsers = parser.add_subparsers(dest=\"command\", help=\"Available commands\")\n\n# Lab commands\nlab_parser = subparsers.add_parser(\"lab\", help=\"Lab environment management\")\nlab_subparsers = lab_parser.add_subparsers(dest=\"lab_command\")\n\n# fawkes lab start\nstart_parser = lab_subparsers.add_parser(\"start\", help=\"Start lab environment\")\nstart_parser.add_argument(\"--module\", type=int, required=True, help=\"Module number (1-20)\")\n\n# fawkes lab validate\nvalidate_parser = lab_subparsers.add_parser(\"validate\", help=\"Validate lab completion\")\nvalidate_parser.add_argument(\"--lab\", type=str, required=True, help=\"Lab name (e.g., white-belt-lab1)\")\n\n# fawkes lab stop\nstop_parser = lab_subparsers.add_parser(\"stop\", help=\"Stop lab environment\")\nstop_parser.add_argument(\"--module\", type=int, required=True, help=\"Module number\")\n\n# Assessment commands\nassessment_parser = subparsers.add_parser(\"assessment\", help=\"Assessment management\")\nassessment_subparsers = assessment_parser.add_subparsers(dest=\"assessment_command\")\n\n# fawkes assessment validate\nassess_validate_parser = assessment_subparsers.add_parser(\"validate\", help=\"Validate assessment\")\nassess_validate_parser.add_argument(\"--belt\", type=str, required=True,\n                                   choices=[\"white\", \"yellow\", \"green\", \"brown\", \"black\"],\n                                   help=\"Belt level\")\n\n# Setup command\nsubparsers.add_parser(\"setup\", help=\"Setup lab infrastructure\")\n\nargs = parser.parse_args()\n\n# Execute command\nif args.command == \"lab\":\n    cli = FawkesLabCLI()\n\n    if args.lab_command == \"start\":\n        cli.start_lab(args.module)\n\n    elif args.lab_command == \"validate\":\n        cli.validate_lab(args.lab)\n\n    elif args.lab_command == \"stop\":\n        cleanup_lab_environment(args.module)\n\nelif args.command == \"assessment\":\n    validator = AssessmentValidator()\n\n    if args.assessment_command == \"validate\":\n        result = validator.validate_assessment(args.belt)\n\n        print(\"\\n\" + \"=\"*60)\n        print(f\"   {result['belt'].upper()} BELT ASSESSMENT RESULTS\")\n        print(\"=\"*60)\n        print(f\"\\n   Total Score: {result['total_points']}/{result['max_points']} ({result['percentage']:.1f}%)\")\n        print(f\"   Passing Threshold: {result['passing_threshold']}%\")\n\n        if result['passed']:\n            print(f\"\\n   \u2705 PASSED - Congratulations!\")\n            print(f\"\\n   You have earned the {result['belt'].upper()} Belt certification!\")\n        else:\n            print(f\"\\n   \u274c NOT PASSED\")\n            print(f\"   You need {result['passing_threshold']}% to pass.\")\n            print(f\"   Review the areas where you lost points and try again.\")\n\n        print(\"\\n   Lab Results:\")\n        for lab in result['labs']:\n            status = \"\u2705\" if lab['passed'] else \"\u274c\"\n            print(f\"      {status} {lab['lab']}: {lab['points']}/{lab['max_points']}\")\n\n        print(\"=\"*60 + \"\\n\")\n\nelif args.command == \"setup\":\n    setup_lab_environment()\n\nelse:\n    parser.print_help()\n</code></pre> <p>if name == \"main\":     main()</p>"},{"location":"dojo/labs/lab%20automation/#_13","title":"=============================================================================","text":""},{"location":"dojo/labs/lab%20automation/#example-usage","title":"EXAMPLE USAGE","text":""},{"location":"dojo/labs/lab%20automation/#_14","title":"=============================================================================","text":"<p>\"\"\" Example usage:</p>"},{"location":"dojo/labs/lab%20automation/#start-a-lab-environment","title":"Start a lab environment","text":"<p>$ fawkes lab start --module 1</p>"},{"location":"dojo/labs/lab%20automation/#validate-lab-completion","title":"Validate lab completion","text":"<p>$ fawkes lab validate --lab white-belt-lab1</p>"},{"location":"dojo/labs/lab%20automation/#clean-up-lab","title":"Clean up lab","text":"<p>$ fawkes lab stop --module 1</p>"},{"location":"dojo/labs/lab%20automation/#validate-entire-belt-assessment","title":"Validate entire belt assessment","text":"<p>$ fawkes assessment validate --belt white</p>"},{"location":"dojo/labs/lab%20automation/#setup-lab-infrastructure-one-time","title":"Setup lab infrastructure (one-time)","text":"<p>$ fawkes setup \"\"\"</p>"},{"location":"dojo/labs/white/","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#white-belt-lab-files-complete-lab-environments","title":"WHITE BELT LAB FILES - Complete Lab Environments","text":""},{"location":"dojo/labs/white/#_2","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#this-file-contains-all-kubernetes-manifests-needed-for-white-belt-labs","title":"This file contains all Kubernetes manifests needed for White Belt labs.","text":""},{"location":"dojo/labs/white/#each-lab-is-separated-by-comments-and-can-be-extracted-as-needed","title":"Each lab is separated by comments and can be extracted as needed.","text":""},{"location":"dojo/labs/white/#_3","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#module-1-lab-1-first-deployment","title":"MODULE 1 - LAB 1: First Deployment","text":""},{"location":"dojo/labs/white/#directory-labsmodule-01","title":"Directory: labs/module-01/","text":""},{"location":"dojo/labs/white/#_4","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#labsmodule-01namespaceyaml","title":"labs/module-01/namespace.yaml","text":"<p>apiVersion: v1 kind: Namespace metadata:   name: lab-module-1   labels:     fawkes.io/module: \"1\"     fawkes.io/belt: \"white\"     fawkes.io/lab: \"first-deployment\"</p>"},{"location":"dojo/labs/white/#labsmodule-01sample-app-deploymentyaml","title":"labs/module-01/sample-app-deployment.yaml","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: my-first-app   namespace: lab-module-1   labels:     app: my-first-app     fawkes.io/module: \"1\" spec:   replicas: 1  # Students will change this to 3   selector:     matchLabels:       app: my-first-app   template:     metadata:       labels:         app: my-first-app     spec:       containers:       - name: app         image: nginxdemos/hello:latest  # Simple app that shows hostname         ports:         - containerPort: 80         resources:           requests:             memory: \"64Mi\"             cpu: \"100m\"           limits:             memory: \"128Mi\"             cpu: \"200m\"         livenessProbe:           httpGet:             path: /             port: 80           initialDelaySeconds: 5           periodSeconds: 10         readinessProbe:           httpGet:             path: /             port: 80           initialDelaySeconds: 5           periodSeconds: 5</p>"},{"location":"dojo/labs/white/#labsmodule-01sample-app-serviceyaml","title":"labs/module-01/sample-app-service.yaml","text":"<p>apiVersion: v1 kind: Service metadata:   name: my-first-app   namespace: lab-module-1   labels:     app: my-first-app spec:   type: ClusterIP   selector:     app: my-first-app   ports:   - port: 80     targetPort: 80     protocol: TCP     name: http</p>"},{"location":"dojo/labs/white/#labsmodule-01sample-app-ingressyaml","title":"labs/module-01/sample-app-ingress.yaml","text":"<p>apiVersion: networking.k8s.io/v1 kind: Ingress metadata:   name: my-first-app   namespace: lab-module-1   annotations:     nginx.ingress.kubernetes.io/rewrite-target: / spec:   ingressClassName: nginx   rules:   - host: my-first-app-lab1.fawkes.local     http:       paths:       - path: /         pathType: Prefix         backend:           service:             name: my-first-app             port:               number: 80</p>"},{"location":"dojo/labs/white/#labsmodule-01lab-instructionsyaml","title":"labs/module-01/lab-instructions.yaml","text":""},{"location":"dojo/labs/white/#configmap-with-lab-instructions","title":"ConfigMap with lab instructions","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: lab-instructions   namespace: lab-module-1 data:   instructions.md: |     # Module 1 Lab: Your First Deployment</p> <pre><code>## Objectives\n1. Clone the sample application repository\n2. Modify the deployment to use 3 replicas\n3. Deploy using kubectl or GitOps\n4. Verify all pods are running\n5. Access the application\n\n## Steps\n1. Review the deployment manifest in this namespace\n2. Edit deployment to set replicas: 3\n3. Apply changes: `kubectl apply -f deployment.yaml`\n4. Check status: `kubectl get pods -n lab-module-1`\n5. Access app: http://my-first-app-lab1.fawkes.local\n\n## Validation\nRun: `fawkes lab validate --lab white-belt-lab1`\n</code></pre>"},{"location":"dojo/labs/white/#_5","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#module-2-lab-2-multi-environment-deployment-with-kustomize","title":"MODULE 2 - LAB 2: Multi-Environment Deployment with Kustomize","text":""},{"location":"dojo/labs/white/#directory-labsmodule-02","title":"Directory: labs/module-02/","text":""},{"location":"dojo/labs/white/#_6","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#labsmodule-02namespace-devyaml","title":"labs/module-02/namespace-dev.yaml","text":"<p>apiVersion: v1 kind: Namespace metadata:   name: lab-module-2-dev   labels:     fawkes.io/module: \"2\"     fawkes.io/environment: \"dev\"</p>"},{"location":"dojo/labs/white/#labsmodule-02namespace-prodyaml","title":"labs/module-02/namespace-prod.yaml","text":"<p>apiVersion: v1 kind: Namespace metadata:   name: lab-module-2-prod   labels:     fawkes.io/module: \"2\"     fawkes.io/environment: \"prod\"</p>"},{"location":"dojo/labs/white/#labsmodule-02kustomizebasekustomizationyaml","title":"labs/module-02/kustomize/base/kustomization.yaml","text":""},{"location":"dojo/labs/white/#students-will-create-this-structure","title":"Students will create this structure","text":"<p>apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization</p> <p>resources:   - deployment.yaml   - service.yaml</p> <p>commonLabels:   app: my-first-app</p>"},{"location":"dojo/labs/white/#labsmodule-02kustomizebasedeploymentyaml","title":"labs/module-02/kustomize/base/deployment.yaml","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: my-first-app spec:   replicas: 1  # Base configuration   selector:     matchLabels:       app: my-first-app   template:     metadata:       labels:         app: my-first-app     spec:       containers:       - name: app         image: nginxdemos/hello:latest         ports:         - containerPort: 80</p>"},{"location":"dojo/labs/white/#labsmodule-02kustomizebaseserviceyaml","title":"labs/module-02/kustomize/base/service.yaml","text":"<p>apiVersion: v1 kind: Service metadata:   name: my-first-app spec:   type: ClusterIP   selector:     app: my-first-app   ports:   - port: 80     targetPort: 80</p>"},{"location":"dojo/labs/white/#labsmodule-02kustomizeoverlaysdevkustomizationyaml","title":"labs/module-02/kustomize/overlays/dev/kustomization.yaml","text":"<p>apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization</p> <p>namespace: lab-module-2-dev</p> <p>bases:   - ../../base</p> <p>patches:   - patch: |-       - op: replace         path: /spec/replicas         value: 1     target:       kind: Deployment       name: my-first-app</p> <p>commonLabels:   environment: dev</p>"},{"location":"dojo/labs/white/#labsmodule-02kustomizeoverlaysprodkustomizationyaml","title":"labs/module-02/kustomize/overlays/prod/kustomization.yaml","text":"<p>apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization</p> <p>namespace: lab-module-2-prod</p> <p>bases:   - ../../base</p> <p>patches:   - patch: |-       - op: replace         path: /spec/replicas         value: 3     target:       kind: Deployment       name: my-first-app   - patch: |-       - op: add         path: /spec/template/spec/containers/0/resources         value:           requests:             memory: \"128Mi\"             cpu: \"250m\"           limits:             memory: \"256Mi\"             cpu: \"500m\"     target:       kind: Deployment       name: my-first-app</p> <p>commonLabels:   environment: prod</p>"},{"location":"dojo/labs/white/#labsmodule-02argocd-app-devyaml","title":"labs/module-02/argocd-app-dev.yaml","text":"<p>apiVersion: argoproj.io/v1alpha1 kind: Application metadata:   name: my-first-app-dev   namespace: argocd spec:   project: default   source:     repoURL: https://github.com/student/my-first-app     targetRevision: main     path: k8s/overlays/dev   destination:     server: https://kubernetes.default.svc     namespace: lab-module-2-dev   syncPolicy:     automated:       prune: true       selfHeal: true     syncOptions:       - CreateNamespace=true</p>"},{"location":"dojo/labs/white/#labsmodule-02argocd-app-prodyaml","title":"labs/module-02/argocd-app-prod.yaml","text":"<p>apiVersion: argoproj.io/v1alpha1 kind: Application metadata:   name: my-first-app-prod   namespace: argocd spec:   project: default   source:     repoURL: https://github.com/student/my-first-app     targetRevision: main     path: k8s/overlays/prod   destination:     server: https://kubernetes.default.svc     namespace: lab-module-2-prod   syncPolicy:     automated:       prune: true       selfHeal: true     syncOptions:       - CreateNamespace=true</p>"},{"location":"dojo/labs/white/#_7","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#module-3-lab-3-dora-metrics-dashboard","title":"MODULE 3 - LAB 3: DORA Metrics Dashboard","text":""},{"location":"dojo/labs/white/#directory-labsmodule-03","title":"Directory: labs/module-03/","text":""},{"location":"dojo/labs/white/#_8","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#labsmodule-03namespaceyaml","title":"labs/module-03/namespace.yaml","text":"<p>apiVersion: v1 kind: Namespace metadata:   name: lab-module-3   labels:     fawkes.io/module: \"3\"</p>"},{"location":"dojo/labs/white/#labsmodule-03dora-exporter-deploymentyaml","title":"labs/module-03/dora-exporter-deployment.yaml","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: dora-exporter   namespace: monitoring   labels:     app: dora-exporter spec:   replicas: 1   selector:     matchLabels:       app: dora-exporter   template:     metadata:       labels:         app: dora-exporter       annotations:         prometheus.io/scrape: \"true\"         prometheus.io/port: \"8080\"         prometheus.io/path: \"/metrics\"     spec:       serviceAccountName: dora-exporter       containers:       - name: exporter         image: fawkes/dora-exporter:v1.0.0         ports:         - containerPort: 8080           name: metrics         env:         - name: KUBERNETES_NAMESPACE           valueFrom:             fieldRef:               fieldPath: metadata.namespace         resources:           requests:             memory: \"64Mi\"             cpu: \"100m\"           limits:             memory: \"128Mi\"             cpu: \"200m\"</p>"},{"location":"dojo/labs/white/#labsmodule-03dora-exporter-serviceyaml","title":"labs/module-03/dora-exporter-service.yaml","text":"<p>apiVersion: v1 kind: Service metadata:   name: dora-exporter   namespace: monitoring   labels:     app: dora-exporter spec:   type: ClusterIP   selector:     app: dora-exporter   ports:   - port: 8080     targetPort: 8080     name: metrics</p>"},{"location":"dojo/labs/white/#labsmodule-03dora-exporter-servicemonitoryaml","title":"labs/module-03/dora-exporter-servicemonitor.yaml","text":"<p>apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata:   name: dora-exporter   namespace: monitoring   labels:     app: dora-exporter spec:   selector:     matchLabels:       app: dora-exporter   endpoints:   - port: metrics     interval: 30s     path: /metrics</p>"},{"location":"dojo/labs/white/#labsmodule-03dora-exporter-rbacyaml","title":"labs/module-03/dora-exporter-rbac.yaml","text":"<p>apiVersion: v1 kind: ServiceAccount metadata:   name: dora-exporter   namespace: monitoring</p> <p>apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:   name: dora-exporter rules: - apiGroups: [\"apps\"]   resources: [\"deployments\", \"replicasets\"]   verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"]   resources: [\"pods\", \"events\"]   verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"argoproj.io\"]   resources: [\"applications\"]   verbs: [\"get\", \"list\", \"watch\"]</p> <p>apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata:   name: dora-exporter roleRef:   apiGroup: rbac.authorization.k8s.io   kind: ClusterRole   name: dora-exporter subjects: - kind: ServiceAccount   name: dora-exporter   namespace: monitoring</p>"},{"location":"dojo/labs/white/#labsmodule-03grafana-dashboard-configmapyaml","title":"labs/module-03/grafana-dashboard-configmap.yaml","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: dora-dashboard   namespace: monitoring   labels:     grafana_dashboard: \"1\" data:   dora-metrics.json: |     {       \"dashboard\": {         \"title\": \"DORA Metrics\",         \"panels\": [           {             \"title\": \"Deployment Frequency\",             \"targets\": [               {                 \"expr\": \"rate(deployments_total[7d])\"               }             ]           },           {             \"title\": \"Lead Time for Changes\",             \"targets\": [               {                 \"expr\": \"histogram_quantile(0.95, rate(lead_time_seconds_bucket[1d]))\"               }             ]           },           {             \"title\": \"Mean Time to Recovery\",             \"targets\": [               {                 \"expr\": \"histogram_quantile(0.95, rate(mttr_seconds_bucket[1d]))\"               }             ]           },           {             \"title\": \"Change Failure Rate\",             \"targets\": [               {                 \"expr\": \"(rate(deployments_failed_total[7d]) / rate(deployments_total[7d])) * 100\"               }             ]           }         ]       }     }</p>"},{"location":"dojo/labs/white/#labsmodule-03sample-app-with-annotationsyaml","title":"labs/module-03/sample-app-with-annotations.yaml","text":""},{"location":"dojo/labs/white/#updated-deployment-with-prometheus-annotations","title":"Updated deployment with Prometheus annotations","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: my-first-app   namespace: lab-module-3   annotations:     fawkes.io/dora-tracking: \"true\" spec:   replicas: 3   selector:     matchLabels:       app: my-first-app   template:     metadata:       labels:         app: my-first-app       annotations:         prometheus.io/scrape: \"true\"         prometheus.io/port: \"8080\"         prometheus.io/path: \"/metrics\"     spec:       containers:       - name: app         image: nginxdemos/hello:latest         ports:         - containerPort: 80           name: http         - containerPort: 8080           name: metrics</p>"},{"location":"dojo/labs/white/#_9","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#module-4-lab-your-first-deployment-guided","title":"MODULE 4 - LAB: Your First Deployment (Guided)","text":""},{"location":"dojo/labs/white/#directory-labsmodule-04","title":"Directory: labs/module-04/","text":""},{"location":"dojo/labs/white/#_10","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#labsmodule-04namespaceyaml","title":"labs/module-04/namespace.yaml","text":"<p>apiVersion: v1 kind: Namespace metadata:   name: lab-module-4   labels:     fawkes.io/module: \"4\"     fawkes.io/belt: \"white\"</p>"},{"location":"dojo/labs/white/#labsmodule-04sample-app-templateyaml","title":"labs/module-04/sample-app-template.yaml","text":""},{"location":"dojo/labs/white/#template-that-students-will-fill-in","title":"Template that students will fill in","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: TODO  # Student fills this in   namespace: lab-module-4 spec:   replicas: TODO  # Student sets this   selector:     matchLabels:       app: TODO  # Student sets this   template:     metadata:       labels:         app: TODO  # Student sets this     spec:       containers:       - name: app         image: nginxdemos/hello:latest         ports:         - containerPort: 80</p>"},{"location":"dojo/labs/white/#labsmodule-04solutiondeploymentyaml","title":"labs/module-04/solution/deployment.yaml","text":""},{"location":"dojo/labs/white/#reference-solution-hidden-from-students-initially","title":"Reference solution (hidden from students initially)","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: my-app   namespace: lab-module-4   labels:     app: my-app     fawkes.io/lab: \"module-4\" spec:   replicas: 2   selector:     matchLabels:       app: my-app   template:     metadata:       labels:         app: my-app     spec:       containers:       - name: app         image: nginxdemos/hello:latest         ports:         - containerPort: 80         resources:           requests:             memory: \"64Mi\"             cpu: \"100m\"           limits:             memory: \"128Mi\"             cpu: \"200m\"</p> <p>apiVersion: v1 kind: Service metadata:   name: my-app   namespace: lab-module-4 spec:   type: ClusterIP   selector:     app: my-app   ports:   - port: 80     targetPort: 80</p>"},{"location":"dojo/labs/white/#_11","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#shared-resources-used-by-multiple-labs","title":"SHARED RESOURCES - Used by multiple labs","text":""},{"location":"dojo/labs/white/#directory-labsshared","title":"Directory: labs/shared/","text":""},{"location":"dojo/labs/white/#_12","title":"=============================================================================","text":""},{"location":"dojo/labs/white/#labssharedresource-quotayaml","title":"labs/shared/resource-quota.yaml","text":""},{"location":"dojo/labs/white/#applied-to-each-lab-namespace-for-resource-management","title":"Applied to each lab namespace for resource management","text":"<p>apiVersion: v1 kind: ResourceQuota metadata:   name: lab-quota spec:   hard:     requests.cpu: \"2\"     requests.memory: \"4Gi\"     limits.cpu: \"4\"     limits.memory: \"8Gi\"     persistentvolumeclaims: \"5\"     pods: \"20\"     services: \"10\"</p>"},{"location":"dojo/labs/white/#labssharednetwork-policyyaml","title":"labs/shared/network-policy.yaml","text":""},{"location":"dojo/labs/white/#network-isolation-for-lab-environments","title":"Network isolation for lab environments","text":"<p>apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata:   name: lab-isolation spec:   podSelector: {}   policyTypes:   - Ingress   - Egress   ingress:   - from:     - namespaceSelector:         matchLabels:           fawkes.io/type: lab   egress:   - to:     - namespaceSelector:         matchLabels:           fawkes.io/type: lab   - to:  # Allow DNS     - namespaceSelector:         matchLabels:           name: kube-system     ports:     - protocol: UDP       port: 53</p>"},{"location":"dojo/labs/white/#labssharedlab-rbacyaml","title":"labs/shared/lab-rbac.yaml","text":""},{"location":"dojo/labs/white/#rbac-for-lab-users","title":"RBAC for lab users","text":"<p>apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata:   name: lab-user rules: - apiGroups: [\"\", \"apps\", \"networking.k8s.io\"]   resources: [\"\"]   verbs: [\"\"] - apiGroups: [\"argoproj.io\"]   resources: [\"applications\"]   verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"]</p> <p>apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata:   name: lab-user-binding roleRef:   apiGroup: rbac.authorization.k8s.io   kind: Role   name: lab-user subjects: - kind: Group   name: fawkes-students   apiGroup: rbac.authorization.k8s.io</p>"},{"location":"dojo/labs/yellow%20n%20green/","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#yellow-belt-lab-files-cicd-mastery-modules-5-8","title":"YELLOW BELT LAB FILES - CI/CD Mastery (Modules 5-8)","text":""},{"location":"dojo/labs/yellow%20n%20green/#_2","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#_3","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#module-5-lab-1-production-ci-pipeline","title":"MODULE 5 - LAB 1: Production CI Pipeline","text":""},{"location":"dojo/labs/yellow%20n%20green/#directory-labsmodule-05","title":"Directory: labs/module-05/","text":""},{"location":"dojo/labs/yellow%20n%20green/#_4","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-05github-actions-templateyaml","title":"labs/module-05/github-actions-template.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#githubworkflowsciyml-template-for-students","title":".github/workflows/ci.yml template for students","text":"<p>name: CI Pipeline</p> <p>on:   push:     branches: [ main, develop ]   pull_request:     branches: [ main ]</p> <p>jobs:   test:     runs-on: ubuntu-latest     steps:       - uses: actions/checkout@v3</p> <pre><code>  - name: Setup Node.js\n    uses: actions/setup-node@v3\n    with:\n      node-version: '18'\n      cache: 'npm'\n\n  - name: Install dependencies\n    run: npm ci\n\n  - name: Run tests\n    run: npm test -- --coverage\n\n  - name: Check coverage\n    run: |\n      COVERAGE=$(node -e \"console.log(require('./coverage/coverage-summary.json').total.lines.pct)\")\n      if [ $(echo \"$COVERAGE &lt; 80\" | bc) -eq 1 ]; then\n        echo \"Coverage $COVERAGE% is below 80%\"\n        exit 1\n      fi\n</code></pre> <p>security-scan:     runs-on: ubuntu-latest     steps:       - uses: actions/checkout@v3</p> <pre><code>  - name: Run Semgrep\n    uses: returntocorp/semgrep-action@v1\n    with:\n      config: auto\n\n  - name: Run npm audit\n    run: npm audit --audit-level=high\n</code></pre> <p>build:     needs: [test, security-scan]     runs-on: ubuntu-latest     steps:       - uses: actions/checkout@v3</p> <pre><code>  - name: Set up Docker Buildx\n    uses: docker/setup-buildx-action@v2\n\n  - name: Build image\n    uses: docker/build-push-action@v4\n    with:\n      context: .\n      push: false\n      tags: my-app:${{ github.sha }}\n      cache-from: type=gha\n      cache-to: type=gha,mode=max\n\n  - name: Scan image\n    uses: aquasecurity/trivy-action@master\n    with:\n      image-ref: my-app:${{ github.sha }}\n      exit-code: '1'\n      severity: 'CRITICAL,HIGH'\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-05tekton-pipelineyaml","title":"labs/module-05/tekton-pipeline.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#tekton-pipeline-alternative","title":"Tekton pipeline alternative","text":"<p>apiVersion: tekton.dev/v1beta1 kind: Pipeline metadata:   name: ci-pipeline   namespace: tekton-pipelines spec:   params:     - name: git-url       type: string     - name: git-revision       type: string       default: main   workspaces:     - name: shared-data   tasks:     - name: fetch-source       taskRef:         name: git-clone       workspaces:         - name: output           workspace: shared-data       params:         - name: url           value: $(params.git-url)         - name: revision           value: $(params.git-revision)</p> <pre><code>- name: run-tests\n  runAfter: [fetch-source]\n  taskRef:\n    name: npm-test\n  workspaces:\n    - name: source\n      workspace: shared-data\n\n- name: security-scan\n  runAfter: [fetch-source]\n  taskRef:\n    name: semgrep-scan\n  workspaces:\n    - name: source\n      workspace: shared-data\n\n- name: build-image\n  runAfter: [run-tests, security-scan]\n  taskRef:\n    name: kaniko\n  workspaces:\n    - name: source\n      workspace: shared-data\n  params:\n    - name: IMAGE\n      value: \"registry.fawkes.io/my-app:$(params.git-revision)\"\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-05quality-gatesyaml","title":"labs/module-05/quality-gates.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#quality-gates-configuration","title":"Quality gates configuration","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: quality-gates   namespace: lab-module-5 data:   gates.yaml: |     gates:       test_coverage:         threshold: 80         action: block</p> <pre><code>  security_vulnerabilities:\n    critical: 0\n    high: 0\n    medium: 5\n    action: block\n\n  code_quality:\n    min_maintainability: B\n    max_complexity: 15\n    action: warn\n\n  build_time:\n    max_duration_seconds: 300\n    action: warn\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#_5","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#module-6-lab-2-golden-path-pipelines","title":"MODULE 6 - LAB 2: Golden Path Pipelines","text":""},{"location":"dojo/labs/yellow%20n%20green/#directory-labsmodule-06","title":"Directory: labs/module-06/","text":""},{"location":"dojo/labs/yellow%20n%20green/#_6","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-06golden-path-templateyaml","title":"labs/module-06/golden-path-template.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#reusable-workflow-template","title":"Reusable workflow template","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: golden-path-template   namespace: lab-module-6 data:   node-service.yaml: |     # Golden Path for Node.js Services     name: Node.js Service Pipeline</p> <pre><code>on:\n  push:\n    branches: [main, develop]\n\njobs:\n  golden-path:\n    uses: fawkes/workflows/.github/workflows/golden-path-node.yml@v1\n    with:\n      node-version: '18'\n      test-coverage-threshold: 80\n      security-scan: true\n      deploy-dev: true\n    secrets:\n      REGISTRY_TOKEN: ${{ secrets.REGISTRY_TOKEN }}\n</code></pre> <p>python-service.yaml: |     # Golden Path for Python Services     name: Python Service Pipeline</p> <pre><code>on:\n  push:\n    branches: [main]\n\njobs:\n  golden-path:\n    uses: fawkes/workflows/.github/workflows/golden-path-python.yml@v1\n    with:\n      python-version: '3.11'\n      test-framework: pytest\n      security-scan: true\n    secrets:\n      REGISTRY_TOKEN: ${{ secrets.REGISTRY_TOKEN }}\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#_7","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#module-7-lab-3-security-scanning-quality-gates","title":"MODULE 7 - LAB 3: Security Scanning &amp; Quality Gates","text":""},{"location":"dojo/labs/yellow%20n%20green/#directory-labsmodule-07","title":"Directory: labs/module-07/","text":""},{"location":"dojo/labs/yellow%20n%20green/#_8","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-07semgrep-configyaml","title":"labs/module-07/semgrep-config.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#semgrep-security-scanning-configuration","title":"Semgrep security scanning configuration","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: semgrep-config   namespace: lab-module-7 data:   .semgrep.yml: |     rules:       - id: hardcoded-secret         patterns:           - pattern: password = \"...\"           - pattern: api_key = \"...\"         message: Hardcoded secret detected         severity: ERROR</p> <pre><code>  - id: sql-injection\n    patterns:\n      - pattern: execute($SQL + $INPUT)\n    message: Possible SQL injection\n    severity: ERROR\n\n  - id: xss-vulnerability\n    patterns:\n      - pattern: innerHTML = $INPUT\n    message: Possible XSS vulnerability\n    severity: WARNING\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-07trivy-configyaml","title":"labs/module-07/trivy-config.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#trivy-image-scanning-configuration","title":"Trivy image scanning configuration","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: trivy-config   namespace: lab-module-7 data:   trivy.yaml: |     severity:       - CRITICAL       - HIGH       - MEDIUM</p> <pre><code>vulnerability:\n  type:\n    - os\n    - library\n\nignore-unfixed: true\n\nexit-code: 1  # Fail on findings\n\ncache:\n  ttl: 24h\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-07sonarqube-propertiesyaml","title":"labs/module-07/sonarqube-properties.yaml","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: sonarqube-config   namespace: lab-module-7 data:   sonar-project.properties: |     sonar.projectKey=my-first-app     sonar.projectName=My First App     sonar.sources=src     sonar.tests=test     sonar.javascript.lcov.reportPaths=coverage/lcov.info</p> <pre><code># Quality Gates\nsonar.qualitygate.wait=true\nsonar.coverage.minimum=80\nsonar.bugs.blocker.max=0\nsonar.vulnerabilities.critical.max=0\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#_9","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#module-8-lab-artifact-management","title":"MODULE 8 - LAB: Artifact Management","text":""},{"location":"dojo/labs/yellow%20n%20green/#directory-labsmodule-08","title":"Directory: labs/module-08/","text":""},{"location":"dojo/labs/yellow%20n%20green/#_10","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-08container-registryyaml","title":"labs/module-08/container-registry.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#harbor-container-registry-setup","title":"Harbor container registry setup","text":"<p>apiVersion: v1 kind: Secret metadata:   name: registry-credentials   namespace: lab-module-8 type: kubernetes.io/dockerconfigjson data:   .dockerconfigjson: BASE64_ENCODED_CONFIG</p>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-08image-signing-setupyaml","title":"labs/module-08/image-signing-setup.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#cosign-image-signing-configuration","title":"Cosign image signing configuration","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: cosign-config   namespace: lab-module-8 data:   sign-image.sh: |     #!/bin/bash     set -e</p> <pre><code>IMAGE=$1\n\necho \"Signing image: $IMAGE\"\n\n# Generate key pair (in real scenario, use existing keys)\ncosign generate-key-pair\n\n# Sign the image\ncosign sign --key cosign.key $IMAGE\n\n# Generate SBOM\nsyft packages $IMAGE -o spdx-json=sbom.json\n\n# Attach SBOM to image\ncosign attach sbom --sbom sbom.json $IMAGE\n\necho \"Image signed successfully\"\necho \"Verify with: cosign verify --key cosign.pub $IMAGE\"\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#_11","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#green-belt-lab-files-gitops-deployment-modules-9-12","title":"GREEN BELT LAB FILES - GitOps &amp; Deployment (Modules 9-12)","text":""},{"location":"dojo/labs/yellow%20n%20green/#_12","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#_13","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#module-9-lab-1-gitops-with-argocd","title":"MODULE 9 - LAB 1: GitOps with ArgoCD","text":""},{"location":"dojo/labs/yellow%20n%20green/#directory-labsmodule-09","title":"Directory: labs/module-09/","text":""},{"location":"dojo/labs/yellow%20n%20green/#_14","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-09namespaceyaml","title":"labs/module-09/namespace.yaml","text":"<p>apiVersion: v1 kind: Namespace metadata:   name: lab-module-9   labels:     fawkes.io/module: \"9\"     fawkes.io/belt: \"green\"</p>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-09argocd-applicationyaml","title":"labs/module-09/argocd-application.yaml","text":"<p>apiVersion: argoproj.io/v1alpha1 kind: Application metadata:   name: my-app-gitops   namespace: argocd   finalizers:     - resources-finalizer.argocd.argoproj.io spec:   project: default</p> <p>source:     repoURL: https://github.com/student/my-app     targetRevision: HEAD     path: k8s/base</p> <p>destination:     server: https://kubernetes.default.svc     namespace: lab-module-9</p> <p>syncPolicy:     automated:       prune: true       selfHeal: true       allowEmpty: false     syncOptions:       - CreateNamespace=true       - PrunePropagationPolicy=foreground       - PruneLast=true     retry:       limit: 5       backoff:         duration: 5s         factor: 2         maxDuration: 3m</p>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-09sync-waves-exampleyaml","title":"labs/module-09/sync-waves-example.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#demonstrates-argocd-sync-waves","title":"Demonstrates ArgoCD sync waves","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: database-config   namespace: lab-module-9   annotations:     argocd.argoproj.io/sync-wave: \"1\"  # Deploy first data:   database: \"postgres\"</p> <p>apiVersion: apps/v1 kind: Deployment metadata:   name: backend   namespace: lab-module-9   annotations:     argocd.argoproj.io/sync-wave: \"2\"  # Deploy after config spec:   replicas: 2   selector:     matchLabels:       app: backend   template:     metadata:       labels:         app: backend     spec:       containers:       - name: app         image: backend:v1.0.0         envFrom:         - configMapRef:             name: database-config</p>"},{"location":"dojo/labs/yellow%20n%20green/#_15","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#module-10-lab-2-deployment-strategies","title":"MODULE 10 - LAB 2: Deployment Strategies","text":""},{"location":"dojo/labs/yellow%20n%20green/#directory-labsmodule-10","title":"Directory: labs/module-10/","text":""},{"location":"dojo/labs/yellow%20n%20green/#_16","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-10blue-green-deploymentyaml","title":"labs/module-10/blue-green-deployment.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#blue-green-deployment-example","title":"Blue-Green deployment example","text":"<p>apiVersion: v1 kind: Service metadata:   name: my-app   namespace: lab-module-10 spec:   selector:     app: my-app     version: blue  # Switch to 'green' for blue-green switch   ports:   - port: 80     targetPort: 8080</p> <p>apiVersion: apps/v1 kind: Deployment metadata:   name: my-app-blue   namespace: lab-module-10   labels:     app: my-app     version: blue spec:   replicas: 3   selector:     matchLabels:       app: my-app       version: blue   template:     metadata:       labels:         app: my-app         version: blue     spec:       containers:       - name: app         image: my-app:v1.0.0         ports:         - containerPort: 8080</p> <p>apiVersion: apps/v1 kind: Deployment metadata:   name: my-app-green   namespace: lab-module-10   labels:     app: my-app     version: green spec:   replicas: 3   selector:     matchLabels:       app: my-app       version: green   template:     metadata:       labels:         app: my-app         version: green     spec:       containers:       - name: app         image: my-app:v2.0.0  # New version         ports:         - containerPort: 8080</p>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-10canary-deploymentyaml","title":"labs/module-10/canary-deployment.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#manual-canary-deployment-before-flagger","title":"Manual canary deployment (before Flagger)","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: my-app-stable   namespace: lab-module-10 spec:   replicas: 9  # 90% of traffic   selector:     matchLabels:       app: my-app       track: stable   template:     metadata:       labels:         app: my-app         track: stable     spec:       containers:       - name: app         image: my-app:v1.0.0</p> <p>apiVersion: apps/v1 kind: Deployment metadata:   name: my-app-canary   namespace: lab-module-10 spec:   replicas: 1  # 10% of traffic   selector:     matchLabels:       app: my-app       track: canary   template:     metadata:       labels:         app: my-app         track: canary     spec:       containers:       - name: app         image: my-app:v2.0.0</p> <p>apiVersion: v1 kind: Service metadata:   name: my-app   namespace: lab-module-10 spec:   selector:     app: my-app  # Routes to both stable and canary   ports:   - port: 80     targetPort: 8080</p>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-10rolling-updateyaml","title":"labs/module-10/rolling-update.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#rolling-update-strategy","title":"Rolling update strategy","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: my-app-rolling   namespace: lab-module-10 spec:   replicas: 5   strategy:     type: RollingUpdate     rollingUpdate:       maxSurge: 1        # 1 extra pod during update       maxUnavailable: 1  # 1 pod can be unavailable   selector:     matchLabels:       app: my-app   template:     metadata:       labels:         app: my-app     spec:       containers:       - name: app         image: my-app:v2.0.0         readinessProbe:           httpGet:             path: /health             port: 8080           initialDelaySeconds: 5           periodSeconds: 5</p>"},{"location":"dojo/labs/yellow%20n%20green/#_17","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#module-11-lab-3-progressive-delivery-with-flagger","title":"MODULE 11 - LAB 3: Progressive Delivery with Flagger","text":""},{"location":"dojo/labs/yellow%20n%20green/#directory-labsmodule-11","title":"Directory: labs/module-11/","text":""},{"location":"dojo/labs/yellow%20n%20green/#_18","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-11flagger-canaryyaml","title":"labs/module-11/flagger-canary.yaml","text":"<p>apiVersion: flagger.app/v1beta1 kind: Canary metadata:   name: my-app   namespace: lab-module-11 spec:   # deployment reference   targetRef:     apiVersion: apps/v1     kind: Deployment     name: my-app</p> <p># HPA reference (optional)   autoscalerRef:     apiVersion: autoscaling/v2     kind: HorizontalPodAutoscaler     name: my-app</p> <p># service port   service:     port: 80     targetPort: 8080</p> <p># canary analysis   analysis:     # schedule interval     interval: 1m</p> <pre><code># max number of failed metric checks before rollback\nthreshold: 5\n\n# max traffic percentage routed to canary\nmaxWeight: 50\n\n# canary increment step\nstepWeight: 10\n\n# metrics\nmetrics:\n- name: request-success-rate\n  thresholdRange:\n    min: 99\n  interval: 1m\n\n- name: request-duration\n  thresholdRange:\n    max: 500\n  interval: 30s\n\n# webhooks\nwebhooks:\n- name: load-test\n  url: http://flagger-loadtester/\n  timeout: 5s\n  metadata:\n    type: cmd\n    cmd: \"hey -z 1m -q 10 -c 2 http://my-app-canary.lab-module-11/\"\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-11flagger-loadtesteryaml","title":"labs/module-11/flagger-loadtester.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#load-testing-service-for-flagger","title":"Load testing service for Flagger","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: flagger-loadtester   namespace: lab-module-11 spec:   replicas: 1   selector:     matchLabels:       app: flagger-loadtester   template:     metadata:       labels:         app: flagger-loadtester     spec:       containers:       - name: loadtester         image: ghcr.io/fluxcd/flagger-loadtester:0.29.0         ports:         - name: http           containerPort: 8080         command:         - ./loadtester         - -port=8080         - -log-level=info         - -timeout=1h</p> <p>apiVersion: v1 kind: Service metadata:   name: flagger-loadtester   namespace: lab-module-11 spec:   type: ClusterIP   selector:     app: flagger-loadtester   ports:   - name: http     port: 80     targetPort: http</p>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-11prometheus-metricsyaml","title":"labs/module-11/prometheus-metrics.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#servicemonitor-for-prometheus-metrics","title":"ServiceMonitor for Prometheus metrics","text":"<p>apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata:   name: my-app   namespace: lab-module-11 spec:   selector:     matchLabels:       app: my-app   endpoints:   - port: http-metrics     interval: 15s</p>"},{"location":"dojo/labs/yellow%20n%20green/#_19","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#module-12-lab-4-rollback-incident-response","title":"MODULE 12 - LAB 4: Rollback &amp; Incident Response","text":""},{"location":"dojo/labs/yellow%20n%20green/#directory-labsmodule-12","title":"Directory: labs/module-12/","text":""},{"location":"dojo/labs/yellow%20n%20green/#_20","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-12incident-simulationyaml","title":"labs/module-12/incident-simulation.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#deployment-that-will-fail-for-practice","title":"Deployment that will fail (for practice)","text":"<p>apiVersion: apps/v1 kind: Deployment metadata:   name: broken-app   namespace: lab-module-12   labels:     app: broken-app spec:   replicas: 3   selector:     matchLabels:       app: broken-app   template:     metadata:       labels:         app: broken-app     spec:       containers:       - name: app         image: nginx:latest         ports:         - containerPort: 80         env:         - name: CRASH_ON_START           value: \"true\"  # This will cause the app to crash         livenessProbe:           httpGet:             path: /health             port: 8080           initialDelaySeconds: 5           periodSeconds: 5           failureThreshold: 3</p>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-12rollback-scriptyaml","title":"labs/module-12/rollback-script.yaml","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: rollback-scripts   namespace: lab-module-12 data:   rollback-deployment.sh: |     #!/bin/bash     set -e</p> <pre><code>DEPLOYMENT_NAME=$1\nNAMESPACE=${2:-default}\n\necho \"Rolling back deployment: $DEPLOYMENT_NAME in namespace: $NAMESPACE\"\n\n# Get current revision\nCURRENT=$(kubectl rollout history deployment/$DEPLOYMENT_NAME -n $NAMESPACE | tail -1 | awk '{print $1}')\necho \"Current revision: $CURRENT\"\n\n# Rollback to previous revision\nkubectl rollout undo deployment/$DEPLOYMENT_NAME -n $NAMESPACE\n\n# Wait for rollback to complete\nkubectl rollout status deployment/$DEPLOYMENT_NAME -n $NAMESPACE --timeout=5m\n\necho \"Rollback completed successfully\"\n\n# Verify pods are running\nkubectl get pods -n $NAMESPACE -l app=$DEPLOYMENT_NAME\n</code></pre> <p>rollback-argocd.sh: |     #!/bin/bash     set -e</p> <pre><code>APP_NAME=$1\n\necho \"Rolling back ArgoCD application: $APP_NAME\"\n\n# Get current revision\nCURRENT=$(argocd app get $APP_NAME -o json | jq -r '.status.sync.revision')\necho \"Current revision: $CURRENT\"\n\n# Get history\nargocd app history $APP_NAME\n\n# Rollback to previous revision\nPREVIOUS=$(argocd app history $APP_NAME -o json | jq -r '.[-2].id')\nargocd app rollback $APP_NAME $PREVIOUS\n\n# Wait for sync\nargocd app wait $APP_NAME --timeout 300\n\necho \"ArgoCD rollback completed\"\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-12incident-playbookyaml","title":"labs/module-12/incident-playbook.yaml","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: incident-playbook   namespace: lab-module-12 data:   playbook.md: |     # Incident Response Playbook</p> <pre><code>## Phase 1: Detection (0-2 minutes)\n- [ ] Alert received\n- [ ] Acknowledge incident\n- [ ] Create incident channel (#incident-YYYYMMDD-NNN)\n- [ ] Page on-call engineer\n\n## Phase 2: Triage (2-5 minutes)\n- [ ] Check recent deployments\n- [ ] Review error logs\n- [ ] Check monitoring dashboards\n- [ ] Determine severity (P0/P1/P2)\n\n## Phase 3: Mitigation (5-10 minutes)\n- [ ] Decision: Rollback or fix-forward?\n- [ ] If rollback: `kubectl rollout undo deployment/NAME`\n- [ ] If fix-forward: Deploy hotfix\n- [ ] Verify mitigation: Check metrics\n\n## Phase 4: Recovery (10-15 minutes)\n- [ ] Confirm all services healthy\n- [ ] Notify stakeholders\n- [ ] Update status page\n- [ ] Document timeline\n\n## Phase 5: Postmortem (Within 48 hours)\n- [ ] Schedule postmortem meeting\n- [ ] Document root cause\n- [ ] Create action items\n- [ ] Update runbooks\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#labsmodule-12monitoring-alertsyaml","title":"labs/module-12/monitoring-alerts.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#prometheusrule-for-incident-detection","title":"PrometheusRule for incident detection","text":"<p>apiVersion: monitoring.coreos.com/v1 kind: PrometheusRule metadata:   name: app-alerts   namespace: lab-module-12 spec:   groups:   - name: app-health     interval: 30s     rules:     - alert: HighErrorRate       expr: |         (           rate(http_requests_total{status=~\"5..\"}[5m])           /           rate(http_requests_total[5m])         ) &gt; 0.05       for: 2m       labels:         severity: critical       annotations:         summary: \"High error rate detected\"         description: \"Error rate is {{ $value | humanizePercentage }}\"</p> <pre><code>- alert: PodCrashLooping\n  expr: |\n    rate(kube_pod_container_status_restarts_total[15m]) &gt; 0\n  for: 5m\n  labels:\n    severity: warning\n  annotations:\n    summary: \"Pod is crash looping\"\n    description: \"Pod {{ $labels.pod }} is restarting frequently\"\n\n- alert: DeploymentReplicasMismatch\n  expr: |\n    kube_deployment_spec_replicas != kube_deployment_status_replicas_available\n  for: 10m\n  labels:\n    severity: warning\n  annotations:\n    summary: \"Deployment replicas mismatch\"\n    description: \"Deployment {{ $labels.deployment }} has mismatched replicas\"\n</code></pre>"},{"location":"dojo/labs/yellow%20n%20green/#_21","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#shared-green-belt-resources","title":"SHARED GREEN BELT RESOURCES","text":""},{"location":"dojo/labs/yellow%20n%20green/#directory-labsgreen-belt-shared","title":"Directory: labs/green-belt-shared/","text":""},{"location":"dojo/labs/yellow%20n%20green/#_22","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsgreen-belt-sharedflagger-installyaml","title":"labs/green-belt-shared/flagger-install.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#install-flagger-for-all-green-belt-labs","title":"Install Flagger for all green belt labs","text":"<p>apiVersion: v1 kind: Namespace metadata:   name: flagger-system</p> <p>apiVersion: apps/v1 kind: Deployment metadata:   name: flagger   namespace: flagger-system spec:   replicas: 1   selector:     matchLabels:       app: flagger   template:     metadata:       labels:         app: flagger     spec:       serviceAccountName: flagger       containers:       - name: flagger         image: ghcr.io/fluxcd/flagger:1.32.0         ports:         - name: http           containerPort: 8080         command:         - ./flagger         - -mesh-provider=kubernetes         - -metrics-server=http://prometheus.monitoring:9090</p>"},{"location":"dojo/labs/yellow%20n%20green/#labsgreen-belt-sharedargocd-configyaml","title":"labs/green-belt-shared/argocd-config.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#argocd-configuration-for-labs","title":"ArgoCD configuration for labs","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: argocd-cm   namespace: argocd data:   # Enable anonymous access for lab environment   users.anonymous.enabled: \"true\"</p> <p># Increase timeout for sync operations   timeout.reconciliation: \"300s\"</p> <p># Resource customizations   resource.customizations: |     apps/Deployment:       health.lua: |         hs = {}         if obj.status ~= nil then           if obj.status.updatedReplicas == obj.spec.replicas then             hs.status = \"Healthy\"             hs.message = \"Deployment is healthy\"             return hs           end         end         hs.status = \"Progressing\"         hs.message = \"Waiting for deployment\"         return hs</p>"},{"location":"dojo/labs/yellow%20n%20green/#labsgreen-belt-sharedlab-app-baseyaml","title":"labs/green-belt-shared/lab-app-base.yaml","text":""},{"location":"dojo/labs/yellow%20n%20green/#base-application-used-across-multiple-labs","title":"Base application used across multiple labs","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: app-config data:   config.json: |     {       \"environment\": \"lab\",       \"logging\": {         \"level\": \"info\",         \"format\": \"json\"       },       \"metrics\": {         \"enabled\": true,         \"port\": 8080       },       \"health\": {         \"endpoint\": \"/health\",         \"liveness\": \"/health/live\",         \"readiness\": \"/health/ready\"       }     }</p> <p>apiVersion: apps/v1 kind: Deployment metadata:   name: sample-app spec:   replicas: 2   selector:     matchLabels:       app: sample-app   template:     metadata:       labels:         app: sample-app       annotations:         prometheus.io/scrape: \"true\"         prometheus.io/port: \"8080\"         prometheus.io/path: \"/metrics\"     spec:       containers:       - name: app         image: ghcr.io/fawkes/sample-app:v1.0.0         ports:         - name: http           containerPort: 8080         - name: metrics           containerPort: 9090         env:         - name: CONFIG_PATH           value: /config/config.json         volumeMounts:         - name: config           mountPath: /config         livenessProbe:           httpGet:             path: /health/live             port: 8080           initialDelaySeconds: 10           periodSeconds: 10         readinessProbe:           httpGet:             path: /health/ready             port: 8080           initialDelaySeconds: 5           periodSeconds: 5         resources:           requests:             memory: \"128Mi\"             cpu: \"100m\"           limits:             memory: \"256Mi\"             cpu: \"500m\"       volumes:       - name: config         configMap:           name: app-config</p> <p>apiVersion: v1 kind: Service metadata:   name: sample-app spec:   type: ClusterIP   selector:     app: sample-app   ports:   - name: http     port: 80     targetPort: http   - name: metrics     port: 9090     targetPort: metrics</p>"},{"location":"dojo/labs/yellow%20n%20green/#_23","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#lab-setup-automation","title":"LAB SETUP AUTOMATION","text":""},{"location":"dojo/labs/yellow%20n%20green/#_24","title":"=============================================================================","text":""},{"location":"dojo/labs/yellow%20n%20green/#labsscriptssetup-labsh","title":"labs/scripts/setup-lab.sh","text":"<p>apiVersion: v1 kind: ConfigMap metadata:   name: lab-setup-scripts   namespace: fawkes-system data:   setup-module.sh: |     #!/bin/bash     # Automated lab setup script     set -e</p> <pre><code>MODULE=$1\nSTUDENT_EMAIL=$2\n\nif [ -z \"$MODULE\" ] || [ -z \"$STUDENT_EMAIL\" ]; then\n  echo \"Usage: $0 &lt;module-number&gt; &lt;student-email&gt;\"\n  exit 1\nfi\n\nNAMESPACE=\"lab-module-${MODULE}-$(echo $STUDENT_EMAIL | cut -d@ -f1)\"\n\necho \"Setting up lab for Module $MODULE\"\necho \"Student: $STUDENT_EMAIL\"\necho \"Namespace: $NAMESPACE\"\n\n# Create namespace\nkubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -\n\n# Label namespace\nkubectl label namespace $NAMESPACE \\\n  fawkes.io/module=\"$MODULE\" \\\n  fawkes.io/student=\"$STUDENT_EMAIL\" \\\n  --overwrite\n\n# Apply resource quota\nkubectl apply -f /labs/shared/resource-quota.yaml -n $NAMESPACE\n\n# Apply network policy\nkubectl apply -f /labs/shared/network-policy.yaml -n $NAMESPACE\n\n# Apply lab-specific resources\nif [ -d \"/labs/module-$(printf %02d $MODULE)\" ]; then\n  kubectl apply -f /labs/module-$(printf %02d $MODULE)/ -n $NAMESPACE\nfi\n\necho \"Lab setup complete!\"\necho \"Access with: kubectl config set-context --current --namespace=$NAMESPACE\"\n</code></pre> <p>cleanup-lab.sh: |     #!/bin/bash     # Cleanup lab environment     set -e</p> <pre><code>MODULE=$1\nSTUDENT_EMAIL=$2\n\nNAMESPACE=\"lab-module-${MODULE}-$(echo $STUDENT_EMAIL | cut -d@ -f1)\"\n\necho \"Cleaning up lab: $NAMESPACE\"\n\n# Delete namespace (cascades all resources)\nkubectl delete namespace $NAMESPACE --wait=true --timeout=120s\n\necho \"Lab cleanup complete!\"\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/","title":"Module 17: Platform as a Product","text":"<p>Belt Level: \u26ab Black Belt Duration: 60 minutes Prerequisites: Modules 1-16, especially Module 2 (DORA Metrics) Certification Track: Fawkes Platform Architect</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<p>By the end of this module, you will be able to:</p> <ol> <li>Apply product management principles to internal developer platforms</li> <li>Conduct user research to understand developer needs and pain points</li> <li>Build a platform roadmap driven by user feedback and business value</li> <li>Measure platform adoption, satisfaction, and impact using key metrics</li> <li>Establish feedback loops and customer success practices for internal platforms</li> </ol>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#theory-your-platform-is-a-product","title":"\ud83d\udcda Theory: Your Platform is a Product","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#the-platform-as-a-product-mindset","title":"The Platform as a Product Mindset","text":"<p>Traditional IT thinking: - \"We build infrastructure, developers must use it\" - Success = Infrastructure availability (99.9% uptime) - Mandate adoption through policy - One-size-fits-all solutions</p> <p>Platform as a Product thinking: - \"We serve developers, they are our customers\" - Success = Developer satisfaction + business outcomes - Earn adoption through superior experience - Tailored solutions for different user personas</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#why-this-matters","title":"Why This Matters","text":"<p>The \"Build It and They Will Come\" Fallacy:</p> <p>Many platform teams build technically excellent platforms that nobody uses: - \u274c Kubernetes cluster set up perfectly, but developers still deploy to VMs - \u274c CI/CD pipelines available, but teams continue using manual processes - \u274c Observability stack deployed, but no one looks at the dashboards</p> <p>Root cause: Building for technical excellence without understanding user needs.</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#the-platform-product-triad","title":"The Platform Product Triad","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              PLATFORM AS A PRODUCT TRIAD                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                             \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502                    \u2502   DESIRABLE  \u2502                         \u2502\n\u2502                    \u2502  Do users     \u2502                         \u2502\n\u2502                    \u2502  want it?     \u2502                         \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                            \u2502                                 \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502              \u2502                           \u2502                  \u2502\n\u2502              \u2502                           \u2502                  \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502     \u2502    FEASIBLE     \u2502         \u2502     VIABLE     \u2502         \u2502\n\u2502     \u2502  Can we build   \u2502         \u2502  Does it drive \u2502         \u2502\n\u2502     \u2502  it reliably?   \u2502         \u2502  business      \u2502         \u2502\n\u2502     \u2502                 \u2502         \u2502  value?        \u2502         \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                                                             \u2502\n\u2502  SWEET SPOT: All three overlap                             \u2502\n\u2502  - Developers want it (adoption)                           \u2502\n\u2502  - We can build/maintain it (technical feasibility)        \u2502\n\u2502  - It improves business metrics (DORA, cost, velocity)     \u2502\n\u2502                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#your-platforms-customers","title":"Your Platform's \"Customers\"","text":"<p>Unlike external products, your customers are internal:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    USER PERSONAS                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                              \u2502\n\u2502  PERSONA 1: Frontend Developer (Alex)                       \u2502\n\u2502  \u251c\u2500 Needs: Fast iteration, preview environments             \u2502\n\u2502  \u251c\u2500 Pain: Complex deployment process, no staging            \u2502\n\u2502  \u251c\u2500 Skills: React/Vue, basic Docker, no Kubernetes          \u2502\n\u2502  \u2514\u2500 Success: Can deploy feature in &lt;5 minutes               \u2502\n\u2502                                                              \u2502\n\u2502  PERSONA 2: Backend Engineer (Jordan)                       \u2502\n\u2502  \u251c\u2500 Needs: Database migrations, service mesh                \u2502\n\u2502  \u251c\u2500 Pain: Manual DB changes, no service discovery           \u2502\n\u2502  \u251c\u2500 Skills: Java/Python, SQL, intermediate Kubernetes       \u2502\n\u2502  \u2514\u2500 Success: Zero-downtime deployments with DB changes      \u2502\n\u2502                                                              \u2502\n\u2502  PERSONA 3: Data Scientist (Sam)                            \u2502\n\u2502  \u251c\u2500 Needs: GPU resources, Jupyter notebooks, data access    \u2502\n\u2502  \u251c\u2500 Pain: No ML infrastructure, manual model deployment     \u2502\n\u2502  \u251c\u2500 Skills: Python/R, ML frameworks, zero DevOps            \u2502\n\u2502  \u2514\u2500 Success: Train and deploy models without ops team       \u2502\n\u2502                                                              \u2502\n\u2502  PERSONA 4: SRE/DevOps (Morgan)                             \u2502\n\u2502  \u251c\u2500 Needs: Observability, incident response tools           \u2502\n\u2502  \u251c\u2500 Pain: Alert fatigue, no runbooks                        \u2502\n\u2502  \u251c\u2500 Skills: Expert Kubernetes, Terraform, monitoring        \u2502\n\u2502  \u2514\u2500 Success: MTTR &lt; 5 minutes, no 3am pages                 \u2502\n\u2502                                                              \u2502\n\u2502  PERSONA 5: Engineering Manager (Taylor)                    \u2502\n\u2502  \u251c\u2500 Needs: Team velocity metrics, cost visibility           \u2502\n\u2502  \u251c\u2500 Pain: No visibility into bottlenecks, surprise bills    \u2502\n\u2502  \u251c\u2500 Skills: Technical background, business focus            \u2502\n\u2502  \u2514\u2500 Success: Data-driven decisions, predictable costs       \u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key insight: Different personas have different needs. A one-size-fits-all platform will satisfy no one.</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#user-research-for-platforms","title":"\ud83d\udd0d User Research for Platforms","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#discovery-understanding-the-problem","title":"Discovery: Understanding the Problem","text":"<p>Methods for platform user research:</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#1-user-interviews-most-valuable","title":"1. User Interviews (Most valuable)","text":"<pre><code>INTERVIEW SCRIPT TEMPLATE:\n\nOpening (5 min):\n- Thank you for your time\n- We're improving the platform based on developer feedback\n- No wrong answers, honest feedback helps us most\n- Will take 30 minutes\n\nCurrent Workflow (10 min):\n- Walk me through how you deployed your last feature\n- What tools did you use?\n- Where did you get stuck?\n- How long did the whole process take?\n\nPain Points (10 min):\n- What's the most frustrating part of your deployment process?\n- If you could change one thing, what would it be?\n- What takes longer than it should?\n- What do you work around or hack together?\n\nDesired Future (5 min):\n- If I could wave a magic wand, what would your ideal workflow be?\n- What would success look like?\n- How would you measure improvement?\n\nClosing:\n- Can I follow up if we need clarification?\n- Would you be willing to test early versions?\n</code></pre> <p>Pro tips: - Ask \"How?\" and \"Why?\" not \"Would you use...?\" - Observe actual behavior, not stated preferences - Look for workarounds (reveals unmet needs) - Interview both happy and unhappy users</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#2-shadowing-observation","title":"2. Shadowing / Observation","text":"<p>Sit with developers and watch them work: - Where do they wait? - What do they Google? - What tools do they switch between? - Where do they ask for help?</p> <p>Example insights: - \"They spent 20 minutes figuring out environment variable syntax\" - \"They copy-pasted from another team's repo instead of using docs\" - \"They waited 15 minutes for CI pipeline, then force-pushed to debug\"</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#3-surveys-quantitative-validation","title":"3. Surveys (Quantitative validation)","text":"<p>Use after interviews to validate at scale:</p> <pre><code>PLATFORM SATISFACTION SURVEY (NPS-style):\n\n1. How likely are you to recommend our platform to a colleague? (0-10)\n\n2. What is the PRIMARY reason for your score?\n   [Open text field]\n\n3. How often do you deploy to production?\n   \u25cb Multiple times per day\n   \u25cb Daily\n   \u25cb Weekly\n   \u25cb Monthly or less\n\n4. How satisfied are you with the following? (1-5 scale)\n   - Deployment speed\n   - Documentation quality\n   - Getting help when stuck\n   - Observability/debugging\n   - Local development experience\n\n5. What would make the biggest positive impact on your productivity?\n   [Open text field]\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#4-analytics-telemetry","title":"4. Analytics / Telemetry","text":"<p>Instrument your platform to observe usage: - Which features are used most/least? - Where do users drop off? - How long do tasks take? - What errors do they hit?</p> <pre><code># Example: Track platform usage\napiVersion: backstage.io/v1alpha1\nkind: Component\nmetadata:\n  name: payment-service\n  annotations:\n    analytics/deploy-frequency: \"5.2/day\"\n    analytics/avg-deploy-time: \"8m 32s\"\n    analytics/rollback-rate: \"2.1%\"\n    analytics/support-tickets: \"3/month\"\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#synthesizing-research","title":"Synthesizing Research","text":"<p>Turn insights into themes:</p> <pre><code>RAW FEEDBACK (from 15 interviews):\n\n\"Deployments are slow\" (8 mentions)\n\"I don't know if my deploy worked\" (12 mentions)\n\"Kubernetes YAML is confusing\" (6 mentions)\n\"I waste time waiting for CI\" (7 mentions)\n\"Can't debug production issues\" (10 mentions)\n\n\u2193 Synthesize into themes \u2193\n\nTHEME 1: Lack of visibility (12 mentions)\n- No real-time deploy status\n- Can't see what's running in production\n- No easy way to check logs/metrics\n\nTHEME 2: Slow feedback loops (8 mentions)\n- Deployments take &gt;10 minutes\n- CI pipelines are slow\n- No local development that matches prod\n\nTHEME 3: Steep learning curve (6 mentions)\n- Kubernetes concepts are hard\n- Too much YAML configuration\n- Documentation assumes too much knowledge\n</code></pre> <p>Prioritize using Impact vs Effort:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           IMPACT vs EFFORT MATRIX                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                        \u2502\n\u2502  HIGH IMPACT                                           \u2502\n\u2502    \u2502                                                   \u2502\n\u2502    \u2502   [Deployment Status]    [Observability]         \u2502\n\u2502    \u2502   \ud83d\udcca DO FIRST            \ud83d\udcca DO NEXT              \u2502\n\u2502    \u2502                                                   \u2502\n\u2502    \u2502                                                   \u2502\n\u2502    \u2502   [Better Docs]          [Local Dev]             \u2502\n\u2502    \u2502   \ud83d\udcdd QUICK WINS          \u2699\ufe0f  PLAN FOR            \u2502\n\u2502    \u2502                                                   \u2502\n\u2502  LOW IMPACT                                            \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6        \u2502\n\u2502         LOW EFFORT              HIGH EFFORT            \u2502\n\u2502                                                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nNEXT SPRINT:\n1. Deployment status dashboard (high impact, medium effort)\n2. Improve documentation (medium impact, low effort)\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#building-a-platform-roadmap","title":"\ud83d\udccb Building a Platform Roadmap","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#product-roadmap-structure","title":"Product Roadmap Structure","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              PLATFORM ROADMAP (Q1-Q4 2025)                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                              \u2502\n\u2502  NORTH STAR: Reduce deployment time from 30min to &lt;5min     \u2502\n\u2502                                                              \u2502\n\u2502  Q1: VISIBILITY &amp; FEEDBACK                                  \u2502\n\u2502  \u251c\u2500 Deployment status dashboard (Backstage plugin)          \u2502\n\u2502  \u251c\u2500 Real-time logs in UI                                    \u2502\n\u2502  \u251c\u2500 Slack notifications for deploy events                   \u2502\n\u2502  \u2514\u2500 Metrics: 80% developers check dashboard weekly          \u2502\n\u2502                                                              \u2502\n\u2502  Q2: SPEED &amp; RELIABILITY                                     \u2502\n\u2502  \u251c\u2500 Progressive delivery (canary deployments)               \u2502\n\u2502  \u251c\u2500 Parallel CI pipelines (5min \u2192 2min)                     \u2502\n\u2502  \u251c\u2500 Auto-rollback on errors                                 \u2502\n\u2502  \u2514\u2500 Metrics: Deploy time P95 &lt; 8 minutes                    \u2502\n\u2502                                                              \u2502\n\u2502  Q3: DEVELOPER EXPERIENCE                                    \u2502\n\u2502  \u251c\u2500 Self-service preview environments                       \u2502\n\u2502  \u251c\u2500 Local development with Tilt                             \u2502\n\u2502  \u251c\u2500 Golden path templates for common patterns               \u2502\n\u2502  \u2514\u2500 Metrics: 60% of teams using preview envs                \u2502\n\u2502                                                              \u2502\n\u2502  Q4: SCALE &amp; OPTIMIZATION                                    \u2502\n\u2502  \u251c\u2500 Cost optimization dashboard                             \u2502\n\u2502  \u251c\u2500 Auto-scaling for production workloads                   \u2502\n\u2502  \u251c\u2500 Multi-region deployments                                \u2502\n\u2502  \u2514\u2500 Metrics: 25% cost reduction, 99.9% availability         \u2502\n\u2502                                                              \u2502\n\u2502  CONTINUOUS:                                                 \u2502\n\u2502  \u251c\u2500 Weekly office hours                                     \u2502\n\u2502  \u251c\u2500 Monthly user interviews (5 developers)                  \u2502\n\u2502  \u251c\u2500 Quarterly satisfaction surveys (NPS)                    \u2502\n\u2502  \u2514\u2500 Backstage documentation updates                         \u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#roadmap-principles","title":"Roadmap Principles","text":"<ol> <li>Themes, not features: Organize by user goals, not technical tasks</li> <li>Timeboxed: Quarterly or bi-weekly sprints, not \"when it's done\"</li> <li>Outcome-driven: Each item has success metrics</li> <li>Communicated: Public roadmap visible to all developers</li> <li>Flexible: Re-prioritize based on feedback</li> </ol>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#saying-no-productively","title":"Saying No (Productively)","text":"<p>Not every request makes the roadmap:</p> <pre><code>REQUEST: \"Can we add support for Terraform 1.6?\"\n\nBAD RESPONSE:\n\"No, we're too busy.\"\n\nGOOD RESPONSE:\n\"Thanks for the request! We track all feedback. Currently we're\nfocused on reducing deploy times (our #1 pain point from user\nresearch). Terraform 1.6 affects ~5 teams, while deploy speed\naffects all 40 teams. We've added your request to the backlog\nand will revisit in Q3. Does that work for you?\"\n\nEVEN BETTER:\n\"Let's understand the need. What's the use case for 1.6?\n[Discussion reveals they just need a specific provider version]\nOh! We can enable that without upgrading Terraform core.\nCan you test this next week?\"\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#platform-metrics-kpis","title":"\ud83d\udcca Platform Metrics &amp; KPIs","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#metrics-pyramid","title":"Metrics Pyramid","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  BUSINESS OUTCOMES                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502  - Revenue impact                             \u2502     \u2502\n\u2502  \u2502  - Time to market                             \u2502     \u2502\n\u2502  \u2502  - Engineering cost per deploy                \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                        \u25b2                               \u2502\n\u2502                        \u2502                               \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\n\u2502              \u2502   DORA METRICS    \u2502                     \u2502\n\u2502              \u2502 - Deploy frequency\u2502                     \u2502\n\u2502              \u2502 - Lead time       \u2502                     \u2502\n\u2502              \u2502 - MTTR            \u2502                     \u2502\n\u2502              \u2502 - Change fail rate\u2502                     \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502                        \u25b2                               \u2502\n\u2502                        \u2502                               \u2502\n\u2502        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502        \u2502   PLATFORM ADOPTION           \u2502               \u2502\n\u2502        \u2502 - Active users                \u2502               \u2502\n\u2502        \u2502 - Usage frequency             \u2502               \u2502\n\u2502        \u2502 - Feature adoption            \u2502               \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                        \u25b2                               \u2502\n\u2502                        \u2502                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502         USER SATISFACTION                      \u2502    \u2502\n\u2502  \u2502  - NPS (Net Promoter Score)                   \u2502    \u2502\n\u2502  \u2502  - Support ticket volume                      \u2502    \u2502\n\u2502  \u2502  - Documentation clarity rating               \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nStart measuring from bottom up:\n1. Are users satisfied? (surveys, interviews)\n2. Are they adopting? (usage analytics)\n3. Is it improving DORA? (deployment metrics)\n4. Is it driving business value? (cost, velocity)\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#key-platform-metrics","title":"Key Platform Metrics","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#1-adoption-metrics","title":"1. Adoption Metrics","text":"<pre><code>METRIC: Platform Adoption Rate\nFormula: (Teams using platform / Total teams) \u00d7 100%\n\nTargets:\n- Month 1: 10% (early adopters)\n- Month 3: 30% (early majority)\n- Month 6: 60% (late majority)\n- Month 12: 80%+ (full adoption)\n\nTrack by feature:\n- CI/CD pipeline: 75% adoption\n- GitOps deployment: 60% adoption\n- Observability: 45% adoption\n- Preview environments: 25% adoption\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#2-satisfaction-metrics-nps","title":"2. Satisfaction Metrics (NPS)","text":"<pre><code>Net Promoter Score: \"How likely would you recommend our\nplatform to a colleague?\" (0-10)\n\nCalculation:\n- Promoters (9-10): Enthusiastic users\n- Passives (7-8): Satisfied but not advocates\n- Detractors (0-6): Unhappy, at risk\n\nNPS = % Promoters - % Detractors\n\nBenchmark:\n- NPS &gt; 50: Excellent\n- NPS 30-50: Good\n- NPS 0-30: Needs improvement\n- NPS &lt; 0: Crisis mode\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#3-efficiency-metrics","title":"3. Efficiency Metrics","text":"<pre><code>METRIC: Time to First Deployment\nTrack: How long from \"I want to deploy\" to \"It's in production\"\n\nBaseline (no platform): 4 hours\n- Request infrastructure: 2 hours\n- Manual setup: 1 hour\n- Deploy + verify: 1 hour\n\nTarget (with platform): 15 minutes\n- Self-service: 2 minutes\n- Auto-deploy via Git push: 8 minutes\n- Auto-verify health: 5 minutes\n\nImpact: 93% reduction in time to deploy\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#4-support-reliability-metrics","title":"4. Support &amp; Reliability Metrics","text":"<pre><code>METRIC: Mean Time to Resolution (Support)\nTrack: How fast can developers unblock themselves?\n\nSupport ticket categories:\n- Documentation issue: MTTR &lt; 10 minutes (self-service)\n- Configuration help: MTTR &lt; 2 hours (async)\n- Platform bug: MTTR &lt; 4 hours (urgent)\n- Feature request: Tracked in backlog\n\nTarget: 80% of issues resolved in &lt;1 hour\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#dashboard-example","title":"Dashboard Example","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           FAWKES PLATFORM HEALTH DASHBOARD                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                              \u2502\n\u2502  ADOPTION                                                    \u2502\n\u2502  \u251c\u2500 Active Teams: 32/40 (80%) \u25b2 +3 this month              \u2502\n\u2502  \u251c\u2500 Daily Deployments: 127 \u25b2 +15% MoM                       \u2502\n\u2502  \u2514\u2500 Feature Usage:                                           \u2502\n\u2502      \u2022 CI/CD: 85% \u25b2                                          \u2502\n\u2502      \u2022 GitOps: 70% \u25b2                                         \u2502\n\u2502      \u2022 Observability: 55% \u25b2                                  \u2502\n\u2502                                                              \u2502\n\u2502  SATISFACTION (NPS: 42)                                      \u2502\n\u2502  \u251c\u2500 Promoters: 55% (22 users)                               \u2502\n\u2502  \u251c\u2500 Passives: 32% (13 users)                                \u2502\n\u2502  \u2514\u2500 Detractors: 13% (5 users) \u26a0\ufe0f                            \u2502\n\u2502                                                              \u2502\n\u2502  DORA METRICS                                                \u2502\n\u2502  \u251c\u2500 Deploy Frequency: 5.2/day \u25b2 (Target: &gt;5)               \u2502\n\u2502  \u251c\u2500 Lead Time: 45 min \u25bc (Target: &lt;1 hour)                  \u2502\n\u2502  \u251c\u2500 MTTR: 12 min \u25b2 (Target: &lt;15 min)                       \u2502\n\u2502  \u2514\u2500 Change Fail Rate: 3.2% \u25b2 (Target: &lt;5%)                 \u2502\n\u2502                                                              \u2502\n\u2502  SUPPORT                                                     \u2502\n\u2502  \u251c\u2500 Open Tickets: 8 (3 urgent)                              \u2502\n\u2502  \u251c\u2500 MTTR: 2.3 hours \u25bc (Target: &lt;4 hours)                   \u2502\n\u2502  \u2514\u2500 Top Issues:                                              \u2502\n\u2502      1. Deployment timeouts (3 tickets)                     \u2502\n\u2502      2. Secret management confusion (2 tickets)             \u2502\n\u2502                                                              \u2502\n\u2502  ACTIONS                                                     \u2502\n\u2502  \ud83d\udd34 Investigate detractors (schedule 5 interviews)           \u2502\n\u2502  \ud83d\udfe1 Improve deployment timeout documentation                \u2502\n\u2502  \ud83d\udfe2 Celebrate: Hit 80% adoption milestone! \ud83c\udf89               \u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#hands-on-lab-building-a-platform-product","title":"\ud83d\udee0\ufe0f Hands-On Lab: Building a Platform Product","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#lab-overview","title":"Lab Overview","text":"<p>You will practice product management for a platform by: 1. Analyzing user feedback and identifying themes 2. Prioritizing features using impact vs. effort 3. Creating a quarterly roadmap 4. Setting up NPS surveys and adoption tracking 5. Building a platform health dashboard</p> <p>Duration: 25 minutes Tools: Backstage, Fawkes CLI, survey tools</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#lab-setup","title":"Lab Setup","text":"<pre><code># Start the platform product lab\nfawkes lab start --module 17\n\n# This provides:\n# - Backstage instance with sample feedback\n# - Analytics data from 40 development teams\n# - Survey responses (30 developers)\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#exercise-1-analyze-user-feedback-6-minutes","title":"Exercise 1: Analyze User Feedback (6 minutes)","text":"<p>Objective: Review user interviews and identify top 3 themes.</p> <pre><code># View feedback data\ncd ~/fawkes-lab-17/user-research\ncat interviews.json | jq '.[] | {name, role, pain_points}'\n</code></pre> <p>Sample feedback (you'll see 15 interviews):</p> <pre><code>{\n  \"interviews\": [\n    {\n      \"name\": \"Alex (Frontend Dev)\",\n      \"pain_points\": [\n        \"Deployments take 25 minutes\",\n        \"No way to see if my deploy worked\",\n        \"Kubernetes is confusing\"\n      ]\n    },\n    {\n      \"name\": \"Jordan (Backend Dev)\",\n      \"pain_points\": [\n        \"Can't debug production issues\",\n        \"No staging environment\",\n        \"Database migrations are manual\"\n      ]\n    }\n    // ... 13 more interviews\n  ]\n}\n</code></pre> <p>Your task: Use the provided script to analyze themes:</p> <pre><code># Run theme analysis\npython analyze_feedback.py interviews.json\n\n# Output:\n# THEME 1: Slow deployments (12 mentions)\n# THEME 2: Lack of visibility (15 mentions)\n# THEME 3: No staging/preview envs (8 mentions)\n# THEME 4: Difficult debugging (10 mentions)\n# THEME 5: Steep learning curve (7 mentions)\n</code></pre> <p>Question: Which theme should you prioritize? Consider: - Frequency (how many users mentioned it) - Severity (how much pain does it cause) - Feasibility (can you solve it in &lt;1 quarter)</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#exercise-2-prioritize-using-impact-vs-effort-5-minutes","title":"Exercise 2: Prioritize Using Impact vs Effort (5 minutes)","text":"<p>Objective: Plot features on an impact/effort matrix.</p> <pre><code># View proposed features\ncat features.yaml\n</code></pre> <p>features.yaml: <pre><code>features:\n  - name: \"Real-time deployment dashboard\"\n    impact: high\n    effort: medium\n    theme: \"Lack of visibility\"\n\n  - name: \"Self-service preview environments\"\n    impact: high\n    effort: high\n    theme: \"No staging\"\n\n  - name: \"Improve documentation\"\n    impact: medium\n    effort: low\n    theme: \"Learning curve\"\n\n  - name: \"Integrated log viewer\"\n    impact: medium\n    effort: medium\n    theme: \"Debugging\"\n\n  - name: \"Parallel CI pipelines\"\n    impact: high\n    effort: medium\n    theme: \"Slow deployments\"\n</code></pre></p> <p>Your task: Use the Fawkes CLI to generate a prioritization matrix:</p> <pre><code>fawkes product prioritize --input features.yaml --output priority-matrix.png\n\n# Opens an image showing features plotted\n</code></pre> <p>Expected result: <pre><code>DO FIRST (High Impact, Low-Med Effort):\n1. Real-time deployment dashboard\n2. Parallel CI pipelines\n3. Improve documentation\n\nDO NEXT (High Impact, High Effort):\n4. Self-service preview environments\n\nBACKLOG:\n5. Integrated log viewer\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#exercise-3-create-a-quarterly-roadmap-6-minutes","title":"Exercise 3: Create a Quarterly Roadmap (6 minutes)","text":"<p>Objective: Build a Q1 roadmap based on prioritized features.</p> <pre><code># Use roadmap template\ncp templates/roadmap-template.md Q1-2025-roadmap.md\nvim Q1-2025-roadmap.md\n</code></pre> <p>Fill in the template:</p> <pre><code># Q1 2025 Platform Roadmap\n\n## North Star Goal\nReduce deployment time from 25 minutes to &lt;8 minutes (68% improvement)\n\n## Sprint 1-2 (Weeks 1-4): Visibility\n**Theme**: Developers can't see what's happening\n\n- [ ] Deployment status dashboard in Backstage\n  - Real-time progress (queued \u2192 building \u2192 deploying \u2192 healthy)\n  - Estimated time remaining\n  - Success metric: 70% of developers check dashboard weekly\n\n- [ ] Slack notifications\n  - Deploy started/completed/failed\n  - @ mention author on failures\n  - Success metric: &lt;2 min to notice failed deploy\n\n## Sprint 3-4 (Weeks 5-8): Speed\n**Theme**: Deployments are too slow\n\n- [ ] Parallel CI pipelines\n  - Run tests in parallel (8min \u2192 3min)\n  - Cache dependencies\n  - Success metric: P95 build time &lt;5 minutes\n\n- [ ] Optimize Docker builds\n  - Multi-stage builds\n  - Layer caching\n  - Success metric: Image build &lt;2 minutes\n\n## Sprint 5-6 (Weeks 9-12): Polish\n**Theme**: Improve overall experience\n\n- [ ] Documentation overhaul\n  - Step-by-step tutorials for common tasks\n  - Video walkthroughs\n  - Success metric: NPS +10 points\n\n- [ ] Weekly office hours\n  - 1 hour/week for Q&amp;A\n  - Success metric: 15+ attendees average\n\n## Success Criteria (End of Q1)\n- [ ] Deploy time P95: &lt;8 minutes (from 25min)\n- [ ] Platform adoption: 85% of teams (from 70%)\n- [ ] NPS: 50+ (from 38)\n- [ ] Support tickets: &lt;10/week (from 18/week)\n</code></pre> <p>Validate your roadmap:</p> <pre><code>fawkes product validate-roadmap Q1-2025-roadmap.md\n\n# Checks:\n# \u2705 All items have success metrics\n# \u2705 North Star goal is measurable\n# \u2705 Timeboxed to one quarter\n# \u26a0\ufe0f  Warning: Sprint 1-2 may be overloaded (2 major features)\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#exercise-4-set-up-nps-surveys-4-minutes","title":"Exercise 4: Set Up NPS Surveys (4 minutes)","text":"<p>Objective: Configure automated NPS surveys in Backstage.</p> <pre><code># Install Backstage feedback plugin\ncd ~/fawkes-lab-17/backstage\nyarn add @backstage/plugin-user-feedback\n</code></pre> <p>Configure survey:</p> <pre><code># app-config.yaml\nuserFeedback:\n  surveys:\n    - id: platform-nps\n      title: \"Platform Satisfaction Survey\"\n      frequency: quarterly\n      questions:\n        - id: nps\n          type: nps\n          text: \"How likely are you to recommend Fawkes Platform to a colleague?\"\n\n        - id: reason\n          type: text\n          text: \"What's the PRIMARY reason for your score?\"\n\n        - id: biggest-pain\n          type: text\n          text: \"What's your biggest pain point with the platform?\"\n\n        - id: feature-satisfaction\n          type: matrix\n          text: \"How satisfied are you with the following?\"\n          rows:\n            - \"Deployment speed\"\n            - \"Documentation\"\n            - \"Getting help when stuck\"\n            - \"Observability/debugging\"\n          scale: 1-5\n</code></pre> <p>Test the survey:</p> <pre><code># Simulate 10 survey responses\nfawkes lab simulate-surveys --count 10\n\n# View results dashboard\nopen http://localhost:3000/user-feedback/platform-nps\n</code></pre> <p>Expected dashboard: <pre><code>Platform NPS: 42\n\u251c\u2500 Promoters (9-10): 12 responses (55%)\n\u251c\u2500 Passives (7-8): 7 responses (32%)\n\u2514\u2500 Detractors (0-6): 3 responses (13%)\n\nTop Pain Points:\n1. \"Deployments are still too slow\" (8 mentions)\n2. \"Documentation is hard to find\" (5 mentions)\n3. \"Don't know how to debug prod issues\" (4 mentions)\n\nFeature Satisfaction (1-5 scale):\n\u251c\u2500 Deployment speed: 3.2/5 \u26a0\ufe0f\n\u251c\u2500 Documentation: 3.8/5\n\u251c\u2500 Getting help: 4.1/5 \u2705\n\u2514\u2500 Observability: 3.5/5\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#exercise-5-build-platform-health-dashboard-4-minutes","title":"Exercise 5: Build Platform Health Dashboard (4 minutes)","text":"<p>Objective: Create a dashboard showing adoption, satisfaction, and DORA metrics.</p> <pre><code># Use Grafana with pre-configured datasources\ncd ~/fawkes-lab-17/grafana\ndocker-compose up -d\n\n# Import dashboard\ncurl -X POST http://localhost:3000/api/dashboards/db \\\n  -H \"Content-Type: application/json\" \\\n  -d @platform-health-dashboard.json\n</code></pre> <p>Dashboard panels (pre-configured):</p> <ol> <li> <p>Adoption Panel: <pre><code># Teams using platform\ncount(count by (team) (deployment_total{platform=\"fawkes\"}))\n\n# Daily deployments\nrate(deployment_total{platform=\"fawkes\"}[1d])\n</code></pre></p> </li> <li> <p>Satisfaction Panel: <pre><code>-- NPS score\nSELECT\n  (COUNT(*) FILTER (WHERE score &gt;= 9) * 100.0 / COUNT(*) -\n   COUNT(*) FILTER (WHERE score &lt;= 6) * 100.0 / COUNT(*)) as nps\nFROM survey_responses\nWHERE survey_id = 'platform-nps'\n  AND created_at &gt; NOW() - INTERVAL '90 days'\n</code></pre></p> </li> <li> <p>DORA Metrics Panel: <pre><code># Deploy frequency (per day per team)\navg(rate(deployment_total[1d])) by (team)\n\n# Lead time for changes (commit to deploy)\nhistogram_quantile(0.95,\n  rate(lead_time_seconds_bucket[1d])\n)\n\n# MTTR\nhistogram_quantile(0.95,\n  rate(incident_resolution_seconds_bucket[1d])\n)\n\n# Change failure rate\n(rate(deployment_failed_total[1d]) /\n rate(deployment_total[1d])) * 100\n</code></pre></p> </li> </ol> <p>View the dashboard:</p> <pre><code>open http://localhost:3000/d/platform-health\n\n# You should see a comprehensive dashboard showing all key metrics\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#lab-validation","title":"Lab Validation","text":"<pre><code># Run validation\nfawkes lab validate --module 17\n\n# Expected output:\n# \u2705 User feedback analyzed and themes identified\n# \u2705 Features prioritized using impact/effort matrix\n# \u2705 Quarterly roadmap created with success metrics\n# \u2705 NPS survey configured and tested\n# \u2705 Platform health dashboard deployed\n</code></pre> <p>Cleanup:</p> <pre><code>fawkes lab stop --module 17\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#knowledge-check","title":"\u2705 Knowledge Check","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#question-1-product-mindset","title":"Question 1: Product Mindset","text":"<p>What's the key difference between \"platform as infrastructure\" vs \"platform as a product\"?</p> <p>A) Products are externally sold, infrastructure is internal B) Products focus on user satisfaction, infrastructure focuses on uptime C) Products cost more to build D) Infrastructure is more reliable</p> Show Answer  **Answer: B**  Platform as a product treats internal developers as customers and measures success by their satisfaction and outcomes, not just technical availability. You can have 99.99% uptime but zero adoption if developers don't find it valuable."},{"location":"dojo/modules/black-belt/module-17-platform-product/#question-2-user-research","title":"Question 2: User Research","text":"<p>Which user research method provides the deepest insights into developer pain points?</p> <p>A) Anonymous surveys B) Usage analytics C) In-person interviews with observation D) Support ticket analysis</p> Show Answer  **Answer: C**  One-on-one interviews combined with observing actual workflows reveal not just what people say, but what they actually do. You discover workarounds, inefficiencies, and unspoken needs that surveys miss."},{"location":"dojo/modules/black-belt/module-17-platform-product/#question-3-user-personas","title":"Question 3: User Personas","text":"<p>Why create user personas for your platform?</p> <p>A) To segment users for marketing B) Different roles have different needs requiring tailored solutions C) It's a requirement for product management D) To decide which users to prioritize</p> Show Answer  **Answer: B**  Frontend developers, backend engineers, data scientists, and SREs have vastly different needs. A one-size-fits-all platform satisfies no one. Personas help you design appropriate experiences for each group."},{"location":"dojo/modules/black-belt/module-17-platform-product/#question-4-nps-net-promoter-score","title":"Question 4: NPS (Net Promoter Score)","text":"<p>Your platform has an NPS of -15. What does this mean?</p> <p>A) 15% of users are happy B) More detractors than promoters - urgent action needed C) Average satisfaction is 15% D) Normal score for internal platforms</p> Show Answer  **Answer: B**  NPS = % Promoters - % Detractors. A negative NPS means you have more unhappy users than happy ones. This indicates serious problems requiring immediate investigation and action."},{"location":"dojo/modules/black-belt/module-17-platform-product/#question-5-roadmap-prioritization","title":"Question 5: Roadmap Prioritization","text":"<p>You have two features: \"Real-time logs\" (high impact, high effort) and \"Improved docs\" (medium impact, low effort). Which should you build first?</p> <p>A) Real-time logs (higher impact) B) Improved docs (faster to ship) C) Build both simultaneously D) Survey users to decide</p> Show Answer  **Answer: B**  Start with \"quick wins\" (medium impact, low effort) to build momentum and trust. Better docs can ship in weeks and immediately help users. Real-time logs takes months and users may not trust you to deliver if you haven't shipped smaller improvements first."},{"location":"dojo/modules/black-belt/module-17-platform-product/#question-6-adoption-metrics","title":"Question 6: Adoption Metrics","text":"<p>Your platform has 40% adoption after 6 months. What should you do?</p> <p>A) Mandate usage via policy B) Interview non-adopters to understand barriers C) Add more features to attract users D) Wait longer for organic adoption</p> Show Answer  **Answer: B**  Low adoption indicates your platform doesn't meet user needs. Talk to the 60% who aren't using it - they'll tell you exactly what's blocking them. Mandating usage creates resentment, and adding features may worsen the problem if they're not addressing real needs."},{"location":"dojo/modules/black-belt/module-17-platform-product/#question-7-success-metrics","title":"Question 7: Success Metrics","text":"<p>Which metric best indicates your platform is succeeding?</p> <p>A) Number of features shipped B) Infrastructure uptime percentage C) Improvement in DORA metrics for users D) Size of your platform team</p> Show Answer  **Answer: C**  The ultimate measure of platform success is whether it improves outcomes for your users. If teams using your platform deploy more frequently with fewer failures (better DORA metrics), you're succeeding regardless of feature count or uptime."},{"location":"dojo/modules/black-belt/module-17-platform-product/#question-8-saying-no","title":"Question 8: Saying No","text":"<p>A senior engineer requests a niche feature that would take 2 months but only helps their team. How do you respond?</p> <p>A) \"No, we're too busy\" B) \"File a ticket and we'll get to it eventually\" C) Build it (they're senior so must be important) D) Explain current priorities and understand the underlying need</p> Show Answer  **Answer: D**  Productively saying no means: (1) Acknowledge the request, (2) Explain current priorities and why, (3) Understand the underlying need (there may be a simpler solution), (4) Offer alternatives or a timeline for reconsideration. Never just say no."},{"location":"dojo/modules/black-belt/module-17-platform-product/#real-world-examples","title":"\ud83c\udf0d Real-World Examples","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#example-1-spotifys-backstage-dogfooding-as-product-strategy","title":"Example 1: Spotify's Backstage - Dogfooding as Product Strategy","text":"<p>Challenge: 280+ engineers, hundreds of microservices, fragmented tooling creating chaos.</p> <p>Product Approach: - Started with research: Interviewed 50 engineers about pain points - Built for themselves first: Backstage solved Spotify's own problems - Measured everything: Tracked time-to-deploy, incident response time, onboarding speed - Iterated based on feedback: Weekly demos, monthly retrospectives</p> <p>Key Product Decisions: - Golden paths, not enforcement: Made easy path obvious, didn't block alternatives - Self-service: Developers create services without ops tickets - Plugin ecosystem: Teams can extend for their needs</p> <p>Results: - Onboarding time: 10 days \u2192 1 day (90% improvement) - Time to first deploy: 4 hours \u2192 5 minutes (98% improvement) - Adoption: 100% of teams (voluntary, not mandated)</p> <p>Lesson: \"If we couldn't convince ourselves to use it, we knew developers wouldn't either.\"</p> <p>Learn more: Backstage Engineering Blog</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#example-2-netflixs-paved-road-product-thinking-at-scale","title":"Example 2: Netflix's Paved Road - Product Thinking at Scale","text":"<p>Philosophy: \"We don't require you to use the paved road, but we make it so good that you'd be crazy not to.\"</p> <p>Product Strategy:</p> <pre><code>UNPAVED ROAD (Hard way):\n\u251c\u2500 Provision infrastructure yourself: 2 days\n\u251c\u2500 Configure monitoring: 4 hours\n\u251c\u2500 Set up CI/CD: 1 day\n\u251c\u2500 Security scanning: 3 hours\n\u2514\u2500 Total: 3+ days + ongoing maintenance\n\nPAVED ROAD (Netflix platform):\n\u251c\u2500 Run: netflix-scaffold new-service\n\u251c\u2500 Infrastructure auto-provisioned: 10 minutes\n\u251c\u2500 Monitoring pre-configured: 0 minutes\n\u251c\u2500 CI/CD ready: 0 minutes\n\u251c\u2500 Security included: 0 minutes\n\u2514\u2500 Total: 10 minutes + zero maintenance\n</code></pre> <p>Key Insight: Don't mandate the platform, make it irresistibly better.</p> <p>Product Metrics: - Adoption: 95%+ voluntary (not mandated) - Developer satisfaction: NPS 72 (world-class) - Time saved: 40+ engineering hours per new service</p> <p>How they measured product-market fit: - Tracked adoption rate by team - Monthly surveys (NPS + open feedback) - Usage analytics (which features, how often) - \"Paved road health score\" dashboard</p> <p>Lesson: Product thinking means your platform wins by being better, not by being required.</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#example-3-etsys-product-management-for-infrastructure","title":"Example 3: Etsy's Product Management for Infrastructure","text":"<p>Challenge: Platform team seen as \"cost center\" with unclear value.</p> <p>Product Transformation:</p> <p>Before (Infrastructure mindset): - Success = Uptime percentage - Shipped features, hoped developers used them - No user research - Reactive support (waiting for tickets)</p> <p>After (Product mindset): - Hired product manager for platform team - Quarterly OKRs tied to developer productivity - Regular user research: 10 developer interviews/month - Platform health dashboard: Adoption, satisfaction, DORA metrics - Proactive support: Office hours, documentation, onboarding</p> <p>Product Management Practices:</p> <ol> <li> <p>Quarterly Planning: <pre><code>Q1 OKRs:\nObjective: Make deployments delightful\n\u251c\u2500 KR1: Deploy time P95 &lt; 10 minutes (from 30min)\n\u251c\u2500 KR2: Deployment success rate &gt; 95% (from 88%)\n\u2514\u2500 KR3: Developer NPS &gt; 40 (from 18)\n</code></pre></p> </li> <li> <p>Bi-weekly User Testing:</p> </li> <li>Watch developers deploy a feature</li> <li>Identify friction points</li> <li> <p>Ship improvements within 1 sprint</p> </li> <li> <p>Feature Flags for Platform Features: <pre><code># Gradually roll out new features\nfeatures:\n  parallel_ci:\n    enabled_teams: [\"payments\", \"search\", \"checkout\"]\n    rollout_percentage: 25%\n    feedback_required: true\n</code></pre></p> </li> </ol> <p>Results: - NPS: 18 \u2192 58 in 6 months - Adoption: 45% \u2192 85% - Platform budget: Increased 40% (demonstrated clear value) - Team morale: Platform team seen as strategic, not cost center</p> <p>Lesson: Treating infrastructure as a product transforms how the organization views and funds platform teams.</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#example-4-airbnbs-platform-product-management","title":"Example 4: Airbnb's Platform Product Management","text":"<p>Structure: Each platform capability has a dedicated product manager.</p> <p>Example: CI/CD Product Manager</p> <p>Responsibilities: - User research: Interview 5 developers weekly - Roadmap: Prioritize features based on impact - Metrics: Own deployment frequency and lead time - Communication: Publish monthly updates to eng org</p> <p>Sample Project: \"Project Lightning\" (Faster CI/CD)</p> <p>Discovery Phase (2 weeks): <pre><code>Research findings:\n- 78% of developers frustrated with CI speed\n- Average build time: 18 minutes\n- 40% of builds fail due to flaky tests\n- Developers context-switch while waiting\n\nUser quotes:\n\"I start a build then go get coffee. By the time I'm back,\n I've forgotten what I was working on.\"\n\n\"Half the time the build fails because of a flaky test,\n not my code. It's demoralizing.\"\n</code></pre></p> <p>Roadmap (3 months): <pre><code>Month 1: Quick wins\n\u251c\u2500 Parallel test execution: 18min \u2192 12min\n\u251c\u2500 Better test splitting\n\u2514\u2500 Success metric: 33% faster builds\n\nMonth 2: Reliability\n\u251c\u2500 Quarantine flaky tests\n\u251c\u2500 Auto-retry failed tests once\n\u2514\u2500 Success metric: &lt;10% false failures\n\nMonth 3: Intelligence\n\u251c\u2500 Predictive test selection (only run affected tests)\n\u251c\u2500 Smart caching\n\u2514\u2500 Success metric: 12min \u2192 5min average build time\n</code></pre></p> <p>Communication: - Weekly Slack updates in #engineering - Demo videos showing improvements - \"Build time tracker\" dashboard (public)</p> <p>Results: - Build time: 18min \u2192 5min (72% faster) - False failure rate: 40% \u2192 8% - Developer NPS: +28 points - 2,000+ engineering hours saved/month</p> <p>Lesson: Dedicated product management for platform capabilities drives meaningful improvements. Treat each platform area (CI/CD, observability, deployment) as its own product.</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#dora-capabilities-mapping","title":"\ud83d\udcca DORA Capabilities Mapping","text":"<p>This module directly supports these DORA capabilities:</p> Capability How This Module Helps Impact on Metrics Generative Culture Product thinking fosters collaboration between platform and dev teams Improves all DORA metrics through better alignment Visual Management Platform health dashboards make work visible Faster identification of bottlenecks Team Experimentation User research and feedback loops enable rapid iteration Higher deployment frequency through faster learning Work in Small Batches Quarterly roadmaps and iterative improvement Reduced lead time and change failure rate Learning Culture Continuous user feedback creates learning organization Sustained improvement across all metrics"},{"location":"dojo/modules/black-belt/module-17-platform-product/#troubleshooting-common-issues","title":"\ud83d\udd27 Troubleshooting Common Issues","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#issue-1-low-adoption-despite-good-technology","title":"Issue 1: Low Adoption Despite Good Technology","text":"<p>Symptom: You've built a technically excellent platform but only 30% adoption after 6 months.</p> <p>Root Causes: - Built for perceived needs, not actual needs - No marketing/evangelism of the platform - Lack of documentation or examples - Migration path too difficult from existing solutions</p> <p>Solution:</p> <pre><code>STEP 1: Interview non-adopters\n\"Why aren't you using the platform?\"\nCommon answers:\n- \"Didn't know it existed\"\n- \"Too hard to migrate\"\n- \"My current solution works fine\"\n- \"Tried it once, got stuck, gave up\"\n\nSTEP 2: Address barriers systematically\n\u251c\u2500 Awareness: Weekly demos, Slack announcements, onboarding talks\n\u251c\u2500 Migration: Build automated migration tools\n\u251c\u2500 Documentation: Step-by-step tutorials for common use cases\n\u2514\u2500 Support: Dedicated office hours, Slack channel with fast response\n\nSTEP 3: Create champions\n\u251c\u2500 Find early adopters who love the platform\n\u251c\u2500 Have them present at team meetings\n\u251c\u2500 \"Platform champions\" program with incentives\n\u2514\u2500 Share success stories publicly\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#issue-2-negative-nps-more-detractors-than-promoters","title":"Issue 2: Negative NPS (More Detractors Than Promoters)","text":"<p>Symptom: NPS of -10 or below, lots of complaints.</p> <p>Immediate Actions:</p> <pre><code>WEEK 1: Understand the damage\n\u251c\u2500 Read every detractor comment\n\u251c\u2500 Schedule calls with 10 most vocal detractors\n\u251c\u2500 Identify the top 3 pain points\n\nWEEK 2: Quick wins\n\u251c\u2500 Fix documentation gaps (lowest effort)\n\u251c\u2500 Improve most common error messages\n\u251c\u2500 Send personal follow-ups to detractors\n\nMONTH 1: Address systemic issues\n\u251c\u2500 Tackle #1 pain point from research\n\u251c\u2500 Communicate progress transparently\n\u251c\u2500 Re-survey after changes ship\n\nONGOING: Prevent future issues\n\u251c\u2500 Monthly NPS surveys (catch problems early)\n\u251c\u2500 Faster response to support tickets\n\u251c\u2500 Proactive communication about known issues\n</code></pre> <p>Example Turnaround: <pre><code>GitHub Internal Platform (fictional example):\n- Month 0: NPS -15 (crisis mode)\n  - Top issue: Deployments failing randomly\n  - Action: All-hands to fix reliability\n\n- Month 1: NPS -5 (improving)\n  - Fixed deployment reliability\n  - Added status page for transparency\n\n- Month 3: NPS +15 (positive)\n  - Continued improvements\n  - Regular communication building trust\n\n- Month 6: NPS +42 (healthy)\n  - Platform now trusted\n  - Adoption increasing\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#issue-3-feature-requests-overwhelming-your-backlog","title":"Issue 3: Feature Requests Overwhelming Your Backlog","text":"<p>Symptom: 200+ feature requests, can't prioritize, team paralyzed.</p> <p>Solution - Ruthless Prioritization:</p> <pre><code>FRAMEWORK: Impact vs Strategic Alignment\n\nStep 1: Categorize all requests\n\u251c\u2500 P0 (Do Now): High impact + Strategic alignment\n\u2502   Example: Deploy speed improvements (affects all teams)\n\u2502\n\u251c\u2500 P1 (Do Soon): High impact OR Strategic alignment\n\u2502   Example: Preview environments (affects 60% of teams)\n\u2502\n\u251c\u2500 P2 (Do Later): Medium impact + Nice to have\n\u2502   Example: Additional language support\n\u2502\n\u2514\u2500 P3 (Don't Do): Low impact + Off-strategy\n    Example: Custom CI runners for 1 team\n\nStep 2: Communicate decisions\n\u251c\u2500 Publish prioritization criteria\n\u251c\u2500 Explain \"why\" for each category\n\u251c\u2500 Set expectations (P0 this quarter, P1 next quarter, P2 backlog, P3 rejected)\n\nStep 3: Review quarterly\n\u251c\u2500 Re-prioritize based on new data\n\u251c\u2500 Business priorities may change\n\u2514\u2500 Some P2s become P0s (and vice versa)\n</code></pre> <p>Sample Communication:</p> <pre><code># Platform Roadmap Prioritization\n\n## How We Prioritize\n\n**P0 Criteria** (Do This Quarter):\n- Affects &gt;50% of teams\n- Improves DORA metrics significantly\n- Blocks other high-priority work\n\n**Current P0 Features** (Q1 2025):\n1. Deployment speed improvements (18min \u2192 8min target)\n2. Real-time deployment status dashboard\n3. Parallel CI pipelines\n\n**P1 Features** (Q2 2025):\n4. Self-service preview environments\n5. Integrated log viewer\n6. Cost optimization dashboard\n\n## Your Request: \"Support for Terraform 1.7\"\n- Priority: P2 (Do Later)\n- Reasoning: Affects 5 teams (12%), existing 1.6 sufficient for most use cases\n- Timeline: Q3 2025 (will revisit if Terraform 1.7 becomes critical)\n\nQuestions? Disagree with priority? Let's talk: #platform-feedback\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#issue-4-platform-team-seen-as-cost-center-not-value-driver","title":"Issue 4: Platform Team Seen as Cost Center, Not Value Driver","text":"<p>Symptom: Budget cuts, no headcount, leadership doesn't understand platform value.</p> <p>Solution - Quantify Business Impact:</p> <pre><code>BUILD A BUSINESS CASE\n\n1. Quantify Time Savings:\n   Before platform: 40 teams \u00d7 4 hours/deploy \u00d7 $150/hour = $24,000/deploy\n   After platform: 40 teams \u00d7 0.5 hours/deploy \u00d7 $150/hour = $3,000/deploy\n   Savings per deploy: $21,000\n   Deploys per day: 50\n   Annual savings: $21,000 \u00d7 50 \u00d7 250 days = $262.5M\n\n2. Quantify Faster Time-to-Market:\n   Lead time improvement: 2 weeks \u2192 2 days\n   Revenue impact: Ship features 10 days faster\n   If feature generates $100k/month revenue:\n   Value: $100k \u00d7 (10/30) = $33k per feature\n   Features per year: 100\n   Annual value: $3.3M\n\n3. Quantify Risk Reduction:\n   MTTR improvement: 2 hours \u2192 15 minutes\n   Downtime cost: $50k/hour\n   Incidents per month: 5\n   Annual savings: $50k \u00d7 1.75 \u00d7 5 \u00d7 12 = $5.25M\n\nTOTAL ANNUAL VALUE: $271M\nPlatform team cost: $5M/year (10 engineers)\nROI: 54x\n</code></pre> <p>Present to Leadership:</p> <pre><code># Platform Team Business Case\n\n## Executive Summary\nOur platform team drives $271M in annual value through:\n- $262.5M in developer productivity gains\n- $3.3M in faster time-to-market\n- $5.25M in reduced downtime costs\n\nAt $5M/year cost, we deliver 54x ROI.\n\n## Metrics\n- Deploy frequency: 5/day (up from 0.5/day)\n- Lead time: 2 days (down from 14 days)\n- MTTR: 15 minutes (down from 2 hours)\n- Developer NPS: 52 (up from 18)\n\n## Request\nMaintain current headcount (10 FTE) and approve Q1 roadmap.\nWithout platform investment, we risk losing competitive advantage\nin deployment velocity.\n</code></pre>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#books","title":"Books","text":"<ul> <li>\"The Lean Startup\" by Eric Ries - Core product principles applicable to platforms</li> <li>\"Inspired: How to Create Tech Products Customers Love\" by Marty Cagan - Product management fundamentals</li> <li>\"Escaping the Build Trap\" by Melissa Perri - Outcome-driven product development</li> <li>\"User Story Mapping\" by Jeff Patton - Understanding user journeys</li> <li>\"The Mom Test\" by Rob Fitzpatrick - How to conduct effective user interviews</li> </ul>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#articles-papers","title":"Articles &amp; Papers","text":"<ul> <li>\"Team Topologies\" by Matthew Skelton &amp; Manuel Pais - Platform team structures</li> <li>\"Platform Strategy\" by Evan Bottcher (ThoughtWorks) - Defining platform vision</li> <li>\"Developers Are Users Too\" by Jean Yang - Applying UX to developer tools</li> <li>DORA State of DevOps Reports - Measuring platform impact</li> </ul>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#courses-communities","title":"Courses &amp; Communities","text":"<ul> <li>Platform Engineering Community - platformengineering.org</li> <li>Product School - Internal product management courses</li> <li>Mind the Product - Product management community and resources</li> </ul>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#tools","title":"Tools","text":"<ul> <li>Backstage - Platform with built-in user feedback and analytics</li> <li>Pendo - Product analytics for internal tools</li> <li>Dovetail - User research repository</li> <li>ProductBoard - Roadmap management</li> <li>Fullstory - Session replay for internal tools</li> </ul>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#key-takeaways","title":"\ud83c\udfaf Key Takeaways","text":"<p>By completing this module, you've learned:</p> <ol> <li>\u2705 Platform as a product mindset - Your users are developers; measure their satisfaction</li> <li>\u2705 User research methods - Interviews, surveys, shadowing, analytics</li> <li>\u2705 Prioritization frameworks - Impact vs. effort, strategic alignment</li> <li>\u2705 Roadmap building - Outcome-driven, timeboxed, measurable</li> <li>\u2705 Key metrics - NPS, adoption, DORA metrics, support efficiency</li> <li>\u2705 Product management practices - Feedback loops, iteration, communication</li> </ol> <p>Critical insight: The best platform is useless if developers don't adopt it. Product thinking ensures you build what users actually need, not what you think they need.</p> <p>Remember: - \ud83c\udfaf Outcomes over outputs: Measure impact, not features shipped - \ud83d\udc42 Listen more than talk: Users know their problems better than you - \ud83d\udd01 Iterate relentlessly: Small improvements compound over time - \ud83d\udce2 Communicate constantly: Share progress, celebrate wins, be transparent about challenges</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#next-steps","title":"\ud83d\ude80 Next Steps","text":""},{"location":"dojo/modules/black-belt/module-17-platform-product/#in-module-18-multi-tenancy-resource-management","title":"In Module 18: Multi-Tenancy &amp; Resource Management","text":"<p>You'll learn how to: - Design multi-tenant platforms serving multiple teams securely - Implement resource quotas and isolation - Handle namespace management and RBAC at scale - Create self-service onboarding workflows - Monitor and optimize resource utilization across tenants</p> <p>Prepare by: - Identifying how many teams your platform will serve - Understanding your organization's compliance requirements - Listing resources that need quota enforcement (CPU, memory, storage)</p>"},{"location":"dojo/modules/black-belt/module-17-platform-product/#black-belt-progress","title":"\ud83c\udfc6 Black Belt Progress","text":"<p>Module 17 Complete! \u2705</p> <pre><code>Black Belt Progress:\n[\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] 25% (1/4 modules)\n\n\u2705 Module 17: Platform as a Product\n\u2b1c Module 18: Multi-Tenancy &amp; Resource Management\n\u2b1c Module 19: Security &amp; Zero Trust\n\u2b1c Module 20: Multi-Cloud Strategies\n\nNext: Module 18 to continue your Black Belt journey!\n</code></pre> <p>Module 17: Platform as a Product | Fawkes Dojo | Black Belt \"Build what users need, not what you think they need\" | Version 1.0</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/","title":"Fawkes Dojo Module 18: Multi-Tenancy &amp; RBAC","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \u26ab Black Belt - Platform Architecture Module: 2 of 4 (Black Belt) Duration: 90 minutes Difficulty: Expert Prerequisites: - Module 17: Platform Architecture complete - Deep Kubernetes knowledge - Security fundamentals - Understanding of identity systems</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Design multi-tenant platform architectures</li> <li>\u2705 Implement robust RBAC systems</li> <li>\u2705 Create security boundaries and isolation</li> <li>\u2705 Manage namespace strategies at scale</li> <li>\u2705 Implement policy enforcement with OPA</li> <li>\u2705 Design quota and resource management</li> <li>\u2705 Handle tenant lifecycle management</li> </ol> <p>DORA Capabilities Addressed: - \u2713 Security &amp; Compliance - \u2713 Access Control - \u2713 Team Autonomy (with guardrails) - \u2713 Resource Efficiency</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#part-1-multi-tenancy-fundamentals","title":"\ud83d\udcd6 Part 1: Multi-Tenancy Fundamentals","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#what-is-multi-tenancy","title":"What is Multi-Tenancy?","text":"<p>Definition: Multiple teams (tenants) sharing a platform while maintaining isolation</p> <p>Isolation Levels:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Isolation Level            Cost    Security    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Soft (Namespace)           Low     Basic       \u2502\n\u2502  Medium (vCluster)          Medium  Good        \u2502\n\u2502  Hard (Separate Clusters)   High    Excellent   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#tenancy-models","title":"Tenancy Models","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#model-1-namespace-per-team","title":"Model 1: Namespace-per-Team","text":"<pre><code>Cluster: production\n\u251c\u2500 Namespace: team-alpha-prod\n\u2502  \u251c\u2500 Deployment: service-a\n\u2502  \u251c\u2500 Service: service-a\n\u2502  \u2514\u2500 ResourceQuota: team-alpha-quota\n\u251c\u2500 Namespace: team-beta-prod\n\u2502  \u251c\u2500 Deployment: service-b\n\u2502  \u2514\u2500 ResourceQuota: team-beta-quota\n\u2514\u2500 Namespace: team-gamma-prod\n   \u2514\u2500 Deployment: service-c\n</code></pre> <p>Pros: - \u2705 Simple to implement - \u2705 Low overhead - \u2705 Easy cross-team communication</p> <p>Cons: - \u274c Shared control plane (noisy neighbor) - \u274c Limited isolation - \u274c Version lock (same K8s version)</p> <p>Best For: Internal teams, trusted tenants</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#model-2-virtual-clusters-vcluster","title":"Model 2: Virtual Clusters (vCluster)","text":"<pre><code>Host Cluster\n\u251c\u2500 Namespace: vcluster-team-alpha\n\u2502  \u2514\u2500 Virtual Control Plane\n\u2502     \u2514\u2500 Virtual Namespace: default\n\u2502        \u2514\u2500 Pods (run in host namespace)\n\u251c\u2500 Namespace: vcluster-team-beta\n\u2502  \u2514\u2500 Virtual Control Plane\n\u2502     \u2514\u2500 Virtual Namespace: default\n\u2514\u2500 Namespace: vcluster-team-gamma\n</code></pre> <p>Pros: - \u2705 Full Kubernetes API per tenant - \u2705 Different versions possible - \u2705 Better isolation - \u2705 Admin-level access per tenant</p> <p>Cons: - \u274c More complex - \u274c Higher resource overhead - \u274c Cross-vCluster networking tricky</p> <p>Best For: Agencies, managed services, dev environments</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#model-3-cluster-per-team","title":"Model 3: Cluster-per-Team","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Team Alpha   \u2502  \u2502 Team Beta    \u2502  \u2502 Team Gamma   \u2502\n\u2502 Cluster      \u2502  \u2502 Cluster      \u2502  \u2502 Cluster      \u2502\n\u2502              \u2502  \u2502              \u2502  \u2502              \u2502\n\u2502 Full Control \u2502  \u2502 Full Control \u2502  \u2502 Full Control \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Pros: - \u2705 Complete isolation - \u2705 Full autonomy - \u2705 Blast radius contained</p> <p>Cons: - \u274c High cost - \u274c Management overhead - \u274c Shared services duplication</p> <p>Best For: Large enterprises, critical workloads, external customers</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#security-boundaries","title":"Security Boundaries","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Security Layers                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  1. Network Policies (L3/L4)                \u2502\n\u2502     \u2514\u2500 Block cross-namespace traffic        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  2. RBAC (API Access)                       \u2502\n\u2502     \u2514\u2500 Who can do what                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  3. Pod Security Standards                  \u2502\n\u2502     \u2514\u2500 What containers can do               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  4. Policy Enforcement (OPA)                \u2502\n\u2502     \u2514\u2500 Custom rules and validation          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  5. Resource Quotas                         \u2502\n\u2502     \u2514\u2500 Prevent resource exhaustion          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  6. Service Mesh (mTLS)                     \u2502\n\u2502     \u2514\u2500 Encrypted service-to-service         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#part-2-kubernetes-rbac-deep-dive","title":"\ud83d\udd10 Part 2: Kubernetes RBAC Deep Dive","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#rbac-components","title":"RBAC Components","text":"<pre><code>User/ServiceAccount\n        \u2502\n        \u2502 (binds to)\n        \u25bc\n      Role/ClusterRole\n        \u2502\n        \u2502 (defines)\n        \u25bc\n    Permissions\n  (verbs on resources)\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#example-rbac-setup","title":"Example RBAC Setup","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#1-developer-role-namespace-scoped","title":"1. Developer Role (Namespace-scoped)","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: developer\n  namespace: team-alpha-prod\nrules:\n# Read access to most resources\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"configmaps\", \"secrets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n\n# Write access to deployments\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"]\n\n# Execute into pods for debugging\n- apiGroups: [\"\"]\n  resources: [\"pods/exec\"]\n  verbs: [\"create\"]\n\n# View logs\n- apiGroups: [\"\"]\n  resources: [\"pods/log\"]\n  verbs: [\"get\"]\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#2-admin-role-namespace-scoped","title":"2. Admin Role (Namespace-scoped)","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: team-admin\n  namespace: team-alpha-prod\nrules:\n# Full access to namespace resources\n- apiGroups: [\"*\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#3-platform-admin-role-cluster-scoped","title":"3. Platform Admin Role (Cluster-scoped)","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: platform-admin\nrules:\n# Full cluster access\n- apiGroups: [\"*\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n\n# Access to cluster-scoped resources\n- nonResourceURLs: [\"*\"]\n  verbs: [\"*\"]\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#4-read-only-role-cluster-scoped","title":"4. Read-Only Role (Cluster-scoped)","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: read-only\nrules:\n- apiGroups: [\"*\"]\n  resources: [\"*\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#rolebinding-examples","title":"RoleBinding Examples","text":"<pre><code># Bind developer role to user\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: alice-developer\n  namespace: team-alpha-prod\nsubjects:\n- kind: User\n  name: alice@company.com\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: developer\n  apiGroup: rbac.authorization.k8s.io\n\n---\n# Bind admin role to group\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: team-alpha-admins\n  namespace: team-alpha-prod\nsubjects:\n- kind: Group\n  name: team-alpha-leads\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: team-admin\n  apiGroup: rbac.authorization.k8s.io\n\n---\n# Bind cluster role with ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: platform-admins\nsubjects:\n- kind: Group\n  name: platform-team\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: platform-admin\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#service-account-rbac","title":"Service Account RBAC","text":"<pre><code># Service account for CI/CD\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: ci-deployer\n  namespace: team-alpha-prod\n\n---\n# Role for deployment\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: deployer\n  namespace: team-alpha-prod\nrules:\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\"]\n  verbs: [\"get\", \"list\", \"update\", \"patch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"list\"]\n\n---\n# Bind role to service account\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: ci-deployer-binding\n  namespace: team-alpha-prod\nsubjects:\n- kind: ServiceAccount\n  name: ci-deployer\n  namespace: team-alpha-prod\nroleRef:\n  kind: Role\n  name: deployer\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#part-3-namespace-strategy","title":"\ud83c\udfd7\ufe0f Part 3: Namespace Strategy","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#naming-convention","title":"Naming Convention","text":"<pre><code>&lt;team&gt;-&lt;environment&gt;-&lt;region&gt;\n\nExamples:\n- team-alpha-prod-us-east\n- team-alpha-staging-us-east\n- team-alpha-dev-us-east\n- team-beta-prod-eu-west\n- platform-core-prod-us-east\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#namespace-template","title":"Namespace Template","text":"<pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: team-alpha-prod\n  labels:\n    team: alpha\n    environment: production\n    region: us-east\n    cost-center: \"1234\"\n  annotations:\n    description: \"Team Alpha production workloads\"\n    owner: \"alice@company.com\"\n\n---\n# Resource Quota\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: team-alpha-quota\n  namespace: team-alpha-prod\nspec:\n  hard:\n    requests.cpu: \"100\"\n    requests.memory: 200Gi\n    limits.cpu: \"200\"\n    limits.memory: 400Gi\n    persistentvolumeclaims: \"20\"\n    services.loadbalancers: \"3\"\n\n---\n# Limit Range (default limits)\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: team-alpha-limits\n  namespace: team-alpha-prod\nspec:\n  limits:\n  - max:\n      cpu: \"4\"\n      memory: \"8Gi\"\n    min:\n      cpu: \"10m\"\n      memory: \"10Mi\"\n    default:\n      cpu: \"500m\"\n      memory: \"512Mi\"\n    defaultRequest:\n      cpu: \"100m\"\n      memory: \"128Mi\"\n    type: Container\n\n---\n# Network Policy (deny all by default)\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: team-alpha-prod\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#automated-namespace-provisioning","title":"Automated Namespace Provisioning","text":"<pre><code># namespace_provisioner.py\nimport kubernetes\nfrom jinja2 import Template\n\nclass NamespaceProvisioner:\n    def __init__(self, k8s_config):\n        kubernetes.config.load_kube_config(k8s_config)\n        self.api = kubernetes.client.CoreV1Api()\n        self.rbac_api = kubernetes.client.RbacAuthorizationV1Api()\n\n    def create_tenant_namespace(self, tenant_config):\n        \"\"\"\n        Create namespace with all required resources\n\n        Args:\n            tenant_config: dict with team, environment, quotas, etc.\n        \"\"\"\n        namespace_name = f\"{tenant_config['team']}-{tenant_config['environment']}\"\n\n        # 1. Create namespace\n        self._create_namespace(namespace_name, tenant_config)\n\n        # 2. Create resource quota\n        self._create_resource_quota(namespace_name, tenant_config['quotas'])\n\n        # 3. Create limit ranges\n        self._create_limit_range(namespace_name, tenant_config['limits'])\n\n        # 4. Create network policies\n        self._create_network_policies(namespace_name)\n\n        # 5. Create RBAC roles\n        self._create_rbac(namespace_name, tenant_config['members'])\n\n        # 6. Create service accounts\n        self._create_service_accounts(namespace_name)\n\n        return namespace_name\n\n    def _create_namespace(self, name, config):\n        \"\"\"Create namespace with labels and annotations\"\"\"\n        namespace = kubernetes.client.V1Namespace(\n            metadata=kubernetes.client.V1ObjectMeta(\n                name=name,\n                labels={\n                    'team': config['team'],\n                    'environment': config['environment'],\n                    'managed-by': 'platform-automation'\n                },\n                annotations={\n                    'owner': config['owner'],\n                    'cost-center': config['cost_center'],\n                    'created-by': 'namespace-provisioner'\n                }\n            )\n        )\n        self.api.create_namespace(namespace)\n        print(f\"\u2705 Created namespace: {name}\")\n\n    def _create_resource_quota(self, namespace, quotas):\n        \"\"\"Create resource quota\"\"\"\n        quota = kubernetes.client.V1ResourceQuota(\n            metadata=kubernetes.client.V1ObjectMeta(name=\"tenant-quota\"),\n            spec=kubernetes.client.V1ResourceQuotaSpec(\n                hard={\n                    'requests.cpu': quotas['cpu_requests'],\n                    'requests.memory': quotas['memory_requests'],\n                    'limits.cpu': quotas['cpu_limits'],\n                    'limits.memory': quotas['memory_limits'],\n                    'persistentvolumeclaims': str(quotas['pvc_count'])\n                }\n            )\n        )\n        self.api.create_namespaced_resource_quota(namespace, quota)\n        print(f\"\u2705 Created resource quota in {namespace}\")\n\n    def _create_rbac(self, namespace, members):\n        \"\"\"Create roles and role bindings for team members\"\"\"\n\n        # Developer role\n        dev_role = kubernetes.client.V1Role(\n            metadata=kubernetes.client.V1ObjectMeta(name=\"developer\"),\n            rules=[\n                kubernetes.client.V1PolicyRule(\n                    api_groups=[\"\"],\n                    resources=[\"pods\", \"services\", \"configmaps\"],\n                    verbs=[\"get\", \"list\", \"watch\"]\n                ),\n                kubernetes.client.V1PolicyRule(\n                    api_groups=[\"apps\"],\n                    resources=[\"deployments\"],\n                    verbs=[\"get\", \"list\", \"watch\", \"update\", \"patch\"]\n                )\n            ]\n        )\n        self.rbac_api.create_namespaced_role(namespace, dev_role)\n\n        # Bind developers\n        for member in members.get('developers', []):\n            binding = kubernetes.client.V1RoleBinding(\n                metadata=kubernetes.client.V1ObjectMeta(\n                    name=f\"{member}-developer\"\n                ),\n                subjects=[\n                    kubernetes.client.V1Subject(\n                        kind=\"User\",\n                        name=member,\n                        api_group=\"rbac.authorization.k8s.io\"\n                    )\n                ],\n                role_ref=kubernetes.client.V1RoleRef(\n                    kind=\"Role\",\n                    name=\"developer\",\n                    api_group=\"rbac.authorization.k8s.io\"\n                )\n            )\n            self.rbac_api.create_namespaced_role_binding(namespace, binding)\n\n        print(f\"\u2705 Created RBAC in {namespace}\")\n\n# Usage\nconfig = {\n    'team': 'alpha',\n    'environment': 'production',\n    'owner': 'alice@company.com',\n    'cost_center': '1234',\n    'quotas': {\n        'cpu_requests': '100',\n        'memory_requests': '200Gi',\n        'cpu_limits': '200',\n        'memory_limits': '400Gi',\n        'pvc_count': 20\n    },\n    'limits': {\n        'default_cpu': '500m',\n        'default_memory': '512Mi'\n    },\n    'members': {\n        'developers': ['alice@company.com', 'bob@company.com'],\n        'admins': ['carol@company.com']\n    }\n}\n\nprovisioner = NamespaceProvisioner('/path/to/kubeconfig')\nnamespace = provisioner.create_tenant_namespace(config)\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#part-4-policy-enforcement-with-opa","title":"\ud83d\udee1\ufe0f Part 4: Policy Enforcement with OPA","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#what-is-open-policy-agent-opa","title":"What is Open Policy Agent (OPA)?","text":"<p>Policy engine for cloud-native environments. Write policies as code.</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#opa-gatekeeper","title":"OPA Gatekeeper","text":"<p>Kubernetes admission controller using OPA.</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#installation","title":"Installation","text":"<pre><code>kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#example-policies","title":"Example Policies","text":"<p>Policy 1: Require Labels</p> <pre><code>apiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8srequiredlabels\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sRequiredLabels\n      validation:\n        openAPIV3Schema:\n          type: object\n          properties:\n            labels:\n              type: array\n              items:\n                type: string\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8srequiredlabels\n\n        violation[{\"msg\": msg, \"details\": {\"missing_labels\": missing}}] {\n          provided := {label | input.review.object.metadata.labels[label]}\n          required := {label | label := input.parameters.labels[_]}\n          missing := required - provided\n          count(missing) &gt; 0\n          msg := sprintf(\"Missing required labels: %v\", [missing])\n        }\n\n---\n# Apply the constraint\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sRequiredLabels\nmetadata:\n  name: require-team-label\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Namespace\"]\n  parameters:\n    labels: [\"team\", \"environment\", \"cost-center\"]\n</code></pre> <p>Policy 2: Block Privileged Containers</p> <pre><code>apiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sPSPPrivilegedContainer\nmetadata:\n  name: block-privileged-containers\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n    excludedNamespaces:\n      - kube-system\n      - platform-core\n</code></pre> <p>Policy 3: Enforce Resource Limits</p> <pre><code>apiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sContainerLimits\nmetadata:\n  name: container-must-have-limits\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n  parameters:\n    cpu: \"4\"\n    memory: \"8Gi\"\n</code></pre> <p>Policy 4: Restrict Registry Sources</p> <pre><code>apiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8sallowedrepos\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sAllowedRepos\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8sallowedrepos\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.containers[_]\n          satisfied := [good | repo = input.parameters.repos[_]\n                              good = startswith(container.image, repo)]\n          not any(satisfied)\n          msg := sprintf(\"Container image %v not from approved registry\", [container.image])\n        }\n\n---\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sAllowedRepos\nmetadata:\n  name: allowed-registries\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n  parameters:\n    repos:\n      - \"harbor.company.com/\"\n      - \"gcr.io/company/\"\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#part-5-resource-management","title":"\ud83d\udcb0 Part 5: Resource Management","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#resource-quotas-by-team","title":"Resource Quotas by Team","text":"<pre><code># Small team\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: small-team-quota\n  namespace: team-small-prod\nspec:\n  hard:\n    requests.cpu: \"20\"\n    requests.memory: 40Gi\n    limits.cpu: \"40\"\n    limits.memory: 80Gi\n    pods: \"50\"\n    services: \"10\"\n    persistentvolumeclaims: \"10\"\n\n---\n# Medium team\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: medium-team-quota\n  namespace: team-medium-prod\nspec:\n  hard:\n    requests.cpu: \"100\"\n    requests.memory: 200Gi\n    limits.cpu: \"200\"\n    limits.memory: 400Gi\n    pods: \"200\"\n    services: \"50\"\n    persistentvolumeclaims: \"50\"\n\n---\n# Large team\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: large-team-quota\n  namespace: team-large-prod\nspec:\n  hard:\n    requests.cpu: \"500\"\n    requests.memory: 1Ti\n    limits.cpu: \"1000\"\n    limits.memory: 2Ti\n    pods: \"1000\"\n    services: \"200\"\n    persistentvolumeclaims: \"200\"\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#priority-classes","title":"Priority Classes","text":"<pre><code># Critical workloads\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: critical\nvalue: 1000000\nglobalDefault: false\ndescription: \"Critical production workloads\"\n\n---\n# High priority\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: high\nvalue: 100000\ndescription: \"High priority production workloads\"\n\n---\n# Normal priority\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: normal\nvalue: 10000\nglobalDefault: true\ndescription: \"Normal priority workloads\"\n\n---\n# Low priority\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: low\nvalue: 1000\ndescription: \"Low priority batch jobs\"\n</code></pre> <p>Usage in Pod:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: critical-app\nspec:\n  priorityClassName: critical\n  containers:\n  - name: app\n    image: myapp:v1.0\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#part-6-network-isolation","title":"\ud83d\udd12 Part 6: Network Isolation","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#network-policies","title":"Network Policies","text":"<p>Default Deny All</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: team-alpha-prod\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n</code></pre> <p>Allow Within Namespace</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-same-namespace\n  namespace: team-alpha-prod\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector: {}\n</code></pre> <p>Allow from Ingress</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-from-ingress\n  namespace: team-alpha-prod\nspec:\n  podSelector:\n    matchLabels:\n      role: frontend\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: ingress-nginx\n    ports:\n    - protocol: TCP\n      port: 8080\n</code></pre> <p>Allow Egress to DNS and External</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-dns-and-external\n  namespace: team-alpha-prod\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  # Allow DNS\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: UDP\n      port: 53\n  # Allow external HTTPS\n  - to:\n    - podSelector: {}\n    ports:\n    - protocol: TCP\n      port: 443\n</code></pre>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#part-7-hands-on-lab-build-multi-tenant-platform","title":"\ud83d\udcaa Part 7: Hands-On Lab - Build Multi-Tenant Platform","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#scenario","title":"Scenario","text":"<p>Design multi-tenancy for 10 engineering teams.</p> <p>Requirements: - Namespace isolation - RBAC for developers and admins - Resource quotas per team - Network policies (zero-trust) - Policy enforcement (OPA) - Cost allocation per team</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#tasks","title":"Tasks","text":"<p>Task 1: Design Tenancy Model - [ ] Choose model (namespace/vcluster/cluster) - [ ] Define namespace naming convention - [ ] Create namespace template</p> <p>Task 2: Implement RBAC - [ ] Create developer role - [ ] Create admin role - [ ] Create read-only role - [ ] Set up RoleBindings</p> <p>Task 3: Configure Resource Management - [ ] Define quota tiers (small/medium/large) - [ ] Create LimitRanges - [ ] Set up PriorityClasses</p> <p>Task 4: Implement Network Isolation - [ ] Default deny all traffic - [ ] Allow intra-namespace - [ ] Allow from ingress - [ ] Allow DNS and external</p> <p>Task 5: Policy Enforcement - [ ] Require labels policy - [ ] Block privileged containers - [ ] Enforce resource limits - [ ] Restrict image registries</p> <p>Task 6: Automation - [ ] Namespace provisioning script - [ ] RBAC automation - [ ] Onboarding documentation</p> <p>Validation: - [ ] Namespace isolation working - [ ] RBAC permissions correct - [ ] Resource quotas enforced - [ ] Network policies blocking unauthorized traffic - [ ] OPA policies validating resources - [ ] Cost allocation labels present</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#part-8-knowledge-check","title":"\ud83c\udf93 Part 8: Knowledge Check","text":"<ol> <li>What's the lightest multi-tenancy model?</li> <li>[x] Namespace-per-team</li> <li>[ ] vCluster</li> <li>[ ] Cluster-per-team</li> <li> <p>[ ] Virtual machines</p> </li> <li> <p>What does RBAC stand for?</p> </li> <li>[ ] Resource-Based Access Control</li> <li>[x] Role-Based Access Control</li> <li>[ ] Rule-Based Access Control</li> <li> <p>[ ] Rights-Based Access Control</p> </li> <li> <p>Which is cluster-scoped?</p> </li> <li>[ ] Role</li> <li>[x] ClusterRole</li> <li>[ ] RoleBinding</li> <li> <p>[ ] ResourceQuota</p> </li> <li> <p>What does OPA stand for?</p> </li> <li>[ ] Optimal Policy Agent</li> <li>[x] Open Policy Agent</li> <li>[ ] Orchestrated Policy Administration</li> <li> <p>[ ] Operational Policy Automation</p> </li> <li> <p>What enforces resource limits per namespace?</p> </li> <li>[ ] NetworkPolicy</li> <li>[ ] PodSecurityPolicy</li> <li>[x] ResourceQuota</li> <li> <p>[ ] RBAC</p> </li> <li> <p>Default network policy should be:</p> </li> <li>[x] Deny all, whitelist specific traffic</li> <li>[ ] Allow all, blacklist bad traffic</li> <li>[ ] No policy needed</li> <li> <p>[ ] Allow within cluster only</p> </li> <li> <p>What does vCluster provide?</p> </li> <li>[ ] Virtual machines</li> <li>[ ] Virtual networks</li> <li>[x] Virtual Kubernetes control planes</li> <li> <p>[ ] Virtual storage</p> </li> <li> <p>Priority Classes are used for:</p> </li> <li>[ ] Security levels</li> <li>[ ] Network priority</li> <li>[x] Pod scheduling priority during resource contention</li> <li>[ ] RBAC levels</li> </ol> <p>Answers: 1-A, 2-B, 3-B, 4-B, 5-C, 6-A, 7-C, 8-C</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#part-9-module-summary-next-steps","title":"\ud83c\udfaf Part 9: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#what-you-learned","title":"What You Learned","text":"<p>\u2705 Multi-Tenancy Models: Namespace, vCluster, cluster-per-tenant \u2705 RBAC Deep Dive: Roles, bindings, service accounts \u2705 Namespace Strategy: Naming, templates, automation \u2705 Policy Enforcement: OPA Gatekeeper policies \u2705 Resource Management: Quotas, limits, priorities \u2705 Network Isolation: NetworkPolicies, zero-trust</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Choose tenancy model wisely - Balance isolation, cost, complexity</li> <li>RBAC is foundational - Get permissions right from day one</li> <li>Automate tenant lifecycle - Manual provisioning doesn't scale</li> <li>Deny by default - Whitelist only necessary access</li> <li>Policy as code - OPA enables declarative governance</li> <li>Monitor quota usage - Prevent resource exhaustion</li> <li>Document everything - Clear ownership and boundaries</li> </ol>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#real-world-impact","title":"Real-World Impact","text":"<p>\"After implementing proper multi-tenancy: - Onboarding time: 2 weeks \u2192 1 hour (automation) - Security incidents: 12/year \u2192 1/year (isolation) - Resource waste: 40% \u2192 10% (quotas) - Cost allocation: Impossible \u2192 Precise (labels) - Team autonomy: Limited \u2192 High (self-service) - Compliance: Manual \u2192 Automated (OPA)</p> <p>We scaled from 5 teams to 50 teams without increasing platform team size.\" - Platform Director, Tech Unicorn</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#tools","title":"Tools","text":"<ul> <li>vCluster - Virtual Kubernetes clusters</li> <li>OPA Gatekeeper</li> <li>Hierarchical Namespaces</li> <li>Kyverno - Alternative to OPA</li> <li>Capsule - Multi-tenancy operator</li> </ul>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#documentation","title":"Documentation","text":"<ul> <li>Kubernetes Multi-Tenancy</li> <li>RBAC Best Practices</li> <li>Network Policies</li> </ul>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#books-articles","title":"Books &amp; Articles","text":"<ul> <li>Kubernetes Security - Liz Rice &amp; Michael Hausenblas</li> <li>Multi-Tenancy in Kubernetes</li> </ul>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#module-completion","title":"\ud83c\udfc5 Module Completion","text":""},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#assessment-checklist","title":"Assessment Checklist","text":"<ul> <li>[ ] Conceptual Understanding</li> <li>[ ] Explain tenancy models</li> <li>[ ] Understand RBAC components</li> <li> <p>[ ] Know isolation strategies</p> </li> <li> <p>[ ] Practical Skills</p> </li> <li>[ ] Design namespace strategy</li> <li>[ ] Implement RBAC</li> <li>[ ] Create OPA policies</li> <li>[ ] Configure network policies</li> <li> <p>[ ] Automate provisioning</p> </li> <li> <p>[ ] Hands-On Lab</p> </li> <li>[ ] Multi-tenant platform designed</li> <li>[ ] RBAC implemented correctly</li> <li>[ ] Policies enforcing rules</li> <li> <p>[ ] Isolation verified</p> </li> <li> <p>[ ] Quiz</p> </li> <li>[ ] Score 80% or higher (6/8 questions)</li> </ul>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#certification-credit","title":"Certification Credit","text":"<p>Upon completion, you earn: - 10 points toward Black Belt certification (50% complete) - Badge: \"Multi-Tenancy Architect\" - Skill Unlocked: Enterprise Platform Design</p>"},{"location":"dojo/modules/black-belt/module-18-multi-tenancy/#black-belt-progress","title":"\ud83c\udf96\ufe0f Black Belt Progress","text":"<pre><code>Black Belt: Platform Architecture\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModule 17: Platform Architecture   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 25% \u2713\nModule 18: Multi-Tenancy &amp; RBAC    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 50% \u2713\nModule 19: Cost Optimization       \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\nModule 20: Platform Leadership     \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n</code></pre> <p>Halfway to Black Belt! \ud83c\udf89</p> <p>Next Module Preview: Module 19 - Cost Optimization (FinOps, right-sizing, cloud efficiency)</p> <p>Fawkes Dojo - Where Platform Engineers Are Forged Version 1.0 | Last Updated: October 2025 License: MIT | https://github.com/paruff/fawkes</p> <p>\ud83c\udf89 Module 18 Complete - Multi-Tenancy Mastery Achieved! \ud83c\udf89</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/","title":"Module 19: Security &amp; Zero Trust Architecture","text":"<p>Belt Level: \u26ab Black Belt Duration: 60 minutes Prerequisites: Modules 1-18, especially Module 7 (Security Scanning), Module 13 (Observability) Certification Track: Fawkes Platform Architect</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<p>By the end of this module, you will be able to:</p> <ol> <li>Design and implement a zero trust security architecture for internal developer platforms</li> <li>Apply the principle of \"never trust, always verify\" to CI/CD pipelines and deployment workflows</li> <li>Implement mutual TLS (mTLS), service mesh security, and workload identity</li> <li>Configure policy-as-code enforcement using Open Policy Agent (OPA) and admission controllers</li> <li>Establish supply chain security practices including SBOM generation, image signing, and provenance verification</li> </ol>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#theory-zero-trust-for-platform-engineering","title":"\ud83d\udcda Theory: Zero Trust for Platform Engineering","text":""},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#what-is-zero-trust","title":"What is Zero Trust?","text":"<p>Zero trust is a security model based on the principle of \"never trust, always verify\". Unlike traditional perimeter-based security (castle-and-moat), zero trust assumes:</p> <ul> <li>No implicit trust: Location (inside/outside network) doesn't grant access</li> <li>Verify explicitly: Always authenticate and authorize based on all available data points</li> <li>Least privilege access: Grant minimum permissions necessary for the task</li> <li>Assume breach: Design systems expecting compromise at any point</li> </ul>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#why-zero-trust-matters-for-idps","title":"Why Zero Trust Matters for IDPs","text":"<p>Internal Developer Platforms handle:</p> <ul> <li>Credentials and secrets for all production systems</li> <li>CI/CD pipelines that deploy code to production</li> <li>Container registries with potentially vulnerable images</li> <li>Service-to-service communication across microservices</li> <li>Developer access to sensitive production resources</li> </ul> <p>A breach at any point could cascade across your entire platform. Zero trust minimizes blast radius.</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#the-zero-trust-architecture-pillars","title":"The Zero Trust Architecture Pillars","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    ZERO TRUST PRINCIPLES                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                             \u2502\n\u2502  1. IDENTITY                                                \u2502\n\u2502     \u251c\u2500 Workload Identity (not long-lived credentials)      \u2502\n\u2502     \u251c\u2500 Human Identity (SSO, MFA, short-lived tokens)       \u2502\n\u2502     \u2514\u2500 Machine Identity (service accounts, mTLS)           \u2502\n\u2502                                                             \u2502\n\u2502  2. DEVICE                                                  \u2502\n\u2502     \u251c\u2500 Endpoint security posture                           \u2502\n\u2502     \u251c\u2500 Compliance validation                               \u2502\n\u2502     \u2514\u2500 Device certificates                                 \u2502\n\u2502                                                             \u2502\n\u2502  3. NETWORK                                                 \u2502\n\u2502     \u251c\u2500 Encrypt all traffic (TLS everywhere)                \u2502\n\u2502     \u251c\u2500 Micro-segmentation                                  \u2502\n\u2502     \u2514\u2500 Service mesh (Istio, Linkerd)                       \u2502\n\u2502                                                             \u2502\n\u2502  4. APPLICATION                                             \u2502\n\u2502     \u251c\u2500 Policy-as-code enforcement                          \u2502\n\u2502     \u251c\u2500 Runtime security (Falco, AppArmor)                  \u2502\n\u2502     \u2514\u2500 Admission controllers                               \u2502\n\u2502                                                             \u2502\n\u2502  5. DATA                                                    \u2502\n\u2502     \u251c\u2500 Encryption at rest and in transit                   \u2502\n\u2502     \u251c\u2500 Data classification and DLP                         \u2502\n\u2502     \u2514\u2500 Secret management (Vault, External Secrets)         \u2502\n\u2502                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#zero-trust-in-cicd-pipelines","title":"Zero Trust in CI/CD Pipelines","text":"<p>Traditional CI/CD often uses: - \u274c Long-lived credentials stored in CI system - \u274c Broad permissions for deployment service accounts - \u274c No verification of artifact provenance - \u274c Implicit trust between pipeline stages</p> <p>Zero trust CI/CD: - \u2705 Workload identity for pipeline authentication (OIDC) - \u2705 Least-privilege, ephemeral credentials - \u2705 Cryptographic verification of artifacts (Sigstore/Cosign) - \u2705 Policy enforcement at every stage</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#core-concepts","title":"\ud83d\udd10 Core Concepts","text":""},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#1-workload-identity","title":"1. Workload Identity","text":"<p>Problem: Traditional approaches use long-lived service account keys stored as secrets.</p> <p>Zero Trust Solution: Workload identity allows pods/pipelines to authenticate using short-lived tokens.</p> <p>Example: GitHub Actions \u2192 AWS <pre><code># Traditional approach (NEVER DO THIS)\n- name: Configure AWS Credentials\n  env:\n    AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}     # \u274c Long-lived\n    AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_KEY }} # \u274c Rotated manually\n\n# Zero trust approach with OIDC\n- name: Configure AWS Credentials\n  uses: aws-actions/configure-aws-credentials@v4\n  with:\n    role-to-assume: arn:aws:iam::123456789:role/GitHubActionsRole\n    aws-region: us-east-1\n    # \u2705 No secrets stored in GitHub\n    # \u2705 Short-lived tokens (1 hour)\n    # \u2705 Scoped to specific repos/branches\n</code></pre></p> <p>Example: Kubernetes Workload Identity <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: payment-service\n  annotations:\n    # AWS: Map to IAM role\n    eks.amazonaws.com/role-arn: arn:aws:iam::123456789:role/payment-service\n\n    # GCP: Map to GCP service account\n    iam.gke.io/gcp-service-account: payment@project.iam.gserviceaccount.com\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: payment-service\nspec:\n  template:\n    spec:\n      serviceAccountName: payment-service  # \u2705 Pod gets temporary credentials\n      containers:\n      - name: app\n        image: payment-service:v1.2.3\n        # No AWS_ACCESS_KEY_ID needed! SDK auto-discovers credentials\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#2-mutual-tls-mtls-and-service-mesh","title":"2. Mutual TLS (mTLS) and Service Mesh","text":"<p>mTLS: Both client and server authenticate using certificates, encrypting all traffic.</p> <p>Service Mesh (Istio, Linkerd, Consul) provides: - Automatic mTLS between all services - Fine-grained authorization policies - Traffic encryption without code changes</p> <p>Example: Istio Authorization Policy <pre><code>apiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: payment-access-policy\n  namespace: payments\nspec:\n  selector:\n    matchLabels:\n      app: payment-api\n  action: ALLOW\n  rules:\n  - from:\n    - source:\n        principals:\n        - \"cluster.local/ns/checkout/sa/checkout-service\"  # Only checkout can call\n    to:\n    - operation:\n        methods: [\"POST\"]\n        paths: [\"/api/v1/charge\"]\n  - from:\n    - source:\n        principals:\n        - \"cluster.local/ns/admin/sa/admin-dashboard\"\n    to:\n    - operation:\n        methods: [\"GET\"]\n        paths: [\"/api/v1/transactions/*\"]\n</code></pre></p> <p>Result: Even if an attacker compromises the <code>frontend</code> service, they cannot call the payment API.</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#3-policy-as-code-with-opa","title":"3. Policy-as-Code with OPA","text":"<p>Open Policy Agent (OPA): Express security policies as code, enforce them at runtime.</p> <p>Gatekeeper: OPA integration for Kubernetes admission control.</p> <p>Example: Require Image Signatures <pre><code>package kubernetes.admission\n\nimport future.keywords.contains\nimport future.keywords.if\n\n# Deny pods with unsigned images\ndeny[msg] {\n    input.request.kind.kind == \"Pod\"\n    image := input.request.object.spec.containers[_].image\n    not image_is_signed(image)\n    msg := sprintf(\"Image %v is not signed. All images must be signed with Cosign.\", [image])\n}\n\n# Check if image has valid signature\nimage_is_signed(image) if {\n    # Query external service or cache of verified images\n    verified_images := data.verified_images\n    image_ref := split(image, \"@\")[0]\n    verified_images[image_ref]\n}\n</code></pre></p> <p>Example: Enforce Resource Limits <pre><code>package kubernetes.admission\n\ndeny[msg] {\n    input.request.kind.kind == \"Deployment\"\n    container := input.request.object.spec.template.spec.containers[_]\n    not container.resources.limits.memory\n    msg := sprintf(\"Container %v must specify memory limits\", [container.name])\n}\n\ndeny[msg] {\n    input.request.kind.kind == \"Deployment\"\n    container := input.request.object.spec.template.spec.containers[_]\n    not container.resources.limits.cpu\n    msg := sprintf(\"Container %v must specify CPU limits\", [container.name])\n}\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#4-supply-chain-security-slsa","title":"4. Supply Chain Security (SLSA)","text":"<p>Supply chain attacks: Compromise the build or delivery process to inject malicious code.</p> <p>SLSA (Supply Chain Levels for Software Artifacts): Framework for supply chain integrity.</p> <p>Key Components:</p> <ol> <li>SBOM (Software Bill of Materials): List all dependencies</li> <li>Provenance: Cryptographically signed record of how artifact was built</li> <li>Image Signing: Sign container images with Cosign/Sigstore</li> <li>Verification: Verify signatures before deployment</li> </ol> <p>Example: Generate SBOM with Syft <pre><code># Generate SBOM for container image\nsyft packages registry:ghcr.io/myorg/payment-service:v1.2.3 \\\n  -o spdx-json=sbom.json\n\n# Generate SBOM during build\nsyft packages dir:. -o cyclonedx-json=sbom.json\n</code></pre></p> <p>Example: Sign Image with Cosign <pre><code># Sign image (uses keyless signing with Sigstore)\ncosign sign ghcr.io/myorg/payment-service:v1.2.3\n\n# Generate provenance attestation\ncosign attest --predicate provenance.json \\\n  ghcr.io/myorg/payment-service:v1.2.3\n\n# Verify signature before deployment\ncosign verify ghcr.io/myorg/payment-service:v1.2.3 \\\n  --certificate-identity-regexp 'https://github.com/myorg/*' \\\n  --certificate-oidc-issuer 'https://token.actions.githubusercontent.com'\n</code></pre></p> <p>Example: Policy to Require Signatures <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: verify-image-signatures\nspec:\n  validationFailureAction: enforce\n  rules:\n  - name: verify-signature\n    match:\n      any:\n      - resources:\n          kinds:\n          - Pod\n    verifyImages:\n    - imageReferences:\n      - \"ghcr.io/myorg/*\"\n      attestors:\n      - entries:\n        - keyless:\n            subject: \"https://github.com/myorg/*\"\n            issuer: \"https://token.actions.githubusercontent.com\"\n            rekor:\n              url: https://rekor.sigstore.dev\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#5-secret-management","title":"5. Secret Management","text":"<p>Never store secrets in: - \u274c Git repositories - \u274c Environment variables in Dockerfiles - \u274c ConfigMaps - \u274c Hardcoded in source code</p> <p>Zero trust secret management:</p> <pre><code># External Secrets Operator: Sync from Vault/AWS Secrets Manager\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: payment-api-secrets\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: aws-secretsmanager\n    kind: SecretStore\n  target:\n    name: payment-api-secrets\n    creationPolicy: Owner\n  data:\n  - secretKey: stripe-api-key\n    remoteRef:\n      key: prod/payment/stripe-api-key\n  - secretKey: database-password\n    remoteRef:\n      key: prod/payment/db-password\n</code></pre> <p>Vault Integration: <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: payment-service\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: payment-service\nspec:\n  template:\n    metadata:\n      annotations:\n        vault.hashicorp.com/agent-inject: \"true\"\n        vault.hashicorp.com/role: \"payment-service\"\n        vault.hashicorp.com/agent-inject-secret-stripe: \"secret/data/payment/stripe\"\n    spec:\n      serviceAccountName: payment-service\n      containers:\n      - name: app\n        image: payment-service:v1.2.3\n        # Vault agent sidecar injects secrets at /vault/secrets/stripe\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#zero-trust-architecture-for-fawkes","title":"\ud83c\udfd7\ufe0f Zero Trust Architecture for Fawkes","text":""},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#reference-architecture","title":"Reference Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         DEVELOPER                               \u2502\n\u2502                              \u2502                                  \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502                    \u2502   SSO + MFA        \u2502                       \u2502\n\u2502                    \u2502   (Okta, Keycloak) \u2502                       \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                              \u2502                                  \u2502\n\u2502                              \u2502 OIDC Token                       \u2502\n\u2502                              \u2502                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                              \u25bc                                  \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502                    \u2502  API Gateway     \u2502                         \u2502\n\u2502                    \u2502  + Policy Engine \u2502                         \u2502\n\u2502                    \u2502  (OPA, Kyverno)  \u2502                         \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                             \u2502                                   \u2502\n\u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502          \u2502                  \u2502                  \u2502                \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502    \u2502  Backstage \u2502    \u2502   ArgoCD    \u2502   \u2502  CI System   \u2502        \u2502\n\u2502    \u2502  (mTLS)    \u2502    \u2502   (mTLS)    \u2502   \u2502  (Tekton)    \u2502        \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502          \u2502                  \u2502                  \u2502                \u2502\n\u2502          \u2502 Workload Identity\u2502 Workload Identity\u2502                \u2502\n\u2502          \u2502                  \u2502                  \u2502                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          \u2502                  \u2502                  \u2502                \u2502\n\u2502          \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502                \u2502\n\u2502          \u2502          \u2502  Service Mesh    \u2502       \u2502                \u2502\n\u2502          \u2502          \u2502  (Istio/Linkerd) \u2502       \u2502                \u2502\n\u2502          \u2502          \u2502   - mTLS         \u2502       \u2502                \u2502\n\u2502          \u2502          \u2502   - AuthZ Policy \u2502       \u2502                \u2502\n\u2502          \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502                \u2502\n\u2502          \u2502                  \u2502                  \u2502                \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502    \u2502           Application Workloads                   \u2502        \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502        \u2502\n\u2502    \u2502  \u2502 Frontend \u2502  \u2502  Backend \u2502  \u2502 Database \u2502       \u2502        \u2502\n\u2502    \u2502  \u2502  (mTLS)  \u2502  \u2502  (mTLS)  \u2502  \u2502  (mTLS)  \u2502       \u2502        \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502        \u2502\n\u2502    \u2502                                                   \u2502        \u2502\n\u2502    \u2502  \ud83d\udd10 All traffic encrypted                        \u2502        \u2502\n\u2502    \u2502  \ud83d\udd10 Every request authenticated                  \u2502        \u2502\n\u2502    \u2502  \ud83d\udd10 Authorization at every hop                   \u2502        \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502                                                                 \u2502\n\u2502  Secrets: Vault / External Secrets Operator                    \u2502\n\u2502  Logging: All authN/authZ decisions \u2192 SIEM                     \u2502\n\u2502  Policy: OPA Gatekeeper + Kyverno admission controllers        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#zero-trust-cicd-pipeline","title":"Zero Trust CI/CD Pipeline","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  1. CODE COMMIT                                              \u2502\n\u2502     \u2514\u2500 Developer pushes to GitHub                           \u2502\n\u2502        \u2514\u2500 Signed commit (GPG signature required)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  2. CI PIPELINE TRIGGERED (Tekton/GitHub Actions)            \u2502\n\u2502     \u251c\u2500 Authenticate with OIDC (no long-lived credentials)   \u2502\n\u2502     \u251c\u2500 Scan code (SAST: Semgrep, CodeQL)                    \u2502\n\u2502     \u251c\u2500 Dependency check (Dependabot, Snyk)                  \u2502\n\u2502     \u251c\u2500 Build image in ephemeral runner                      \u2502\n\u2502     \u251c\u2500 Scan image (Trivy, Grype)                            \u2502\n\u2502     \u251c\u2500 Generate SBOM (Syft)                                 \u2502\n\u2502     \u251c\u2500 Sign image (Cosign/Sigstore)                         \u2502\n\u2502     \u251c\u2500 Generate provenance attestation                      \u2502\n\u2502     \u2514\u2500 Push to registry with signature                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  3. ADMISSION CONTROL (Kubernetes)                           \u2502\n\u2502     \u251c\u2500 Gatekeeper/Kyverno verify signature                  \u2502\n\u2502     \u251c\u2500 Check SBOM for known vulnerabilities                 \u2502\n\u2502     \u251c\u2500 Enforce resource limits                              \u2502\n\u2502     \u251c\u2500 Validate security context (no root, read-only FS)    \u2502\n\u2502     \u2514\u2500 Only allow if ALL policies pass                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  4. DEPLOYMENT (ArgoCD)                                      \u2502\n\u2502     \u251c\u2500 ArgoCD authenticates with workload identity          \u2502\n\u2502     \u251c\u2500 Applies manifests to cluster                         \u2502\n\u2502     \u251c\u2500 Service mesh injects mTLS sidecar                    \u2502\n\u2502     \u2514\u2500 Pod authenticates to Vault for secrets               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  5. RUNTIME SECURITY                                         \u2502\n\u2502     \u251c\u2500 Falco monitors for suspicious syscalls               \u2502\n\u2502     \u251c\u2500 Service mesh enforces authorization policies         \u2502\n\u2502     \u251c\u2500 All traffic encrypted with mTLS                      \u2502\n\u2502     \u2514\u2500 Logs sent to SIEM for audit                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#hands-on-lab-implementing-zero-trust-for-fawkes","title":"\ud83d\udee0\ufe0f Hands-On Lab: Implementing Zero Trust for Fawkes","text":""},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#lab-overview","title":"Lab Overview","text":"<p>You will implement key zero trust components: 1. Configure workload identity for CI/CD 2. Deploy a service mesh with mTLS 3. Implement policy-as-code with OPA Gatekeeper 4. Sign and verify container images with Cosign 5. Configure External Secrets Operator</p> <p>Duration: 25 minutes Tools: <code>kubectl</code>, <code>cosign</code>, <code>helm</code>, <code>fawkes</code> CLI</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#lab-setup","title":"Lab Setup","text":"<pre><code># Ensure you're in the Fawkes lab environment\nfawkes lab start --module 19\n\n# Verify cluster access\nkubectl get nodes\n\n# You should see a 3-node cluster with Istio pre-installed\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#exercise-1-deploy-istio-service-mesh-5-minutes","title":"Exercise 1: Deploy Istio Service Mesh (5 minutes)","text":"<p>Objective: Enable mTLS for all services in the <code>payments</code> namespace.</p> <pre><code># Istio is already installed in the lab. Enable strict mTLS for payments namespace.\nkubectl create namespace payments\n\nkubectl apply -f - &lt;&lt;EOF\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: payments\nspec:\n  mtls:\n    mode: STRICT  # Require mTLS for all traffic\nEOF\n\n# Verify\nkubectl get peerauthentication -n payments\n</code></pre> <p>Deploy a test service:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: payment-api\n  namespace: payments\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: payment-api\n  namespace: payments\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: payment-api\n  template:\n    metadata:\n      labels:\n        app: payment-api\n    spec:\n      serviceAccountName: payment-api\n      containers:\n      - name: app\n        image: ghcr.io/fawkes-demo/payment-api:v1.0.0\n        ports:\n        - containerPort: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: payment-api\n  namespace: payments\nspec:\n  selector:\n    app: payment-api\n  ports:\n  - port: 80\n    targetPort: 8080\nEOF\n</code></pre> <p>Apply authorization policy:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: payment-api-authz\n  namespace: payments\nspec:\n  selector:\n    matchLabels:\n      app: payment-api\n  action: ALLOW\n  rules:\n  - from:\n    - source:\n        principals:\n        - \"cluster.local/ns/checkout/sa/checkout-service\"\n    to:\n    - operation:\n        methods: [\"POST\"]\n        paths: [\"/api/v1/charge\"]\nEOF\n</code></pre> <p>Test the policy:</p> <pre><code># This should FAIL (no valid service account)\nkubectl run -it --rm curl-test --image=curlimages/curl --restart=Never -- \\\n  curl -v http://payment-api.payments.svc.cluster.local/api/v1/charge\n\n# You should see \"RBAC: access denied\"\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#exercise-2-install-opa-gatekeeper-and-policies-5-minutes","title":"Exercise 2: Install OPA Gatekeeper and Policies (5 minutes)","text":"<p>Objective: Enforce that all pods must have resource limits.</p> <pre><code># Install Gatekeeper\nkubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml\n\n# Wait for Gatekeeper to be ready\nkubectl wait --for=condition=ready pod -l control-plane=controller-manager -n gatekeeper-system --timeout=120s\n</code></pre> <p>Create a constraint template:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8srequiredresources\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sRequiredResources\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8srequiredresources\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.containers[_]\n          not container.resources.limits.memory\n          msg := sprintf(\"Container &lt;%v&gt; must specify memory limits\", [container.name])\n        }\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.containers[_]\n          not container.resources.limits.cpu\n          msg := sprintf(\"Container &lt;%v&gt; must specify CPU limits\", [container.name])\n        }\nEOF\n</code></pre> <p>Create the constraint:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sRequiredResources\nmetadata:\n  name: must-have-resource-limits\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"apps\"]\n        kinds: [\"Deployment\"]\n    namespaces:\n      - \"payments\"\nEOF\n</code></pre> <p>Test the policy:</p> <pre><code># This should FAIL (no resource limits)\nkubectl apply -f - &lt;&lt;EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bad-deployment\n  namespace: payments\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bad-app\n  template:\n    metadata:\n      labels:\n        app: bad-app\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        # \u274c No resource limits!\nEOF\n\n# You should see: \"Container &lt;nginx&gt; must specify memory limits\"\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#exercise-3-sign-and-verify-container-images-8-minutes","title":"Exercise 3: Sign and Verify Container Images (8 minutes)","text":"<p>Objective: Sign an image with Cosign and configure policy to require signatures.</p> <pre><code># Install Cosign\ncurl -sLO https://github.com/sigstore/cosign/releases/latest/download/cosign-linux-amd64\nchmod +x cosign-linux-amd64\nsudo mv cosign-linux-amd64 /usr/local/bin/cosign\n\n# Generate a key pair (in production, use keyless signing)\ncosign generate-key-pair\n\n# Sign the payment-api image\ncosign sign --key cosign.key ghcr.io/fawkes-demo/payment-api:v1.0.0\n\n# Enter password when prompted\n</code></pre> <p>Verify the signature:</p> <pre><code>cosign verify --key cosign.pub ghcr.io/fawkes-demo/payment-api:v1.0.0\n\n# You should see \"Verification for ghcr.io/fawkes-demo/payment-api:v1.0.0 -- The following checks were performed...\"\n</code></pre> <p>Install Kyverno for signature verification:</p> <pre><code>helm repo add kyverno https://kyverno.github.io/kyverno/\nhelm repo update\nhelm install kyverno kyverno/kyverno -n kyverno --create-namespace\n</code></pre> <p>Create a policy to verify signatures:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: verify-image-signature\nspec:\n  validationFailureAction: enforce\n  webhookTimeoutSeconds: 30\n  rules:\n  - name: verify-signature\n    match:\n      any:\n      - resources:\n          kinds:\n          - Pod\n          namespaces:\n          - payments\n    verifyImages:\n    - imageReferences:\n      - \"ghcr.io/fawkes-demo/*\"\n      attestors:\n      - count: 1\n        entries:\n        - keys:\n            publicKeys: |-\n$(cat cosign.pub | sed 's/^/              /')\nEOF\n</code></pre> <p>Test the policy:</p> <pre><code># This should SUCCEED (signed image)\nkubectl run signed-pod --image=ghcr.io/fawkes-demo/payment-api:v1.0.0 -n payments\n\n# This should FAIL (unsigned image)\nkubectl run unsigned-pod --image=nginx:latest -n payments\n\n# You should see: \"resource validation error: image signature verification failed\"\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#exercise-4-configure-external-secrets-operator-7-minutes","title":"Exercise 4: Configure External Secrets Operator (7 minutes)","text":"<p>Objective: Store secrets in AWS Secrets Manager and sync them to Kubernetes.</p> <pre><code># Install External Secrets Operator\nhelm repo add external-secrets https://charts.external-secrets.io\nhelm install external-secrets external-secrets/external-secrets -n external-secrets-system --create-namespace\n\n# For the lab, we'll use a fake backend. In production, configure AWS/GCP/Vault.\n</code></pre> <p>Create a SecretStore (using Kubernetes secrets as backend for demo):</p> <pre><code># Create a secret to act as our \"vault\"\nkubectl create secret generic payment-secrets -n payments \\\n  --from-literal=stripe-api-key=sk_test_abc123 \\\n  --from-literal=db-password=super-secret-password\n\nkubectl apply -f - &lt;&lt;EOF\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: kubernetes-backend\n  namespace: payments\nspec:\n  provider:\n    kubernetes:\n      remoteNamespace: payments\n      auth:\n        serviceAccount:\n          name: external-secrets\n      server:\n        caProvider:\n          type: ConfigMap\n          name: kube-root-ca.crt\n          key: ca.crt\nEOF\n</code></pre> <p>Create an ExternalSecret:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: payment-api-external-secret\n  namespace: payments\nspec:\n  refreshInterval: 1m\n  secretStoreRef:\n    name: kubernetes-backend\n    kind: SecretStore\n  target:\n    name: payment-api-secrets\n    creationPolicy: Owner\n  data:\n  - secretKey: STRIPE_API_KEY\n    remoteRef:\n      key: payment-secrets\n      property: stripe-api-key\n  - secretKey: DB_PASSWORD\n    remoteRef:\n      key: payment-secrets\n      property: db-password\nEOF\n</code></pre> <p>Verify the secret was synced:</p> <pre><code>kubectl get externalsecret -n payments\nkubectl get secret payment-api-secrets -n payments -o yaml\n\n# You should see STRIPE_API_KEY and DB_PASSWORD\n</code></pre> <p>Update deployment to use the external secret:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: payment-api\n  namespace: payments\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: payment-api\n  template:\n    metadata:\n      labels:\n        app: payment-api\n    spec:\n      serviceAccountName: payment-api\n      containers:\n      - name: app\n        image: ghcr.io/fawkes-demo/payment-api:v1.0.0\n        envFrom:\n        - secretRef:\n            name: payment-api-secrets  # \u2705 Synced from external source\n        resources:\n          limits:\n            memory: \"256Mi\"\n            cpu: \"500m\"\n          requests:\n            memory: \"128Mi\"\n            cpu: \"250m\"\nEOF\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#lab-validation","title":"Lab Validation","text":"<pre><code># Run the validation script\nfawkes lab validate --module 19\n\n# You should see:\n# \u2705 Istio mTLS enabled in payments namespace\n# \u2705 Authorization policies configured\n# \u2705 OPA Gatekeeper installed with resource limit policy\n# \u2705 Image signature verification with Cosign\n# \u2705 Kyverno policy enforcing signatures\n# \u2705 External Secrets Operator syncing secrets\n</code></pre> <p>Cleanup:</p> <pre><code>fawkes lab stop --module 19\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#knowledge-check","title":"\u2705 Knowledge Check","text":"<p>Test your understanding with these questions:</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#question-1-zero-trust-principles","title":"Question 1: Zero Trust Principles","text":"<p>Which of the following is NOT a core principle of zero trust?</p> <p>A) Never trust, always verify B) Assume breach C) Trust based on network location D) Least privilege access</p> Show Answer  **Answer: C**  Zero trust explicitly rejects the idea that network location (inside/outside perimeter) should grant trust. All access must be verified regardless of location."},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#question-2-workload-identity","title":"Question 2: Workload Identity","text":"<p>What is the main advantage of workload identity over long-lived service account keys?</p> <p>A) Easier to configure B) Works with more cloud providers C) Credentials are short-lived and automatically rotated D) Requires less compute resources</p> Show Answer  **Answer: C**  Workload identity provides short-lived tokens (typically 1 hour) that are automatically rotated, eliminating the risk of leaked credentials and manual rotation processes."},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#question-3-service-mesh-security","title":"Question 3: Service Mesh Security","text":"<p>What does mTLS (mutual TLS) provide that regular TLS does not?</p> <p>A) Faster encryption B) Both client and server authenticate each other C) Compression of network traffic D) Load balancing capabilities</p> Show Answer  **Answer: B**  In regular TLS, only the server authenticates to the client. With mTLS, both parties authenticate using certificates, ensuring both ends of the connection are trusted."},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#question-4-supply-chain-security","title":"Question 4: Supply Chain Security","text":"<p>Which tool is used to cryptographically sign container images?</p> <p>A) Trivy B) Cosign C) Falco D) OPA</p> Show Answer  **Answer: B**  Cosign (part of Sigstore project) is used to sign and verify container images. Trivy is for scanning, Falco for runtime security, and OPA for policy enforcement."},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#question-5-policy-as-code","title":"Question 5: Policy-as-Code","text":"<p>What happens when a Kubernetes admission controller policy is violated?</p> <p>A) The resource is created with a warning B) The resource creation is rejected C) The policy is automatically updated D) An email is sent to administrators</p> Show Answer  **Answer: B**  Admission controllers (like Gatekeeper and Kyverno) run before resources are persisted to etcd. If a policy is violated, the API request is rejected and the resource is not created."},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#question-6-secret-management","title":"Question 6: Secret Management","text":"<p>Why should secrets never be stored in Git repositories?</p> <p>A) Git is too slow for secret retrieval B) Git history is immutable - secrets remain even if deleted C) Git doesn't support encryption D) Secrets take up too much storage</p> Show Answer  **Answer: B**  Git history is permanent. Even if you delete a file containing secrets, they remain in the repository's history and can be retrieved by anyone with access to the repo."},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#question-7-sbom-software-bill-of-materials","title":"Question 7: SBOM (Software Bill of Materials)","text":"<p>What is the primary purpose of an SBOM?</p> <p>A) To compress container images B) To list all software components and dependencies in an artifact C) To encrypt network traffic D) To monitor application performance</p> Show Answer  **Answer: B**  An SBOM provides a complete inventory of all software components, libraries, and dependencies in an artifact, enabling vulnerability tracking and license compliance."},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#question-8-zero-trust-cicd","title":"Question 8: Zero Trust CI/CD","text":"<p>Which authentication method is recommended for CI/CD pipelines in a zero trust architecture?</p> <p>A) Storing AWS access keys in GitHub Secrets B) Using long-lived service account tokens C) OIDC-based workload identity D) Username and password authentication</p> Show Answer  **Answer: C**  OIDC-based workload identity (like GitHub Actions OIDC to AWS) provides short-lived credentials without storing long-lived secrets, aligning with zero trust principles."},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#real-world-examples","title":"\ud83c\udf0d Real-World Examples","text":""},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#example-1-netflixs-zero-trust-journey","title":"Example 1: Netflix's Zero Trust Journey","text":"<p>Challenge: Netflix runs on AWS with thousands of microservices. Traditional perimeter security was insufficient.</p> <p>Solution: - No VPN: All services authenticate individually, no network-based trust - mTLS everywhere: Every service-to-service call uses mutual TLS - Dynamic authorization: Zuul gateway enforces fine-grained policies based on user/service identity - Credential rotation: All credentials rotate automatically every few hours</p> <p>Result: - Eliminated network perimeter as security boundary - Reduced blast radius of security incidents - Enabled faster deployment (no VPN bottlenecks)</p> <p>Learn more: Netflix Security Blog</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#example-2-googles-beyondcorp","title":"Example 2: Google's BeyondCorp","text":"<p>Challenge: Employees working remotely needed access to internal applications without VPN.</p> <p>Solution (BeyondCorp): - Device trust: Verify device posture before granting access - User identity: Strong authentication (2FA/U2F keys) - Context-aware access: Consider user, device, location, and resource sensitivity - Zero trust proxy: All access flows through proxy that enforces policy</p> <p>Key insight: \"Location is not a proxy for trust\"</p> <p>Result: - Employees work securely from anywhere without VPN - Reduced attack surface (no broad network access) - Better visibility into access patterns</p> <p>Learn more: BeyondCorp Research Papers</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#example-3-capital-one-breach-what-went-wrong","title":"Example 3: Capital One Breach (What Went Wrong)","text":"<p>Incident (2019): Attacker compromised a web application firewall (WAF), accessed IAM credentials, and exfiltrated data on 100 million customers.</p> <p>Root Causes: - \u274c Overly permissive IAM role: WAF had broad access to S3 - \u274c No network segmentation: Compromised WAF could reach production data - \u274c Missing detection: Exfiltration not detected in real-time</p> <p>Zero Trust Would Have Prevented This: - \u2705 Least privilege: WAF should not have S3 access - \u2705 Workload identity: Short-lived credentials, not long-lived IAM keys - \u2705 Micro-segmentation: WAF isolated from data storage layer - \u2705 Continuous monitoring: Alert on unusual S3 access patterns</p> <p>Lesson: Assume breach. Design systems so a single compromise doesn't cascade.</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#example-4-shopifys-vault-backed-secrets","title":"Example 4: Shopify's Vault-Backed Secrets","text":"<p>Challenge: Thousands of microservices needed secure access to secrets (API keys, database passwords).</p> <p>Old approach: - Secrets stored in environment variables - Rotated manually (infrequently) - Broad access (many services could read all secrets)</p> <p>Zero trust approach: - HashiCorp Vault: Central secret management - Dynamic secrets: Database credentials generated on-demand, expire after use - Fine-grained ACLs: Each service can only access its required secrets - Audit logging: Every secret access logged</p> <p>Result: - Secrets rotated automatically - Reduced blast radius (leaked credential only works for one service) - Complete audit trail for compliance</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#dora-capabilities-mapping","title":"\ud83d\udcca DORA Capabilities Mapping","text":"<p>This module directly supports these DORA capabilities:</p> Capability How This Module Helps Impact on Metrics Shift Left on Security Integrate security scanning and policy enforcement early in CI/CD Reduces change failure rate by catching vulnerabilities before production Continuous Delivery Zero trust enables secure automation without manual approval gates Improves deployment frequency and lead time Loosely Coupled Architecture Service mesh and mTLS allow secure communication without tight coupling Enables independent deployment of services Monitoring &amp; Observability Audit all authentication/authorization decisions for compliance Faster MTTR with clear audit trails"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#troubleshooting-common-issues","title":"\ud83d\udd27 Troubleshooting Common Issues","text":""},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#issue-1-pods-fail-to-start-after-enabling-strict-mtls","title":"Issue 1: Pods Fail to Start After Enabling Strict mTLS","text":"<p>Symptom: <pre><code>Error from server: error when creating \"deployment.yaml\":\nadmission webhook \"validation.gatekeeper.sh\" denied the request\n</code></pre></p> <p>Cause: Pods without Istio sidecar injection cannot communicate when strict mTLS is enabled.</p> <p>Solution: <pre><code># Ensure namespace has Istio injection enabled\nkubectl label namespace payments istio-injection=enabled\n\n# Restart pods to inject sidecar\nkubectl rollout restart deployment -n payments\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#issue-2-image-signature-verification-fails","title":"Issue 2: Image Signature Verification Fails","text":"<p>Symptom: <pre><code>Error: image signature verification failed: no matching signatures\n</code></pre></p> <p>Cause: Image was not signed, or signature verification policy references wrong public key.</p> <p>Solution: <pre><code># Verify the image is signed\ncosign verify --key cosign.pub ghcr.io/myorg/app:v1.0.0\n\n# If not signed, sign it\ncosign sign --key cosign.key ghcr.io/myorg/app:v1.0.0\n\n# Ensure Kyverno policy references correct public key\nkubectl edit clusterpolicy verify-image-signature\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#issue-3-external-secrets-not-syncing","title":"Issue 3: External Secrets Not Syncing","text":"<p>Symptom: <pre><code>kubectl get externalsecret\nNAME            STORE    REFRESH INTERVAL   STATUS         READY\nmy-ext-secret   vault    1m                 SecretSyncedError   False\n</code></pre></p> <p>Cause: External Secrets Operator cannot authenticate to secret backend (Vault/AWS).</p> <p>Solution: <pre><code># Check ExternalSecret status\nkubectl describe externalsecret my-ext-secret -n payments\n\n# Verify SecretStore configuration\nkubectl describe secretstore -n payments\n\n# For AWS: Ensure service account has correct IAM role annotation\nkubectl get sa external-secrets -n payments -o yaml\n\n# For Vault: Verify Kubernetes auth is configured\nvault auth list\nvault read auth/kubernetes/config\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#issue-4-opa-gatekeeper-policies-not-enforcing","title":"Issue 4: OPA Gatekeeper Policies Not Enforcing","text":"<p>Symptom: Resources are created despite violating policies.</p> <p>Cause: Constraint may not be applied, or validation failure action is \"dryrun\".</p> <p>Solution: <pre><code># Check if constraint is created\nkubectl get constraints\n\n# Verify constraint status\nkubectl describe k8srequiredresources must-have-resource-limits\n\n# Ensure enforcement (not dryrun)\nkubectl get k8srequiredresources must-have-resource-limits -o yaml | grep validationFailureAction\n\n# Should show: validationFailureAction: enforce\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#issue-5-workload-identity-not-working","title":"Issue 5: Workload Identity Not Working","text":"<p>Symptom: Pods cannot authenticate to cloud provider (AWS/GCP/Azure).</p> <p>Cause: Service account not properly annotated, or OIDC provider not configured.</p> <p>Solution for AWS (EKS): <pre><code># Verify OIDC provider exists\naws eks describe-cluster --name my-cluster --query \"cluster.identity.oidc.issuer\"\n\n# Verify service account annotation\nkubectl get sa payment-service -n payments -o yaml | grep eks.amazonaws.com/role-arn\n\n# Should show: eks.amazonaws.com/role-arn: arn:aws:iam::123456789:role/payment-service\n\n# Verify IAM role trust policy allows the service account\naws iam get-role --role-name payment-service --query 'Role.AssumeRolePolicyDocument'\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#official-documentation","title":"Official Documentation","text":"<ul> <li>NIST Zero Trust Architecture - Comprehensive guide to zero trust principles</li> <li>CISA Zero Trust Maturity Model - Framework for assessing zero trust adoption</li> <li>Sigstore Documentation - Software signing and verification</li> <li>SLSA Framework - Supply chain security levels</li> </ul>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#tools-projects","title":"Tools &amp; Projects","text":"<ul> <li>Istio Security - Service mesh security</li> <li>OPA Gatekeeper - Kubernetes policy enforcement</li> <li>Kyverno - Kubernetes-native policy management</li> <li>External Secrets Operator - Sync secrets from external sources</li> <li>Falco - Runtime security monitoring</li> <li>Cosign - Container image signing</li> </ul>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#books-papers","title":"Books &amp; Papers","text":"<ul> <li>\"Zero Trust Networks\" by Evan Gilman &amp; Doug Barth (O'Reilly)</li> <li>\"Kubernetes Security and Observability\" by Brendan Creane &amp; Amit Gupta (O'Reilly)</li> <li>Google's BeyondCorp Papers - Research on zero trust implementation</li> </ul>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#video-tutorials","title":"Video Tutorials","text":"<ul> <li>Securing the Software Supply Chain - KubeCon talk on Sigstore</li> <li>Zero Trust Security in Kubernetes - Practical implementation guide</li> </ul>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#key-takeaways","title":"\ud83c\udfaf Key Takeaways","text":"<p>By completing this module, you've learned:</p> <ol> <li>\u2705 Zero trust principles - Never trust, always verify; assume breach; least privilege</li> <li>\u2705 Workload identity - Short-lived credentials via OIDC instead of long-lived keys</li> <li>\u2705 Service mesh security - mTLS and fine-grained authorization with Istio</li> <li>\u2705 Policy-as-code - Enforce security policies with OPA Gatekeeper and Kyverno</li> <li>\u2705 Supply chain security - Sign images, generate SBOMs, verify provenance</li> <li>\u2705 Secret management - External Secrets Operator for centralized secret handling</li> </ol> <p>Zero trust is not a product, it's an architecture philosophy. Every component in your platform should: - Authenticate explicitly (no implicit trust) - Authorize with least privilege (only what's needed) - Encrypt all traffic (TLS everywhere) - Audit all access (comprehensive logging)</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#next-steps","title":"\ud83d\ude80 Next Steps","text":""},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#in-module-20-multi-cloud-strategies","title":"In Module 20: Multi-Cloud Strategies","text":"<p>You'll learn how to: - Design platform architectures that span multiple cloud providers - Abstract cloud-specific APIs with unified interfaces - Implement disaster recovery and failover across clouds - Manage cost optimization in multi-cloud environments - Navigate the tradeoffs of multi-cloud vs. cloud-agnostic approaches</p> <p>Prepare by: - Reviewing your organization's cloud provider usage - Identifying which services are cloud-specific vs. portable - Considering disaster recovery requirements (RTO/RPO)</p>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#black-belt-progress","title":"\ud83c\udfc6 Black Belt Progress","text":"<p>Module 19 Complete! \u2705</p> <pre><code>Black Belt Progress:\n[\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591] 75% (3/4 modules)\n\n\u2705 Module 17: Platform as a Product\n\u2705 Module 18: Multi-Tenancy &amp; Resource Management\n\u2705 Module 19: Security &amp; Zero Trust\n\u2b1c Module 20: Multi-Cloud Strategies\n\nNext: Complete Module 20 to finish Black Belt curriculum!\n</code></pre>"},{"location":"dojo/modules/black-belt/module-19-security-zerotrust/#certification-path","title":"\ud83c\udf93 Certification Path","text":"<p>After completing all Black Belt modules (17-20), you will:</p> <ol> <li>Complete the Black Belt Assessment (4 hours):</li> <li>Design a complete platform architecture</li> <li>Present to peer review panel</li> <li>Implement multi-tenant design with zero trust</li> <li>Contribute to Fawkes codebase</li> <li> <p>Mentor 2 White Belt learners</p> </li> <li> <p>Earn the \"Fawkes Platform Architect\" Certification:</p> </li> <li>Demonstrates mastery of platform engineering principles</li> <li>Validates ability to design production-grade platforms</li> <li>Recognized credential in the platform engineering community</li> </ol> <p>Keep going! You're one module away from Black Belt! \ud83e\udd4b</p> <p>Module 19: Security &amp; Zero Trust | Fawkes Dojo | Black Belt \"Never trust, always verify\" | Version 1.0</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/","title":"Module 20: Multi-Cloud Strategies","text":"<p>Belt Level: \u26ab Black Belt Duration: 60 minutes Prerequisites: Modules 1-19, especially Module 17 (Platform as a Product), Module 18 (Multi-Tenancy) Certification Track: Fawkes Platform Architect</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<p>By the end of this module, you will be able to:</p> <ol> <li>Evaluate when multi-cloud architecture makes sense vs. single-cloud with vendor lock-in mitigation</li> <li>Design abstraction layers that enable portability across cloud providers</li> <li>Implement disaster recovery and failover strategies across multiple clouds</li> <li>Optimize costs by leveraging pricing differences and committed use discounts</li> <li>Navigate the tradeoffs between cloud-agnostic tools and cloud-native services</li> </ol>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#theory-multi-cloud-architecture","title":"\ud83d\udcda Theory: Multi-Cloud Architecture","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#what-is-multi-cloud","title":"What is Multi-Cloud?","text":"<p>Multi-cloud: Using services from multiple cloud providers (AWS, GCP, Azure) within the same organization or architecture.</p> <p>Types of multi-cloud:</p> <ol> <li>Distributed workloads: Different applications run on different clouds</li> <li>Redundant deployment: Same application deployed to multiple clouds for resilience</li> <li>Hybrid bursting: Primary cloud with overflow to secondary cloud</li> <li>Data residency: Workloads placed in specific clouds for compliance</li> </ol>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#why-multi-cloud","title":"Why Multi-Cloud?","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#valid-reasons","title":"\u2705 Valid Reasons:","text":"<ol> <li>Avoid vendor lock-in: Reduce dependency on single provider</li> <li>Disaster recovery: Survive cloud provider outage</li> <li>Regulatory compliance: Data residency requirements (EU data must stay in EU)</li> <li>Cost optimization: Use cheapest provider for specific workload</li> <li>Acquisitions: Inherited cloud environments from acquired companies</li> <li>Best-of-breed services: Leverage unique capabilities (e.g., BigQuery on GCP, SageMaker on AWS)</li> </ol>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#poor-reasons","title":"\u274c Poor Reasons:","text":"<ol> <li>\"Just in case\" vendor lock-in fear: Adds massive complexity without clear benefit</li> <li>Negotiation leverage: Threat of moving is often sufficient</li> <li>Resume-driven development: Learning new cloud for sake of it</li> <li>Avoiding architectural decisions: Multi-cloud doesn't solve bad architecture</li> </ol>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#the-multi-cloud-spectrum","title":"The Multi-Cloud Spectrum","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    CLOUD STRATEGY SPECTRUM                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                \u2502\n\u2502  SINGLE CLOUD (CLOUD-NATIVE)                                   \u2502\n\u2502  \u251c\u2500 Deeply integrate with cloud-specific services             \u2502\n\u2502  \u251c\u2500 Fastest time-to-market, most features                     \u2502\n\u2502  \u251c\u2500 Highest vendor lock-in                                    \u2502\n\u2502  \u251c\u2500 Example: Lambda, DynamoDB, SQS, S3, CloudWatch            \u2502\n\u2502  \u2514\u2500 Best for: Startups, rapid innovation                      \u2502\n\u2502                                                                \u2502\n\u2502  SINGLE CLOUD (WITH ABSTRACTION)                               \u2502\n\u2502  \u251c\u2500 Use cloud-agnostic tools on single cloud                  \u2502\n\u2502  \u251c\u2500 Kubernetes, PostgreSQL, Kafka, Redis                      \u2502\n\u2502  \u251c\u2500 Could migrate but requires effort                         \u2502\n\u2502  \u251c\u2500 Example: EKS + RDS PostgreSQL + MSK Kafka                 \u2502\n\u2502  \u2514\u2500 Best for: Most enterprises                                \u2502\n\u2502                                                                \u2502\n\u2502  MULTI-CLOUD (DISTRIBUTED)                                     \u2502\n\u2502  \u251c\u2500 Different apps on different clouds                        \u2502\n\u2502  \u251c\u2500 Moderate complexity, limited blast radius                 \u2502\n\u2502  \u251c\u2500 Each app optimized for its cloud                          \u2502\n\u2502  \u251c\u2500 Example: Web app on AWS, ML on GCP, legacy on Azure       \u2502\n\u2502  \u2514\u2500 Best for: Large orgs with diverse needs                   \u2502\n\u2502                                                                \u2502\n\u2502  MULTI-CLOUD (PORTABLE)                                        \u2502\n\u2502  \u251c\u2500 Same app deployable to any cloud                          \u2502\n\u2502  \u251c\u2500 High complexity, maximum portability                      \u2502\n\u2502  \u251c\u2500 Abstraction layer hides cloud differences                 \u2502\n\u2502  \u251c\u2500 Example: Kubernetes + Crossplane + Terraform              \u2502\n\u2502  \u2514\u2500 Best for: High-compliance industries, DR requirements     \u2502\n\u2502                                                                \u2502\n\u2502  MULTI-CLOUD (ACTIVE-ACTIVE)                                   \u2502\n\u2502  \u251c\u2500 Same app running on multiple clouds simultaneously        \u2502\n\u2502  \u251c\u2500 Highest complexity, highest resilience                    \u2502\n\u2502  \u251c\u2500 Data replication, global routing, conflict resolution     \u2502\n\u2502  \u251c\u2500 Example: CockroachDB across 3 clouds with global LB       \u2502\n\u2502  \u2514\u2500 Best for: Mission-critical systems (financial, healthcare)\u2502\n\u2502                                                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nComplexity &amp; Cost \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\n                                                    Portability \u25b6\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#the-cost-of-multi-cloud","title":"The Cost of Multi-Cloud","text":"<p>Operational overhead: - Multiple IAM systems to manage - Different networking models (VPC, VNet, VPC) - Divergent monitoring and logging tools - Team training for multiple clouds - More complex incident response</p> <p>Financial costs: - Data egress fees (expensive to move data between clouds) - Lost volume discounts (spend split across providers) - Duplication of resources (CI/CD, monitoring, networks)</p> <p>Engineering complexity: - Lowest common denominator (can't use best-of-breed services) - Abstraction layers introduce bugs and performance overhead - Testing must cover all cloud environments</p> <p>Rule of thumb: Multi-cloud adds 30-50% operational overhead compared to single cloud.</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#multi-cloud-architecture-patterns","title":"\ud83c\udfd7\ufe0f Multi-Cloud Architecture Patterns","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#pattern-1-multi-cloud-by-application","title":"Pattern 1: Multi-Cloud by Application","text":"<p>When to use: Different teams/products have different cloud requirements.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Organization                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                 \u2502\n\u2502  Product A (AWS)          Product B (GCP)       \u2502\n\u2502  \u251c\u2500 EKS                   \u251c\u2500 GKE               \u2502\n\u2502  \u251c\u2500 RDS PostgreSQL        \u251c\u2500 Cloud SQL          \u2502\n\u2502  \u251c\u2500 S3                    \u251c\u2500 BigQuery           \u2502\n\u2502  \u2514\u2500 CloudWatch            \u2514\u2500 Cloud Monitoring   \u2502\n\u2502                                                 \u2502\n\u2502  Shared Platform Team                           \u2502\n\u2502  \u251c\u2500 Terraform modules for both clouds          \u2502\n\u2502  \u251c\u2500 Separate CI/CD per cloud                   \u2502\n\u2502  \u2514\u2500 Unified observability (Datadog)            \u2502\n\u2502                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Pros: - Each team optimizes for their cloud - Limited complexity (no cross-cloud communication) - Easy to start (pilot one app on new cloud)</p> <p>Cons: - Teams must learn different clouds - Harder to share infrastructure - Duplicated platform tooling</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#pattern-2-multi-cloud-for-disaster-recovery","title":"Pattern 2: Multi-Cloud for Disaster Recovery","text":"<p>When to use: Must survive cloud provider outage (99.99%+ availability requirement).</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  PRIMARY CLOUD (AWS)                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502  Production Workloads                           \u2502     \u2502\n\u2502  \u2502  \u251c\u2500 Active traffic (100%)                      \u2502     \u2502\n\u2502  \u2502  \u251c\u2500 Continuous deployment                      \u2502     \u2502\n\u2502  \u2502  \u2514\u2500 Real-time data replication \u2500\u2500\u2510             \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                         \u2502\n                                         \u2502 Replicate data\n                                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                SECONDARY CLOUD (GCP)                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502  Standby Workloads                              \u2502     \u2502\n\u2502  \u2502  \u251c\u2500 Infrastructure pre-provisioned              \u2502     \u2502\n\u2502  \u2502  \u251c\u2500 Data replicated continuously                \u2502     \u2502\n\u2502  \u2502  \u2514\u2500 Auto-failover if AWS unhealthy              \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nGlobal Load Balancer (Cloudflare, AWS Route53)\n\u251c\u2500 Health checks both clouds\n\u251c\u2500 Automatic failover (DNS/Anycast)\n\u2514\u2500 Failback once primary recovers\n</code></pre> <p>Implementation: - Active-Passive: Primary handles all traffic, secondary is warm standby - Active-Active: Both clouds handle traffic (more complex, requires data sync)</p> <p>Key decisions: - RTO (Recovery Time Objective): How long can you be down?   - RTO &lt; 5 min \u2192 Active-Active (expensive)   - RTO 5-30 min \u2192 Warm standby (moderate cost)   - RTO &gt; 30 min \u2192 Cold standby (cheapest) - RPO (Recovery Point Objective): How much data can you lose?   - RPO = 0 \u2192 Synchronous replication (very expensive)   - RPO &lt; 5 min \u2192 Continuous async replication   - RPO &gt; 15 min \u2192 Periodic snapshots</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#pattern-3-multi-cloud-with-kubernetes","title":"Pattern 3: Multi-Cloud with Kubernetes","text":"<p>When to use: Need portable workloads with minimal cloud-specific code.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             APPLICATION LAYER (Cloud-Agnostic)           \u2502\n\u2502  \u251c\u2500 Kubernetes YAML manifests                           \u2502\n\u2502  \u251c\u2500 Helm charts                                          \u2502\n\u2502  \u251c\u2500 ArgoCD for GitOps deployment                        \u2502\n\u2502  \u2514\u2500 Prometheus + Grafana for monitoring                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502               \u2502               \u2502\n     \u25bc               \u25bc               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   EKS   \u2502    \u2502   GKE   \u2502    \u2502   AKS   \u2502\n\u2502  (AWS)  \u2502    \u2502  (GCP)  \u2502    \u2502 (Azure) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502               \u2502               \u2502\n     \u25bc               \u25bc               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Cloud  \u2502    \u2502  Cloud  \u2502    \u2502  Cloud  \u2502\n\u2502 Services\u2502    \u2502 Services\u2502    \u2502 Services\u2502\n\u2502         \u2502    \u2502         \u2502    \u2502         \u2502\n\u2502 RDS     \u2502    \u2502Cloud SQL\u2502    \u2502CosmosDB \u2502\n\u2502 S3      \u2502    \u2502 GCS     \u2502    \u2502 Blob    \u2502\n\u2502 SQS     \u2502    \u2502 Pub/Sub \u2502    \u2502ServiceBs\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Abstraction strategies:</p> <ol> <li> <p>Storage: Use Kubernetes CSI drivers <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-pvc\nspec:\n  storageClassName: fast-ssd  # Maps to EBS (AWS), PD-SSD (GCP), Premium (Azure)\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n</code></pre></p> </li> <li> <p>Secrets: Use External Secrets Operator <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: cloud-secrets\nspec:\n  provider:\n    # Automatically detects AWS Secrets Manager, GCP Secret Manager, or Azure Key Vault\n    # based on cluster environment\n</code></pre></p> </li> <li> <p>Databases: Use Crossplane for cloud resource provisioning <pre><code>apiVersion: database.crossplane.io/v1alpha1\nkind: PostgreSQLInstance\nmetadata:\n  name: my-database\nspec:\n  forProvider:\n    # Crossplane translates to RDS, Cloud SQL, or Azure Database\n    engineVersion: \"14\"\n    instanceClass: db.t3.medium\n    storageGB: 100\n  providerConfigRef:\n    name: default  # Points to current cloud\n</code></pre></p> </li> </ol>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#pattern-4-data-residency-compliance","title":"Pattern 4: Data Residency &amp; Compliance","text":"<p>When to use: Regulatory requirements dictate where data must reside (GDPR, data sovereignty).</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    GLOBAL APPLICATION                       \u2502\n\u2502                  (Single codebase, multi-region)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502              \u2502              \u2502\n            \u25bc              \u25bc              \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   AWS EU     \u2502 \u2502   GCP US     \u2502 \u2502 Azure APAC   \u2502\n    \u2502 eu-central-1 \u2502 \u2502 us-central1  \u2502 \u2502 australiaeast\u2502\n    \u2502              \u2502 \u2502              \u2502 \u2502              \u2502\n    \u2502 GDPR         \u2502 \u2502 HIPAA        \u2502 \u2502 AU Privacy   \u2502\n    \u2502 compliant    \u2502 \u2502 compliant    \u2502 \u2502 Act          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    EU customer      US customer      APAC customer\n    data stays in    data stays in    data stays in\n    EU region        US region        APAC region\n</code></pre> <p>Implementation: - Geo-routing: Route users to nearest compliant region (DNS, Anycast) - Data partitioning: Customer data sharded by geography - Cross-region replication: Limited to regions with adequate legal frameworks</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#tools-for-multi-cloud","title":"\ud83d\udee0\ufe0f Tools for Multi-Cloud","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#1-infrastructure-as-code","title":"1. Infrastructure-as-Code","text":"<p>Terraform: De facto standard for multi-cloud IaC.</p> <pre><code># Single Terraform module can provision across clouds\n\nresource \"aws_s3_bucket\" \"data_lake\" {\n  count = var.cloud_provider == \"aws\" ? 1 : 0\n  bucket = \"my-data-lake\"\n}\n\nresource \"google_storage_bucket\" \"data_lake\" {\n  count = var.cloud_provider == \"gcp\" ? 1 : 0\n  name = \"my-data-lake\"\n  location = \"US\"\n}\n\nresource \"azurerm_storage_account\" \"data_lake\" {\n  count = var.cloud_provider == \"azure\" ? 1 : 0\n  name = \"mydatalake\"\n  resource_group_name = azurerm_resource_group.main[0].name\n  location = \"eastus\"\n}\n\n# Output abstraction\noutput \"data_lake_url\" {\n  value = var.cloud_provider == \"aws\" ? aws_s3_bucket.data_lake[0].bucket_regional_domain_name :\n          var.cloud_provider == \"gcp\" ? google_storage_bucket.data_lake[0].url :\n          azurerm_storage_account.data_lake[0].primary_blob_endpoint\n}\n</code></pre> <p>Pulumi: Multi-cloud IaC using real programming languages.</p> <pre><code>import * as aws from \"@pulumi/aws\";\nimport * as gcp from \"@pulumi/gcp\";\nimport * as azure from \"@pulumi/azure-native\";\n\n// Abstract storage bucket across clouds\nfunction createStorageBucket(provider: string, name: string) {\n  switch (provider) {\n    case \"aws\":\n      return new aws.s3.Bucket(name);\n    case \"gcp\":\n      return new gcp.storage.Bucket(name, { location: \"US\" });\n    case \"azure\":\n      const resourceGroup = new azure.resources.ResourceGroup(\"rg\");\n      return new azure.storage.StorageAccount(name, {\n        resourceGroupName: resourceGroup.name,\n        location: \"eastus\",\n      });\n  }\n}\n\nconst bucket = createStorageBucket(process.env.CLOUD_PROVIDER, \"my-bucket\");\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#2-kubernetes-abstraction","title":"2. Kubernetes Abstraction","text":"<p>Crossplane: Provision cloud resources using Kubernetes APIs.</p> <pre><code># Define a composition that works across clouds\napiVersion: apiextensions.crossplane.io/v1\nkind: CompositeResourceDefinition\nmetadata:\n  name: xdatabases.example.com\nspec:\n  group: example.com\n  names:\n    kind: XDatabase\n    plural: xdatabases\n  versions:\n  - name: v1alpha1\n    schema:\n      openAPIV3Schema:\n        type: object\n        properties:\n          spec:\n            type: object\n            properties:\n              size:\n                type: string\n                enum: [small, medium, large]\n              engine:\n                type: string\n                enum: [postgres, mysql]\n---\n# Composition for AWS\napiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: xdatabase.aws\nspec:\n  compositeTypeRef:\n    apiVersion: example.com/v1alpha1\n    kind: XDatabase\n  resources:\n  - name: rds-instance\n    base:\n      apiVersion: database.aws.crossplane.io/v1beta1\n      kind: RDSInstance\n      spec:\n        forProvider:\n          engine: # Set from spec.engine\n          instanceClass: # Map spec.size to AWS instance class\n---\n# Composition for GCP\napiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: xdatabase.gcp\nspec:\n  compositeTypeRef:\n    apiVersion: example.com/v1alpha1\n    kind: XDatabase\n  resources:\n  - name: cloudsql-instance\n    base:\n      apiVersion: database.gcp.crossplane.io/v1beta1\n      kind: CloudSQLInstance\n      spec:\n        forProvider:\n          databaseVersion: # Set from spec.engine\n          tier: # Map spec.size to GCP tier\n</code></pre> <p>Usage (same manifest works on any cloud): <pre><code>apiVersion: example.com/v1alpha1\nkind: XDatabase\nmetadata:\n  name: my-app-db\nspec:\n  size: medium\n  engine: postgres\n  # Crossplane automatically provisions RDS on AWS, Cloud SQL on GCP, etc.\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#3-service-mesh-for-multi-cloud-networking","title":"3. Service Mesh for Multi-Cloud Networking","text":"<p>Istio Multi-Cluster: Connect services across multiple Kubernetes clusters in different clouds.</p> <pre><code># Configure Istio to treat GKE and EKS clusters as one mesh\napiVersion: install.istio.io/v1alpha1\nkind: IstioOperator\nmetadata:\n  name: istio-control-plane\nspec:\n  values:\n    global:\n      meshID: shared-mesh\n      multiCluster:\n        clusterName: aws-east-cluster  # or gcp-us-cluster\n      network: aws-network  # or gcp-network\n</code></pre> <p>Service in AWS can call service in GCP transparently: <pre><code># Payment service running in AWS EKS\napiVersion: v1\nkind: Service\nmetadata:\n  name: payment-api\n  namespace: payments\n---\n# Fraud detection service running in GCP GKE\napiVersion: v1\nkind: Service\nmetadata:\n  name: fraud-detection\n  namespace: fraud\n\n# Payment service can call: http://fraud-detection.fraud.svc.cluster.local\n# Istio routes across clouds with mTLS\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#4-observability","title":"4. Observability","text":"<p>Unified observability across clouds:</p> <pre><code># Prometheus scrapes metrics from all clouds\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\ndata:\n  prometheus.yml: |\n    global:\n      external_labels:\n        cluster: 'multi-cloud'\n\n    scrape_configs:\n    - job_name: 'aws-services'\n      ec2_sd_configs:\n      - region: us-east-1\n        access_key: ${AWS_ACCESS_KEY}\n        secret_key: ${AWS_SECRET_KEY}\n\n    - job_name: 'gcp-services'\n      gce_sd_configs:\n      - project: my-project\n        zone: us-central1-a\n\n    - job_name: 'azure-services'\n      azure_sd_configs:\n      - subscription_id: ${AZURE_SUBSCRIPTION_ID}\n        tenant_id: ${AZURE_TENANT_ID}\n\n    remote_write:\n    - url: https://prometheus.example.com/api/v1/write\n      # Centralized long-term storage\n</code></pre> <p>Grafana dashboards showing unified view: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Application Performance (All Clouds)           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                 \u2502\n\u2502  Request Rate:        1,250 req/s              \u2502\n\u2502    \u251c\u2500 AWS:     800 req/s  (64%)                \u2502\n\u2502    \u251c\u2500 GCP:     350 req/s  (28%)                \u2502\n\u2502    \u2514\u2500 Azure:   100 req/s  (8%)                 \u2502\n\u2502                                                 \u2502\n\u2502  Error Rate:          0.12%                     \u2502\n\u2502    \u251c\u2500 AWS:     0.08%                            \u2502\n\u2502    \u251c\u2500 GCP:     0.15%                            \u2502\n\u2502    \u2514\u2500 Azure:   0.25%                            \u2502\n\u2502                                                 \u2502\n\u2502  P99 Latency:         245ms                     \u2502\n\u2502    \u251c\u2500 AWS:     220ms                            \u2502\n\u2502    \u251c\u2500 GCP:     250ms                            \u2502\n\u2502    \u2514\u2500 Azure:   310ms                            \u2502\n\u2502                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#5-cost-management","title":"5. Cost Management","text":"<p>Cloud Cost Optimization Tools:</p> <ul> <li>Kubecost: Multi-cluster Kubernetes cost visibility</li> <li>CloudHealth: Cross-cloud cost management</li> <li>Infracost: Estimate Terraform costs before deployment</li> </ul> <p>Example: Compare costs across clouds</p> <pre><code># Infracost for Terraform\ninfracost breakdown --path . --usage-file usage.yml\n\n# Output:\n# AWS:    $12,450/month\n# GCP:    $10,200/month (18% cheaper)\n# Azure:  $13,100/month (5% more expensive)\n</code></pre> <p>Strategy: Hybrid committed use discounts</p> <pre><code>Single Cloud (AWS only):\n\u251c\u2500 3-year Reserved Instances: 60% of capacity\n\u251c\u2500 1-year Reserved Instances: 20% of capacity\n\u2514\u2500 On-demand: 20% of capacity\n\u2514\u2500 Average discount: 45%\n\nMulti-Cloud (AWS + GCP):\n\u251c\u2500 Can't commit as much (workloads split)\n\u251c\u2500 AWS: 40% reserved, 60% on-demand\n\u2514\u2500 GCP: 40% committed use, 60% on-demand\n\u2514\u2500 Average discount: 30%\n\nResult: Multi-cloud loses ~15% in discounts\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#hands-on-lab-multi-cloud-deployment","title":"\ud83c\udfd7\ufe0f Hands-On Lab: Multi-Cloud Deployment","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#lab-overview","title":"Lab Overview","text":"<p>You will deploy the same application to AWS (EKS) and GCP (GKE) using: 1. Terraform to provision infrastructure 2. Kubernetes manifests for the application 3. Crossplane to provision cloud-specific resources (RDS, Cloud SQL) 4. Istio multi-cluster for cross-cloud service communication 5. Unified observability with Prometheus + Grafana</p> <p>Duration: 25 minutes Tools: <code>terraform</code>, <code>kubectl</code>, <code>helm</code>, <code>fawkes</code> CLI</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#lab-setup","title":"Lab Setup","text":"<pre><code># Start the multi-cloud lab environment\nfawkes lab start --module 20\n\n# This provisions:\n# - AWS account with EKS cluster (simulated in lab)\n# - GCP account with GKE cluster (simulated in lab)\n# - Pre-configured kubectl contexts: aws-cluster, gcp-cluster\n\n# Verify access to both clusters\nkubectl config get-contexts\n\n# You should see:\n# CURRENT   NAME           CLUSTER\n# *         aws-cluster    aws-cluster\n#           gcp-cluster    gcp-cluster\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#exercise-1-provision-infrastructure-with-terraform-7-minutes","title":"Exercise 1: Provision Infrastructure with Terraform (7 minutes)","text":"<p>Objective: Use Terraform to create VPCs, subnets, and Kubernetes clusters on both AWS and GCP.</p> <pre><code>cd ~/fawkes-lab-20/terraform\n\n# Review the multi-cloud Terraform configuration\ncat main.tf\n</code></pre> <p>main.tf: <pre><code># Multi-cloud infrastructure\nvariable \"cloud_provider\" {\n  type = string\n  # Set via: terraform apply -var=\"cloud_provider=aws\"\n}\n\n# AWS Resources\nmodule \"aws_infrastructure\" {\n  count  = var.cloud_provider == \"aws\" ? 1 : 0\n  source = \"./modules/aws\"\n\n  cluster_name = \"fawkes-eks\"\n  region       = \"us-east-1\"\n  node_count   = 3\n}\n\n# GCP Resources\nmodule \"gcp_infrastructure\" {\n  count  = var.cloud_provider == \"gcp\" ? 1 : 0\n  source = \"./modules/gcp\"\n\n  cluster_name = \"fawkes-gke\"\n  region       = \"us-central1\"\n  node_count   = 3\n}\n\n# Outputs\noutput \"cluster_endpoint\" {\n  value = var.cloud_provider == \"aws\" ? module.aws_infrastructure[0].cluster_endpoint : module.gcp_infrastructure[0].cluster_endpoint\n}\n\noutput \"kubeconfig_command\" {\n  value = var.cloud_provider == \"aws\" ? \"aws eks update-kubeconfig --name fawkes-eks\" : \"gcloud container clusters get-credentials fawkes-gke\"\n}\n</code></pre></p> <p>Apply infrastructure:</p> <pre><code># Provision AWS cluster\nterraform init\nterraform apply -var=\"cloud_provider=aws\" -auto-approve\n\n# Switch to GCP\nterraform apply -var=\"cloud_provider=gcp\" -auto-approve\n\n# Both clusters are now running\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#exercise-2-deploy-application-to-both-clouds-5-minutes","title":"Exercise 2: Deploy Application to Both Clouds (5 minutes)","text":"<p>Objective: Deploy identical application manifests to both AWS and GCP clusters.</p> <pre><code>cd ~/fawkes-lab-20/k8s\n\n# Deploy to AWS\nkubectl config use-context aws-cluster\nkubectl apply -f namespace.yaml\nkubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\n\n# Deploy to GCP\nkubectl config use-context gcp-cluster\nkubectl apply -f namespace.yaml\nkubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\n\n# Verify deployments\nkubectl get pods -n payments --context aws-cluster\nkubectl get pods -n payments --context gcp-cluster\n</code></pre> <p>deployment.yaml (same for both clouds): <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: payment-api\n  namespace: payments\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: payment-api\n  template:\n    metadata:\n      labels:\n        app: payment-api\n    spec:\n      containers:\n      - name: api\n        image: ghcr.io/fawkes-demo/payment-api:v2.0.0\n        ports:\n        - containerPort: 8080\n        env:\n        - name: CLOUD_PROVIDER\n          value: \"auto-detect\"  # App detects AWS vs GCP\n        resources:\n          limits:\n            memory: \"256Mi\"\n            cpu: \"500m\"\n          requests:\n            memory: \"128Mi\"\n            cpu: \"250m\"\n</code></pre></p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#exercise-3-provision-cloud-resources-with-crossplane-6-minutes","title":"Exercise 3: Provision Cloud Resources with Crossplane (6 minutes)","text":"<p>Objective: Use Crossplane to provision PostgreSQL databases on both clouds using the same API.</p> <pre><code># Install Crossplane on both clusters\nhelm repo add crossplane-stable https://charts.crossplane.io/stable\nhelm repo update\n\n# Install on AWS cluster\nkubectl config use-context aws-cluster\nhelm install crossplane crossplane-stable/crossplane \\\n  --namespace crossplane-system --create-namespace\n\n# Install on GCP cluster\nkubectl config use-context gcp-cluster\nhelm install crossplane crossplane-stable/crossplane \\\n  --namespace crossplane-system --create-namespace\n\n# Install cloud provider packages\nkubectl config use-context aws-cluster\nkubectl crossplane install provider crossplane/provider-aws:v0.35.0\n\nkubectl config use-context gcp-cluster\nkubectl crossplane install provider crossplane/provider-gcp:v0.30.0\n</code></pre> <p>Create database using cloud-agnostic API:</p> <pre><code># On AWS (will create RDS)\nkubectl config use-context aws-cluster\nkubectl apply -f - &lt;&lt;EOF\napiVersion: database.example.com/v1alpha1\nkind: Database\nmetadata:\n  name: payment-db\n  namespace: payments\nspec:\n  engine: postgres\n  version: \"14\"\n  size: small\n  storageGB: 100\nEOF\n\n# On GCP (will create Cloud SQL)\nkubectl config use-context gcp-cluster\nkubectl apply -f - &lt;&lt;EOF\napiVersion: database.example.com/v1alpha1\nkind: Database\nmetadata:\n  name: payment-db\n  namespace: payments\nspec:\n  engine: postgres\n  version: \"14\"\n  size: small\n  storageGB: 100\nEOF\n\n# Same manifest, different implementations!\n</code></pre> <p>Verify databases are provisioning:</p> <pre><code>kubectl get database -n payments --context aws-cluster\n# NAME         READY   PROVIDER   SIZE\n# payment-db   True    AWS RDS    small\n\nkubectl get database -n payments --context gcp-cluster\n# NAME         READY   PROVIDER      SIZE\n# payment-db   True    GCP CloudSQL  small\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#exercise-4-configure-multi-cluster-service-mesh-7-minutes","title":"Exercise 4: Configure Multi-Cluster Service Mesh (7 minutes)","text":"<p>Objective: Connect services across AWS and GCP clusters using Istio.</p> <pre><code># Istio is pre-installed in the lab. Configure multi-cluster mesh.\n\n# Install east-west gateway on AWS\nkubectl config use-context aws-cluster\nkubectl apply -f ~/fawkes-lab-20/istio/aws-east-west-gateway.yaml\n\n# Install east-west gateway on GCP\nkubectl config use-context gcp-cluster\nkubectl apply -f ~/fawkes-lab-20/istio/gcp-east-west-gateway.yaml\n\n# Exchange discovery secrets (allow clusters to find each other)\nistioctl x create-remote-secret \\\n  --context=aws-cluster \\\n  --name=aws | \\\n  kubectl apply -f - --context=gcp-cluster\n\nistioctl x create-remote-secret \\\n  --context=gcp-cluster \\\n  --name=gcp | \\\n  kubectl apply -f - --context=aws-cluster\n</code></pre> <p>Test cross-cloud communication:</p> <pre><code># Deploy a client pod in AWS that calls service in GCP\nkubectl config use-context aws-cluster\nkubectl run -it curl-test --image=curlimages/curl --restart=Never -- \\\n  curl http://payment-api.payments.svc.cluster.local\n\n# This request will:\n# 1. DNS resolves to local service\n# 2. Istio detects service also exists in GCP\n# 3. Load balances across both clouds\n# 4. Encrypts traffic with mTLS through east-west gateway\n</code></pre> <p>View traffic distribution:</p> <pre><code># Deploy Kiali dashboard\nkubectl apply -f ~/fawkes-lab-20/kiali/kiali.yaml --context aws-cluster\n\n# Port-forward to view\nkubectl port-forward svc/kiali 20001:20001 -n istio-system --context aws-cluster\n\n# Open browser: http://localhost:20001\n# You'll see traffic flowing between AWS and GCP clusters\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#lab-validation","title":"Lab Validation","text":"<pre><code># Run validation\nfawkes lab validate --module 20\n\n# You should see:\n# \u2705 AWS EKS cluster provisioned\n# \u2705 GCP GKE cluster provisioned\n# \u2705 Application deployed to both clouds\n# \u2705 Crossplane databases created (RDS + Cloud SQL)\n# \u2705 Istio multi-cluster mesh configured\n# \u2705 Cross-cloud service communication working\n</code></pre> <p>Cleanup:</p> <pre><code>fawkes lab stop --module 20\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#knowledge-check","title":"\u2705 Knowledge Check","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#question-1-multi-cloud-rationale","title":"Question 1: Multi-Cloud Rationale","text":"<p>Which is a VALID reason to adopt multi-cloud architecture?</p> <p>A) To learn new technologies B) Regulatory requirement for data residency in specific regions C) To have leverage in vendor negotiations D) To avoid making architectural decisions</p> Show Answer  **Answer: B**  Data residency requirements (e.g., GDPR mandating EU data stay in EU) are legitimate drivers for multi-cloud. Learning, negotiation leverage, and avoiding decisions are poor reasons that don't justify the added complexity."},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#question-2-multi-cloud-cost","title":"Question 2: Multi-Cloud Cost","text":"<p>What is the typical operational overhead increase when moving from single-cloud to multi-cloud?</p> <p>A) 5-10% B) 15-20% C) 30-50% D) 100%+</p> Show Answer  **Answer: C**  Industry studies show multi-cloud typically adds 30-50% operational overhead due to: multiple IAM systems, divergent tooling, team training, lost volume discounts, and increased complexity."},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#question-3-disaster-recovery","title":"Question 3: Disaster Recovery","text":"<p>For a system requiring RTO (Recovery Time Objective) of 30 minutes, which DR strategy is most appropriate?</p> <p>A) Cold standby (infrastructure provisioned on-demand) B) Warm standby (infrastructure pre-provisioned, app in standby) C) Hot standby (active-active across clouds) D) No DR needed</p> Show Answer  **Answer: B**  Warm standby balances cost and recovery time. Cold standby takes too long (&gt;30 min to provision infrastructure). Hot standby (active-active) is overkill for 30-minute RTO and significantly more expensive."},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#question-4-kubernetes-portability","title":"Question 4: Kubernetes Portability","text":"<p>Which component is NOT helpful for multi-cloud Kubernetes portability?</p> <p>A) CSI (Container Storage Interface) drivers B) Crossplane for cloud resource provisioning C) AWS Lambda functions D) External Secrets Operator</p> Show Answer  **Answer: C**  AWS Lambda is cloud-specific and tightly coupled to AWS. CSI drivers, Crossplane, and External Secrets Operator all provide abstraction layers that work across clouds."},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#question-5-data-egress-costs","title":"Question 5: Data Egress Costs","text":"<p>Why is data transfer between clouds expensive?</p> <p>A) Bandwidth limitations B) Cloud providers charge high egress fees C) Encryption overhead D) Latency penalties</p> Show Answer  **Answer: B**  Cloud providers charge significant egress fees (often $0.08-0.12/GB) when data leaves their network. This makes active-active multi-cloud with frequent data sync very expensive."},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#question-6-service-mesh","title":"Question 6: Service Mesh","text":"<p>What does an Istio multi-cluster east-west gateway provide?</p> <p>A) Load balancing within a single cluster B) Secure connectivity between clusters in different clouds C) DNS resolution for external services D) Container image registry</p> Show Answer  **Answer: B**  East-west gateways enable secure, mTLS-encrypted communication between services in different Kubernetes clusters, even across cloud providers."},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#question-7-terraform-vs-crossplane","title":"Question 7: Terraform vs Crossplane","text":"<p>What is the key difference between Terraform and Crossplane for multi-cloud?</p> <p>A) Terraform is faster B) Crossplane uses Kubernetes APIs, Terraform uses CLI C) Terraform only supports AWS D) Crossplane is cheaper</p> Show Answer  **Answer: B**  Crossplane provisions cloud resources using Kubernetes Custom Resources (declarative, reconciliation loops). Terraform uses its own CLI and state files (imperative with state management)."},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#question-8-cloud-native-vs-cloud-agnostic","title":"Question 8: Cloud-Native vs Cloud-Agnostic","text":"<p>When should you prefer cloud-native services over cloud-agnostic tools?</p> <p>A) Never, always use cloud-agnostic B) When speed-to-market and features outweigh portability concerns C) Only for non-production environments D) When you have unlimited budget</p> Show Answer  **Answer: B**  Cloud-native services (Lambda, DynamoDB, BigQuery) offer better performance, features, and developer experience. Use them when portability is not a primary concern (which is most startups and many enterprises)."},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#real-world-examples","title":"\ud83c\udf0d Real-World Examples","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#example-1-shopifys-multi-cloud-strategy","title":"Example 1: Shopify's Multi-Cloud Strategy","text":"<p>Approach: Multi-cloud by region, not by workload.</p> <p>Architecture: - Primary: GCP (main infrastructure) - Disaster Recovery: AWS (warm standby) - Data residency: Regional clouds for EU/APAC</p> <p>Key decisions: - Standardized on Kubernetes (GKE primary, EKS secondary) - Used Terraform for infrastructure provisioning - Avoided active-active (complexity not worth it) - Invested heavily in observability (Datadog across clouds)</p> <p>Results: - Survived GCP outage in 2020 with minimal downtime - Achieved 99.99% availability SLA - Cost: ~20% overhead vs single-cloud</p> <p>Lesson: Multi-cloud for DR makes sense at scale, but keep it simple (active-passive, not active-active).</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#example-2-spotifys-cloud-migration","title":"Example 2: Spotify's Cloud Migration","text":"<p>Journey: Datacenter \u2192 GCP (2016-2018)</p> <p>Why NOT multi-cloud?: - Decided vendor lock-in risk &lt; operational complexity cost - Bet on GCP for best-of-breed data/ML services (BigQuery, Dataflow) - Negotiated favorable pricing with Google</p> <p>How they mitigated lock-in: - Used Kubernetes for all workloads (portable if needed) - Abstracted storage with GCS-compatible libraries - Open-sourced internal tools (Backstage) for community portability</p> <p>Results: - Successful migration in 2 years - Reduced infrastructure costs by 30% - Faster feature development (cloud-native services)</p> <p>Lesson: For most companies, single-cloud with portability planning is better than multi-cloud execution.</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#example-3-capital-ones-multi-cloud-hybrid","title":"Example 3: Capital One's Multi-Cloud Hybrid","text":"<p>Approach: AWS-primary with strategic GCP usage.</p> <p>Architecture: - 95% of workloads: AWS (core banking systems) - ML/AI workloads: GCP (BigQuery, Vertex AI) - Data analytics: GCP (better data warehouse pricing)</p> <p>Implementation: - Cross-cloud VPN for secure connectivity - Replicate data to GCP for analytics (batch, nightly) - Unified IAM via Okta SSO</p> <p>Results: - Best-of-breed services without full multi-cloud complexity - Contained GCP usage to specific use cases - Avoided active-active complexity</p> <p>Lesson: Tactical multi-cloud (best tool for the job) is more practical than strategic multi-cloud (everything everywhere).</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#example-4-dropboxs-cloud-repatriation","title":"Example 4: Dropbox's Cloud Repatriation","text":"<p>Journey: AWS \u2192 Own Datacenters (2016)</p> <p>Why leave the cloud?: - At scale (exabytes of data), cloud economics inverted - 90% of workload predictable (not bursty) - Egress fees killed economics ($75M+/year in bandwidth)</p> <p>Result: - Saved ~$75M over 2 years - Better performance (purpose-built infrastructure) - Retained AWS for edge locations and burst capacity</p> <p>Lesson: Multi-cloud isn't always the answer. Sometimes \"no cloud\" or \"hybrid cloud\" makes more sense at extreme scale.</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#dora-capabilities-mapping","title":"\ud83d\udcca DORA Capabilities Mapping","text":"<p>This module supports these DORA capabilities:</p> Capability How This Module Helps Impact on Metrics Deployment Automation Terraform + Crossplane enable automated provisioning across clouds Improves deployment frequency Loosely Coupled Architecture Service mesh enables independent deployment across clouds Enables faster changes, reduces dependencies Monitoring &amp; Observability Unified observability (Prometheus, Grafana) across clouds Reduces MTTR with consistent tooling Database Change Management Crossplane provides declarative database provisioning Safer, faster database changes"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#troubleshooting-common-issues","title":"\ud83d\udd27 Troubleshooting Common Issues","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#issue-1-cross-cloud-networking-latency","title":"Issue 1: Cross-Cloud Networking Latency","text":"<p>Symptom: Services in AWS calling services in GCP have 200ms+ latency.</p> <p>Cause: Geographic distance + internet routing.</p> <p>Solution:</p> <pre><code># Use dedicated interconnect\n# AWS Direct Connect \u2194 GCP Cloud Interconnect\n\n# Or optimize service placement\n# - Deploy services that talk frequently in same cloud\n# - Use caching (Redis) to reduce cross-cloud calls\n# - Async messaging (Kafka) instead of synchronous HTTP\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#issue-2-istio-multi-cluster-not-working","title":"Issue 2: Istio Multi-Cluster Not Working","text":"<p>Symptom: Services in one cluster cannot reach services in another cluster.</p> <p>Cause: Missing east-west gateway or incorrect network configuration.</p> <p>Solution:</p> <pre><code># Verify east-west gateway is running\nkubectl get svc -n istio-system --context aws-cluster\nkubectl get svc -n istio-system --context gcp-cluster\n\n# Check if remote secrets are created\nkubectl get secrets -n istio-system --context aws-cluster | grep gcp\nkubectl get secrets -n istio-system --context gcp-cluster | grep aws\n\n# Verify service endpoints are discovered\nistioctl proxy-config endpoints &lt;pod-name&gt; -n payments --context aws-cluster\n\n# Should show endpoints from both clusters\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#issue-3-terraform-state-conflicts","title":"Issue 3: Terraform State Conflicts","text":"<p>Symptom: <code>Error acquiring the state lock</code> when running Terraform.</p> <p>Cause: Multiple people/pipelines running Terraform simultaneously.</p> <p>Solution:</p> <pre><code># Use remote state with locking\nterraform {\n  backend \"s3\" {\n    bucket         = \"terraform-state-bucket\"\n    key            = \"multi-cloud/terraform.tfstate\"\n    region         = \"us-east-1\"\n    dynamodb_table = \"terraform-locks\"  # Enables locking\n    encrypt        = true\n  }\n}\n\n# Alternative: Use Terraform Cloud for automatic locking\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#issue-4-crossplane-resource-stuck-in-provisioning","title":"Issue 4: Crossplane Resource Stuck in \"Provisioning\"","text":"<p>Symptom: Database resource shows \"Provisioning\" for &gt;10 minutes.</p> <p>Cause: Cloud provider API errors or missing permissions.</p> <p>Solution:</p> <pre><code># Check Crossplane provider logs\nkubectl logs -n crossplane-system -l pkg.crossplane.io/provider=provider-aws\n\n# Common issues:\n# - IAM role missing permissions\n# - API rate limits hit\n# - Invalid parameter (e.g., unsupported instance type)\n\n# Describe the resource for detailed error\nkubectl describe database payment-db -n payments\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#issue-5-cost-explosion-from-data-egress","title":"Issue 5: Cost Explosion from Data Egress","text":"<p>Symptom: Cloud bill 2x higher than expected.</p> <p>Cause: Frequent data transfer between clouds.</p> <p>Solution:</p> <pre><code># Audit data transfer\naws ce get-cost-and-usage \\\n  --time-period Start=2025-10-01,End=2025-10-31 \\\n  --granularity MONTHLY \\\n  --metrics BlendedCost \\\n  --group-by Type=DIMENSION,Key=USAGE_TYPE | \\\n  grep DataTransfer\n\n# Optimization strategies:\n# 1. Cache frequently accessed data locally (Redis)\n# 2. Batch data transfers (nightly sync vs real-time)\n# 3. Use compression (gzip) for data transfer\n# 4. Colocate services that communicate frequently\n# 5. Consider CDN (CloudFlare) for static assets\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#official-documentation","title":"Official Documentation","text":"<ul> <li>AWS Well-Architected Framework - Multi-Region</li> <li>GCP Multi-Cloud Architecture</li> <li>Azure Arc for Multi-Cloud</li> <li>CNCF Multi-Cloud White Paper</li> </ul>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#tools-frameworks","title":"Tools &amp; Frameworks","text":"<ul> <li>Terraform Multi-Cloud Modules</li> <li>Crossplane Documentation</li> <li>Istio Multi-Cluster</li> <li>Kubecost for Multi-Cloud</li> </ul>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#books-papers","title":"Books &amp; Papers","text":"<ul> <li>\"Cloud Native Transformation\" by Pini Reznik, Jamie Dobson &amp; Michelle Gienow (O'Reilly) - Chapter on multi-cloud strategies</li> <li>\"Architecting the Cloud\" by Michael J. Kavis - Multi-cloud decision framework</li> <li>ThoughtWorks Technology Radar - Regular assessment of multi-cloud tools</li> </ul>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#case-studies","title":"Case Studies","text":"<ul> <li>Shopify Engineering Blog - Multi-Cloud</li> <li>Spotify Labs - Why We Chose GCP</li> <li>Dropbox Tech Blog - Infrastructure</li> </ul>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#key-takeaways","title":"\ud83c\udfaf Key Takeaways","text":"<p>By completing this module, you've learned:</p> <ol> <li>\u2705 When multi-cloud makes sense - DR, compliance, best-of-breed; not \"just in case\"</li> <li>\u2705 The multi-cloud spectrum - From single-cloud to active-active, understand tradeoffs</li> <li>\u2705 Abstraction strategies - Kubernetes, Crossplane, Terraform for portability</li> <li>\u2705 Cost implications - 30-50% overhead, lost volume discounts, egress fees</li> <li>\u2705 Implementation patterns - Multi-cloud by app, DR, data residency</li> <li>\u2705 Practical tools - Terraform, Crossplane, Istio, unified observability</li> </ol> <p>Critical insight: Multi-cloud is a tool, not a goal. Most organizations benefit more from single-cloud excellence with portability planning than premature multi-cloud complexity.</p> <p>Decision framework: - Start-up: Single cloud, cloud-native services (speed &gt; portability) - Growth stage: Single cloud with abstraction layers (prepare for optionality) - Enterprise: Selective multi-cloud (DR, compliance, best-of-breed)</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#next-steps","title":"\ud83d\ude80 Next Steps","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#congratulations-youve-completed-the-black-belt-curriculum","title":"Congratulations! You've Completed the Black Belt Curriculum! \ud83e\udd4b","text":"<p>You've mastered all 20 modules of the Fawkes Dojo. Here's what comes next:</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#1-black-belt-assessment-4-hours","title":"1. Black Belt Assessment (4 hours)","text":"<p>To earn your Fawkes Platform Architect certification, complete:</p> <p>Written Exam (50 questions, 90% pass required): - Multi-cloud architecture design - Zero trust security implementation - Platform-as-a-product principles - Multi-tenancy patterns - DORA metrics and continuous improvement</p> <p>Practical Assessment: 1. Architecture Design (90 minutes)    - Design a complete platform architecture for a given scenario    - Present to peer review panel    - Defend design decisions under questioning</p> <ol> <li>Implementation Challenge (90 minutes)</li> <li>Implement multi-tenant namespace with resource quotas</li> <li>Configure zero trust policies (mTLS, image signing)</li> <li>Deploy application across two cloud providers</li> <li> <p>Set up unified observability</p> </li> <li> <p>Code Contribution (60 minutes)</p> </li> <li>Contribute a feature or bug fix to Fawkes codebase</li> <li>Submit PR with documentation and tests</li> <li> <p>Code review by platform team</p> </li> <li> <p>Mentorship (Outside assessment time)</p> </li> <li>Mentor 2 White Belt learners through Module 1-4</li> <li>Document learner progress</li> <li>Provide constructive feedback</li> </ol>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#2-continue-your-platform-engineering-journey","title":"2. Continue Your Platform Engineering Journey","text":"<p>Advanced Topics (self-study): - FinOps: Cloud cost optimization at scale - Platform Security: Advanced threat modeling, security-as-code - Developer Experience: Measuring and improving DORA metrics - SRE Practices: Error budgets, on-call rotation, incident response - Platform Product Management: Roadmapping, user research, adoption metrics</p> <p>Recommended Certifications: - Kubernetes: CKA (Certified Kubernetes Administrator) - Cloud: AWS Solutions Architect, GCP Professional Cloud Architect - Security: CISSP, Certified Ethical Hacker - SRE: Google SRE Certification (if available)</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#3-contribute-to-the-platform-engineering-community","title":"3. Contribute to the Platform Engineering Community","text":"<p>Ways to give back: - Write blog posts about your platform journey - Speak at meetups or conferences (KubeCon, PlatformCon) - Contribute to open-source platform tools (Backstage, Crossplane, ArgoCD) - Mentor junior engineers at your organization - Share learnings in #platformengineering on Twitter/LinkedIn</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#4-apply-your-skills","title":"4. Apply Your Skills","text":"<p>Platform Engineering Career Paths:</p> <ol> <li>Platform Engineer: Build and maintain internal developer platforms</li> <li>Staff Platform Engineer: Lead platform initiatives, mentor team</li> <li>Platform Architect: Design enterprise-wide platform strategies</li> <li>Developer Experience Engineer: Focus on DX metrics and improvements</li> <li>SRE (Site Reliability Engineer): Own production reliability</li> <li>DevOps Architect: Bridge development and operations at scale</li> <li>Cloud Architect: Design multi-cloud and hybrid cloud solutions</li> <li>Platform Product Manager: Own platform roadmap and adoption</li> </ol> <p>Salary Ranges (US, 2025): - Platform Engineer: $120k - $180k - Senior Platform Engineer: $150k - $220k - Staff Platform Engineer: $180k - $280k - Platform Architect: $200k - $350k+</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#your-fawkes-dojo-progress","title":"\ud83d\udcca Your Fawkes Dojo Progress","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551              FAWKES DOJO COMPLETION SUMMARY                  \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nWhite Belt (Platform Fundamentals)          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100%\n  \u2705 Module 1: Internal Delivery Platforms\n  \u2705 Module 2: DORA Metrics\n  \u2705 Module 3: GitOps Principles\n  \u2705 Module 4: Your First Deployment\n\nYellow Belt (CI/CD Mastery)                 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100%\n  \u2705 Module 5: Continuous Integration Fundamentals\n  \u2705 Module 6: Building Golden Path Pipelines\n  \u2705 Module 7: Security Scanning &amp; Quality Gates\n  \u2705 Module 8: Artifact Management\n\nGreen Belt (GitOps &amp; Deployment)            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100%\n  \u2705 Module 9: GitOps with ArgoCD\n  \u2705 Module 10: Deployment Strategies\n  \u2705 Module 11: Progressive Delivery\n  \u2705 Module 12: Rollback &amp; Incident Response\n\nBrown Belt (Observability &amp; SRE)            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100%\n  \u2705 Module 13: Metrics, Logs, and Traces\n  \u2705 Module 14: DORA Metrics Deep Dive\n  \u2705 Module 15: SLIs, SLOs, and Error Budgets\n  \u2705 Module 16: Incident Management &amp; Postmortems\n\nBlack Belt (Platform Architecture)          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100%\n  \u2705 Module 17: Platform as a Product\n  \u2705 Module 18: Multi-Tenancy &amp; Resource Management\n  \u2705 Module 19: Security &amp; Zero Trust\n  \u2705 Module 20: Multi-Cloud Strategies\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nOVERALL PROGRESS: 20/20 MODULES COMPLETE (100%)\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n\ud83c\udfc6 Ready for Black Belt Certification Assessment!\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#certification-roadmap","title":"\ud83c\udf93 Certification Roadmap","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 YOU ARE HERE!                               \u2502\n\u2502                      \u2193                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502  \ud83e\udd4b Black Belt Complete (Modules 1-20)           \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502                     \u2502                                       \u2502\n\u2502                     \u25bc                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502  \ud83d\udcdd Black Belt Assessment                         \u2502      \u2502\n\u2502  \u2502     - 50-question exam (90% pass)                \u2502      \u2502\n\u2502  \u2502     - Architecture design presentation           \u2502      \u2502\n\u2502  \u2502     - Implementation challenge                   \u2502      \u2502\n\u2502  \u2502     - Code contribution to Fawkes                \u2502      \u2502\n\u2502  \u2502     - Mentor 2 White Belt learners               \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502                     \u2502                                       \u2502\n\u2502                     \u25bc                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502  \ud83c\udf93 FAWKES PLATFORM ARCHITECT CERTIFICATION       \u2502      \u2502\n\u2502  \u2502                                                   \u2502      \u2502\n\u2502  \u2502  Certificate Number: FPA-2025-XXXXX              \u2502      \u2502\n\u2502  \u2502  Digital Badge: Add to LinkedIn                  \u2502      \u2502\n\u2502  \u2502  Recognition: Fawkes Contributors Page           \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#what-youve-accomplished","title":"\ud83c\udfc5 What You've Accomplished","text":"<p>Over the course of 20 modules, you've learned:</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#technical-skills","title":"Technical Skills","text":"<ul> <li>\u2705 Design and implement internal developer platforms</li> <li>\u2705 Build CI/CD pipelines with security scanning and quality gates</li> <li>\u2705 Implement GitOps workflows with ArgoCD</li> <li>\u2705 Deploy using progressive delivery (canary, blue-green)</li> <li>\u2705 Establish comprehensive observability (metrics, logs, traces)</li> <li>\u2705 Define and track DORA metrics</li> <li>\u2705 Create SLIs, SLOs, and error budgets</li> <li>\u2705 Respond to incidents and conduct blameless postmortems</li> <li>\u2705 Design platforms as products with user research</li> <li>\u2705 Implement multi-tenancy and resource management</li> <li>\u2705 Architect zero trust security for platforms</li> <li>\u2705 Design multi-cloud strategies and disaster recovery</li> </ul>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#leadership-soft-skills","title":"Leadership &amp; Soft Skills","text":"<ul> <li>\u2705 Communicate platform value to stakeholders</li> <li>\u2705 Gather and incorporate user feedback</li> <li>\u2705 Balance technical debt with feature development</li> <li>\u2705 Lead architectural decisions</li> <li>\u2705 Mentor junior engineers</li> <li>\u2705 Navigate organizational change</li> </ul>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#industry-knowledge","title":"Industry Knowledge","text":"<ul> <li>\u2705 DORA research and high-performing organizations</li> <li>\u2705 Platform engineering best practices</li> <li>\u2705 DevOps and SRE principles</li> <li>\u2705 Cloud architecture patterns</li> <li>\u2705 Security and compliance requirements</li> </ul>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#feedback-community","title":"\ud83d\udcac Feedback &amp; Community","text":""},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#share-your-experience","title":"Share Your Experience","text":"<p>We'd love to hear about your Fawkes Dojo journey!</p> <p>Join the community: - \ud83d\udcac Mattermost: <code>#dojo-graduates</code> channel - \ud83d\udc26 Twitter: Tweet with <code>#FawkesDojo</code> and <code>@FawkesPlatform</code> - \ud83d\udcbc LinkedIn: Add \"Fawkes Platform Architect\" to certifications - \ud83d\udcdd Blog: Write about your learning experience</p> <p>Help improve the Dojo: - Submit feedback via Backstage feedback plugin - Suggest new modules or improvements - Contribute lab exercises or quizzes - Help translate content (internationalization)</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#fawkes-platform-architect-badge","title":"\ud83c\udf1f Fawkes Platform Architect Badge","text":"<p>Upon passing the Black Belt Assessment, you'll receive:</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                           \u2551\n\u2551                  \ud83c\udfc6 FAWKES DOJO \ud83c\udfc6                        \u2551\n\u2551                                                           \u2551\n\u2551              PLATFORM ARCHITECT CERTIFIED                 \u2551\n\u2551                                                           \u2551\n\u2551                    \u26ab BLACK BELT \u26ab                        \u2551\n\u2551                                                           \u2551\n\u2551  This certifies that [YOUR NAME] has demonstrated        \u2551\n\u2551  mastery in platform engineering, achieving the          \u2551\n\u2551  highest level of the Fawkes Dojo curriculum.            \u2551\n\u2551                                                           \u2551\n\u2551  Competencies:                                            \u2551\n\u2551    \u2713 Platform Architecture &amp; Design                      \u2551\n\u2551    \u2713 CI/CD &amp; GitOps                                      \u2551\n\u2551    \u2713 Observability &amp; SRE                                 \u2551\n\u2551    \u2713 Security &amp; Zero Trust                               \u2551\n\u2551    \u2713 Multi-Cloud Strategies                              \u2551\n\u2551                                                           \u2551\n\u2551  Certificate ID: FPA-2025-XXXXX                          \u2551\n\u2551  Issue Date: [DATE]                                      \u2551\n\u2551  Valid Until: [DATE + 2 years]                           \u2551\n\u2551                                                           \u2551\n\u2551  Verify: https://fawkes.io/verify/FPA-2025-XXXXX         \u2551\n\u2551                                                           \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p>Digital badge includes: - Credly integration (add to LinkedIn, resume) - QR code for verification - Skill tags for recruiter searches - Expiration date (renew every 2 years with continued learning)</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#recertification","title":"\ud83d\udcc5 Recertification","text":"<p>Platform engineering evolves rapidly. To maintain your certification:</p> <p>Recertification Options (every 2 years):</p> <ol> <li>Continuous Learning Path:</li> <li>Complete 4 new Fawkes Dojo modules (as they're released)</li> <li>Attend 2 platform engineering conferences/workshops</li> <li> <p>Contribute to 2 open-source platform projects</p> </li> <li> <p>Advanced Assessment:</p> </li> <li>Take updated Black Belt exam (reflects new tools/practices)</li> <li> <p>Present case study from your production platform</p> </li> <li> <p>Mentorship Track:</p> </li> <li>Mentor 5 engineers through Fawkes Dojo</li> <li>Conduct 2 internal platform workshops</li> <li>Document learnings and best practices</li> </ol>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#congratulations","title":"\ud83c\udf89 Congratulations!","text":"<p>You've completed the most comprehensive platform engineering curriculum available. You're now equipped to:</p> <ul> <li>Build world-class internal developer platforms</li> <li>Lead platform initiatives at your organization</li> <li>Mentor the next generation of platform engineers</li> <li>Shape the future of platform engineering</li> </ul> <p>The journey doesn't end here \u2013 it's just beginning. Platform engineering is a rapidly evolving field, and continuous learning is essential.</p> <p>Go forth and build amazing platforms! \ud83d\ude80</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#stay-connected","title":"\ud83d\udcde Stay Connected","text":"<ul> <li>Fawkes Website: https://fawkes.io</li> <li>Documentation: https://docs.fawkes.io</li> <li>GitHub: https://github.com/fawkes-platform</li> <li>Community Forum: https://community.fawkes.io</li> <li>Mattermost: #platform-engineering</li> <li>Twitter: @FawkesPlatform</li> <li>YouTube: Fawkes Platform Engineering</li> </ul> <p>Module 20: Multi-Cloud Strategies | Fawkes Dojo | Black Belt \"Build once, deploy anywhere\" | Version 1.0</p>"},{"location":"dojo/modules/black-belt/module-20-multi-cloud/#black-belt-status-complete","title":"\ud83c\udfc6 Black Belt Status: COMPLETE! \u2705","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                          \u2551\n\u2551      \ud83e\udd4b BLACK BELT CURRICULUM COMPLETE! \ud83e\udd4b               \u2551\n\u2551                                                          \u2551\n\u2551  All 20 modules mastered. You are ready to:             \u2551\n\u2551                                                          \u2551\n\u2551  \u2713 Schedule Black Belt Assessment                       \u2551\n\u2551  \u2713 Design enterprise platform architectures             \u2551\n\u2551  \u2713 Lead platform engineering teams                      \u2551\n\u2551  \u2713 Mentor junior platform engineers                     \u2551\n\u2551  \u2713 Contribute to platform engineering community         \u2551\n\u2551                                                          \u2551\n\u2551  Next step: fawkes dojo assess --level black-belt       \u2551\n\u2551                                                          \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p>You did it! \ud83c\udf8a Now go earn that certification! \ud83d\udcaa</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/","title":"Fawkes Dojo Module 13: Monitoring, Observability &amp; DORA Metrics","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#module-overview","title":"Module Overview","text":"<p>Duration: 3-4 hours Level: Advanced Prerequisites: Modules 1-4, Working Fawkes deployment, Basic understanding of Kubernetes and CI/CD</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this module, you will be able to:</p> <ol> <li>Implement comprehensive monitoring and observability for your Fawkes platform</li> <li>Configure and customize dashboards for platform health and performance</li> <li>Measure and track the Four Key DORA metrics</li> <li>Set up alerting and incident response workflows</li> <li>Use observability data to drive continuous improvement</li> <li>Implement distributed tracing for application performance monitoring</li> </ol>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-1-understanding-observability-in-platform-engineering","title":"Part 1: Understanding Observability in Platform Engineering","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#the-three-pillars-of-observability","title":"The Three Pillars of Observability","text":"<p>Metrics: Numerical measurements over time - Infrastructure metrics (CPU, memory, disk, network) - Application metrics (request rate, error rate, latency) - Business metrics (deployments, lead time, failure rate)</p> <p>Logs: Event records from systems and applications - Structured vs. unstructured logs - Log aggregation and centralization - Log levels and filtering</p> <p>Traces: Request flows through distributed systems - Distributed tracing concepts - Span and trace relationships - Performance bottleneck identification</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#why-observability-matters-for-dora","title":"Why Observability Matters for DORA","text":"<p>The Four Key Metrics require robust observability:</p> <ol> <li>Deployment Frequency: Track deployments through CI/CD events</li> <li>Lead Time for Changes: Measure from commit to production</li> <li>Change Failure Rate: Monitor deployment failures and rollbacks</li> <li>Mean Time to Restore (MTTR): Detect and measure incident resolution time</li> </ol>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-2-fawkes-monitoring-stack","title":"Part 2: Fawkes Monitoring Stack","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#components-overview","title":"Components Overview","text":"<p>Fawkes includes an integrated monitoring stack:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Grafana Dashboards                \u2502\n\u2502        (Visualization &amp; Alerting)           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Prometheus  \u2502  \u2502    Loki    \u2502\n\u2502  (Metrics)  \u2502  \u2502   (Logs)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Node Exporters          \u2502\n\u2502   Application Exporters      \u2502\n\u2502      Fluent Bit/Promtail     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Kubernetes Cluster  \u2502\n    \u2502    Applications      \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#included-tools","title":"Included Tools","text":"<ul> <li>Prometheus: Metrics collection and storage</li> <li>Grafana: Dashboard visualization and alerting</li> <li>Loki: Log aggregation (lightweight alternative to ELK)</li> <li>Tempo: Distributed tracing (optional)</li> <li>AlertManager: Alert routing and notification</li> <li>Node Exporter: Infrastructure metrics</li> <li>kube-state-metrics: Kubernetes object metrics</li> </ul>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-3-hands-on-lab-deploying-the-monitoring-stack","title":"Part 3: Hands-On Lab - Deploying the Monitoring Stack","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#lab-setup","title":"Lab Setup","text":"<p>Scenario: You have a running Fawkes platform on Kubernetes. Now you'll deploy the full monitoring stack and configure dashboards.</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#step-1-deploy-monitoring-components","title":"Step 1: Deploy Monitoring Components","text":"<pre><code># Navigate to the platform monitoring directory\ncd fawkes/platform/monitoring\n\n# Deploy Prometheus Operator and stack\nkubectl create namespace monitoring\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\n\n# Install kube-prometheus-stack (includes Prometheus, Grafana, AlertManager)\nhelm install prometheus prometheus-community/kube-prometheus-stack \\\n  --namespace monitoring \\\n  --set prometheus.prometheusSpec.retention=30d \\\n  --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=50Gi \\\n  --set grafana.adminPassword=admin123 \\\n  -f values/prometheus-values.yaml\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#step-2-deploy-loki-for-log-aggregation","title":"Step 2: Deploy Loki for Log Aggregation","text":"<pre><code># Install Loki\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm install loki grafana/loki-stack \\\n  --namespace monitoring \\\n  --set promtail.enabled=true \\\n  --set loki.persistence.enabled=true \\\n  --set loki.persistence.size=50Gi\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#step-3-configure-data-sources-in-grafana","title":"Step 3: Configure Data Sources in Grafana","text":"<pre><code># Get Grafana admin password\nkubectl get secret --namespace monitoring prometheus-grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode\n\n# Port-forward to access Grafana\nkubectl port-forward -n monitoring svc/prometheus-grafana 3000:80\n</code></pre> <p>Visit <code>http://localhost:3000</code> and log in with admin credentials.</p> <p>Add Loki Data Source: 1. Go to Configuration \u2192 Data Sources 2. Add data source \u2192 Loki 3. URL: <code>http://loki:3100</code> 4. Save &amp; Test</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#step-4-verify-metrics-collection","title":"Step 4: Verify Metrics Collection","text":"<pre><code># Check Prometheus targets\nkubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090\n\n# Open http://localhost:9090/targets\n# Verify all targets are \"UP\"\n</code></pre> <p>Expected targets: - kubernetes-apiservers - kubernetes-nodes - kubernetes-pods - kubernetes-service-endpoints - kube-state-metrics - node-exporter</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-4-configuring-dora-metrics-dashboards","title":"Part 4: Configuring DORA Metrics Dashboards","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#creating-custom-metrics","title":"Creating Custom Metrics","text":"<p>To track DORA metrics, we need to instrument our CI/CD pipeline to emit custom metrics.</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#deployment-frequency-metric","title":"Deployment Frequency Metric","text":"<p>Add to your CI/CD pipeline (e.g., Jenkins, GitLab CI, ArgoCD):</p> <pre><code># Example: Prometheus metrics endpoint in your deployment controller\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: deployment-metrics\n  namespace: fawkes-platform\ndata:\n  record-deployment.sh: |\n    #!/bin/bash\n    # Record deployment event\n    cat &lt;&lt;EOF | curl --data-binary @- http://prometheus-pushgateway:9091/metrics/job/deployments\n    # TYPE deployment_total counter\n    # HELP deployment_total Total number of deployments\n    deployment_total{environment=\"$ENV\",application=\"$APP\",status=\"$STATUS\"} 1\n    EOF\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#lead-time-for-changes","title":"Lead Time for Changes","text":"<p>Track commit-to-deployment time:</p> <pre><code># Example Python script to calculate lead time\nfrom prometheus_client import Gauge, push_to_gateway\nimport os\nfrom datetime import datetime\n\nlead_time_gauge = Gauge('lead_time_seconds', 'Time from commit to deployment', ['application', 'environment'])\n\ndef record_lead_time(commit_timestamp, deploy_timestamp, app, env):\n    lead_time = (deploy_timestamp - commit_timestamp).total_seconds()\n    lead_time_gauge.labels(application=app, environment=env).set(lead_time)\n    push_to_gateway('prometheus-pushgateway:9091', job='lead_time', registry=registry)\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#change-failure-rate","title":"Change Failure Rate","text":"<p>Monitor deployment failures and rollbacks:</p> <pre><code># In your deployment script, record success/failure\ndeployment_status=\"success\"  # or \"failure\"\n\ncat &lt;&lt;EOF | curl --data-binary @- http://prometheus-pushgateway:9091/metrics/job/deployment_results\ndeployment_result{application=\"$APP\",environment=\"$ENV\",status=\"$deployment_status\"} 1\nEOF\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#mttr-mean-time-to-restore","title":"MTTR (Mean Time to Restore)","text":"<p>Use AlertManager and incident tracking:</p> <pre><code># PromQL query for MTTR\nrate(alert_duration_seconds_sum[7d]) / rate(alert_duration_seconds_count[7d])\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#import-dora-dashboard","title":"Import DORA Dashboard","text":"<p>Create a Grafana dashboard (<code>dora-metrics-dashboard.json</code>):</p> <pre><code>{\n  \"dashboard\": {\n    \"title\": \"DORA Four Key Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Deployment Frequency\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(rate(deployment_total[1d])) by (environment)\"\n          }\n        ],\n        \"type\": \"graph\"\n      },\n      {\n        \"title\": \"Lead Time for Changes (Average)\",\n        \"targets\": [\n          {\n            \"expr\": \"avg(lead_time_seconds) by (application)\"\n          }\n        ],\n        \"type\": \"stat\"\n      },\n      {\n        \"title\": \"Change Failure Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(rate(deployment_result{status='failure'}[7d])) / sum(rate(deployment_result[7d])) * 100\"\n          }\n        ],\n        \"type\": \"gauge\"\n      },\n      {\n        \"title\": \"Mean Time to Restore (MTTR)\",\n        \"targets\": [\n          {\n            \"expr\": \"avg(alert_duration_seconds) by (severity)\"\n          }\n        ],\n        \"type\": \"stat\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Import into Grafana: <pre><code># Import dashboard\ncurl -X POST http://admin:admin123@localhost:3000/api/dashboards/db \\\n  -H \"Content-Type: application/json\" \\\n  -d @dora-metrics-dashboard.json\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-5-alerting-and-incident-response","title":"Part 5: Alerting and Incident Response","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#configuring-alertmanager","title":"Configuring AlertManager","text":"<p>Edit AlertManager configuration:</p> <pre><code># alertmanager-config.yaml\nglobal:\n  resolve_timeout: 5m\n  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'\n\nroute:\n  group_by: ['alertname', 'cluster', 'service']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 12h\n  receiver: 'default'\n  routes:\n  - match:\n      severity: critical\n    receiver: 'pagerduty-critical'\n  - match:\n      severity: warning\n    receiver: 'slack-warnings'\n\nreceivers:\n- name: 'default'\n  slack_configs:\n  - channel: '#alerts'\n    title: 'Alert: {{ .GroupLabels.alertname }}'\n    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'\n\n- name: 'pagerduty-critical'\n  pagerduty_configs:\n  - service_key: 'YOUR_PAGERDUTY_KEY'\n\n- name: 'slack-warnings'\n  slack_configs:\n  - channel: '#warnings'\n    title: 'Warning: {{ .GroupLabels.alertname }}'\n</code></pre> <p>Apply configuration: <pre><code>kubectl create secret generic alertmanager-config \\\n  --from-file=alertmanager.yaml=alertmanager-config.yaml \\\n  -n monitoring\n\nkubectl rollout restart statefulset/alertmanager-prometheus-kube-prometheus-alertmanager -n monitoring\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#creating-alert-rules","title":"Creating Alert Rules","text":"<pre><code># prometheus-rules.yaml\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: fawkes-platform-alerts\n  namespace: monitoring\nspec:\n  groups:\n  - name: platform_health\n    interval: 30s\n    rules:\n    - alert: HighPodCrashRate\n      expr: rate(kube_pod_container_status_restarts_total[15m]) &gt; 0.1\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"High pod crash rate detected\"\n        description: \"Pod {{ $labels.pod }} is crash-looping\"\n\n    - alert: DeploymentFailed\n      expr: increase(deployment_result{status=\"failure\"}[5m]) &gt; 0\n      for: 1m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Deployment failure detected\"\n        description: \"Deployment for {{ $labels.application }} failed\"\n\n    - alert: HighChangeFailureRate\n      expr: |\n        sum(rate(deployment_result{status=\"failure\"}[7d]))\n        / sum(rate(deployment_result[7d])) * 100 &gt; 15\n      for: 10m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Change failure rate exceeds 15%\"\n        description: \"Current CFR: {{ $value }}%\"\n\n    - alert: LowDeploymentFrequency\n      expr: sum(rate(deployment_total[1d])) &lt; 0.1\n      for: 1h\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Deployment frequency is low\"\n        description: \"Less than 1 deployment per 10 days\"\n\n    - alert: HighLeadTime\n      expr: avg(lead_time_seconds) &gt; 86400\n      for: 1h\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Lead time exceeds 24 hours\"\n        description: \"Average lead time: {{ $value }}s\"\n</code></pre> <p>Apply rules: <pre><code>kubectl apply -f prometheus-rules.yaml\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-6-application-performance-monitoring-with-tracing","title":"Part 6: Application Performance Monitoring with Tracing","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#deploy-tempo-for-distributed-tracing","title":"Deploy Tempo for Distributed Tracing","text":"<pre><code># Install Tempo\nhelm install tempo grafana/tempo \\\n  --namespace monitoring \\\n  --set persistence.enabled=true\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#instrument-your-application","title":"Instrument Your Application","text":"<p>Example using OpenTelemetry (Java Spring Boot):</p> <pre><code>&lt;!-- pom.xml --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n    &lt;artifactId&gt;opentelemetry-api&lt;/artifactId&gt;\n    &lt;version&gt;1.32.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n    &lt;artifactId&gt;opentelemetry-exporter-otlp&lt;/artifactId&gt;\n    &lt;version&gt;1.32.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <pre><code>// Application configuration\n@Configuration\npublic class TracingConfig {\n    @Bean\n    public OpenTelemetry openTelemetry() {\n        OtlpGrpcSpanExporter spanExporter = OtlpGrpcSpanExporter.builder()\n            .setEndpoint(\"http://tempo:4317\")\n            .build();\n\n        SdkTracerProvider tracerProvider = SdkTracerProvider.builder()\n            .addSpanProcessor(BatchSpanProcessor.builder(spanExporter).build())\n            .build();\n\n        return OpenTelemetrySdk.builder()\n            .setTracerProvider(tracerProvider)\n            .buildAndRegisterGlobal();\n    }\n}\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#configure-tempo-in-grafana","title":"Configure Tempo in Grafana","text":"<ol> <li>Add Tempo data source in Grafana</li> <li>URL: <code>http://tempo:3100</code></li> <li>Enable trace to logs correlation with Loki</li> </ol>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-7-log-analysis-and-troubleshooting","title":"Part 7: Log Analysis and Troubleshooting","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#effective-log-queries-with-logql","title":"Effective Log Queries with LogQL","text":"<p>Find errors in the last hour: <pre><code>{namespace=\"fawkes-platform\"} |= \"ERROR\" | json | line_format \"{{.timestamp}} {{.level}} {{.message}}\"\n</code></pre></p> <p>Track deployment events: <pre><code>{job=\"deployment-controller\"} |= \"deployment\" | json | status=\"success\"\n</code></pre></p> <p>Analyze slow requests: <pre><code>{app=\"api-gateway\"} | json | duration &gt; 1000 | line_format \"Slow request: {{.path}} took {{.duration}}ms\"\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#creating-log-based-alerts","title":"Creating Log-Based Alerts","text":"<pre><code># Grafana alert from logs\n- alert: HighErrorRate\n  expr: |\n    sum(rate({namespace=\"fawkes-platform\"} |= \"ERROR\" [5m]))\n    &gt; 10\n  for: 5m\n  labels:\n    severity: warning\n  annotations:\n    summary: \"High error rate in platform logs\"\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-8-dashboarding-best-practices","title":"Part 8: Dashboarding Best Practices","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#dashboard-design-principles","title":"Dashboard Design Principles","text":"<ol> <li>Top-down approach: Overall health \u2192 Specific components</li> <li>Red method for services: Rate, Errors, Duration</li> <li>USE method for resources: Utilization, Saturation, Errors</li> <li>Actionable metrics: Every panel should inform decisions</li> <li>Consistent time ranges: Synchronize across panels</li> </ol>"},{"location":"dojo/modules/brown-belt/module-13-observability/#example-platform-health-dashboard-structure","title":"Example Platform Health Dashboard Structure","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Overall Platform Health (Single stat)      \u2502\n\u2502  \u25cf Cluster Status  \u25cf Deployments  \u25cf Alerts \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Deployment Freq.    \u2502 \u2502  Lead Time Trend  \u2502\n\u2502  (Time series)       \u2502 \u2502  (Time series)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Change Failure %    \u2502 \u2502  MTTR (Avg)       \u2502\n\u2502  (Gauge)             \u2502 \u2502  (Stat)           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Recent Deployments (Table)                 \u2502\n\u2502  Time | App | Env | Status | Duration       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Active Alerts (Table)                      \u2502\n\u2502  Severity | Alert | Time | Status           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-9-practical-exercise","title":"Part 9: Practical Exercise","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#exercise-complete-observability-implementation","title":"Exercise: Complete Observability Implementation","text":"<p>Objective: Implement end-to-end observability for a sample application deployed on Fawkes.</p> <p>Steps:</p> <ol> <li> <p>Deploy Sample Application <pre><code>kubectl apply -f exercises/sample-app/\n</code></pre></p> </li> <li> <p>Configure Application Metrics</p> </li> <li>Expose Prometheus metrics endpoint</li> <li>Add custom business metrics</li> <li> <p>Verify scraping in Prometheus</p> </li> <li> <p>Set Up Logging</p> </li> <li>Ensure structured JSON logs</li> <li>Verify logs appear in Loki</li> <li> <p>Create useful log queries</p> </li> <li> <p>Create Dashboard</p> </li> <li>Import base dashboard template</li> <li>Add custom panels for your app</li> <li> <p>Configure variables for filtering</p> </li> <li> <p>Configure Alerts</p> </li> <li>Create alert for high error rate</li> <li>Create alert for deployment failures</li> <li> <p>Test alert firing and resolution</p> </li> <li> <p>Implement Tracing</p> </li> <li>Add OpenTelemetry instrumentation</li> <li>Generate sample traces</li> <li> <p>Correlate traces with logs</p> </li> <li> <p>Measure DORA Metrics</p> </li> <li>Deploy multiple times</li> <li>Introduce a failure</li> <li>Calculate all four metrics</li> <li>Identify improvement opportunities</li> </ol> <p>Validation Checklist: - [ ] Application metrics visible in Prometheus - [ ] Logs searchable in Grafana/Loki - [ ] Dashboard shows real-time data - [ ] Alerts fire and resolve correctly - [ ] Traces show request flows - [ ] DORA metrics calculated and displayed</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-10-advanced-topics","title":"Part 10: Advanced Topics","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#cost-optimization","title":"Cost Optimization","text":"<p>Reduce metric cardinality: <pre><code># Drop unnecessary labels\nmetric_relabel_configs:\n  - source_labels: [__name__]\n    regex: 'go_.*'\n    action: drop\n</code></pre></p> <p>Adjust retention: <pre><code># Shorter retention for high-volume metrics\n- record: aggregated:deployment_total:sum\n  expr: sum(rate(deployment_total[5m])) by (environment)\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#high-availability-setup","title":"High Availability Setup","text":"<pre><code># Prometheus HA with Thanos\nprometheus:\n  prometheusSpec:\n    replicas: 2\n    thanos:\n      image: quay.io/thanos/thanos:v0.32.0\n      objectStorageConfig:\n        secret: thanos-objstore-config\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#multi-cluster-monitoring","title":"Multi-Cluster Monitoring","text":"<pre><code># Use Thanos or Cortex for cross-cluster metrics\nhelm install thanos bitnami/thanos \\\n  --set query.enabled=true \\\n  --set storegateway.enabled=true\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-11-troubleshooting-common-issues","title":"Part 11: Troubleshooting Common Issues","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#prometheus-not-scraping-targets","title":"Prometheus Not Scraping Targets","text":"<p>Symptom: Targets show as \"DOWN\" in Prometheus</p> <p>Solution: <pre><code># Check ServiceMonitor configuration\nkubectl get servicemonitors -n monitoring\n\n# Verify service selector matches\nkubectl describe servicemonitor &lt;name&gt; -n monitoring\n\n# Check network policies\nkubectl get networkpolicies -n monitoring\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#high-cardinality-problems","title":"High Cardinality Problems","text":"<p>Symptom: Prometheus using excessive memory</p> <p>Solution: <pre><code># Identify high-cardinality metrics\ncurl http://localhost:9090/api/v1/status/tsdb | jq .\n\n# Drop or aggregate problematic metrics\n# Add to prometheus-values.yaml\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#missing-logs-in-loki","title":"Missing Logs in Loki","text":"<p>Symptom: No logs appearing in Grafana</p> <p>Solution: <pre><code># Check Promtail is running\nkubectl get pods -n monitoring -l app=promtail\n\n# Verify Promtail configuration\nkubectl logs -n monitoring -l app=promtail\n\n# Check Loki ingester\nkubectl logs -n monitoring -l app=loki -c ingester\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#part-12-summary-and-next-steps","title":"Part 12: Summary and Next Steps","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Observability is critical for platform reliability and DORA metrics</li> <li>The three pillars (metrics, logs, traces) provide complementary insights</li> <li>Automation of metric collection reduces manual work</li> <li>Dashboards should be actionable and inform decisions</li> <li>Alerting requires tuning to avoid fatigue</li> <li>DORA metrics drive continuous improvement</li> </ol>"},{"location":"dojo/modules/brown-belt/module-13-observability/#measuring-success","title":"Measuring Success","text":"<p>After completing this module, you should have: - \u2705 Working Prometheus + Grafana + Loki stack - \u2705 Custom dashboards for DORA metrics - \u2705 Configured alerts for platform health - \u2705 Application instrumentation for tracing - \u2705 Log aggregation and search capability - \u2705 Understanding of observability best practices</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#continuous-improvement","title":"Continuous Improvement","text":"<p>Weekly Activities: - Review DORA metrics trends - Analyze alert patterns - Optimize slow queries - Update dashboards based on team feedback</p> <p>Monthly Activities: - Review and adjust alert thresholds - Archive old metrics data - Update documentation - Train team members on new features</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#additional-resources","title":"Additional Resources","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Best Practices</li> <li>OpenTelemetry Specification</li> <li>DORA Research</li> <li>Google SRE Book - Monitoring</li> <li>Loki LogQL Documentation</li> </ul>"},{"location":"dojo/modules/brown-belt/module-13-observability/#module-assessment","title":"Module Assessment","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#knowledge-check-questions","title":"Knowledge Check Questions","text":"<ol> <li>What are the three pillars of observability?</li> <li>How do you calculate the Change Failure Rate?</li> <li>What's the difference between metrics and traces?</li> <li>When should you use Prometheus vs. Loki?</li> <li>What is metric cardinality and why does it matter?</li> <li>How do you correlate traces with logs in Grafana?</li> <li>What's the purpose of AlertManager's grouping?</li> <li>How can you reduce monitoring costs?</li> </ol>"},{"location":"dojo/modules/brown-belt/module-13-observability/#practical-assessment","title":"Practical Assessment","text":"<p>Complete the following tasks: 1. Deploy a complete monitoring stack 2. Create a custom dashboard with DORA metrics 3. Configure three meaningful alerts 4. Instrument an application with tracing 5. Write five useful LogQL queries 6. Generate a weekly DORA metrics report</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#bonus-challenge","title":"Bonus Challenge","text":"<p>Implement a complete observability solution for a multi-service application that: - Tracks deployments across three environments - Correlates traces across microservices - Provides SLO/SLA dashboards - Alerts on DORA metric degradation - Exports metrics to external systems</p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#appendix-a-metric-examples-reference","title":"Appendix A: Metric Examples Reference","text":""},{"location":"dojo/modules/brown-belt/module-13-observability/#infrastructure-metrics","title":"Infrastructure Metrics","text":"<pre><code># Node CPU usage\n100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)\n\n# Node memory usage\n100 * (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)\n\n# Disk usage\n100 - (node_filesystem_avail_bytes / node_filesystem_size_bytes * 100)\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#kubernetes-metrics","title":"Kubernetes Metrics","text":"<pre><code># Pod restart rate\nrate(kube_pod_container_status_restarts_total[1h])\n\n# Deployment replicas available\nkube_deployment_status_replicas_available / kube_deployment_spec_replicas\n\n# Node readiness\nkube_node_status_condition{condition=\"Ready\",status=\"true\"}\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#application-metrics","title":"Application Metrics","text":"<pre><code># Request rate (RED method)\nsum(rate(http_requests_total[5m])) by (service)\n\n# Error rate\nsum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m]))\n\n# Request duration (p95)\nhistogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-13-observability/#appendix-b-dashboard-json-templates","title":"Appendix B: Dashboard JSON Templates","text":"<p>See the Fawkes repository for complete dashboard templates: - <code>dashboards/platform-overview.json</code> - <code>dashboards/dora-metrics.json</code> - <code>dashboards/application-health.json</code> - <code>dashboards/infrastructure.json</code></p>"},{"location":"dojo/modules/brown-belt/module-13-observability/#feedback-and-contributions","title":"Feedback and Contributions","text":"<p>Have feedback on this module? Found errors or want to suggest improvements?</p> <ul> <li>Open an issue: https://github.com/paruff/fawkes/issues</li> <li>Submit a PR: https://github.com/paruff/fawkes/pulls</li> <li>Join discussions: https://github.com/paruff/fawkes/discussions</li> </ul> <p>Module 5 Complete! \ud83c\udf89</p> <p>You now have the knowledge to implement comprehensive observability and measure DORA metrics for your Fawkes platform. Continue to Module 6 for advanced platform operations and troubleshooting.</p> <p>Next Module Preview: Module 6 - Platform Operations &amp; Advanced Troubleshooting</p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/","title":"Fawkes Dojo Module 14: DORA Metrics Deep Dive","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe4 Brown Belt - Observability &amp; SRE Module: 2 of 4 (Brown Belt) Duration: 60 minutes Difficulty: Advanced Prerequisites: - Module 2: DORA Metrics (White Belt) review recommended - Module 13: Observability complete - Understanding of Prometheus and Grafana - Familiarity with GitOps workflows</p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Calculate and track all four DORA metrics automatically</li> <li>\u2705 Build comprehensive DORA dashboards in Grafana</li> <li>\u2705 Implement metric collection across the entire delivery pipeline</li> <li>\u2705 Analyze trends and identify improvement opportunities</li> <li>\u2705 Benchmark against industry standards</li> <li>\u2705 Use metrics to drive platform improvements</li> <li>\u2705 Present DORA metrics to leadership effectively</li> </ol> <p>DORA Capabilities Addressed: - \u2713 All 4 Key Metrics (Deployment Frequency, Lead Time, MTTR, Change Failure Rate) - \u2713 Monitoring and Observability - \u2713 Data-Driven Decision Making</p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#part-1-dora-metrics-review-advanced-concepts","title":"\ud83d\udcd6 Part 1: DORA Metrics Review &amp; Advanced Concepts","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#the-four-key-metrics-refresher","title":"The Four Key Metrics (Refresher)","text":"Metric What It Measures Elite Performance Deployment Frequency How often you deploy Multiple per day Lead Time for Changes Commit \u2192 Production time &lt; 1 hour Change Failure Rate % of deployments causing failures 0-15% Mean Time to Restore Time to recover from failure &lt; 1 hour"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#why-these-four","title":"Why These Four?","text":"<p>Research shows these metrics are: - Predictive of organizational performance - Balanced between speed (DF, LT) and stability (CFR, MTTR) - Actionable - teams can directly improve them - Universal - apply across industries and tech stacks</p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#advanced-dora-concepts","title":"Advanced DORA Concepts","text":"<p>1. Metric Correlation</p> <p>Metrics don't exist in isolation:</p> <pre><code>High Deployment Frequency\n    \u2193\nSmaller batch sizes\n    \u2193\nLower Change Failure Rate\n    \u2193\nFaster Lead Time (less code per deploy)\n    \u2193\nBetter MTTR (easier to identify issues)\n</code></pre> <p>2. Team-Level vs Organization-Level</p> <ul> <li>Team-level: Track individual team performance</li> <li>Organization-level: Aggregate across all teams</li> <li>Service-level: Track per microservice/application</li> </ul> <p>3. Metric Distributions Matter</p> <p>Don't just track averages: - P50 (Median): Typical case - P95: Worst 5% of cases - P99: Outliers that hurt user experience</p> <p>Example: <pre><code>Lead Time:\n- Average: 2 hours\n- P50: 30 minutes \u2705 (Most deploys are fast)\n- P95: 8 hours \u274c (5% take too long - investigate why)\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#part-2-calculating-dora-metrics","title":"\ud83d\udd22 Part 2: Calculating DORA Metrics","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#metric-1-deployment-frequency","title":"Metric 1: Deployment Frequency","text":"<p>Definition: Number of deployments per time period</p> <p>Calculation: <pre><code>Deployment Frequency = Total Deployments / Time Period\n\nExample:\n- 150 deployments in 30 days\n- DF = 150 / 30 = 5 deployments per day \u2705 Elite\n</code></pre></p> <p>Data Sources: - ArgoCD sync events - GitOps repository commits - CI/CD pipeline completions - Kubernetes deployment events</p> <p>Prometheus Query: <pre><code># Count deployments per day\nsum(increase(argocd_app_sync_total{phase=\"Succeeded\"}[1d]))\n\n# Deployment frequency by application\nsum(rate(argocd_app_sync_total{phase=\"Succeeded\"}[7d])) by (name) * 86400\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#metric-2-lead-time-for-changes","title":"Metric 2: Lead Time for Changes","text":"<p>Definition: Time from code commit to running in production</p> <p>Calculation: <pre><code>Lead Time = Production Deployment Time - Commit Time\n\nExample:\n- Commit: 2025-10-10 14:00:00\n- Production: 2025-10-10 14:25:00\n- Lead Time: 25 minutes \u2705 Elite\n</code></pre></p> <p>Components: <pre><code>Total Lead Time =\n    Code Review Time +\n    CI Build Time +\n    Test Execution Time +\n    Security Scanning Time +\n    Artifact Creation Time +\n    Deployment Time +\n    Validation Time\n</code></pre></p> <p>Data Collection: <pre><code># Webhook receiver for Git commits\n@app.route('/webhook/commit', methods=['POST'])\ndef record_commit():\n    commit_sha = request.json['after']\n    commit_time = request.json['head_commit']['timestamp']\n\n    # Store in database\n    db.store_commit(commit_sha, commit_time)\n\n    return '', 200\n\n# Webhook receiver for deployments\n@app.route('/webhook/deploy', methods=['POST'])\ndef record_deployment():\n    commit_sha = request.json['revision']\n    deploy_time = datetime.utcnow()\n\n    # Calculate lead time\n    commit_time = db.get_commit_time(commit_sha)\n    lead_time = (deploy_time - commit_time).total_seconds()\n\n    # Send to Prometheus\n    lead_time_histogram.labels(app=app_name).observe(lead_time)\n\n    return '', 200\n</code></pre></p> <p>Prometheus Query: <pre><code># Average lead time (seconds)\navg(deployment_lead_time_seconds)\n\n# P95 lead time\nhistogram_quantile(0.95, sum(rate(deployment_lead_time_seconds_bucket[7d])) by (le))\n\n# Lead time by team\navg(deployment_lead_time_seconds) by (team)\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#metric-3-change-failure-rate","title":"Metric 3: Change Failure Rate","text":"<p>Definition: Percentage of deployments that result in failure</p> <p>Calculation: <pre><code>CFR = (Failed Deployments / Total Deployments) \u00d7 100\n\nExample:\n- Total deployments: 100\n- Failed deployments: 8\n- CFR = (8 / 100) \u00d7 100 = 8% \u2705 Elite\n</code></pre></p> <p>Defining \"Failure\": - Deployment rollback within 24 hours - Incident created within 24 hours of deployment - Deployment marked as failed in ArgoCD - Health checks fail post-deployment</p> <p>Data Collection: <pre><code>def calculate_change_failure_rate(timeframe_hours=24):\n    \"\"\"\n    Calculate CFR by correlating deployments with incidents\n    \"\"\"\n    deployments = get_deployments(since=timeframe_hours)\n    failures = 0\n\n    for deployment in deployments:\n        deploy_time = deployment['timestamp']\n\n        # Check for incidents within 24h\n        incidents = get_incidents(\n            since=deploy_time,\n            until=deploy_time + timedelta(hours=24)\n        )\n\n        # Check for rollbacks\n        rollback = get_rollback(\n            deployment_id=deployment['id'],\n            since=deploy_time,\n            until=deploy_time + timedelta(hours=24)\n        )\n\n        if incidents or rollback:\n            failures += 1\n\n    cfr = (failures / len(deployments)) * 100 if deployments else 0\n    return cfr\n</code></pre></p> <p>Prometheus Query: <pre><code># Change Failure Rate (%)\nsum(deployment_result{status=\"failed\"}) / sum(deployment_result) * 100\n\n# CFR by application\n(sum(deployment_result{status=\"failed\"}) by (app) / sum(deployment_result) by (app)) * 100\n\n# CFR trend over time\nsum(rate(deployment_result{status=\"failed\"}[7d])) / sum(rate(deployment_result[7d])) * 100\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#metric-4-mean-time-to-restore-mttr","title":"Metric 4: Mean Time to Restore (MTTR)","text":"<p>Definition: Average time to recover from a production failure</p> <p>Calculation: <pre><code>MTTR = Total Downtime / Number of Incidents\n\nExample:\n- 5 incidents in a month\n- Total downtime: 125 minutes\n- MTTR = 125 / 5 = 25 minutes \u2705 Elite\n</code></pre></p> <p>Data Collection: <pre><code># Incident lifecycle tracking\nclass Incident:\n    def __init__(self, id, severity):\n        self.id = id\n        self.severity = severity\n        self.detected_at = datetime.utcnow()\n        self.mitigated_at = None\n        self.resolved_at = None\n\n    def mitigate(self):\n        \"\"\"Service restored, but root cause not fixed\"\"\"\n        self.mitigated_at = datetime.utcnow()\n        ttm = (self.mitigated_at - self.detected_at).total_seconds()\n\n        # Time to Mitigate (what we really care about for MTTR)\n        mttr_histogram.labels(severity=self.severity).observe(ttm)\n\n    def resolve(self):\n        \"\"\"Root cause fixed, incident closed\"\"\"\n        self.resolved_at = datetime.utcnow()\n        ttr = (self.resolved_at - self.detected_at).total_seconds()\n\n        # Time to Resolve (total incident duration)\n        incident_duration_histogram.labels(severity=self.severity).observe(ttr)\n</code></pre></p> <p>Prometheus Query: <pre><code># Average MTTR (seconds)\navg(incident_duration_seconds)\n\n# MTTR by severity\navg(incident_duration_seconds) by (severity)\n\n# P95 MTTR (captures worst cases)\nhistogram_quantile(0.95, sum(rate(incident_duration_seconds_bucket[30d])) by (le))\n\n# MTTR trend\navg_over_time(incident_duration_seconds[7d])\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#part-3-building-the-ultimate-dora-dashboard","title":"\ud83d\udcca Part 3: Building the Ultimate DORA Dashboard","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#dashboard-architecture","title":"Dashboard Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              DORA Metrics Dashboard                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Executive Summary (Current vs Target)             \u2502 \u2502\n\u2502  \u2502  DF: 5/day (Elite) | LT: 45m (Elite)              \u2502 \u2502\n\u2502  \u2502  CFR: 8% (Elite)   | MTTR: 25m (Elite)            \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 Deployment   \u2502 \u2502 Lead Time    \u2502 \u2502 Change       \u2502   \u2502\n\u2502  \u2502 Frequency    \u2502 \u2502 Trend        \u2502 \u2502 Failure Rate \u2502   \u2502\n\u2502  \u2502 (Time Series)\u2502 \u2502 (Histogram)  \u2502 \u2502 (Gauge)      \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  MTTR Analysis (by Severity &amp; Trend)             \u2502  \u2502\n\u2502  \u2502  SEV1: 15m | SEV2: 1.5h | SEV3: 4h              \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Team Comparison (Leaderboard)                    \u2502  \u2502\n\u2502  \u2502  Team A: Elite | Team B: High | Team C: Medium  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Improvement Trends (30-day vs 90-day)           \u2502  \u2502\n\u2502  \u2502  DF: \u219115% | LT: \u219320% | CFR: \u219310% | MTTR: \u219325% \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#grafana-dashboard-json","title":"Grafana Dashboard JSON","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"DORA Metrics - Platform Performance\",\n    \"tags\": [\"dora\", \"metrics\", \"platform\"],\n    \"timezone\": \"utc\",\n    \"panels\": [\n      {\n        \"id\": 1,\n        \"title\": \"Deployment Frequency (per day)\",\n        \"type\": \"stat\",\n        \"targets\": [{\n          \"expr\": \"sum(rate(argocd_app_sync_total{phase='Succeeded'}[7d])) * 86400\",\n          \"legendFormat\": \"Deployments/Day\"\n        }],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"value\": 0, \"color\": \"red\"},\n                {\"value\": 0.1, \"color\": \"yellow\"},\n                {\"value\": 1, \"color\": \"green\"}\n              ]\n            },\n            \"mappings\": [],\n            \"unit\": \"short\"\n          }\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 0, \"y\": 0}\n      },\n      {\n        \"id\": 2,\n        \"title\": \"Lead Time for Changes (P95)\",\n        \"type\": \"stat\",\n        \"targets\": [{\n          \"expr\": \"histogram_quantile(0.95, sum(rate(deployment_lead_time_seconds_bucket[7d])) by (le)) / 3600\",\n          \"legendFormat\": \"P95 Hours\"\n        }],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"thresholds\": {\n              \"steps\": [\n                {\"value\": 0, \"color\": \"green\"},\n                {\"value\": 1, \"color\": \"yellow\"},\n                {\"value\": 24, \"color\": \"red\"}\n              ]\n            },\n            \"unit\": \"h\"\n          }\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 6, \"y\": 0}\n      },\n      {\n        \"id\": 3,\n        \"title\": \"Change Failure Rate\",\n        \"type\": \"gauge\",\n        \"targets\": [{\n          \"expr\": \"sum(rate(deployment_result{status='failed'}[7d])) / sum(rate(deployment_result[7d])) * 100\"\n        }],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"thresholds\": {\n              \"steps\": [\n                {\"value\": 0, \"color\": \"green\"},\n                {\"value\": 15, \"color\": \"yellow\"},\n                {\"value\": 30, \"color\": \"red\"}\n              ]\n            },\n            \"max\": 100,\n            \"unit\": \"percent\"\n          }\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 12, \"y\": 0}\n      },\n      {\n        \"id\": 4,\n        \"title\": \"Mean Time to Restore\",\n        \"type\": \"stat\",\n        \"targets\": [{\n          \"expr\": \"avg(incident_duration_seconds) / 60\",\n          \"legendFormat\": \"Avg Minutes\"\n        }],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"thresholds\": {\n              \"steps\": [\n                {\"value\": 0, \"color\": \"green\"},\n                {\"value\": 60, \"color\": \"yellow\"},\n                {\"value\": 1440, \"color\": \"red\"}\n              ]\n            },\n            \"unit\": \"m\"\n          }\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 18, \"y\": 0}\n      },\n      {\n        \"id\": 5,\n        \"title\": \"Deployment Frequency Trend\",\n        \"type\": \"graph\",\n        \"targets\": [{\n          \"expr\": \"sum(rate(argocd_app_sync_total{phase='Succeeded'}[1d])) by (name) * 86400\",\n          \"legendFormat\": \"{{name}}\"\n        }],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8}\n      },\n      {\n        \"id\": 6,\n        \"title\": \"Lead Time Distribution\",\n        \"type\": \"heatmap\",\n        \"targets\": [{\n          \"expr\": \"sum(increase(deployment_lead_time_seconds_bucket[1h])) by (le)\",\n          \"format\": \"heatmap\",\n          \"legendFormat\": \"{{le}}\"\n        }],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8}\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#part-4-hands-on-lab-complete-dora-implementation","title":"\ud83c\udfaf Part 4: Hands-On Lab - Complete DORA Implementation","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#objective","title":"Objective","text":"<p>Implement end-to-end DORA metrics collection and visualization for Fawkes platform.</p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#step-1-deploy-dora-metrics-collector","title":"Step 1: Deploy DORA Metrics Collector","text":"<p>Create <code>dora-collector.yaml</code>:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dora-collector\n  namespace: dojo-metrics\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dora-collector\n  template:\n    metadata:\n      labels:\n        app: dora-collector\n    spec:\n      containers:\n      - name: collector\n        image: fawkes/dora-collector:v1.0\n        ports:\n        - containerPort: 8080\n          name: http\n        - containerPort: 9090\n          name: metrics\n        env:\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: dora-db-credentials\n              key: url\n        - name: PROMETHEUS_URL\n          value: \"http://prometheus:9090\"\n        resources:\n          requests:\n            memory: \"128Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"256Mi\"\n            cpu: \"200m\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dora-collector\n  namespace: dojo-metrics\nspec:\n  selector:\n    app: dora-collector\n  ports:\n  - name: http\n    port: 80\n    targetPort: 8080\n  - name: metrics\n    port: 9090\n    targetPort: 9090\n---\napiVersion: monitoring.coreos.io/v1\nkind: ServiceMonitor\nmetadata:\n  name: dora-collector\n  namespace: dojo-metrics\nspec:\n  selector:\n    matchLabels:\n      app: dora-collector\n  endpoints:\n  - port: metrics\n    interval: 30s\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#step-2-configure-webhooks","title":"Step 2: Configure Webhooks","text":"<p>ArgoCD Webhook (for deployments):</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-notifications-cm\n  namespace: argocd\ndata:\n  service.webhook.dora: |\n    url: http://dora-collector.dojo-metrics/webhook/deploy\n    headers:\n    - name: Content-Type\n      value: application/json\n\n  trigger.on-deployed: |\n    - when: app.status.operationState.phase in ['Succeeded']\n      send: [dora-deploy-succeeded]\n    - when: app.status.operationState.phase in ['Failed']\n      send: [dora-deploy-failed]\n\n  template.dora-deploy-succeeded: |\n    webhook:\n      dora:\n        method: POST\n        body: |\n          {\n            \"event\": \"deployment\",\n            \"status\": \"success\",\n            \"app\": \"{{.app.metadata.name}}\",\n            \"revision\": \"{{.app.status.sync.revision}}\",\n            \"timestamp\": \"{{.app.status.operationState.finishedAt}}\"\n          }\n\n  template.dora-deploy-failed: |\n    webhook:\n      dora:\n        method: POST\n        body: |\n          {\n            \"event\": \"deployment\",\n            \"status\": \"failed\",\n            \"app\": \"{{.app.metadata.name}}\",\n            \"revision\": \"{{.app.status.sync.revision}}\",\n            \"timestamp\": \"{{.app.status.operationState.finishedAt}}\"\n          }\n</code></pre> <p>Git Webhook (for commits):</p> <pre><code># Add webhook to GitHub repository\ncurl -X POST \\\n  -H \"Authorization: token ${GITHUB_TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  https://api.github.com/repos/myorg/myapp/hooks \\\n  -d '{\n    \"name\": \"web\",\n    \"active\": true,\n    \"events\": [\"push\"],\n    \"config\": {\n      \"url\": \"https://dora-collector.fawkes.io/webhook/commit\",\n      \"content_type\": \"json\"\n    }\n  }'\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#step-3-create-grafana-dashboard","title":"Step 3: Create Grafana Dashboard","text":"<pre><code># Import dashboard via API\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer ${GRAFANA_API_KEY}\" \\\n  http://grafana:3000/api/dashboards/db \\\n  -d @dora-dashboard.json\n\n# Or import via UI:\n# Grafana \u2192 Dashboards \u2192 Import \u2192 Upload dora-dashboard.json\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#step-4-validate-data-collection","title":"Step 4: Validate Data Collection","text":"<pre><code># Check if metrics are being collected\nkubectl port-forward -n dojo-metrics svc/dora-collector 9090:9090\n\n# Query Prometheus\ncurl \"http://localhost:9090/metrics\" | grep deployment\n\n# Expected output:\n# deployment_frequency_total{app=\"myapp\"} 150\n# deployment_lead_time_seconds_sum{app=\"myapp\"} 450000\n# deployment_lead_time_seconds_count{app=\"myapp\"} 150\n# deployment_result{app=\"myapp\",status=\"success\"} 142\n# deployment_result{app=\"myapp\",status=\"failed\"} 8\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#step-5-analyze-your-metrics","title":"Step 5: Analyze Your Metrics","text":"<p>Access Grafana dashboard and analyze:</p> <ol> <li>Deployment Frequency: Are you deploying daily? Multiple times per day?</li> <li>Lead Time: What's your P95? Where are the bottlenecks?</li> <li>CFR: Which deployments are failing? Common patterns?</li> <li>MTTR: How quickly do you recover? Can you automate more?</li> </ol>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#part-5-advanced-analysis-techniques","title":"\ud83d\udcc8 Part 5: Advanced Analysis Techniques","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#trend-analysis","title":"Trend Analysis","text":"<p>Week-over-week comparison: <pre><code># Current week deployment frequency\nsum(rate(argocd_app_sync_total{phase=\"Succeeded\"}[7d])) * 86400\n\n# Previous week\nsum(rate(argocd_app_sync_total{phase=\"Succeeded\"}[7d] offset 7d)) * 86400\n\n# % change\n(\n  sum(rate(argocd_app_sync_total{phase=\"Succeeded\"}[7d]))\n  -\n  sum(rate(argocd_app_sync_total{phase=\"Succeeded\"}[7d] offset 7d))\n)\n/\nsum(rate(argocd_app_sync_total{phase=\"Succeeded\"}[7d] offset 7d))\n* 100\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#correlation-analysis","title":"Correlation Analysis","text":"<p>Does higher deployment frequency correlate with lower CFR?</p> <pre><code>import pandas as pd\nfrom scipy.stats import pearsonr\n\n# Fetch data\ndf = pd.DataFrame({\n    'team': teams,\n    'deployment_freq': [get_deployment_freq(t) for t in teams],\n    'cfr': [get_cfr(t) for t in teams]\n})\n\n# Calculate correlation\ncorrelation, p_value = pearsonr(df['deployment_freq'], df['cfr'])\n\nprint(f\"Correlation: {correlation:.2f}\")\nprint(f\"P-value: {p_value:.4f}\")\n\n# Expected: Negative correlation (higher DF \u2192 lower CFR)\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#identifying-bottlenecks","title":"Identifying Bottlenecks","text":"<p>Lead time breakdown: <pre><code># Time in each stage\nsum(ci_stage_duration_seconds{stage=\"build\"}) by (app)\nsum(ci_stage_duration_seconds{stage=\"test\"}) by (app)\nsum(ci_stage_duration_seconds{stage=\"scan\"}) by (app)\nsum(ci_stage_duration_seconds{stage=\"deploy\"}) by (app)\n</code></pre></p> <p>Create waterfall chart to visualize: <pre><code>Commit \u2192 Build (3m) \u2192 Test (5m) \u2192 Scan (2m) \u2192 Deploy (1m) = 11m total\n         \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2588\u2588\u2588\u2588        \u2588\u2588\n\nBottleneck: Testing takes 45% of lead time\nAction: Parallelize tests or optimize slow tests\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#part-6-driving-improvements-with-data","title":"\ud83d\udcaa Part 6: Driving Improvements with Data","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#improvement-framework","title":"Improvement Framework","text":"<p>1. Measure Current State <pre><code>Current Performance (Last 30 days):\n- DF: 3 per day (High)\n- LT: 2 hours (High)\n- CFR: 12% (Elite)\n- MTTR: 45 minutes (Elite)\n\nOverall: High Performer\n</code></pre></p> <p>2. Set Targets <pre><code>3-Month Goals:\n- DF: 5 per day (Elite) - \u219167%\n- LT: 1 hour (Elite) - \u219350%\n- CFR: &lt;10% (Elite) - \u219317%\n- MTTR: &lt;30 min (Elite) - \u219333%\n</code></pre></p> <p>3. Identify Bottlenecks <pre><code>Lead Time Breakdown:\n- Code Review: 45 min (38%)\n- CI Build: 15 min (13%)\n- Testing: 35 min (29%)\n- Deployment: 25 min (21%)\n\nBiggest opportunity: Code Review (38% of lead time)\n</code></pre></p> <p>4. Implement Changes <pre><code>Actions:\n1. Reduce PR size (enforce &lt;300 lines)\n2. Pair programming for complex changes (faster review)\n3. Async code review tools (remove scheduling overhead)\n4. Auto-approve trivial changes (docs, formatting)\n\nExpected Impact: Reduce code review time by 50% (22min savings)\nNew Lead Time: 1h 5min \u2192 Target not quite met, but significant progress\n</code></pre></p> <p>5. Measure Impact <pre><code>After 30 days:\n- DF: 4.5 per day \u2705 (On track)\n- LT: 1h 15min \u26a0\ufe0f (Close to target)\n- CFR: 9% \u2705 (Target met!)\n- MTTR: 28 min \u2705 (Target exceeded!)\n\nContinue iteration...\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#part-7-knowledge-check","title":"\ud83c\udf93 Part 7: Knowledge Check","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#quiz-questions","title":"Quiz Questions","text":"<ol> <li>What does P95 lead time represent?</li> <li>[ ] Average lead time</li> <li>[ ] Fastest lead time</li> <li>[x] 95% of deployments complete within this time</li> <li> <p>[ ] Slowest lead time</p> </li> <li> <p>How do you calculate Change Failure Rate?</p> </li> <li>[ ] Failed deployments \u00d7 100</li> <li>[x] (Failed deployments / Total deployments) \u00d7 100</li> <li>[ ] Total deployments / Failed deployments</li> <li> <p>[ ] Failed deployments / Successful deployments</p> </li> <li> <p>What's the Elite benchmark for Deployment Frequency?</p> </li> <li>[ ] Once per week</li> <li>[ ] Once per day</li> <li>[x] Multiple times per day</li> <li> <p>[ ] Continuous deployment</p> </li> <li> <p>What should MTTR measure?</p> </li> <li>[ ] Time to write code</li> <li>[ ] Time to test</li> <li>[x] Time to restore service after incident</li> <li> <p>[ ] Time to deploy</p> </li> <li> <p>Why track team-level DORA metrics separately?</p> </li> <li>[ ] To rank teams</li> <li>[x] To identify improvement opportunities specific to each team</li> <li>[ ] To punish low performers</li> <li> <p>[ ] It's not necessary</p> </li> <li> <p>What does high DF + low CFR indicate?</p> </li> <li>[ ] Luck</li> <li>[x] Mature CI/CD with good quality gates</li> <li>[ ] Metrics are broken</li> <li> <p>[ ] Too much testing</p> </li> <li> <p>How often should you review DORA metrics?</p> </li> <li>[ ] Annually</li> <li>[ ] When problems occur</li> <li>[x] Weekly or monthly for trends</li> <li> <p>[ ] Once after implementation</p> </li> <li> <p>What's a good first step to improve lead time?</p> </li> <li>[ ] Skip testing</li> <li>[ ] Deploy less frequently</li> <li>[x] Identify and optimize the slowest stage</li> <li>[ ] Hire more people</li> </ol> <p>Answers: 1-C, 2-B, 3-C, 4-C, 5-B, 6-B, 7-C, 8-C</p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#part-8-module-summary-next-steps","title":"\ud83c\udfaf Part 8: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#what-you-learned","title":"What You Learned","text":"<p>\u2705 Advanced Calculation: All 4 metrics with distributions \u2705 Data Collection: Webhooks, Prometheus, automation \u2705 Dashboards: Comprehensive Grafana visualizations \u2705 Analysis: Trends, correlations, bottlenecks \u2705 Improvement: Data-driven optimization framework \u2705 Presentation: Communicate metrics to leadership</p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#dora-capabilities-achieved","title":"DORA Capabilities Achieved","text":"<ul> <li>\u2705 All 4 Key Metrics: Automated collection and tracking</li> <li>\u2705 Monitoring: Real-time visibility into delivery performance</li> <li>\u2705 Data-Driven: Metrics inform platform improvements</li> </ul>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Metrics must be actionable - If you can't improve it, don't measure it</li> <li>Track distributions, not just averages - P95/P99 reveal user experience</li> <li>Compare teams carefully - Context matters (legacy vs greenfield)</li> <li>Automate collection - Manual tracking doesn't scale</li> <li>Review regularly - Weekly trends reveal improvement opportunities</li> </ol>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#real-world-impact","title":"Real-World Impact","text":"<p>\"After implementing comprehensive DORA tracking: - Identified bottleneck: Code review was 40% of lead time - Action: Reduced PR size, added auto-approval for trivial changes - Result: Lead time decreased 35% in 60 days - Visibility: Leadership now tracks metrics quarterly - Culture: Teams compete (healthily) to improve metrics</p> <p>Metrics transformed from vanity to value.\" - Engineering Director, Tech Company</p>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#tools","title":"Tools","text":"<ul> <li>Four Keys - DORA metrics collection</li> <li>Sleuth - DORA tracking SaaS</li> <li>LinearB - Engineering intelligence</li> </ul>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#reading","title":"Reading","text":"<ul> <li>DORA State of DevOps Reports</li> <li>Accelerate - The research behind DORA</li> <li>DORA Metrics Guide</li> </ul>"},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#module-completion","title":"\ud83c\udfc5 Module Completion","text":""},{"location":"dojo/modules/brown-belt/module-14-dora-deep-dive/#assessment-checklist","title":"Assessment Checklist","text":"<ul> <li>[ ] Conceptual Understanding</li> <li>[ ] Calculate all 4 metrics correctly</li> <li>[ ] Understand P50/P95/P99 distributions</li> <li> <p>[ ] Explain metric correlations</p> </li> <li> <p>[ ] Practical Skills</p> </li> <li>[ ] Deploy DORA collector</li> <li>[ ] Configure webhooks</li> <li>[ ] Build Grafana dashboard</li> <li>[ ] Analyze trends   -</li> </ul>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/","title":"Fawkes Dojo Module 15: SLIs, SLOs, and Error Budgets","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe4 Brown Belt - Observability &amp; SRE Module: 3 of 4 (Brown Belt) Duration: 60 minutes Difficulty: Advanced Prerequisites: - Module 13: Observability complete - Module 14: DORA Metrics Deep Dive complete - Understanding of Prometheus and monitoring - Basic statistics knowledge (percentiles, averages)</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Define Service Level Indicators (SLIs) for your services</li> <li>\u2705 Create meaningful Service Level Objectives (SLOs)</li> <li>\u2705 Calculate and track error budgets</li> <li>\u2705 Implement SLI/SLO monitoring in Prometheus</li> <li>\u2705 Balance innovation velocity with reliability</li> <li>\u2705 Make data-driven decisions about service reliability</li> <li>\u2705 Communicate service health to stakeholders</li> </ol> <p>DORA Capabilities Addressed: - \u2713 Monitoring and Observability - \u2713 Service Reliability - \u2713 Data-Driven Decision Making - \u2713 Customer Focus</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-1-the-reliability-framework","title":"\ud83d\udcd6 Part 1: The Reliability Framework","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#why-slisslos-matter","title":"Why SLIs/SLOs Matter","text":"<p>Without SLIs/SLOs: <pre><code>Team: \"Our service is pretty reliable\"\nCustomer: \"It's been down twice this week!\"\nPM: \"Can we deploy this risky feature?\"\nOps: \"I don't know, maybe?\"\n\nResult:\n- No shared understanding of reliability\n- Arbitrary decisions about risk\n- Customer dissatisfaction\n- Team stress and conflict\n</code></pre></p> <p>With SLIs/SLOs: <pre><code>Team: \"We have 99.9% availability (SLO) and we're at 99.95%\"\nCustomer: \"Within SLO, acceptable\"\nPM: \"We have error budget remaining, let's deploy\"\nOps: \"Budget shows we can tolerate this risk\"\n\nResult:\n- Shared language for reliability\n- Data-driven risk decisions\n- Customer expectations managed\n- Team alignment\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#the-sre-hierarchy","title":"The SRE Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     User Happiness (Ultimate Goal)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Service Level Indicators (SLIs)   \u2502\n\u2502   What we measure (metrics)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Service Level Objectives (SLOs)    \u2502\n\u2502  Targets for SLIs (promises)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       Error Budget                   \u2502\n\u2502  Allowed unreliability (innovation)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-2-service-level-indicators-slis","title":"\ud83c\udfaf Part 2: Service Level Indicators (SLIs)","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#what-is-an-sli","title":"What is an SLI?","text":"<p>SLI: A carefully selected metric that represents user happiness</p> <p>Good SLI characteristics: - \u2705 User-centric (measures what users care about) - \u2705 Measurable (can be quantified) - \u2705 Actionable (team can improve it) - \u2705 Aggregatable (can combine across services)</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#common-sli-types","title":"Common SLI Types","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#1-availability-uptime","title":"1. Availability (Uptime)","text":"<p>Definition: Proportion of time service is operational</p> <pre><code># Availability SLI\nsum(up{service=\"myapp\"}) / count(up{service=\"myapp\"}) * 100\n\n# Example: 99.5% availability\n</code></pre> <p>User impact: \"Can I access the service?\"</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#2-latency-speed","title":"2. Latency (Speed)","text":"<p>Definition: Time to respond to requests</p> <pre><code># Latency SLI (p95)\nhistogram_quantile(0.95,\n  sum(rate(http_request_duration_seconds_bucket{service=\"myapp\"}[5m])) by (le)\n)\n\n# Example: p95 &lt; 200ms\n</code></pre> <p>User impact: \"How fast does it respond?\"</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#3-error-rate-correctness","title":"3. Error Rate (Correctness)","text":"<p>Definition: Proportion of requests that fail</p> <pre><code># Error rate SLI\nsum(rate(http_requests_total{service=\"myapp\",status=~\"5..\"}[5m]))\n/\nsum(rate(http_requests_total{service=\"myapp\"}[5m]))\n* 100\n\n# Example: 0.1% error rate\n</code></pre> <p>User impact: \"Does it work correctly?\"</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#4-throughput-capacity","title":"4. Throughput (Capacity)","text":"<p>Definition: Requests handled per unit time</p> <pre><code># Throughput SLI\nsum(rate(http_requests_total{service=\"myapp\"}[5m]))\n\n# Example: 1000 req/s\n</code></pre> <p>User impact: \"Can it handle my load?\"</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#5-durability-data-safety","title":"5. Durability (Data Safety)","text":"<p>Definition: Proportion of data successfully stored/retrieved</p> <pre><code># Durability SLI\nsum(successful_writes) / sum(total_writes) * 100\n\n# Example: 99.999% durability\n</code></pre> <p>User impact: \"Is my data safe?\"</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#selecting-slis-for-your-service","title":"Selecting SLIs for Your Service","text":"<p>Step 1: Identify User Journeys</p> <p>Example: E-commerce checkout</p> <pre><code>User Journey: Purchase Product\n1. Browse catalog\n2. Add to cart\n3. Enter payment\n4. Complete purchase\n5. Receive confirmation\n</code></pre> <p>Step 2: Map to SLIs</p> Journey Step SLI Target Why It Matters Browse catalog Latency p95 &lt; 300ms Slow browsing = abandoned Add to cart Availability 99.9% Can't shop if cart broken Enter payment Error rate &lt; 0.1% Payment errors = lost sales Complete purchase Latency p99 &lt; 1s Checkout must be fast Receive confirmation Availability 99.99% Legal requirement <p>Step 3: Prioritize</p> <p>Focus on 3-5 most critical SLIs: 1. Checkout error rate (revenue impact) 2. Checkout latency (abandonment risk) 3. Catalog availability (engagement)</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-3-service-level-objectives-slos","title":"\ud83d\udcca Part 3: Service Level Objectives (SLOs)","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#what-is-an-slo","title":"What is an SLO?","text":"<p>SLO: A target value or range for an SLI over a time window</p> <p>Format: <code>SLI \u2265 Target over Time Window</code></p> <p>Examples: - Availability \u2265 99.9% over 30 days - p95 latency \u2264 200ms over 7 days - Error rate &lt; 0.5% over 30 days</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#setting-good-slos","title":"Setting Good SLOs","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#rule-1-align-with-user-expectations","title":"Rule 1: Align with User Expectations","text":"<p>Bad: \"5 nines (99.999%) because we're perfectionists\" Good: \"99.9% because user research shows this meets needs\"</p> <p>User tolerance varies by context: - Search engine: p95 &lt; 100ms (users expect instant) - Banking transfer: p95 &lt; 2s (users tolerate some delay) - Batch report: p95 &lt; 30s (users expect processing time)</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#rule-2-start-conservative-tighten-over-time","title":"Rule 2: Start Conservative, Tighten Over Time","text":"<p>Initial SLO: 99.5% availability - Monitor for 3 months - Actual: 99.7% - Tighten: 99.6% (between actual and previous)</p> <p>Why: Easier to exceed SLO and tighten than miss and relax</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#rule-3-fewer-is-better","title":"Rule 3: Fewer is Better","text":"<p>Bad: 15 SLOs for one service Good: 3-5 SLOs that matter most</p> <p>Example: <pre><code>Service: Payment API\nSLOs:\n1. Availability \u2265 99.95% (30 days)\n2. p95 latency \u2264 500ms (7 days)\n3. Error rate &lt; 0.1% (30 days)\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#rule-4-document-your-slos","title":"Rule 4: Document Your SLOs","text":"<pre><code># slo-definition.yaml\nservice: payment-api\nslos:\n  - name: availability\n    description: \"Proportion of successful requests\"\n    type: availability\n    target: 99.95\n    window: 30d\n    sli: |\n      sum(http_requests_total{status!~\"5..\"})\n      / sum(http_requests_total) * 100\n\n  - name: latency\n    description: \"95th percentile response time\"\n    type: latency\n    target: 500ms\n    window: 7d\n    sli: |\n      histogram_quantile(0.95,\n        sum(rate(http_duration_bucket[5m])) by (le)\n      )\n\n  - name: error_rate\n    description: \"Proportion of failed requests\"\n    type: error_rate\n    target: 0.1\n    window: 30d\n    sli: |\n      sum(rate(http_requests_total{status=~\"5..\"}[5m]))\n      / sum(rate(http_requests_total[5m])) * 100\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#multi-window-slos","title":"Multi-Window SLOs","text":"<p>Track SLOs over different time windows:</p> <pre><code>Service: API\nSLO: 99.9% availability\n\nWindows:\n- 1 hour:  99.99% \u2705 (shorter window, stricter)\n- 1 day:   99.95% \u2705\n- 7 days:  99.92% \u2705\n- 30 days: 99.91% \u2705 (meets SLO)\n</code></pre> <p>Benefit: Early warning system - Hour/day violations = potential trend - 30-day still met = no customer impact yet</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-4-error-budgets","title":"\ud83d\udcb0 Part 4: Error Budgets","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#what-is-an-error-budget","title":"What is an Error Budget?","text":"<p>Error Budget: Allowed unreliability based on SLO</p> <p>Formula: <code>Error Budget = 100% - SLO</code></p> <p>Example: <pre><code>SLO: 99.9% availability\nError Budget: 0.1% (100% - 99.9%)\n\nIn a 30-day month:\n- Total time: 30 days = 43,200 minutes\n- Error budget: 0.1% \u00d7 43,200 = 43.2 minutes\n- Allowed downtime: ~43 minutes per month\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#error-budget-as-currency","title":"Error Budget as Currency","text":"<p>Think of error budget as innovation currency:</p> <pre><code>Monthly Error Budget: 43 minutes\n\nSpent on:\n- Planned maintenance: 10 minutes\n- Feature deploy issues: 15 minutes\n- Infrastructure failure: 8 minutes\n- Security patching: 5 minutes\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal spent: 38 minutes\nRemaining: 5 minutes (healthy) \u2705\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#burn-rate","title":"Burn Rate","text":"<p>Burn Rate: How fast you're consuming error budget</p> <p>Formula: <code>Burn Rate = (Error Rate / Error Budget) \u00d7 Time Window</code></p> <p>Example: <pre><code>Current error rate: 0.5%\nError budget: 0.1%\nBurn rate: 0.5% / 0.1% = 5x\n\nAt this rate:\n- 30-day budget consumed in 6 days\n- Action required! \ud83d\udea8\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#error-budget-policies","title":"Error Budget Policies","text":"<p>Define policies for budget exhaustion:</p> <pre><code>error_budget_policy:\n  - condition: \"50% remaining\"\n    action: \"Continue normal operations\"\n\n  - condition: \"25% remaining\"\n    action:\n      - \"Freeze non-critical feature deploys\"\n      - \"Increase monitoring\"\n      - \"Review recent changes\"\n\n  - condition: \"10% remaining\"\n    action:\n      - \"Freeze ALL feature deploys\"\n      - \"Focus on reliability improvements\"\n      - \"Daily team review\"\n      - \"Incident commander assigned\"\n\n  - condition: \"0% remaining (exhausted)\"\n    action:\n      - \"Complete deploy freeze\"\n      - \"Root cause analysis required\"\n      - \"Reliability sprint\"\n      - \"Executive notification\"\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-5-hands-on-lab-implementing-slisslos","title":"\ud83d\udee0\ufe0f Part 5: Hands-On Lab - Implementing SLIs/SLOs","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#step-1-define-slis","title":"Step 1: Define SLIs","text":"<p>Create <code>sli-definitions.yaml</code>:</p> <pre><code># Service: payment-api\nslis:\n  # Availability SLI\n  - name: availability\n    description: \"Percentage of successful HTTP requests\"\n    query: |\n      sum(rate(http_requests_total{service=\"payment-api\",status!~\"5..\"}[5m]))\n      /\n      sum(rate(http_requests_total{service=\"payment-api\"}[5m]))\n      * 100\n    unit: percent\n\n  # Latency SLI (p95)\n  - name: latency_p95\n    description: \"95th percentile HTTP request duration\"\n    query: |\n      histogram_quantile(0.95,\n        sum(rate(http_request_duration_seconds_bucket{service=\"payment-api\"}[5m])) by (le)\n      ) * 1000\n    unit: milliseconds\n\n  # Latency SLI (p99)\n  - name: latency_p99\n    description: \"99th percentile HTTP request duration\"\n    query: |\n      histogram_quantile(0.99,\n        sum(rate(http_request_duration_seconds_bucket{service=\"payment-api\"}[5m])) by (le)\n      ) * 1000\n    unit: milliseconds\n\n  # Error Rate SLI\n  - name: error_rate\n    description: \"Percentage of failed HTTP requests\"\n    query: |\n      sum(rate(http_requests_total{service=\"payment-api\",status=~\"5..\"}[5m]))\n      /\n      sum(rate(http_requests_total{service=\"payment-api\"}[5m]))\n      * 100\n    unit: percent\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#step-2-define-slos","title":"Step 2: Define SLOs","text":"<p>Create <code>slo-definitions.yaml</code>:</p> <pre><code># Service: payment-api\nslos:\n  # Availability SLO\n  - name: availability_slo\n    sli: availability\n    objective: 99.9\n    window: 30d\n    description: \"Service available 99.9% of the time over 30 days\"\n    alert_threshold: 99.8  # Alert when approaching SLO breach\n\n  # Latency SLO (p95)\n  - name: latency_p95_slo\n    sli: latency_p95\n    objective: 500  # milliseconds\n    window: 7d\n    description: \"95% of requests complete within 500ms over 7 days\"\n    alert_threshold: 600\n\n  # Error Rate SLO\n  - name: error_rate_slo\n    sli: error_rate\n    objective: 0.1  # 0.1% error rate\n    window: 30d\n    description: \"Error rate below 0.1% over 30 days\"\n    alert_threshold: 0.15\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#step-3-calculate-error-budget","title":"Step 3: Calculate Error Budget","text":"<p>Create <code>error-budget-calculator.yaml</code>:</p> <pre><code># Prometheus recording rules for error budget\ngroups:\n  - name: error_budget\n    interval: 1m\n    rules:\n      # Availability error budget\n      - record: error_budget:availability:remaining_percent\n        expr: |\n          (\n            100 -\n            (\n              (100 - slo:availability:30d) -\n              (100 - sli:availability:30d)\n            ) / (100 - slo:availability:30d) * 100\n          )\n\n      # Availability error budget consumed\n      - record: error_budget:availability:consumed_percent\n        expr: |\n          100 - error_budget:availability:remaining_percent\n\n      # Availability burn rate (1 hour)\n      - record: error_budget:availability:burn_rate_1h\n        expr: |\n          (100 - sli:availability:1h) / (100 - slo:availability:30d)\n\n      # Availability burn rate (6 hours)\n      - record: error_budget:availability:burn_rate_6h\n        expr: |\n          (100 - sli:availability:6h) / (100 - slo:availability:30d)\n\n      # Error rate error budget\n      - record: error_budget:error_rate:remaining_percent\n        expr: |\n          (\n            1 - (sli:error_rate:30d / slo:error_rate:30d)\n          ) * 100\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#step-4-create-prometheus-recording-rules","title":"Step 4: Create Prometheus Recording Rules","text":"<p>Create <code>prometheus-rules.yaml</code>:</p> <pre><code>groups:\n  - name: sli_recording\n    interval: 30s\n    rules:\n      # Availability SLI (real-time)\n      - record: sli:availability:current\n        expr: |\n          sum(rate(http_requests_total{service=\"payment-api\",status!~\"5..\"}[1m]))\n          /\n          sum(rate(http_requests_total{service=\"payment-api\"}[1m]))\n          * 100\n\n      # Availability SLI (1 hour)\n      - record: sli:availability:1h\n        expr: |\n          sum(rate(http_requests_total{service=\"payment-api\",status!~\"5..\"}[1h]))\n          /\n          sum(rate(http_requests_total{service=\"payment-api\"}[1h]))\n          * 100\n\n      # Availability SLI (30 days)\n      - record: sli:availability:30d\n        expr: |\n          sum(rate(http_requests_total{service=\"payment-api\",status!~\"5..\"}[30d]))\n          /\n          sum(rate(http_requests_total{service=\"payment-api\"}[30d]))\n          * 100\n\n      # Error rate SLI (30 days)\n      - record: sli:error_rate:30d\n        expr: |\n          sum(rate(http_requests_total{service=\"payment-api\",status=~\"5..\"}[30d]))\n          /\n          sum(rate(http_requests_total{service=\"payment-api\"}[30d]))\n          * 100\n\n      # Latency p95 SLI (7 days)\n      - record: sli:latency_p95:7d\n        expr: |\n          histogram_quantile(0.95,\n            sum(rate(http_request_duration_seconds_bucket{service=\"payment-api\"}[7d])) by (le)\n          ) * 1000\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#step-5-implement-slo-alerts","title":"Step 5: Implement SLO Alerts","text":"<p>Create <code>slo-alerts.yaml</code>:</p> <pre><code>groups:\n  - name: slo_alerts\n    rules:\n      # Fast burn alert (1 hour window)\n      - alert: ErrorBudgetBurnRateCritical\n        expr: |\n          error_budget:availability:burn_rate_1h &gt; 14.4\n          and\n          error_budget:availability:burn_rate_6h &gt; 6\n        for: 5m\n        labels:\n          severity: critical\n          slo: availability\n        annotations:\n          summary: \"Critical burn rate - will exhaust budget in 2 days\"\n          description: \"Error budget burning at {{ $value }}x normal rate\"\n\n      # Medium burn alert (6 hour window)\n      - alert: ErrorBudgetBurnRateHigh\n        expr: |\n          error_budget:availability:burn_rate_6h &gt; 6\n          and\n          error_budget:availability:remaining_percent &lt; 50\n        for: 30m\n        labels:\n          severity: warning\n          slo: availability\n        annotations:\n          summary: \"High burn rate with low remaining budget\"\n          description: \"{{ $value }}% budget remaining, burning fast\"\n\n      # Budget exhausted\n      - alert: ErrorBudgetExhausted\n        expr: |\n          error_budget:availability:remaining_percent &lt;= 0\n        for: 5m\n        labels:\n          severity: critical\n          slo: availability\n        annotations:\n          summary: \"Error budget completely exhausted\"\n          description: \"Deploy freeze in effect per error budget policy\"\n\n      # SLO approaching breach\n      - alert: SLOApproachingBreach\n        expr: |\n          sli:availability:30d &lt; 99.8  # 0.1% below SLO of 99.9%\n        for: 1h\n        labels:\n          severity: warning\n          slo: availability\n        annotations:\n          summary: \"Availability SLO approaching breach\"\n          description: \"Current: {{ $value }}%, SLO: 99.9%\"\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#step-6-create-grafana-dashboard","title":"Step 6: Create Grafana Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"SLO Dashboard - Payment API\",\n    \"panels\": [\n      {\n        \"title\": \"Availability SLO Status\",\n        \"type\": \"gauge\",\n        \"targets\": [{\n          \"expr\": \"sli:availability:30d\"\n        }],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"thresholds\": {\n              \"steps\": [\n                {\"value\": 0, \"color\": \"red\"},\n                {\"value\": 99.8, \"color\": \"yellow\"},\n                {\"value\": 99.9, \"color\": \"green\"}\n              ]\n            },\n            \"min\": 99,\n            \"max\": 100,\n            \"unit\": \"percent\"\n          }\n        }\n      },\n      {\n        \"title\": \"Error Budget Remaining\",\n        \"type\": \"graph\",\n        \"targets\": [{\n          \"expr\": \"error_budget:availability:remaining_percent\",\n          \"legendFormat\": \"Remaining\"\n        }, {\n          \"expr\": \"error_budget:availability:consumed_percent\",\n          \"legendFormat\": \"Consumed\"\n        }]\n      },\n      {\n        \"title\": \"Burn Rate (Last Hour)\",\n        \"type\": \"stat\",\n        \"targets\": [{\n          \"expr\": \"error_budget:availability:burn_rate_1h\"\n        }],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"thresholds\": {\n              \"steps\": [\n                {\"value\": 0, \"color\": \"green\"},\n                {\"value\": 5, \"color\": \"yellow\"},\n                {\"value\": 10, \"color\": \"red\"}\n              ]\n            }\n          }\n        }\n      },\n      {\n        \"title\": \"SLI vs SLO (30 days)\",\n        \"type\": \"timeseries\",\n        \"targets\": [{\n          \"expr\": \"sli:availability:30d\",\n          \"legendFormat\": \"Actual\"\n        }, {\n          \"expr\": \"99.9\",\n          \"legendFormat\": \"SLO (99.9%)\"\n        }]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-6-advanced-error-budget-management","title":"\ud83d\udcc8 Part 6: Advanced Error Budget Management","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#multi-service-error-budgets","title":"Multi-Service Error Budgets","text":"<p>Aggregate error budgets across microservices:</p> <pre><code># Overall platform error budget\navg(error_budget:availability:remaining_percent{service=~\".*-api\"})\n\n# Worst performing service\nbottomk(1, error_budget:availability:remaining_percent)\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#error-budget-attribution","title":"Error Budget Attribution","text":"<p>Track what consumed your budget:</p> <pre><code># Error budget breakdown\nerror_budget_consumption:\n  total_consumed: 35%\n  breakdown:\n    - cause: \"Database outage\"\n      percentage: 20%\n      duration: \"15 minutes\"\n      date: \"2025-10-01\"\n\n    - cause: \"Bad deployment (v2.1.0)\"\n      percentage: 10%\n      duration: \"8 minutes\"\n      date: \"2025-10-08\"\n\n    - cause: \"DDoS attack\"\n      percentage: 5%\n      duration: \"4 minutes\"\n      date: \"2025-10-12\"\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#error-budget-forecasting","title":"Error Budget Forecasting","text":"<p>Predict when budget will exhaust:</p> <pre><code># Simple linear forecast\ndef forecast_budget_exhaustion(current_burn_rate, remaining_budget):\n    \"\"\"\n    Predict days until error budget exhausted\n\n    Args:\n        current_burn_rate: Current burn rate (multiplier)\n        remaining_budget: Remaining budget (percentage)\n\n    Returns:\n        Days until exhaustion\n    \"\"\"\n    if current_burn_rate &lt;= 0:\n        return float('inf')  # Never exhausts\n\n    # Days in 30-day window\n    days_in_window = 30\n\n    # Expected daily budget consumption at 1x burn rate\n    daily_budget = 100 / days_in_window\n\n    # Actual daily consumption at current burn rate\n    actual_daily = daily_budget * current_burn_rate\n\n    # Days until exhaustion\n    days_remaining = remaining_budget / actual_daily\n\n    return days_remaining\n\n# Example\nburn_rate = 5  # 5x normal\nremaining = 30  # 30% budget left\n\ndays = forecast_budget_exhaustion(burn_rate, remaining)\nprint(f\"Budget exhausted in {days:.1f} days\")\n# Output: Budget exhausted in 1.8 days\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-7-slo-driven-decision-making","title":"\ud83d\udca1 Part 7: SLO-Driven Decision Making","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#scenario-1-should-we-deploy-this-feature","title":"Scenario 1: Should We Deploy This Feature?","text":"<pre><code>Feature: New payment method integration\nRisk: Medium (touches critical path)\nError Budget Remaining: 60%\n\nDecision Framework:\n1. Check error budget: 60% &gt; 25% \u2705\n2. Review recent burn rate: 1.2x (normal) \u2705\n3. Check deployment time: Off-peak hours \u2705\n4. Rollback plan: Yes \u2705\n\nDecision: DEPLOY\nRationale: Sufficient budget, normal burn rate, low-risk timing\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#scenario-2-should-we-continue-this-deployment","title":"Scenario 2: Should We Continue This Deployment?","text":"<pre><code>Feature: UI redesign (v3.0)\nDeployed: 30 minutes ago\nError Budget Remaining: 15% (was 40%)\nBurn Rate: 25x (critical)\n\nDecision Framework:\n1. Budget consumption: 25% in 30 min \ud83d\udea8\n2. Projected exhaustion: &lt;2 hours \ud83d\udea8\n3. User impact: High (errors visible) \ud83d\udea8\n4. Rollback available: Yes \u2705\n\nDecision: IMMEDIATE ROLLBACK\nRationale: Critical burn rate will exhaust budget\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#scenario-3-should-we-focus-on-reliability","title":"Scenario 3: Should We Focus on Reliability?","text":"<pre><code>Current State:\n- Error Budget: 5% remaining\n- Days left in window: 10 days\n- Recent deploys: 8 feature releases\n- Incidents: 3 in last week\n\nDecision Framework:\n1. Budget health: Critical (&lt;10%) \ud83d\udea8\n2. Trend: Worsening (3 incidents/week) \ud83d\udea8\n3. Time remaining: 33% of window left\n4. Feature pressure: High demand from PM\n\nDecision: RELIABILITY SPRINT\nActions:\n- Freeze feature deploys for 10 days\n- Focus team on reliability improvements\n- Daily review of metrics\n- Root cause analysis for incidents\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-8-practical-exercise","title":"\ud83c\udfaf Part 8: Practical Exercise","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#exercise-complete-slo-implementation","title":"Exercise: Complete SLO Implementation","text":"<p>Objective: Implement full SLI/SLO/Error Budget system for a service</p> <p>Scenario: You manage an API service that handles user authentication</p> <p>Requirements:</p> <ol> <li>Define 3 SLIs</li> <li>Availability</li> <li>Latency (p95 and p99)</li> <li> <p>Error rate</p> </li> <li> <p>Set SLOs</p> </li> <li>Based on user requirements</li> <li>Document reasoning</li> <li> <p>Include alert thresholds</p> </li> <li> <p>Calculate Error Budgets</p> </li> <li>Convert SLOs to error budgets</li> <li>Define burn rate alerts</li> <li> <p>Create exhaustion policies</p> </li> <li> <p>Implement Monitoring</p> </li> <li>Prometheus recording rules</li> <li>AlertManager rules</li> <li> <p>Grafana dashboard</p> </li> <li> <p>Document Decision Framework</p> </li> <li>When to deploy</li> <li>When to rollback</li> <li>When to freeze deploys</li> </ol> <p>Starter Template:</p> <pre><code># slo-config.yaml\nservice: auth-api\ndescription: \"User authentication service\"\n\nslis:\n  - name: availability\n    # TODO: Define SLI query\n\n  - name: latency_p95\n    # TODO: Define SLI query\n\n  - name: error_rate\n    # TODO: Define SLI query\n\nslos:\n  - name: availability_slo\n    sli: availability\n    objective: ???  # TODO: Set target\n    window: 30d\n    reasoning: \"???\"  # TODO: Document why\n\n  # TODO: Add latency and error rate SLOs\n\nerror_budget_policy:\n  # TODO: Define policies for budget consumption\n</code></pre> <p>Validation Criteria: - [ ] 3 SLIs defined with Prometheus queries - [ ] 3 SLOs set with clear reasoning - [ ] Error budgets calculated correctly - [ ] Recording rules implemented - [ ] Alert rules configured - [ ] Dashboard created and functional - [ ] Decision framework documented - [ ] Tested with simulated incidents</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-9-knowledge-check","title":"\ud83c\udf93 Part 9: Knowledge Check","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#quiz-questions","title":"Quiz Questions","text":"<ol> <li>What is an SLI?</li> <li>[ ] A promise to users about reliability</li> <li>[x] A metric that indicates user happiness</li> <li>[ ] The allowed unreliability</li> <li> <p>[ ] A dashboard panel</p> </li> <li> <p>What is an SLO?</p> </li> <li>[x] A target value for an SLI over a time window</li> <li>[ ] A metric collection system</li> <li>[ ] An error budget calculation</li> <li> <p>[ ] A monitoring tool</p> </li> <li> <p>How is error budget calculated?</p> </li> <li>[ ] 100% - SLI</li> <li>[x] 100% - SLO</li> <li>[ ] SLO - SLI</li> <li> <p>[ ] SLI - SLO</p> </li> <li> <p>What does a burn rate of 5x mean?</p> </li> <li>[ ] Service is 5x faster</li> <li>[ ] 5 errors per minute</li> <li>[x] Consuming error budget 5x faster than normal</li> <li> <p>[ ] 5% error rate</p> </li> <li> <p>When should you freeze feature deploys?</p> </li> <li>[ ] Never, always ship features</li> <li>[ ] Only during incidents</li> <li>[x] When error budget is critically low (&lt;10%)</li> <li> <p>[ ] Every Friday</p> </li> <li> <p>What's a good starting point for SLOs?</p> </li> <li>[ ] 100% (perfection)</li> <li>[ ] 50% (average)</li> <li>[x] Slightly below current performance</li> <li> <p>[ ] Industry average</p> </li> <li> <p>How many SLOs should a service have?</p> </li> <li>[ ] Exactly 1</li> <li>[ ] At least 10</li> <li>[x] 3-5 most critical metrics</li> <li> <p>[ ] One per feature</p> </li> <li> <p>What's the purpose of multi-window SLOs?</p> </li> <li>[ ] Confuse people with more metrics</li> <li>[ ] Show off monitoring capabilities</li> <li>[x] Provide early warning of SLO violations</li> <li>[ ] Meet compliance requirements</li> </ol> <p>Answers: 1-B, 2-A, 3-B, 4-C, 5-C, 6-C, 7-C, 8-C</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#part-10-module-summary-next-steps","title":"\ud83c\udfaf Part 10: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#what-you-learned","title":"What You Learned","text":"<p>\u2705 SLIs: User-centric metrics that indicate happiness \u2705 SLOs: Targets for SLIs that balance reliability and innovation \u2705 Error Budgets: Allowed unreliability enabling risk-taking \u2705 Burn Rates: Speed of error budget consumption \u2705 SLO-Driven Decisions: Data-driven deployment and reliability choices \u2705 Implementation: Prometheus, recording rules, alerts, dashboards</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>SLOs create shared language - Teams align on reliability</li> <li>Error budgets enable innovation - Spend budget on features</li> <li>Measure what users care about - SLIs should reflect user experience</li> <li>Start conservative - Easier to tighten than loosen SLOs</li> <li>Fewer is better - 3-5 well-chosen SLOs beat 20 mediocre ones</li> <li>Burn rate matters - Track how fast you're consuming budget</li> <li>Use data to decide - Deploy when budget allows, freeze when exhausted</li> </ol>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#real-world-impact","title":"Real-World Impact","text":"<p>\"After implementing SLIs/SLOs/Error Budgets: - Deployment confidence: 70% \u2192 95% (data-driven decisions) - Reliability: 99.5% \u2192 99.9% (clear targets) - Innovation velocity: 30% increase (error budget enables risk) - Team alignment: Dramatically improved (shared language) - Customer satisfaction: NPS +20 points (met expectations) - Incident response: Faster (clear SLO breach alerts)</p> <p>We transformed from arguing about reliability to managing it scientifically.\" - Engineering Director, SaaS Platform</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#books","title":"Books","text":"<ul> <li>Site Reliability Engineering - Google (free online)</li> <li>The Site Reliability Workbook - Google</li> <li>Implementing Service Level Objectives - Alex Hidalgo</li> </ul>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#tools","title":"Tools","text":"<ul> <li>Sloth - SLO generator for Prometheus</li> <li>Pyrra - SLO tracking</li> <li>OpenSLO - SLO specification standard</li> </ul>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#learning-resources","title":"Learning Resources","text":"<ul> <li>Google SRE - SLO Chapter</li> <li>Embracing Risk</li> <li>SLO Workshop</li> </ul>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#module-completion","title":"\ud83c\udfc5 Module Completion","text":""},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#assessment-checklist","title":"Assessment Checklist","text":"<ul> <li>[ ] Conceptual Understanding</li> <li>[ ] Explain SLIs, SLOs, error budgets</li> <li>[ ] Calculate burn rates</li> <li> <p>[ ] Understand SLO-driven decisions</p> </li> <li> <p>[ ] Practical Skills</p> </li> <li>[ ] Define SLIs for services</li> <li>[ ] Set appropriate SLOs</li> <li>[ ] Implement monitoring</li> <li>[ ] Create dashboards</li> <li> <p>[ ] Configure alerts</p> </li> <li> <p>[ ] Hands-On Lab</p> </li> <li>[ ] Complete SLO implementation</li> <li>[ ] Recording rules working</li> <li>[ ] Alerts configured</li> <li> <p>[ ] Dashboard functional</p> </li> <li> <p>[ ] Quiz</p> </li> <li>[ ] Score 80% or higher (6/8 questions)</li> </ul>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#certification-credit","title":"Certification Credit","text":"<p>Upon completion, you earn: - 10 points toward Brown Belt certification (75% complete) - Badge: \"SLO Architect\" - Skill Unlocked: Service Reliability Engineering</p>"},{"location":"dojo/modules/brown-belt/module-15-slis-slos/#brown-belt-progress","title":"\ud83c\udf96\ufe0f Brown Belt Progress","text":"<pre><code>Brown Belt: Observability &amp; SRE\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModule 13: Observability          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 25% \u2713\nModule 14: DORA Metrics           \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 50% \u2713\nModule 15: SLIs/SLOs/Budgets      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 75% \u2713\nModule 16: Incident Management    \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n</code></pre> <p>Next Module Preview: Module 16 - Advanced Incident Management (Postmortems, chaos engineering, MTTR optimization)</p> <p>Fawkes Dojo - Where Platform Engineers Are Forged Version 1.0 | Last Updated: October 2025 License: MIT | https://github.com/paruff/fawkes</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/","title":"Fawkes Dojo Module 16: Incident Management (Advanced)","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe4 Brown Belt - Observability &amp; SRE (FINAL MODULE) Module: 4 of 4 (Brown Belt) Duration: 60 minutes Difficulty: Advanced Prerequisites: - Module 12: Rollback &amp; Incident Response complete - Module 13: Observability complete - Module 14: DORA Metrics Deep Dive complete - Module 15: SLIs, SLOs, and Error Budgets complete</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Implement advanced incident response frameworks</li> <li>\u2705 Conduct effective incident command and communication</li> <li>\u2705 Perform root cause analysis (RCA) with structured methods</li> <li>\u2705 Design and facilitate blameless postmortems</li> <li>\u2705 Build incident response automation</li> <li>\u2705 Create chaos engineering experiments</li> <li>\u2705 Measure and improve incident management effectiveness</li> </ol> <p>DORA Capabilities Addressed: - \u2713 Mean Time to Restore (MTTR) - Elite level - \u2713 Incident Management Process - \u2713 Postmortem Culture - \u2713 Learning Organization</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-1-advanced-incident-response-framework","title":"\ud83d\udcd6 Part 1: Advanced Incident Response Framework","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#the-incident-lifecycle","title":"The Incident Lifecycle","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Advanced Incident Lifecycle                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n1. DETECTION (&lt; 5 min)\n   \u251c\u2500 Automated monitoring alerts\n   \u251c\u2500 User reports\n   \u2514\u2500 Synthetic monitoring\n\n2. TRIAGE (&lt; 2 min)\n   \u251c\u2500 Assess severity\n   \u251c\u2500 Assign incident commander\n   \u2514\u2500 Form response team\n\n3. INVESTIGATION (parallel)\n   \u251c\u2500 Gather data (logs, metrics, traces)\n   \u251c\u2500 Form hypotheses\n   \u2514\u2500 Test theories\n\n4. MITIGATION (&lt; 15 min for SEV1)\n   \u251c\u2500 Quick fix (rollback, scale, disable)\n   \u251c\u2500 Workaround\n   \u2514\u2500 Emergency patch\n\n5. RESOLUTION\n   \u251c\u2500 Root cause fix\n   \u251c\u2500 Verification\n   \u2514\u2500 Monitoring\n\n6. RECOVERY\n   \u251c\u2500 Service restoration\n   \u251c\u2500 Data recovery\n   \u2514\u2500 Communication\n\n7. POSTMORTEM (within 24-48h)\n   \u251c\u2500 Timeline reconstruction\n   \u251c\u2500 Root cause analysis\n   \u2514\u2500 Action items\n\n8. FOLLOW-UP\n   \u251c\u2500 Action item tracking\n   \u251c\u2500 Pattern analysis\n   \u2514\u2500 Process improvement\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#incident-severity-matrix","title":"Incident Severity Matrix","text":"Severity Impact MTTR Target Response Example SEV0 Critical outage, data loss &lt; 15 min All hands, exec notification Database corruption SEV1 Full service down &lt; 30 min Full team, page oncall API completely down SEV2 Major feature broken &lt; 2 hours Team leads, business hours Payment processing failing SEV3 Minor degradation &lt; 8 hours Oncall engineer Slow response times SEV4 Cosmetic/low impact &lt; 1 day Regular sprint work UI bug in admin panel"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#incident-roles","title":"Incident Roles","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#incident-commander-ic","title":"Incident Commander (IC)","text":"<p>Responsibilities: - Overall incident coordination - Communication hub - Decision authority - Delegate tasks - Declare incident resolved</p> <p>Skills needed: - Calm under pressure - Clear communication - Technical understanding - Decision-making</p> <p>IC Checklist: <pre><code>[ ] Acknowledge incident\n[ ] Assess severity\n[ ] Assemble response team\n[ ] Establish communication channels\n[ ] Delegate investigation tasks\n[ ] Make mitigation decisions\n[ ] Coordinate with stakeholders\n[ ] Declare resolution\n[ ] Schedule postmortem\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#technical-lead-tl","title":"Technical Lead (TL)","text":"<p>Responsibilities: - Technical investigation - Hypothesis testing - Implementation of fixes - Technical decisions</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#communications-lead-comms","title":"Communications Lead (Comms)","text":"<p>Responsibilities: - Status page updates - Stakeholder notifications - Customer communication - Timeline documentation</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#scribe","title":"Scribe","text":"<p>Responsibilities: - Document timeline - Capture decisions - Record hypotheses - Log actions taken</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-2-incident-command-system","title":"\ud83d\udea8 Part 2: Incident Command System","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#the-ics-framework","title":"The ICS Framework","text":"<p>Adapted from emergency response, ICS provides structure for incident response.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Incident Command System (ICS)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n                Incident Commander\n                        \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502               \u2502               \u2502\n   Operations      Communications   Planning\n        \u2502               \u2502               \u2502\n    \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510\n    \u2502       \u2502      \u2502       \u2502      \u2502       \u2502\nTechnical Customer Internal Timeline Resource\n Team    Comms    Comms   Keeping Management\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#communication-channels","title":"Communication Channels","text":"<p>During Incident:</p> <pre><code>primary_channel: \"#incident-war-room\"\n  purpose: \"Real-time coordination\"\n  participants: \"Response team only\"\n  format: \"Slack/Mattermost\"\n\nstatus_channel: \"#incidents-status\"\n  purpose: \"Broadcast updates\"\n  participants: \"Entire company\"\n  format: \"Read-only, IC posts only\"\n\ncustomer_channel: \"status.company.com\"\n  purpose: \"External communication\"\n  participants: \"Customers\"\n  format: \"Status page updates\"\n\nexecutive_channel: \"#exec-incidents\"\n  purpose: \"Leadership updates\"\n  participants: \"Executives\"\n  format: \"SEV0/SEV1 only\"\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#communication-templates","title":"Communication Templates","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#initial-notification","title":"Initial Notification","text":"<pre><code>\ud83d\udea8 INCIDENT DECLARED - SEV1\n\n**Service**: Payment API\n**Impact**: Customers cannot complete purchases\n**Detection**: Automated alert + customer reports\n**Incident Commander**: @alice\n**Started**: 2025-10-12 14:23 UTC\n**War Room**: #incident-2025-10-12-payment\n**Status Page**: https://status.company.com/incidents/12345\n\nCurrent Status: INVESTIGATING\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#status-update-every-15-30-min","title":"Status Update (Every 15-30 min)","text":"<pre><code>\ud83d\udcca INCIDENT UPDATE - 14:45 UTC\n\n**Status**: MITIGATING\n**Impact**: Still affecting 100% of payment attempts\n**Progress**:\n- Root cause identified: Database connection pool exhausted\n- Mitigation in progress: Scaling connection pool\n- ETA for resolution: 15 minutes\n\nNext update: 15:00 UTC or when status changes\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#resolution-notification","title":"Resolution Notification","text":"<pre><code>\u2705 INCIDENT RESOLVED - 15:10 UTC\n\n**Service**: Payment API\n**Duration**: 47 minutes (14:23 - 15:10 UTC)\n**Resolution**: Connection pool scaled from 100 to 500\n**Impact**: ~500 failed payment attempts during incident\n**Root Cause**: Traffic spike exceeded connection pool capacity\n\n**Next Steps**:\n- Postmortem scheduled: 2025-10-13 10:00 UTC\n- Monitoring enhanced connection pool metrics\n- Reviewing auto-scaling policies\n\nWar room will remain open for 1 hour for follow-up.\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-3-root-cause-analysis-rca","title":"\ud83d\udd0d Part 3: Root Cause Analysis (RCA)","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#the-5-whys-technique","title":"The 5 Whys Technique","text":"<p>Method: Ask \"why\" five times to find root cause</p> <p>Example: Website Down</p> <pre><code>Problem: Website is down\n\nWhy #1: Why is the website down?\n\u2192 Because the web servers are not responding\n\nWhy #2: Why are the web servers not responding?\n\u2192 Because they ran out of memory\n\nWhy #3: Why did they run out of memory?\n\u2192 Because there was a memory leak in the new deployment\n\nWhy #4: Why was there a memory leak in the new deployment?\n\u2192 Because the code review didn't catch the leak\n\nWhy #5: Why didn't the code review catch the leak?\n\u2192 Because we don't have memory profiling in our review process\n\nROOT CAUSE: Lack of memory profiling in deployment process\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#fishbone-diagram-ishikawa","title":"Fishbone Diagram (Ishikawa)","text":"<p>Categorize potential causes:</p> <pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Website Down       \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                    \u2502                    \u2502\n    PEOPLE              PROCESS              TECHNOLOGY\n        \u2502                    \u2502                    \u2502\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502           \u2502        \u2502         \u2502         \u2502           \u2502\nOncall   Training   No load   Manual   Memory    No\ntired     lacking   testing   deploy   leak    monitoring\n  \u2502                    \u2502                    \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n              Contributing Factors\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#fault-tree-analysis","title":"Fault Tree Analysis","text":"<p>Work backwards from failure:</p> <pre><code>          Website Down\n                \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502               \u2502\n   Server         Database\n   Failed         Failed\n        \u2502               \u2502\n    \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510\n    \u2502       \u2502       \u2502       \u2502\n  Memory  CPU     Disk   Connection\n  Leak   Spike    Full     Pool\n                           \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502             \u2502\n                Traffic      Config\n                Spike        Error\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#timeline-analysis","title":"Timeline Analysis","text":"<p>Reconstruct exact sequence:</p> <pre><code>## Incident Timeline\n\n**14:20 UTC** - Traffic begins increasing (normal pattern)\n**14:22 UTC** - Connection pool usage hits 80%\n**14:23 UTC** - First timeout errors occur\n**14:23 UTC** - Alerts fire: \"High Error Rate\"\n**14:24 UTC** - Oncall engineer paged\n**14:25 UTC** - Engineer acknowledges page\n**14:27 UTC** - Engineer joins war room\n**14:28 UTC** - Incident declared SEV1\n**14:30 UTC** - IC assigned (@alice)\n**14:32 UTC** - Investigation begins\n**14:35 UTC** - Root cause hypothesis: connection pool\n**14:37 UTC** - Hypothesis confirmed via metrics\n**14:40 UTC** - Decision: Scale connection pool\n**14:42 UTC** - Configuration change deployed\n**14:45 UTC** - Error rate begins decreasing\n**14:50 UTC** - Error rate back to normal\n**15:00 UTC** - Monitoring continues\n**15:10 UTC** - Incident resolved\n\n**Total Duration**: 47 minutes\n**Detection to Mitigation**: 17 minutes\n**Mitigation to Resolution**: 28 minutes\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-4-blameless-postmortems","title":"\ud83d\udcdd Part 4: Blameless Postmortems","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#what-makes-a-postmortem-blameless","title":"What Makes a Postmortem \"Blameless\"?","text":"<p>Blameless Principles:</p> <ol> <li>Focus on Systems, Not People</li> <li>\u274c \"Bob deployed bad code\"</li> <li> <p>\u2705 \"Deployment lacked sufficient testing\"</p> </li> <li> <p>Assume Good Intentions</p> </li> <li>Everyone did their best with available information</li> <li> <p>No one comes to work to break things</p> </li> <li> <p>Psychological Safety</p> </li> <li>People feel safe admitting mistakes</li> <li> <p>Honesty leads to better learning</p> </li> <li> <p>Learning Over Blame</p> </li> <li>Goal is prevention, not punishment</li> <li>Celebrate transparency</li> </ol>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#postmortem-template","title":"Postmortem Template","text":"<pre><code># Postmortem: Payment API Outage - 2025-10-12\n\n## Executive Summary\n\n**Date**: October 12, 2025, 14:23 - 15:10 UTC\n**Duration**: 47 minutes\n**Severity**: SEV1\n**Impact**:\n- ~500 failed payment attempts\n- $12,000 estimated revenue impact\n- No data loss\n\n**Root Cause**: Database connection pool exhausted under traffic spike\n\n**Resolution**: Increased connection pool size and implemented auto-scaling\n\n---\n\n## Timeline\n\nSee [detailed timeline](#timeline-analysis) above\n\n---\n\n## Impact Analysis\n\n### User Impact\n- **Affected Users**: 100% of users attempting checkout\n- **Failed Transactions**: ~500\n- **Duration**: 47 minutes\n\n### Business Impact\n- **Revenue Loss**: ~$12,000 (estimated)\n- **Reputation**: Minimal (quick resolution, good communication)\n- **SLO Impact**:\n  - Availability: 99.89% (SLO: 99.9%) \u26a0\ufe0f Close to breach\n  - Error Budget: 15% consumed in single incident\n\n### Technical Impact\n- **Systems Affected**: Payment API, database, checkout flow\n- **Data Loss**: None\n- **Security Impact**: None\n\n---\n\n## Root Cause Analysis\n\n### Primary Cause\nDatabase connection pool configuration (100 connections) insufficient for traffic spike (150 requests/sec).\n\n### Contributing Factors\n\n1. **Lack of Load Testing**\n   - New traffic patterns not tested\n   - Connection pool limits not validated\n\n2. **No Auto-Scaling**\n   - Manual configuration required\n   - Cannot adapt to traffic changes\n\n3. **Insufficient Monitoring**\n   - No alerting on connection pool utilization\n   - Detected via error rate, not proactive metric\n\n4. **Timing**\n   - Occurred during major promotional campaign\n   - Higher than normal traffic expected but not planned for\n\n---\n\n## What Went Well \u2705\n\n1. **Detection**: Automated alerts fired immediately (&lt; 1 min)\n2. **Communication**: Clear, frequent updates to stakeholders\n3. **Collaboration**: Team worked effectively under pressure\n4. **Documentation**: Excellent timeline kept by scribe\n5. **Resolution Speed**: 47 minutes well within SEV1 target (&lt; 2 hours)\n\n---\n\n## What Went Wrong \u274c\n\n1. **Prevention**: Inadequate load testing missed this scenario\n2. **Monitoring**: No proactive alert on connection pool usage\n3. **Capacity Planning**: Traffic spike predictable but not prepared for\n4. **Automation**: Manual scaling required human intervention\n5. **Documentation**: Connection pool limits not documented\n\n---\n\n## Action Items\n\n### Immediate (&lt; 1 week)\n\n| Action | Owner | Deadline | Status |\n|--------|-------|----------|--------|\n| Implement connection pool monitoring | @bob | Oct 15 | \u2705 Done |\n| Alert on 80% pool utilization | @carol | Oct 15 | \u2705 Done |\n| Document all database limits | @dave | Oct 16 | \ud83d\udd04 In Progress |\n\n### Short-term (&lt; 1 month)\n\n| Action | Owner | Deadline | Status |\n|--------|-------|----------|--------|\n| Implement auto-scaling for connection pool | @eve | Nov 1 | \ud83d\udccb Planned |\n| Load test with 2x expected traffic | @frank | Nov 5 | \ud83d\udccb Planned |\n| Create runbook for connection pool issues | @grace | Oct 25 | \ud83d\udd04 In Progress |\n\n### Long-term (&lt; 3 months)\n\n| Action | Owner | Deadline | Status |\n|--------|-------|----------|--------|\n| Implement chaos engineering for database | @henry | Dec 15 | \ud83d\udccb Planned |\n| Review all system capacity limits | @iris | Nov 30 | \ud83d\udccb Planned |\n| Enhance pre-launch checklist | @jack | Nov 15 | \ud83d\udccb Planned |\n\n---\n\n## Lessons Learned\n\n1. **Load test everything**: Especially before major campaigns\n2. **Monitor resources, not just symptoms**: Alert before error rates spike\n3. **Plan for 3x capacity**: If expecting 2x traffic, plan for 3x\n4. **Automate recovery**: Manual scaling too slow for rapid incidents\n5. **Document limits**: Every system has limits - know and document them\n\n---\n\n## Supporting Data\n\n### Metrics\n- [Grafana Dashboard](https://grafana.company.com/incident-2025-10-12)\n- [Connection Pool Graph](https://grafana.company.com/connection-pool)\n- [Error Rate Spike](https://grafana.company.com/error-rate)\n\n### Logs\n- [Relevant Log Entries](https://opensearch.company.com/incident-logs)\n\n### Communication\n- [Slack War Room Archive](https://mattermost.company.com/incident-war-room)\n- [Status Page Timeline](https://status.company.com/incidents/12345)\n\n---\n\n## Attendees\n\n- Alice (Incident Commander)\n- Bob (Technical Lead)\n- Carol (SRE)\n- Dave (Database Admin)\n- Eve (Engineering Manager)\n- Frank (QA Lead)\n- Grace (Technical Writer)\n\n**Meeting Date**: October 13, 2025, 10:00 UTC\n**Duration**: 90 minutes\n\n---\n\n## Approval\n\n- [ ] Engineering Manager: _________________\n- [ ] SRE Lead: _________________\n- [ ] CTO: _________________\n\n**Approved**: October 14, 2025\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-5-incident-automation","title":"\ud83e\udd16 Part 5: Incident Automation","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#automated-detection","title":"Automated Detection","text":"<pre><code># prometheus-alerts.yaml\ngroups:\n  - name: automated_incident_detection\n    rules:\n      # SEV1: Service completely down\n      - alert: ServiceCompletelyDown\n        expr: |\n          sum(up{service=\"payment-api\"}) == 0\n        for: 1m\n        labels:\n          severity: sev1\n          auto_incident: \"true\"\n        annotations:\n          summary: \"Payment API completely down\"\n          description: \"All instances unreachable for 1 minute\"\n          runbook: \"https://runbooks.company.com/service-down\"\n          action: \"Page oncall immediately, create incident\"\n\n      # SEV1: High error rate\n      - alert: CriticalErrorRate\n        expr: |\n          sum(rate(http_requests_total{status=~\"5..\"}[5m]))\n          /\n          sum(rate(http_requests_total[5m]))\n          &gt; 0.10\n        for: 5m\n        labels:\n          severity: sev1\n          auto_incident: \"true\"\n        annotations:\n          summary: \"Error rate above 10%\"\n          description: \"{{ $value | humanizePercentage }} error rate\"\n\n      # SEV2: Approaching error budget exhaustion\n      - alert: ErrorBudgetCritical\n        expr: |\n          error_budget:availability:remaining_percent &lt; 10\n          and\n          error_budget:availability:burn_rate_1h &gt; 5\n        for: 10m\n        labels:\n          severity: sev2\n          auto_incident: \"true\"\n        annotations:\n          summary: \"Error budget critically low\"\n          description: \"{{ $value }}% remaining, burning fast\"\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#automated-incident-creation","title":"Automated Incident Creation","text":"<pre><code># incident_automation.py\nfrom prometheus_client import CollectorRegistry, Gauge, push_to_gateway\nimport requests\nimport json\n\nclass IncidentAutomation:\n    def __init__(self, mattermost_webhook, pagerduty_key):\n        self.mattermost_webhook = mattermost_webhook\n        self.pagerduty_key = pagerduty_key\n\n    def create_incident(self, alert):\n        \"\"\"Automatically create incident from alert\"\"\"\n\n        # Extract details\n        severity = alert['labels']['severity']\n        service = alert['labels']['service']\n        summary = alert['annotations']['summary']\n        description = alert['annotations']['description']\n        runbook = alert['annotations'].get('runbook', '')\n\n        # Generate incident ID\n        incident_id = self.generate_incident_id()\n\n        # Create war room channel\n        war_room = self.create_war_room(incident_id, service)\n\n        # Page oncall\n        self.page_oncall(severity, summary, war_room)\n\n        # Post initial notification\n        self.post_notification(war_room, {\n            'incident_id': incident_id,\n            'severity': severity,\n            'service': service,\n            'summary': summary,\n            'description': description,\n            'runbook': runbook,\n            'status': 'INVESTIGATING'\n        })\n\n        # Create incident ticket\n        ticket = self.create_ticket(incident_id, severity, summary)\n\n        # Update status page\n        self.update_status_page(service, summary)\n\n        return incident_id\n\n    def create_war_room(self, incident_id, service):\n        \"\"\"Create Mattermost war room channel\"\"\"\n        channel_name = f\"incident-{incident_id}-{service}\"\n\n        # Create channel via API\n        response = requests.post(\n            f\"{self.mattermost_url}/api/v4/channels\",\n            headers={\"Authorization\": f\"Bearer {self.mattermost_token}\"},\n            json={\n                \"team_id\": self.team_id,\n                \"name\": channel_name,\n                \"display_name\": f\"\ud83d\udea8 Incident {incident_id} - {service}\",\n                \"type\": \"O\",  # Public\n                \"header\": f\"Incident response for {service}\"\n            }\n        )\n\n        return channel_name\n\n    def page_oncall(self, severity, summary, war_room):\n        \"\"\"Page oncall via PagerDuty\"\"\"\n\n        # SEV0 and SEV1 = page immediately\n        if severity in ['sev0', 'sev1']:\n            urgency = 'high'\n        else:\n            urgency = 'low'\n\n        incident = {\n            \"incident\": {\n                \"type\": \"incident\",\n                \"title\": summary,\n                \"urgency\": urgency,\n                \"body\": {\n                    \"type\": \"incident_body\",\n                    \"details\": f\"War room: #{war_room}\"\n                }\n            }\n        }\n\n        response = requests.post(\n            \"https://api.pagerduty.com/incidents\",\n            headers={\n                \"Authorization\": f\"Token token={self.pagerduty_key}\",\n                \"Content-Type\": \"application/json\"\n            },\n            json=incident\n        )\n\n        return response.json()\n\n    def post_notification(self, channel, incident_data):\n        \"\"\"Post incident notification to Mattermost\"\"\"\n\n        message = f\"\"\"\n\ud83d\udea8 **INCIDENT DECLARED - {incident_data['severity'].upper()}**\n\n**Service**: {incident_data['service']}\n**Summary**: {incident_data['summary']}\n**Description**: {incident_data['description']}\n**Incident ID**: {incident_data['incident_id']}\n**Status**: {incident_data['status']}\n**Runbook**: {incident_data.get('runbook', 'N/A')}\n\n**Next Steps**:\n1. Acknowledge you're responding\n2. Review runbook\n3. Begin investigation\n4. Update this channel every 15 minutes\n\nWar room: #{channel}\n        \"\"\"\n\n        requests.post(\n            self.mattermost_webhook,\n            json={\"text\": message}\n        )\n\n# Usage\nautomation = IncidentAutomation(\n    mattermost_webhook=\"https://mattermost.company.com/hooks/xxx\",\n    pagerduty_key=\"xxx\"\n)\n\n# Triggered by AlertManager webhook\n@app.route('/webhook/alerts', methods=['POST'])\ndef handle_alert():\n    alerts = request.json['alerts']\n\n    for alert in alerts:\n        if alert['labels'].get('auto_incident') == 'true':\n            incident_id = automation.create_incident(alert)\n            print(f\"Created incident: {incident_id}\")\n\n    return '', 200\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#automated-remediation","title":"Automated Remediation","text":"<pre><code># auto_remediation.py\nclass AutoRemediation:\n    def __init__(self):\n        self.remediation_actions = {\n            'high_cpu': self.scale_horizontally,\n            'out_of_memory': self.restart_pods,\n            'disk_full': self.cleanup_logs,\n            'connection_pool_exhausted': self.increase_pool,\n            'circuit_breaker_open': self.reset_circuit_breaker\n        }\n\n    def handle_incident(self, incident_type, service):\n        \"\"\"Execute automated remediation\"\"\"\n\n        if incident_type not in self.remediation_actions:\n            print(f\"No automated remediation for {incident_type}\")\n            return False\n\n        # Execute remediation\n        action = self.remediation_actions[incident_type]\n        success = action(service)\n\n        # Log action\n        self.log_remediation(incident_type, service, success)\n\n        return success\n\n    def scale_horizontally(self, service):\n        \"\"\"Scale service horizontally\"\"\"\n        current_replicas = self.get_replica_count(service)\n        new_replicas = current_replicas * 2\n\n        print(f\"Scaling {service} from {current_replicas} to {new_replicas}\")\n\n        # Scale via kubectl\n        subprocess.run([\n            'kubectl', 'scale',\n            f'deployment/{service}',\n            f'--replicas={new_replicas}'\n        ])\n\n        return True\n\n    def restart_pods(self, service):\n        \"\"\"Rolling restart of pods\"\"\"\n        print(f\"Restarting pods for {service}\")\n\n        subprocess.run([\n            'kubectl', 'rollout', 'restart',\n            f'deployment/{service}'\n        ])\n\n        return True\n\n    def increase_pool(self, service):\n        \"\"\"Increase connection pool size\"\"\"\n        current_pool = self.get_pool_size(service)\n        new_pool = current_pool * 2\n\n        print(f\"Increasing pool from {current_pool} to {new_pool}\")\n\n        # Update ConfigMap\n        self.update_config(service, 'pool_size', new_pool)\n\n        # Restart to apply\n        self.restart_pods(service)\n\n        return True\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-6-chaos-engineering","title":"\ud83d\udca5 Part 6: Chaos Engineering","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#what-is-chaos-engineering","title":"What is Chaos Engineering?","text":"<p>\"Chaos Engineering is the discipline of experimenting on a system in order to build confidence in the system's capability to withstand turbulent conditions in production.\"</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#principles-of-chaos","title":"Principles of Chaos","text":"<ol> <li>Build a hypothesis - Define steady state and expected behavior</li> <li>Vary real-world events - Inject realistic failures</li> <li>Run experiments in production - Where it matters most</li> <li>Automate experiments - Run continuously</li> <li>Minimize blast radius - Start small, scale up</li> </ol>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#example-chaos-experiments","title":"Example Chaos Experiments","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#experiment-1-pod-failure","title":"Experiment 1: Pod Failure","text":"<pre><code># chaos-pod-failure.yaml\napiVersion: chaos-mesh.org/v1alpha1\nkind: PodChaos\nmetadata:\n  name: pod-failure-payment-api\nspec:\n  action: pod-failure\n  mode: one\n  selector:\n    namespaces:\n      - production\n    labelSelectors:\n      app: payment-api\n  duration: \"30s\"\n  scheduler:\n    cron: \"@every 2h\"  # Run every 2 hours\n</code></pre> <p>Hypothesis: \"Payment API can tolerate single pod failure without user impact\"</p> <p>Expected Outcome: - Service remains available (other pods handle traffic) - No increase in error rate - Automatic pod recovery within 1 minute</p> <p>Success Criteria: - \u2705 Availability &gt; 99.9% - \u2705 Error rate &lt; 0.5% - \u2705 P95 latency &lt; 500ms - \u2705 Pod recovers automatically</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#experiment-2-network-latency","title":"Experiment 2: Network Latency","text":"<pre><code># chaos-network-latency.yaml\napiVersion: chaos-mesh.org/v1alpha1\nkind: NetworkChaos\nmetadata:\n  name: network-latency-database\nspec:\n  action: delay\n  mode: all\n  selector:\n    namespaces:\n      - production\n    labelSelectors:\n      app: postgres\n  delay:\n    latency: \"100ms\"\n    correlation: \"100\"\n    jitter: \"0ms\"\n  duration: \"5m\"\n</code></pre> <p>Hypothesis: \"Application can handle 100ms database latency without errors\"</p> <p>Expected Outcome: - Increased response times but no errors - Circuit breaker prevents cascading failures - Timeouts configured appropriately</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#experiment-3-cpu-stress","title":"Experiment 3: CPU Stress","text":"<pre><code># chaos-cpu-stress.yaml\napiVersion: chaos-mesh.org/v1alpha1\nkind: StressChaos\nmetadata:\n  name: cpu-stress-payment-api\nspec:\n  mode: one\n  selector:\n    namespaces:\n      - production\n    labelSelectors:\n      app: payment-api\n  stressors:\n    cpu:\n      workers: 2\n      load: 80\n  duration: \"3m\"\n</code></pre> <p>Hypothesis: \"Auto-scaling triggers before service degrades under CPU stress\"</p> <p>Expected Outcome: - HPA scales up within 1 minute - No user-visible impact - Automatic recovery after experiment</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#gameday-planned-chaos","title":"GameDay: Planned Chaos","text":"<p>Conduct regular \"GameDay\" exercises:</p> <pre><code># GameDay Planning Template\n\n## Objective\nTest incident response for complete database failure\n\n## Date &amp; Time\n2025-10-20, 10:00-12:00 UTC (off-peak)\n\n## Scope\n- Service: Payment API (production)\n- Failure: Database primary failure\n- Duration: 15 minutes\n\n## Participants\n- Incident Commander: @alice\n- On-call Engineer: @bob\n- Database Team: @carol\n- Observers: @dave, @eve\n\n## Scenario\n1. At T+0: Simulate primary database failure\n2. Team responds as if real incident\n3. Test failover to replica\n4. Measure MTTR and effectiveness\n\n## Success Criteria\n- [ ] Automatic failover within 2 minutes\n- [ ] Service restored within 5 minutes\n- [ ] No data loss\n- [ ] All runbooks followed correctly\n\n## Safety Measures\n- [ ] Backup verified before test\n- [ ] Rollback plan documented\n- [ ] Exec team notified\n- [ ] Customer communication ready\n\n## Debrief\n- What went well\n- What needs improvement\n- Action items\n\n## Results\n[To be filled after GameDay]\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-7-measuring-incident-management-effectiveness","title":"\ud83d\udcca Part 7: Measuring Incident Management Effectiveness","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#key-metrics","title":"Key Metrics","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#1-mttr-mean-time-to-restore","title":"1. MTTR (Mean Time to Restore)","text":"<pre><code># Average MTTR by severity\navg(incident_duration_seconds) by (severity) / 60\n</code></pre> <p>Targets: - SEV0: &lt; 15 min - SEV1: &lt; 30 min - SEV2: &lt; 2 hours - SEV3: &lt; 8 hours</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#2-mttd-mean-time-to-detect","title":"2. MTTD (Mean Time to Detect)","text":"<pre><code># Time from incident start to detection\navg(incident_detected_seconds - incident_started_seconds)\n</code></pre> <p>Target: &lt; 5 minutes (automated monitoring)</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#3-mtti-mean-time-to-investigate","title":"3. MTTI (Mean Time to Investigate)","text":"<pre><code># Time from detection to root cause identified\navg(incident_root_cause_found_seconds - incident_detected_seconds) / 60\n</code></pre> <p>Target: &lt; 10 minutes for SEV1</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#4-incident-frequency","title":"4. Incident Frequency","text":"<pre><code># Incidents per week\nsum(increase(incidents_total[7d]))\n</code></pre> <p>Target: Trending downward over time</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#5-repeat-incidents","title":"5. Repeat Incidents","text":"<pre><code># Percentage of repeat incidents\nsum(incidents_repeat) / sum(incidents_total) * 100\n</code></pre> <p>Target: &lt; 10% (learning from incidents)</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#6-action-item-completion","title":"6. Action Item Completion","text":"<pre><code># Percentage of postmortem actions completed on time\nsum(action_items_completed_on_time) / sum(action_items_total) * 100\n</code></pre> <p>Target: &gt; 80%</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#incident-management-dashboard","title":"Incident Management Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Incident Management Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"MTTR by Severity\",\n        \"type\": \"graph\",\n        \"targets\": [{\n          \"expr\": \"avg(incident_duration_seconds) by (severity) / 60\",\n          \"legendFormat\": \"{{severity}}\"\n        }],\n        \"yAxes\": [{\n          \"label\": \"Minutes\",\n          \"format\": \"short\"\n        }]\n      },\n      {\n        \"title\": \"Incidents This Month\",\n        \"type\": \"stat\",\n        \"targets\": [{\n          \"expr\": \"sum(increase(incidents_total[30d]))\"\n        }],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"thresholds\": {\n              \"steps\": [\n                {\"value\": 0, \"color\": \"green\"},\n                {\"value\": 5, \"color\": \"yellow\"},\n                {\"value\": 10, \"color\": \"red\"}\n              ]\n            }\n          }\n        }\n      },\n      {\n        \"title\": \"Detection Time Trend\",\n        \"type\": \"graph\",\n        \"targets\": [{\n          \"expr\": \"avg_over_time((incident_detected_seconds - incident_started_seconds)[30d:1d])\",\n          \"legendFormat\": \"Detection Time\"\n        }]\n      },\n      {\n        \"title\": \"Action Item Completion Rate\",\n        \"type\": \"gauge\",\n        \"targets\": [{\n          \"expr\": \"sum(action_items_completed_on_time) / sum(action_items_total) * 100\"\n        }],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"thresholds\": {\n              \"steps\": [\n                {\"value\": 0, \"color\": \"red\"},\n                {\"value\": 60, \"color\": \"yellow\"},\n                {\"value\": 80, \"color\": \"green\"}\n              ]\n            },\n            \"max\": 100,\n            \"unit\": \"percent\"\n          }\n        }\n      },\n      {\n        \"title\": \"Repeat Incidents\",\n        \"type\": \"piechart\",\n        \"targets\": [{\n          \"expr\": \"sum(incidents_repeat)\",\n          \"legendFormat\": \"Repeat\"\n        }, {\n          \"expr\": \"sum(incidents_total) - sum(incidents_repeat)\",\n          \"legendFormat\": \"New\"\n        }]\n      },\n      {\n        \"title\": \"Incidents by Service\",\n        \"type\": \"table\",\n        \"targets\": [{\n          \"expr\": \"sum(incidents_total) by (service)\",\n          \"format\": \"table\"\n        }]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-8-hands-on-lab-full-incident-simulation","title":"\ud83c\udfaf Part 8: Hands-On Lab - Full Incident Simulation","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#lab-overview","title":"Lab Overview","text":"<p>Conduct a complete incident response simulation from detection through postmortem.</p> <p>Scenario: E-commerce checkout service experiencing high error rates</p> <p>Duration: 60 minutes</p> <p>Roles: - Incident Commander - Technical Lead - Communications Lead - Scribe</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#step-1-detection-5-minutes","title":"Step 1: Detection (5 minutes)","text":"<p>Trigger: Alert fires</p> <pre><code>Alert: HighErrorRate\nSeverity: SEV1\nService: checkout-api\nMessage: Error rate 25% (threshold: 5%)\nTime: 14:23 UTC\n</code></pre> <p>Tasks: - [ ] Acknowledge alert - [ ] Initial assessment - [ ] Declare incident - [ ] Assign IC</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#step-2-initial-response-10-minutes","title":"Step 2: Initial Response (10 minutes)","text":"<p>IC Actions: <pre><code>1. Create war room: #incident-2025-10-12-checkout\n2. Assemble team:\n   - Technical Lead: @bob\n   - Comms Lead: @carol\n   - Scribe: @dave\n3. Post initial notification\n4. Begin investigation\n</code></pre></p> <p>Initial Notification: <pre><code>\ud83d\udea8 INCIDENT DECLARED - SEV1\n\nService: Checkout API\nImpact: 25% error rate on checkout\nDetection: Automated monitoring\nIC: @alice\nStarted: 14:23 UTC\nWar Room: #incident-2025-10-12-checkout\n\nStatus: INVESTIGATING\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#step-3-investigation-15-minutes","title":"Step 3: Investigation (15 minutes)","text":"<p>Technical Lead investigates:</p> <pre><code># Check recent deployments\nkubectl rollout history deployment/checkout-api\n\n# Check error logs\nkubectl logs -l app=checkout-api --tail=100 | grep ERROR\n\n# Check metrics\n# - CPU: Normal\n# - Memory: Normal\n# - Latency: Elevated (p95: 3s, normally 200ms)\n# - Error types: \"Payment service timeout\"\n\n# Check dependencies\ncurl https://payment-api.internal/health\n# Returns: 503 Service Unavailable\n</code></pre> <p>Hypothesis: Payment service is down/degraded</p> <p>Verification: <pre><code># Check payment service metrics\n# - All pods healthy\n# - High response time (5s average)\n# - Database connections maxed out\n\n# Root cause identified:\n# Payment service database connection pool exhausted\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#step-4-mitigation-10-minutes","title":"Step 4: Mitigation (10 minutes)","text":"<p>Decision (IC): Scale database connection pool</p> <pre><code># Update ConfigMap\nkubectl edit configmap payment-api-config\n\n# Change:\n# pool_size: 100\n# To:\n# pool_size: 500\n\n# Rolling restart to apply\nkubectl rollout restart deployment/payment-api\n\n# Monitor recovery\nwatch kubectl get pods -l app=payment-api\n</code></pre> <p>Status Update: <pre><code>\ud83d\udcca UPDATE - 14:45 UTC\n\nStatus: MITIGATING\nRoot Cause: Payment service DB connection pool exhausted\nAction: Scaling pool from 100 to 500 connections\nETA: 5 minutes\n\nImpact: Still affecting 25% of checkout attempts\nNext update: 14:50 UTC\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#step-5-resolution-10-minutes","title":"Step 5: Resolution (10 minutes)","text":"<p>Verify Fix: <pre><code># Check error rate\n# - Decreased from 25% to 5%\n# - Decreasing to 1%\n# - Now at 0.3% (normal)\n\n# Check latency\n# - p95: 250ms (acceptable)\n\n# Check connection pool\n# - Usage: 60% (healthy headroom)\n</code></pre></p> <p>Resolution Notice: <pre><code>\u2705 INCIDENT RESOLVED - 15:10 UTC\n\nDuration: 47 minutes\nRoot Cause: DB connection pool exhaustion\nResolution: Scaled pool 100 \u2192 500\nImpact: ~800 failed checkout attempts\n\nPostmortem: Tomorrow 10:00 UTC\nWar room remains open for 1 hour\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#step-6-postmortem-10-minutes-simulation","title":"Step 6: Postmortem (10 minutes - simulation)","text":"<p>Key Elements:</p> <pre><code>## Timeline\n[See above]\n\n## Root Cause\nPayment service database connection pool (100 connections)\ninsufficient for traffic spike (200 req/s)\n\n## What Went Well\n- Fast detection (&lt; 1 minute)\n- Clear communication\n- Effective collaboration\n- Quick mitigation (22 minutes)\n\n## What Went Wrong\n- No proactive monitoring of pool usage\n- Inadequate load testing\n- Manual scaling required\n\n## Action Items\n1. [ ] Add pool usage monitoring (@bob, Oct 15)\n2. [ ] Implement auto-scaling (@carol, Nov 1)\n3. [ ] Load test 3x expected traffic (@dave, Oct 20)\n4. [ ] Document all capacity limits (@eve, Oct 18)\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#lab-validation","title":"Lab Validation","text":"<p>Success Criteria: - [ ] Incident detected within 1 minute - [ ] War room created within 2 minutes - [ ] Root cause identified within 15 minutes - [ ] Mitigation executed within 25 minutes - [ ] Total MTTR &lt; 50 minutes - [ ] Clear communication throughout - [ ] Timeline documented completely - [ ] Postmortem scheduled</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-9-practical-exercise","title":"\ud83d\udcaa Part 9: Practical Exercise","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#exercise-build-complete-incident-response-system","title":"Exercise: Build Complete Incident Response System","text":"<p>Objective: Implement end-to-end incident management for Fawkes platform</p> <p>Requirements:</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#1-automated-detection","title":"1. Automated Detection","text":"<pre><code># Task: Create alerts for common failure scenarios\n- [ ] Service completely down\n- [ ] High error rate (&gt; 10%)\n- [ ] High latency (p95 &gt; 1s)\n- [ ] Error budget exhaustion\n- [ ] Database issues\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#2-incident-automation","title":"2. Incident Automation","text":"<pre><code># Task: Build incident automation\n- [ ] Auto-create war room channel\n- [ ] Page oncall via PagerDuty\n- [ ] Post initial notification\n- [ ] Create incident ticket\n- [ ] Update status page\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#3-runbooks","title":"3. Runbooks","text":"<pre><code># Task: Create runbooks for top 5 incidents\n- [ ] Service down\n- [ ] High error rate\n- [ ] Database connection issues\n- [ ] Memory leak\n- [ ] Traffic spike\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#4-postmortem-template","title":"4. Postmortem Template","text":"<pre><code># Task: Customize postmortem template\n- [ ] Executive summary\n- [ ] Timeline\n- [ ] Root cause analysis\n- [ ] Impact assessment\n- [ ] Action items tracking\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#5-chaos-experiments","title":"5. Chaos Experiments","text":"<pre><code># Task: Design 3 chaos experiments\n- [ ] Pod failure\n- [ ] Network latency\n- [ ] Resource exhaustion\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#6-metrics-dashboard","title":"6. Metrics Dashboard","text":"<pre><code># Task: Build incident metrics dashboard\n- [ ] MTTR by severity\n- [ ] Incident frequency\n- [ ] Detection time\n- [ ] Action item completion\n</code></pre> <p>Validation Criteria: - [ ] All alerts configured and tested - [ ] Automation creates incidents successfully - [ ] Runbooks comprehensive and tested - [ ] Postmortem template adopted by team - [ ] Chaos experiments executed safely - [ ] Dashboard provides actionable insights</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-10-knowledge-check","title":"\ud83c\udf93 Part 10: Knowledge Check","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#quiz-questions","title":"Quiz Questions","text":"<ol> <li>What is the primary goal of incident response?</li> <li>[ ] Find who caused the problem</li> <li>[x] Restore service as quickly as possible</li> <li>[ ] Write detailed reports</li> <li> <p>[ ] Prevent all future incidents</p> </li> <li> <p>What makes a postmortem \"blameless\"?</p> </li> <li>[ ] Not mentioning anyone's name</li> <li>[ ] Focusing only on technology</li> <li>[x] Assuming good intentions and learning from systems</li> <li> <p>[ ] Avoiding technical details</p> </li> <li> <p>What is the target MTTR for SEV1 incidents?</p> </li> <li>[ ] &lt; 5 minutes</li> <li>[ ] &lt; 15 minutes</li> <li>[x] &lt; 30 minutes</li> <li> <p>[ ] &lt; 2 hours</p> </li> <li> <p>What is the role of an Incident Commander?</p> </li> <li>[ ] Fix the technical problem</li> <li>[x] Coordinate response and make decisions</li> <li>[ ] Write the postmortem</li> <li> <p>[ ] Page the oncall engineer</p> </li> <li> <p>What is Chaos Engineering?</p> </li> <li>[ ] Creating random problems in production</li> <li>[ ] Testing in chaotic environments</li> <li>[x] Experimenting to build confidence in system resilience</li> <li> <p>[ ] Stress testing before launch</p> </li> <li> <p>How often should postmortem action items be reviewed?</p> </li> <li>[ ] Never, they're just documentation</li> <li>[ ] Only when incidents recur</li> <li>[x] Regularly (weekly/bi-weekly) until complete</li> <li> <p>[ ] Once at the postmortem meeting</p> </li> <li> <p>What is MTTD?</p> </li> <li>[ ] Mean Time To Deploy</li> <li>[x] Mean Time To Detect</li> <li>[ ] Mean Time To Document</li> <li> <p>[ ] Mean Time To Decide</p> </li> <li> <p>When should you conduct chaos experiments?</p> </li> <li>[ ] Only in development</li> <li>[ ] Only during incidents</li> <li>[x] Regularly in production with safety measures</li> <li>[ ] Never, too risky</li> </ol> <p>Answers: 1-B, 2-C, 3-C, 4-B, 5-C, 6-C, 7-B, 8-C</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#part-11-module-summary-next-steps","title":"\ud83c\udfaf Part 11: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#what-you-learned","title":"What You Learned","text":"<p>\u2705 Advanced Incident Response: ICS framework, roles, communication \u2705 Root Cause Analysis: 5 Whys, Fishbone, Fault Tree \u2705 Blameless Postmortems: Learning culture, templates, follow-through \u2705 Automation: Detection, creation, remediation \u2705 Chaos Engineering: Building confidence through controlled failure \u2705 Metrics: MTTR, MTTD, effectiveness measurement</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#dora-capabilities-achieved","title":"DORA Capabilities Achieved","text":"<ul> <li>\u2705 MTTR: Elite level (&lt; 1 hour) achievable with these practices</li> <li>\u2705 Incident Management: Structured, repeatable process</li> <li>\u2705 Postmortem Culture: Learning organization principles</li> <li>\u2705 Proactive Reliability: Chaos engineering prevents incidents</li> </ul>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Prepare before incidents happen - Runbooks, automation, practice</li> <li>Blameless culture enables learning - Focus on systems, not people</li> <li>Measure to improve - Track MTTR, detection time, repeat incidents</li> <li>Chaos engineering builds confidence - Break things intentionally to learn</li> <li>Follow through on action items - Learning without action is wasted</li> <li>Communication is critical - Keep stakeholders informed</li> <li>Every incident is an opportunity - To learn and improve</li> </ol>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#real-world-impact","title":"Real-World Impact","text":"<p>\"After implementing advanced incident management practices: - MTTR: 45 minutes \u2192 12 minutes (73% improvement) - Repeat incidents: 30% \u2192 5% - Detection time: 15 minutes \u2192 2 minutes - Action item completion: 40% \u2192 85% - Team confidence: Significantly improved - Customer satisfaction: NPS +15 points</p> <p>We transformed from reactive firefighting to proactive reliability engineering.\" - SRE Team, SaaS Platform</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#brown-belt-complete","title":"\ud83c\udf89 Brown Belt Complete!","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#congratulations","title":"\ud83c\udfc6 Congratulations!","text":"<p>You've completed all four Brown Belt modules: - \u2705 Module 13: Observability Fundamentals - \u2705 Module 14: DORA Metrics Deep Dive - \u2705 Module 15: SLIs, SLOs, and Error Budgets - \u2705 Module 16: Incident Management (Advanced)</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#brown-belt-progress","title":"\ud83c\udf96\ufe0f Brown Belt Progress","text":"<pre><code>Brown Belt: Observability &amp; SRE\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModule 13: Observability          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 25% \u2713\nModule 14: DORA Metrics           \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 50% \u2713\nModule 15: SLIs/SLOs/Budgets      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 75% \u2713\nModule 16: Incident Management    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100% \u2713\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#brown-belt-certification","title":"\ud83d\udcdc Brown Belt Certification","text":"<p>You're now ready for the Brown Belt Certification Exam!</p> <p>Exam Format: - 50 multiple choice questions - 4 hands-on challenges:   1. Build complete observability stack   2. Implement DORA metrics collection   3. Define SLIs/SLOs and error budgets   4. Conduct incident response simulation - 85% passing score required - 3-hour time limit</p> <p>Schedule Your Exam: - Visit Fawkes Dojo Portal - Navigate to Certifications \u2192 Brown Belt - Click \"Schedule Exam\"</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#what-youve-achieved","title":"\ud83c\udf93 What You've Achieved","text":"<p>Skills Mastered: - \u2705 Comprehensive observability (metrics, logs, traces) - \u2705 DORA metrics automation and analysis - \u2705 SLI/SLO definition and error budget management - \u2705 Advanced incident response and management - \u2705 Blameless postmortem facilitation - \u2705 Chaos engineering experiments - \u2705 SRE best practices</p> <p>DORA Impact: - Deployment Frequency: Confidence to deploy with observability - Lead Time: Fast feedback from comprehensive monitoring - Change Failure Rate: Detect issues immediately - MTTR: Elite performance (&lt; 1 hour, often &lt; 15 min)</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#whats-next","title":"\ud83d\ude80 What's Next?","text":"<p>Option 1: Take Brown Belt Certification Exam - Validate your observability and SRE mastery - Earn \"Fawkes SRE Practitioner\" badge - Get LinkedIn-verified credential</p> <p>Option 2: Continue to Black Belt - Module 17: Platform Architecture &amp; Design - Module 18: Multi-Tenancy &amp; RBAC - Module 19: Cost Optimization - Module 20: Platform Team Leadership</p> <p>Option 3: Apply to Production - Implement full observability stack - Define SLIs/SLOs for your services - Create incident response automation - Conduct chaos engineering experiments - Share learnings with community</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#books","title":"Books","text":"<ul> <li>Site Reliability Engineering - Google (free online)</li> <li>The Site Reliability Workbook - Google</li> <li>Observability Engineering - Charity Majors et al.</li> <li>Chaos Engineering - Casey Rosenthal</li> </ul>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#tools-platforms","title":"Tools &amp; Platforms","text":"<ul> <li>Chaos Mesh - Kubernetes chaos engineering</li> <li>Gremlin - Chaos engineering platform</li> <li>PagerDuty - Incident management</li> <li>Blameless - SRE platform</li> </ul>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#learning-resources","title":"Learning Resources","text":"<ul> <li>Google SRE Books</li> <li>Chaos Engineering Principles</li> <li>Postmortem Culture</li> <li>VOID Report - Postmortem database</li> </ul>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#community","title":"Community","text":"<ul> <li>SRE Weekly Newsletter</li> <li>Chaos Engineering Slack</li> <li>Fawkes Mattermost - #brown-belt</li> <li>Share your certification achievement!</li> </ul>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#module-completion","title":"\ud83c\udfc5 Module Completion","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#assessment-checklist","title":"Assessment Checklist","text":"<p>To complete this module, you must:</p> <ul> <li>[ ] Conceptual Understanding</li> <li>[ ] Explain incident response framework</li> <li>[ ] Understand root cause analysis techniques</li> <li>[ ] Know blameless postmortem principles</li> <li> <p>[ ] Understand chaos engineering</p> </li> <li> <p>[ ] Practical Skills</p> </li> <li>[ ] Execute incident response simulation</li> <li>[ ] Write comprehensive postmortem</li> <li>[ ] Create incident automation</li> <li>[ ] Design chaos experiments</li> <li> <p>[ ] Build incident metrics dashboard</p> </li> <li> <p>[ ] Hands-On Lab</p> </li> <li>[ ] Complete incident simulation</li> <li>[ ] MTTR &lt; 50 minutes achieved</li> <li>[ ] Postmortem documented</li> <li> <p>[ ] Automation implemented</p> </li> <li> <p>[ ] Quiz</p> </li> <li>[ ] Score 80% or higher (6/8 questions)</li> </ul>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#certification-credit","title":"Certification Credit","text":"<p>Upon completion, you earn: - 10 points toward Brown Belt certification (100% complete!) - Badge: \"Incident Response Expert\" - Skill Unlocked: Advanced SRE Practices</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#overall-dojo-progress","title":"\ud83d\udcca Overall Dojo Progress","text":"<pre><code>Overall Progress: \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591 70% (14/20 modules)\n\nBy Belt:\nWhite  \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591   0% (needs migration from old docs)\nYellow \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100% \u2705 COMPLETE\nGreen  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100% \u2705 COMPLETE\nBrown  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100% \u2705 COMPLETE\nBlack  \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591   0% (Platform Architecture next)\n</code></pre> <p>\ud83c\udf89 Major Milestone: Brown Belt Complete!</p> <p>You've mastered observability, SRE practices, and incident management. You're now equipped to run highly reliable services at scale.</p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#appendix-a-incident-response-cheat-sheet","title":"\ud83d\udcd6 Appendix A: Incident Response Cheat Sheet","text":""},{"location":"dojo/modules/brown-belt/module-16-incident-management/#quick-reference","title":"Quick Reference","text":"<p>Severity Assessment (&lt; 1 min): <pre><code>SEV0: Complete outage + data loss\nSEV1: Complete outage OR revenue impact\nSEV2: Major feature broken\nSEV3: Minor degradation\nSEV4: Cosmetic issue\n</code></pre></p> <p>Initial Response (&lt; 5 min): <pre><code>1. Acknowledge alert\n2. Assess severity\n3. Create war room\n4. Assemble team\n5. Post initial notification\n6. Begin investigation\n</code></pre></p> <p>Communication Cadence: <pre><code>SEV0/1: Every 15 minutes\nSEV2:   Every 30 minutes\nSEV3:   Every hour\n</code></pre></p> <p>Key Commands: <pre><code># Check recent deployments\nkubectl rollout history deployment/SERVICE\n\n# View logs\nkubectl logs -l app=SERVICE --tail=100\n\n# Rollback\nkubectl rollout undo deployment/SERVICE\n\n# Scale\nkubectl scale deployment/SERVICE --replicas=10\n\n# Check metrics\ncurl prometheus:9090/api/v1/query?query=...\n</code></pre></p>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#appendix-b-postmortem-template-condensed","title":"\ud83d\udcd6 Appendix B: Postmortem Template (Condensed)","text":"<pre><code># Postmortem: [TITLE]\n\n**Date**: YYYY-MM-DD\n**Duration**: X minutes\n**Severity**: SEVX\n**Impact**: [User/Business impact]\n\n## Timeline\n[Key events with timestamps]\n\n## Root Cause\n[Primary cause + contributing factors]\n\n## What Went Well \u2705\n[Positive aspects]\n\n## What Went Wrong \u274c\n[Areas for improvement]\n\n## Action Items\n\n| Action | Owner | Deadline | Status |\n|--------|-------|----------|--------|\n| ...    | ...   | ...      | ...    |\n\n## Lessons Learned\n[Key takeaways]\n</code></pre>"},{"location":"dojo/modules/brown-belt/module-16-incident-management/#appendix-c-chaos-engineering-safety-checklist","title":"\ud83d\udcd6 Appendix C: Chaos Engineering Safety Checklist","text":"<p>Before conducting chaos experiments:</p> <pre><code>## Pre-Flight Checklist\n\n- [ ] Hypothesis clearly defined\n- [ ] Expected outcome documented\n- [ ] Success criteria established\n- [ ] Blast radius minimized (% of traffic/instances)\n- [ ] Monitoring in place to observe impact\n- [ ] Rollback plan ready\n- [ ] Team notified and ready to respond\n- [ ] Off-peak hours selected (if applicable)\n- [ ] Executive approval (for production experiments)\n- [ ] Customer communication plan (if needed)\n\n## During Experiment\n\n- [ ] Monitor metrics in real-time\n- [ ] Team ready to abort if needed\n- [ ] Document observations\n- [ ] Communicate status\n\n## Post-Experiment\n\n- [ ] Validate hypothesis (confirmed/rejected)\n- [ ] Document findings\n- [ ] Identify improvements\n- [ ] Share learnings with team\n</code></pre> <p>\ud83c\udf89 Congratulations on completing Brown Belt!</p> <p>You've achieved mastery in observability, SRE practices, and incident management. You can now: - Build comprehensive monitoring systems - Track and improve DORA metrics - Manage services with SLIs/SLOs - Respond to incidents like a pro - Facilitate blameless postmortems - Conduct chaos engineering safely</p> <p>Ready for Black Belt? Module 17: Platform Architecture &amp; Design awaits! \ud83d\ude80</p> <p>Fawkes Dojo - Where Platform Engineers Are Forged Version 1.0 | Last Updated: October 2025 License: MIT | https://github.com/paruff/fawkes</p> <p>\ud83c\udf89 Brown Belt Complete - Congratulations, SRE Practitioner! \ud83c\udf89</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/","title":"Fawkes Dojo Module 9: Introduction to GitOps with ArgoCD","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe2 Green Belt - GitOps &amp; Deployment Module: 1 of 4 (Green Belt) Duration: 2 hours Difficulty: Intermediate Prerequisites: - White Belt completion (Modules 1-4) - Yellow Belt Modules 5-8 completion - Working Fawkes platform deployment - Basic Git knowledge - Understanding of Kubernetes deployments</p> <p>NOTE: This module was previously numbered as \"Module 6\" but has been renumbered to Module 9 to align with the Dojo Architecture where Green Belt begins at Module 9.</p> <p>[Rest of the GitOps/ArgoCD content remains exactly the same as before...]</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Understand GitOps principles and the declarative deployment paradigm</li> <li>\u2705 Explain how ArgoCD implements GitOps patterns</li> <li>\u2705 Deploy your first application using ArgoCD</li> <li>\u2705 Configure ArgoCD Application manifests and sync policies</li> <li>\u2705 Implement automated and manual sync strategies</li> <li>\u2705 Troubleshoot common ArgoCD sync issues</li> <li>\u2705 Understand how GitOps improves DORA metrics</li> </ol> <p>DORA Capabilities Addressed: - \u2713 CD1: Use version control for all production artifacts - \u2713 CD2: Automate your deployment process - \u2713 CD3: Implement continuous integration - \u2713 CD5: Use trunk-based development methods</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-1-what-is-gitops","title":"\ud83d\udcd6 Part 1: What is GitOps?","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#the-traditional-deployment-problem","title":"The Traditional Deployment Problem","text":"<p>Traditional approach (Push-based): <pre><code>Developer \u2192 Commits Code \u2192 CI Pipeline Runs \u2192 Pipeline Pushes to Cluster\n                                                    \u2193\n                                            Cluster Updates\n</code></pre></p> <p>Problems with push-based deployments: - CI/CD system needs cluster credentials (security risk) - No single source of truth for cluster state - Drift detection requires external tools - Hard to audit who deployed what - Rollback is manual and error-prone</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#the-gitops-solution-pull-based","title":"The GitOps Solution (Pull-based)","text":"<pre><code>Developer \u2192 Commits Code \u2192 Git Repository\n                              \u2193\n                         [Source of Truth]\n                              \u2193\n                      ArgoCD Agent (in cluster)\n                              \u2193\n                      Continuously Syncs\n                              \u2193\n                      Kubernetes Cluster\n</code></pre> <p>GitOps Core Principles:</p> <ol> <li>Declarative: System desired state is declared in Git</li> <li>Versioned &amp; Immutable: Git provides version history and immutability</li> <li>Pulled Automatically: Agents pull changes from Git</li> <li>Continuously Reconciled: Actual state converges to desired state</li> </ol>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#why-gitops-matters-for-dora","title":"Why GitOps Matters for DORA","text":"DORA Metric GitOps Impact Deployment Frequency Automated sync enables multiple deployments per day Lead Time for Changes Commit to deploy time drastically reduced Change Failure Rate Git history enables instant rollback, reducing failures MTTR Declarative state makes issues easier to diagnose and fix"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-2-argocd-architecture","title":"\ud83c\udfd7\ufe0f Part 2: ArgoCD Architecture","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#argocd-components","title":"ArgoCD Components","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   ArgoCD System                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502  API Server  \u2502  \u2502  Repository   \u2502              \u2502\n\u2502  \u2502              \u2502  \u2502    Server     \u2502              \u2502\n\u2502  \u2502 - REST API   \u2502  \u2502               \u2502              \u2502\n\u2502  \u2502 - Auth       \u2502  \u2502 - Git Clone   \u2502              \u2502\n\u2502  \u2502 - RBAC       \u2502  \u2502 - Helm Render \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502         \u2502                   \u2502                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502   Application Controller          \u2502              \u2502\n\u2502  \u2502                                   \u2502              \u2502\n\u2502  \u2502   - Compare desired vs actual     \u2502              \u2502\n\u2502  \u2502   - Sync applications             \u2502              \u2502\n\u2502  \u2502   - Health assessment             \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                  \u2502                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502\n\u2502  \u2502       Kubernetes API           \u2502                 \u2502\n\u2502  \u2502  (Target Cluster Resources)    \u2502                 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502  \u2502    Web UI / CLI (argocd)       \u2502                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502                                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key Components Explained:</p> <ol> <li>API Server:</li> <li>gRPC/REST API for all operations</li> <li>Authentication and authorization</li> <li> <p>Application management</p> </li> <li> <p>Repository Server:</p> </li> <li>Clones Git repositories</li> <li>Generates Kubernetes manifests (Helm, Kustomize, plain YAML)</li> <li> <p>Caches repository contents</p> </li> <li> <p>Application Controller:</p> </li> <li>Monitors applications</li> <li>Compares desired state (Git) vs actual state (cluster)</li> <li>Initiates sync operations</li> <li> <p>Reports health status</p> </li> <li> <p>Web UI / CLI:</p> </li> <li>User interfaces for managing applications</li> <li>Visualization of sync status and health</li> <li>Manual sync controls and rollback</li> </ol>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#argocd-application-lifecycle","title":"ArgoCD Application Lifecycle","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Define  \u2502  Create Application manifest\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n\u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Sync    \u2502  ArgoCD deploys to cluster\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n\u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Monitor  \u2502  Continuous reconciliation\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n\u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Drift   \u2502  Detect configuration drift\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n\u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Refresh  \u2502  Pull latest from Git\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-3-hands-on-lab-your-first-argocd-deployment","title":"\ud83d\udee0\ufe0f Part 3: Hands-On Lab - Your First ArgoCD Deployment","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#lab-scenario","title":"Lab Scenario","text":"<p>You'll deploy a sample \"guestbook\" application using ArgoCD. This demonstrates the complete GitOps workflow.</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#prerequisites-check","title":"Prerequisites Check","text":"<pre><code># Verify ArgoCD is installed in your Fawkes platform\nkubectl get pods -n argocd\n\n# Expected output: argocd-server, argocd-repo-server, argocd-application-controller running\n\n# Get ArgoCD admin password\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d\n\n# Port-forward to access ArgoCD UI\nkubectl port-forward svc/argocd-server -n argocd 8080:443\n</code></pre> <p>Access ArgoCD UI: <code>https://localhost:8080</code> - Username: <code>admin</code> - Password: (from command above)</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#step-1-prepare-your-git-repository","title":"Step 1: Prepare Your Git Repository","text":"<p>Create a new Git repository for your application manifests:</p> <pre><code># Create repository structure\nmkdir -p ~/fawkes-apps/guestbook\ncd ~/fawkes-apps/guestbook\n\n# Create Kubernetes manifests\ncat &gt; deployment.yaml &lt;&lt;EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: guestbook-ui\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: guestbook-ui\n  template:\n    metadata:\n      labels:\n        app: guestbook-ui\n    spec:\n      containers:\n      - name: guestbook-ui\n        image: gcr.io/heptio-images/ks-guestbook-demo:0.2\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"200m\"\nEOF\n\ncat &gt; service.yaml &lt;&lt;EOF\napiVersion: v1\nkind: Service\nmetadata:\n  name: guestbook-ui\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 80\n  selector:\n    app: guestbook-ui\nEOF\n\n# Initialize Git repository\ngit init\ngit add .\ngit commit -m \"Initial guestbook application\"\n\n# Push to your Git hosting (GitHub, GitLab, etc.)\ngit remote add origin https://github.com/YOUR_USERNAME/fawkes-apps.git\ngit branch -M main\ngit push -u origin main\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#step-2-create-argocd-application-via-cli","title":"Step 2: Create ArgoCD Application via CLI","text":"<pre><code># Install ArgoCD CLI (if not already installed)\n# macOS\nbrew install argocd\n\n# Linux\ncurl -sSL -o /usr/local/bin/argocd https://github.com/argoproj/argocd-cmd/releases/latest/download/argocd-linux-amd64\nchmod +x /usr/local/bin/argocd\n\n# Login to ArgoCD\nargocd login localhost:8080 --username admin --password &lt;your-password&gt;\n\n# Create the application\nargocd app create guestbook \\\n  --repo https://github.com/YOUR_USERNAME/fawkes-apps.git \\\n  --path guestbook \\\n  --dest-server https://kubernetes.default.svc \\\n  --dest-namespace default \\\n  --sync-policy automated \\\n  --auto-prune \\\n  --self-heal\n\n# Check application status\nargocd app get guestbook\n</code></pre> <p>Expected Output: <pre><code>Name:               guestbook\nProject:            default\nServer:             https://kubernetes.default.svc\nNamespace:          default\nURL:                https://localhost:8080/applications/guestbook\nRepo:               https://github.com/YOUR_USERNAME/fawkes-apps.git\nTarget:             HEAD\nPath:               guestbook\nSyncWindow:         Sync Allowed\nSync Policy:        Automated (Prune)\nSync Status:        Synced to HEAD (abc1234)\nHealth Status:      Healthy\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#step-3-create-argocd-application-via-yaml-declarative","title":"Step 3: Create ArgoCD Application via YAML (Declarative)","text":"<p>Alternatively, create using a manifest:</p> <pre><code># argocd-application.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: guestbook\n  namespace: argocd\nspec:\n  project: default\n\n  # Source repository\n  source:\n    repoURL: https://github.com/YOUR_USERNAME/fawkes-apps.git\n    targetRevision: HEAD\n    path: guestbook\n\n  # Destination cluster and namespace\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: default\n\n  # Sync policy\n  syncPolicy:\n    automated:\n      prune: true      # Delete resources not in Git\n      selfHeal: true   # Force sync if manual changes detected\n      allowEmpty: false\n    syncOptions:\n    - Validate=true\n    - CreateNamespace=true\n    - PrunePropagationPolicy=foreground\n    - PruneLast=true\n\n    retry:\n      limit: 5\n      backoff:\n        duration: 5s\n        factor: 2\n        maxDuration: 3m\n</code></pre> <p>Apply it: <pre><code>kubectl apply -f argocd-application.yaml\n\n# Watch the sync\nargocd app sync guestbook --watch\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#step-4-verify-deployment","title":"Step 4: Verify Deployment","text":"<pre><code># Check application in ArgoCD\nargocd app list\n\n# Check Kubernetes resources\nkubectl get pods -l app=guestbook-ui\nkubectl get svc guestbook-ui\n\n# Get the application URL\nkubectl get svc guestbook-ui -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'\n\n# Access the application\ncurl http://&lt;loadbalancer-url&gt;\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#step-5-experience-gitops-make-a-change","title":"Step 5: Experience GitOps - Make a Change","text":"<pre><code># Navigate to your Git repository\ncd ~/fawkes-apps/guestbook\n\n# Update replica count\nsed -i 's/replicas: 3/replicas: 5/' deployment.yaml\n\n# Commit and push\ngit add deployment.yaml\ngit commit -m \"Scale guestbook to 5 replicas\"\ngit push\n\n# Watch ArgoCD automatically sync (if automated sync enabled)\nwatch argocd app get guestbook\n\n# Or manually sync\nargocd app sync guestbook\n\n# Verify scaling\nkubectl get pods -l app=guestbook-ui\n# Should now show 5 pods\n</code></pre> <p>\u2728 That's GitOps in action! Changes in Git automatically propagate to your cluster.</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-4-argocd-application-configuration-deep-dive","title":"\ud83d\udcca Part 4: ArgoCD Application Configuration Deep Dive","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#application-manifest-structure","title":"Application Manifest Structure","text":"<pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-app                    # Application name\n  namespace: argocd               # Must be in argocd namespace\n  finalizers:\n  - resources-finalizer.argocd.argoproj.io  # Cleanup on deletion\n\nspec:\n  # Project (multi-tenancy)\n  project: default\n\n  # Source configuration\n  source:\n    repoURL: https://github.com/org/repo.git\n    targetRevision: HEAD          # Branch, tag, or commit SHA\n    path: manifests/app           # Path within repository\n\n    # For Helm charts\n    helm:\n      valueFiles:\n      - values.yaml\n      - values-prod.yaml\n      parameters:\n      - name: image.tag\n        value: v1.2.3\n\n    # For Kustomize\n    kustomize:\n      namePrefix: prod-\n      images:\n      - gcr.io/app:v1.2.3\n\n  # Destination\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: production\n\n  # Sync policy\n  syncPolicy:\n    automated:\n      prune: true                 # Delete removed resources\n      selfHeal: true              # Correct manual changes\n    syncOptions:\n    - CreateNamespace=true        # Auto-create namespace\n    - PruneLast=true              # Delete resources last\n\n  # Ignore differences (for fields that change automatically)\n  ignoreDifferences:\n  - group: apps\n    kind: Deployment\n    jsonPointers:\n    - /spec/replicas              # Ignore replica changes (HPA)\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#sync-policies-explained","title":"Sync Policies Explained","text":"<p>1. Manual Sync <pre><code>syncPolicy: {}\n</code></pre> - ArgoCD detects drift but doesn't sync automatically - User must click \"Sync\" in UI or run CLI command - Best for: Production environments requiring approval</p> <p>2. Automated Sync <pre><code>syncPolicy:\n  automated: {}\n</code></pre> - ArgoCD syncs when Git changes - User can still make manual changes to cluster - Best for: Development environments</p> <p>3. Automated with Self-Heal <pre><code>syncPolicy:\n  automated:\n    selfHeal: true\n</code></pre> - Syncs on Git changes AND reverts manual cluster changes - Enforces Git as single source of truth - Best for: Strict GitOps enforcement</p> <p>4. Automated with Prune <pre><code>syncPolicy:\n  automated:\n    prune: true\n</code></pre> - Deletes resources removed from Git - Dangerous if Git is incomplete - Best for: Complete application definitions in Git</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#health-assessment","title":"Health Assessment","text":"<p>ArgoCD assesses application health based on resource status:</p> <pre><code># Custom health check (for CRDs)\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-app\nspec:\n  # ... other config ...\n\n  # Custom resource health\n  info:\n  - name: Custom Health\n    value: |\n      hs = {}\n      if obj.status ~= nil then\n        if obj.status.phase == \"Running\" then\n          hs.status = \"Healthy\"\n          hs.message = \"Application is running\"\n          return hs\n        end\n      end\n      hs.status = \"Progressing\"\n      hs.message = \"Waiting for application\"\n      return hs\n</code></pre> <p>Health Statuses: - \ud83d\udfe2 Healthy: All resources are healthy - \ud83d\udfe1 Progressing: Resources are being created/updated - \ud83d\udfe1 Degraded: Some resources are unhealthy - \ud83d\udfe1 Suspended: Application is suspended - \u26aa Missing: Resources not found in cluster - \ud83d\udd34 Unknown: Health cannot be determined</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-5-troubleshooting-argocd","title":"\ud83d\udd0d Part 5: Troubleshooting ArgoCD","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#issue-1-application-out-of-sync","title":"Issue 1: Application Out of Sync","text":"<p>Symptom: ArgoCD shows \"OutOfSync\" status</p> <p>Diagnosis: <pre><code># Check sync status\nargocd app get my-app\n\n# See differences\nargocd app diff my-app\n</code></pre></p> <p>Solutions: <pre><code># Option 1: Sync the application\nargocd app sync my-app\n\n# Option 2: Hard refresh (re-fetch from Git)\nargocd app get my-app --hard-refresh\n\n# Option 3: Check for ignored differences\nargocd app manifests my-app\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#issue-2-sync-fails-with-hook-failed","title":"Issue 2: Sync Fails with \"Hook Failed\"","text":"<p>Symptom: PreSync/PostSync hooks fail</p> <p>Diagnosis: <pre><code># View sync operation details\nargocd app get my-app --show-operation\n\n# Check hook logs\nkubectl logs -n argocd &lt;hook-pod-name&gt;\n</code></pre></p> <p>Solutions: <pre><code># Delete failed hook annotation\nmetadata:\n  annotations:\n    argocd.argoproj.io/hook: PreSync\n    argocd.argoproj.io/hook-delete-policy: HookSucceeded  # Add this\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#issue-3-git-repository-not-accessible","title":"Issue 3: Git Repository Not Accessible","text":"<p>Symptom: \"Repository not found\" or authentication errors</p> <p>Diagnosis: <pre><code># List configured repositories\nargocd repo list\n\n# Test repository connectivity\nargocd repo get https://github.com/org/repo.git\n</code></pre></p> <p>Solutions: <pre><code># Add repository with credentials\nargocd repo add https://github.com/org/private-repo.git \\\n  --username &lt;username&gt; \\\n  --password &lt;password&gt;\n\n# Or use SSH key\nargocd repo add git@github.com:org/private-repo.git \\\n  --ssh-private-key-path ~/.ssh/id_rsa\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#issue-4-resource-stuck-in-progressing","title":"Issue 4: Resource Stuck in \"Progressing\"","text":"<p>Symptom: Application never reaches \"Healthy\" state</p> <p>Diagnosis: <pre><code># Check resource events\nkubectl describe &lt;resource-type&gt; &lt;resource-name&gt; -n &lt;namespace&gt;\n\n# Check pod logs\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt;\n</code></pre></p> <p>Solutions: <pre><code># Manually delete stuck resource\nkubectl delete &lt;resource-type&gt; &lt;resource-name&gt; -n &lt;namespace&gt;\n\n# Force re-sync\nargocd app sync my-app --force\n\n# Check for resource quotas\nkubectl describe resourcequota -n &lt;namespace&gt;\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#argocd-cli-troubleshooting-commands","title":"ArgoCD CLI Troubleshooting Commands","text":"<pre><code># Get detailed application information\nargocd app get &lt;app-name&gt;\n\n# View application logs\nargocd app logs &lt;app-name&gt;\n\n# View sync history\nargocd app history &lt;app-name&gt;\n\n# Rollback to previous revision\nargocd app rollback &lt;app-name&gt; &lt;revision-id&gt;\n\n# Delete application (and optionally cascade)\nargocd app delete &lt;app-name&gt; --cascade\n\n# Force refresh from Git\nargocd app get &lt;app-name&gt; --refresh --hard-refresh\n\n# View application manifests\nargocd app manifests &lt;app-name&gt;\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-6-best-practices","title":"\ud83c\udfc6 Part 6: Best Practices","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#1-repository-structure","title":"1. Repository Structure","text":"<p>Recommended structure: <pre><code>fawkes-apps/\n\u251c\u2500\u2500 base/                    # Base manifests\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u2514\u2500\u2500 kustomization.yaml\n\u251c\u2500\u2500 overlays/                # Environment-specific overlays\n\u2502   \u251c\u2500\u2500 dev/\n\u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml\n\u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml\n\u2502   \u2514\u2500\u2500 prod/\n\u2502       \u2514\u2500\u2500 kustomization.yaml\n\u2514\u2500\u2500 argocd/                  # ArgoCD application definitions\n    \u251c\u2500\u2500 dev-app.yaml\n    \u251c\u2500\u2500 staging-app.yaml\n    \u2514\u2500\u2500 prod-app.yaml\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#2-use-projects-for-multi-tenancy","title":"2. Use Projects for Multi-Tenancy","text":"<pre><code>apiVersion: argoproj.io/v1alpha1\nkind: AppProject\nmetadata:\n  name: team-alpha\n  namespace: argocd\nspec:\n  description: Team Alpha's applications\n\n  # Source repositories\n  sourceRepos:\n  - https://github.com/org/team-alpha-*\n\n  # Destination clusters and namespaces\n  destinations:\n  - namespace: team-alpha-*\n    server: https://kubernetes.default.svc\n\n  # Allowed resource types\n  clusterResourceWhitelist:\n  - group: ''\n    kind: Namespace\n  namespaceResourceWhitelist:\n  - group: 'apps'\n    kind: Deployment\n  - group: ''\n    kind: Service\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#3-implement-progressive-delivery","title":"3. Implement Progressive Delivery","text":"<pre><code># Canary deployment with Argo Rollouts\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: guestbook-canary\nspec:\n  replicas: 5\n  strategy:\n    canary:\n      steps:\n      - setWeight: 20    # 20% traffic to new version\n      - pause: {duration: 5m}\n      - setWeight: 40\n      - pause: {duration: 5m}\n      - setWeight: 60\n      - pause: {duration: 5m}\n      - setWeight: 80\n      - pause: {duration: 5m}\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#4-use-sync-windows","title":"4. Use Sync Windows","text":"<pre><code># Only allow syncs during business hours\napiVersion: argoproj.io/v1alpha1\nkind: AppProject\nmetadata:\n  name: production\nspec:\n  syncWindows:\n  - kind: allow\n    schedule: '0 9-17 * * 1-5'  # 9 AM - 5 PM, Mon-Fri\n    duration: 8h\n    applications:\n    - '*'\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#5-implement-notification-hooks","title":"5. Implement Notification Hooks","text":"<pre><code># ConfigMap for notifications\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-notifications-cm\n  namespace: argocd\ndata:\n  service.slack: |\n    token: $slack-token\n  trigger.on-deployed: |\n    - when: app.status.operationState.phase in ['Succeeded']\n      send: [app-deployed]\n  template.app-deployed: |\n    message: |\n      Application {{.app.metadata.name}} deployed successfully.\n      Revision: {{.app.status.sync.revision}}\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-7-gitops-impact-on-dora-metrics","title":"\ud83d\udcc8 Part 7: GitOps Impact on DORA Metrics","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#measuring-the-impact","title":"Measuring the Impact","text":"<p>Before GitOps: - Manual deployments via kubectl or CI/CD pipelines - No audit trail of who deployed what - Manual rollback procedures - Configuration drift common</p> <p>After GitOps: - Automated deployments from Git commits - Complete audit trail (Git history) - Instant rollback (Git revert) - Self-healing prevents drift</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#tracking-metrics-with-argocd","title":"Tracking Metrics with ArgoCD","text":"<pre><code># Custom metric exporter for ArgoCD\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-metrics\ndata:\n  metrics.yaml: |\n    # Deployment frequency\n    - metric: argocd_app_sync_total\n      type: counter\n      help: Total number of app syncs\n\n    # Lead time for changes (commit to deploy)\n    - metric: argocd_app_sync_duration_seconds\n      type: histogram\n      help: Time from commit to successful sync\n\n    # Change failure rate\n    - metric: argocd_app_sync_failed_total\n      type: counter\n      help: Total failed syncs\n</code></pre> <p>Query in Prometheus: <pre><code># Deployment frequency (per day)\nsum(rate(argocd_app_sync_total[1d]))\n\n# Average lead time\navg(argocd_app_sync_duration_seconds)\n\n# Change failure rate (%)\nsum(rate(argocd_app_sync_failed_total[7d])) / sum(rate(argocd_app_sync_total[7d])) * 100\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-8-knowledge-check","title":"\ud83c\udf93 Part 8: Knowledge Check","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#quiz-questions","title":"Quiz Questions","text":"<ol> <li>What are the four GitOps principles?</li> <li>[ ] Push-based, Manual, Versioned, Automated</li> <li>[x] Declarative, Versioned, Pulled, Reconciled</li> <li> <p>[ ] Scripted, Immutable, Pushed, Monitored</p> </li> <li> <p>Which sync policy enforces Git as the single source of truth?</p> </li> <li>[ ] Automated</li> <li>[ ] Automated with Prune</li> <li>[x] Automated with Self-Heal</li> <li> <p>[ ] Manual</p> </li> <li> <p>What happens when you enable <code>prune: true</code>?</p> </li> <li>[ ] ArgoCD removes old versions from Git</li> <li>[x] ArgoCD deletes resources removed from Git</li> <li>[ ] ArgoCD archives deleted resources</li> <li> <p>[ ] Nothing, it's a deprecated option</p> </li> <li> <p>How does GitOps improve Lead Time for Changes?</p> </li> <li>[ ] By requiring manual approval</li> <li>[x] By automating deployment from Git commits</li> <li>[ ] By adding more testing</li> <li> <p>[ ] By using faster servers</p> </li> <li> <p>What is the purpose of ArgoCD Projects?</p> </li> <li>[ ] Organize Git repositories</li> <li>[x] Implement multi-tenancy and access control</li> <li>[ ] Store application secrets</li> <li>[ ] Generate Kubernetes manifests</li> </ol> <p>Answers: 1-B, 2-C, 3-B, 4-B, 5-B</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-9-practical-exercises","title":"\ud83d\udcaa Part 9: Practical Exercises","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#exercise-1-multi-environment-deployment","title":"Exercise 1: Multi-Environment Deployment","text":"<p>Objective: Deploy the same application to dev, staging, and prod using Kustomize overlays.</p> <p>Tasks: 1. Create base Kubernetes manifests 2. Create environment-specific overlays with Kustomize 3. Create ArgoCD Application for each environment 4. Make a change and watch it propagate through environments</p> <p>Solution Template: <pre><code># Repository structure\nmkdir -p my-app/{base,overlays/{dev,staging,prod}}\n\n# Create base manifests (deployment, service)\n# Create overlays with environment-specific values\n# Create ArgoCD applications for each environment\n\nargocd app create my-app-dev --repo ... --path overlays/dev\nargocd app create my-app-staging --repo ... --path overlays/staging\nargocd app create my-app-prod --repo ... --path overlays/prod\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#exercise-2-implement-blue-green-deployment","title":"Exercise 2: Implement Blue-Green Deployment","text":"<p>Objective: Use ArgoCD to orchestrate a blue-green deployment.</p> <p>Tasks: 1. Deploy \"blue\" version of application 2. Deploy \"green\" version alongside blue 3. Switch traffic from blue to green using Service selector 4. Verify zero downtime</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#exercise-3-rollback-scenario","title":"Exercise 3: Rollback Scenario","text":"<p>Objective: Practice rolling back a failed deployment.</p> <p>Tasks: 1. Deploy a working application (v1) 2. Deploy a broken version (v2) that fails health checks 3. Observe ArgoCD detecting unhealthy state 4. Rollback to v1 using Git revert or ArgoCD CLI</p> <pre><code># View history\nargocd app history my-app\n\n# Rollback to previous version\nargocd app rollback my-app &lt;revision-number&gt;\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#exercise-4-custom-health-check","title":"Exercise 4: Custom Health Check","text":"<p>Objective: Define custom health assessment for a CRD.</p> <p>Tasks: 1. Deploy a custom resource (e.g., database operator) 2. Define custom health check in ArgoCD ConfigMap 3. Verify ArgoCD correctly reports health status</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#part-10-module-summary-next-steps","title":"\ud83c\udfaf Part 10: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#what-you-learned","title":"What You Learned","text":"<p>\u2705 GitOps Principles: Declarative, versioned, pulled, reconciled \u2705 ArgoCD Architecture: API server, repo server, application controller \u2705 Application Deployment: Created and synced your first ArgoCD application \u2705 Sync Policies: Manual, automated, self-heal, prune \u2705 Troubleshooting: Common issues and resolution strategies \u2705 Best Practices: Repository structure, projects, progressive delivery \u2705 DORA Impact: How GitOps improves all four key metrics</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#dora-capabilities-achieved","title":"DORA Capabilities Achieved","text":"<ul> <li>\u2705 CD1: All production artifacts in version control</li> <li>\u2705 CD2: Fully automated deployment process</li> <li>\u2705 CD5: Trunk-based development support (Git workflow)</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>GitOps inverts the deployment model - clusters pull from Git, not pushed to</li> <li>Git becomes the single source of truth - all changes go through Git</li> <li>Automated sync reduces lead time - deployments happen in seconds/minutes</li> <li>Self-healing prevents drift - manual changes are automatically corrected</li> <li>Declarative state simplifies rollback - just revert the Git commit</li> </ol>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#real-world-impact","title":"Real-World Impact","text":"<p>\"After implementing GitOps with ArgoCD, we went from: - Deployment Frequency: 1x per week \u2192 10x per day - Lead Time: 2-3 hours \u2192 5-10 minutes - Change Failure Rate: 15% \u2192 3% - MTTR: 45 minutes \u2192 5 minutes (Git revert)</p> <p>The biggest win: junior developers can now deploy confidently because Git history provides instant rollback.\" - Platform Engineering Team, Fortune 500 Company</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#official-documentation","title":"Official Documentation","text":"<ul> <li>ArgoCD Documentation</li> <li>GitOps Principles</li> <li>CNCF GitOps Working Group</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Argo Rollouts - Progressive delivery</li> <li>ApplicationSets - Multi-cluster management</li> <li>Argo CD Image Updater - Automated image updates</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#video-tutorials","title":"Video Tutorials","text":"<ul> <li>\"GitOps with ArgoCD\" - CNCF YouTube</li> <li>\"Scaling ArgoCD\" - KubeCon talks</li> <li>\"Progressive Delivery Patterns\" - Argo Project</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#community","title":"Community","text":"<ul> <li>ArgoCD Slack</li> <li>CNCF Slack #gitops</li> <li>GitHub Discussions</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#module-completion","title":"\ud83c\udfc5 Module Completion","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#assessment-checklist","title":"Assessment Checklist","text":"<p>To complete this module, you must:</p> <ul> <li>[ ] Conceptual Understanding</li> <li>[ ] Explain the four GitOps principles</li> <li>[ ] Describe push vs pull deployment models</li> <li>[ ] Explain how GitOps improves DORA metrics</li> <li> <p>[ ] Understand ArgoCD architecture components</p> </li> <li> <p>[ ] Practical Skills</p> </li> <li>[ ] Deploy an application using ArgoCD CLI</li> <li>[ ] Create an ArgoCD Application manifest</li> <li>[ ] Configure automated sync with self-heal</li> <li>[ ] Make a Git change and observe automatic sync</li> <li>[ ] Perform a manual rollback using Git revert</li> <li> <p>[ ] Troubleshoot an OutOfSync application</p> </li> <li> <p>[ ] Hands-On Lab</p> </li> <li>[ ] Complete the guestbook deployment exercise</li> <li>[ ] Successfully scale application via Git commit</li> <li>[ ] View application in ArgoCD UI</li> <li> <p>[ ] Use ArgoCD CLI to inspect application state</p> </li> <li> <p>[ ] Quiz</p> </li> <li>[ ] Score 80% or higher on knowledge check questions</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#certification-credit","title":"Certification Credit","text":"<p>Upon completion, you earn: - 5 points toward Green Belt certification - Badge: \"GitOps Practitioner\" - Skill Unlocked: ArgoCD Application Management</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#green-belt-progress","title":"\ud83c\udf96\ufe0f Green Belt Progress","text":"<pre><code>Green Belt: GitOps &amp; Deployment\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModule 1: Introduction to GitOps \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 25% \u2713\nModule 2: Advanced ArgoCD Patterns \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\nModule 3: Multi-Cluster GitOps     \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\nModule 4: Progressive Delivery     \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n</code></pre> <p>Next Module Preview: Module 7 - Advanced ArgoCD Patterns (Helm, Kustomize, ApplicationSets)</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#lab-submission","title":"\ud83d\udcdd Lab Submission","text":"<p>To receive completion credit, submit the following artifacts:</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#required-artifacts","title":"Required Artifacts","text":"<ol> <li> <p>Screenshot of ArgoCD UI showing your deployed application in \"Synced\" and \"Healthy\" state</p> </li> <li> <p>Git Repository Link with:</p> </li> <li>Application manifests (deployment.yaml, service.yaml)</li> <li>ArgoCD Application manifest</li> <li> <p>Commit history showing at least 2 commits</p> </li> <li> <p>CLI Output showing:    <pre><code>argocd app list\nargocd app get &lt;your-app-name&gt;\nkubectl get all -l app=&lt;your-app&gt;\n</code></pre></p> </li> <li> <p>Written Reflection (200-300 words):</p> </li> <li>What surprised you about GitOps?</li> <li>How does this differ from your current deployment process?</li> <li>What challenges do you anticipate in production?</li> <li>How will this improve your DORA metrics?</li> </ol>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#submission-instructions","title":"Submission Instructions","text":"<pre><code># Create submission directory\nmkdir -p ~/fawkes-dojo/module6-submission\n\n# Add screenshots\ncp ~/screenshots/argocd-ui.png ~/fawkes-dojo/module6-submission/\n\n# Export CLI output\nargocd app get my-app &gt; ~/fawkes-dojo/module6-submission/app-status.txt\nkubectl get all -n default &gt; ~/fawkes-dojo/module6-submission/k8s-resources.txt\n\n# Create reflection document\nnano ~/fawkes-dojo/module6-submission/reflection.md\n\n# Create submission package\ncd ~/fawkes-dojo\ntar -czf module6-submission.tar.gz module6-submission/\n\n# Submit via Fawkes Dojo portal or email to dojo@fawkes-platform.io\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#bonus-challenges-optional","title":"\ud83d\ude80 Bonus Challenges (Optional)","text":"<p>For ambitious learners who want to go deeper:</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#challenge-1-multi-environment-pipeline","title":"Challenge 1: Multi-Environment Pipeline","text":"<p>Difficulty: \u2b50\u2b50\u2b50</p> <p>Deploy the same app to dev \u2192 staging \u2192 prod with promotion workflows: - Auto-sync in dev - Manual sync in staging (requires approval) - Sync window in prod (only during business hours) - Progressive rollout in prod (canary \u2192 full deployment)</p> <p>Hint: Use ArgoCD Projects and sync windows</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#challenge-2-secrets-management","title":"Challenge 2: Secrets Management","text":"<p>Difficulty: \u2b50\u2b50\u2b50\u2b50</p> <p>Integrate secrets management with GitOps: - Install Sealed Secrets or External Secrets Operator - Encrypt secrets before committing to Git - Have ArgoCD automatically sync encrypted secrets - Verify application can read decrypted secrets</p> <p>Hint: Research <code>bitnami-labs/sealed-secrets</code></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#challenge-3-custom-resource-deployment","title":"Challenge 3: Custom Resource Deployment","text":"<p>Difficulty: \u2b50\u2b50\u2b50\u2b50\u2b50</p> <p>Deploy a complex application with CRDs: - Install an operator (e.g., Postgres Operator) - Create custom resources (e.g., PostgresCluster) - Define custom health checks for ArgoCD - Implement backup/restore via Git</p> <p>Hint: Look at Zalando Postgres Operator</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#challenge-4-gitops-everything","title":"Challenge 4: GitOps Everything","text":"<p>Difficulty: \u2b50\u2b50\u2b50\u2b50\u2b50</p> <p>Bootstrap ArgoCD to manage itself: - Deploy ArgoCD via ArgoCD (meta!) - Manage all cluster infrastructure as code - Include cert-manager, ingress-nginx, monitoring stack - Implement disaster recovery via Git</p> <p>Hint: Research \"App of Apps\" pattern</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#community-support","title":"\ud83e\udd1d Community &amp; Support","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#get-help","title":"Get Help","text":"<p>Stuck on something? Don't stay blocked!</p> <ol> <li>Check the Troubleshooting Section (Part 5) - covers 90% of common issues</li> <li>ArgoCD Slack - #argo-cd channel, very responsive community</li> <li>Fawkes Mattermost - #dojo-green-belt channel</li> <li>Office Hours - Bi-weekly live Q&amp;A (see dojo calendar)</li> </ol>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#share-your-success","title":"Share Your Success","text":"<p>Completed the module? Share with the community!</p> <ul> <li>Tweet: \"Just completed @FawkesPlatform Dojo Module 6: GitOps with ArgoCD! \ud83c\udf89 #GitOps #Platform Engineering\"</li> <li>LinkedIn Post: Share your reflection and learnings</li> <li>Fawkes Blog: Write a guest post about your experience</li> <li>Mattermost: Share screenshots in #show-and-tell</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#help-others","title":"Help Others","text":"<p>The best way to solidify your learning: - Answer questions in #dojo-green-belt channel - Review peer submissions - Contribute troubleshooting tips to the docs - Create supplementary learning materials</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#module-metrics","title":"\ud83d\udcca Module Metrics","text":"<p>This module contributes to the following DORA metrics:</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#direct-impact","title":"Direct Impact","text":"<ul> <li>\u2705 Deployment Frequency: Automated sync enables 10x+ deployments</li> <li>\u2705 Lead Time for Changes: Commit-to-deploy reduced to minutes</li> <li>\u2705 Change Failure Rate: Git revert provides instant rollback</li> <li>\u2705 MTTR: Declarative state simplifies troubleshooting</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#dora-capabilities-unlocked","title":"DORA Capabilities Unlocked","text":"Capability Description Status CD1 Version control for production artifacts \u2705 Complete CD2 Automate deployment process \u2705 Complete CD3 Continuous integration \ud83d\udfe1 Partial CD5 Trunk-based development \u2705 Complete CD6 Test automation \u2b1c Next module CD7 Test data management \u2b1c Next module"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#your-learning-metrics","title":"Your Learning Metrics","text":"<p>Track your progress: <pre><code>Time Investment:     2 hours (target)\nConcepts Covered:    12\nHands-On Labs:       3\nCLI Commands Used:   15+\nResources Deployed:  5+ Kubernetes objects\nGit Commits:         3+ required\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#instructor-notes","title":"\ud83c\udf93 Instructor Notes","text":"<p>For Fawkes Dojo facilitators and mentors:</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#teaching-tips","title":"Teaching Tips","text":"<p>Common Student Struggles: 1. Git vs GitOps confusion - Emphasize GitOps is a deployment pattern, not Git itself 2. Sync vs Refresh - Use the car analogy: refresh checks the map, sync drives to the destination 3. When to use manual vs automated sync - Production = manual, dev/staging = automated</p> <p>Live Demo Checklist: - [ ] Show ArgoCD UI application graph visualization - [ ] Demonstrate real-time sync during Git push - [ ] Show self-heal correcting manual kubectl change - [ ] Demonstrate rollback via Git revert - [ ] Show sync failure and troubleshooting process</p> <p>Discussion Questions: - \"What happens if Git repository becomes unavailable?\" - \"How would you handle secrets in Git?\" - \"What's the blast radius if ArgoCD is compromised?\" - \"How does GitOps work with database migrations?\"</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#assessment-rubric","title":"Assessment Rubric","text":"Criteria Excellent (5) Good (4) Satisfactory (3) Needs Work (1-2) Conceptual Understanding Explains GitOps principles clearly with examples Explains principles correctly Basic understanding with gaps Confused concepts ArgoCD Application Creation Perfect YAML syntax, appropriate sync policies Working config with minor issues Functional but not optimized Errors or incomplete Troubleshooting Skills Independently debugs issues using CLI/UI Debugs with occasional hints Requires significant guidance Unable to troubleshoot Git Workflow Multiple meaningful commits, proper messages Clean commits, good messages Basic Git usage Poor Git practices Reflection Quality Deep insights, connects to DORA metrics Good observations Surface-level reflection Missing or inadequate <p>Passing Score: 15/25 points minimum</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#lab-environment-notes","title":"Lab Environment Notes","text":"<p>Resource Requirements: - Kubernetes cluster: 3 nodes, 4 vCPU, 8GB RAM each - ArgoCD: ~500MB memory, ~0.5 CPU - Sample apps: ~200MB memory total</p> <p>Pre-Lab Setup: <pre><code># Instructor should pre-create these\nkubectl create namespace argocd\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n\n# Create student Git repositories template\n# Provide each student with their repo URL\n</code></pre></p> <p>Cleanup: <pre><code># After lab session\nkubectl delete namespace argocd --cascade\nkubectl delete applications --all -n argocd\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#success-stories","title":"\ud83c\udf1f Success Stories","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#real-implementations","title":"Real Implementations","text":"<p>Company A - Financial Services - Before: 2-week release cycles, manual deployments - After: Daily deployments, 99.9% success rate - Impact: Lead time reduced from 2 weeks to 4 hours - Quote: \"GitOps gave us the confidence to deploy to production daily\"</p> <p>Company B - E-Commerce Platform - Before: Frequent production incidents from manual changes - After: Zero drift incidents in 6 months - Impact: MTTR reduced from 45 min to 3 min (Git revert) - Quote: \"Self-heal eliminated configuration drift completely\"</p> <p>Company C - Healthcare SaaS - Before: No audit trail, compliance challenges - After: Complete deployment history in Git - Impact: Passed SOC 2 audit with GitOps evidence - Quote: \"Git history became our deployment audit trail\"</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#module-changelog","title":"\ud83d\udcc5 Module Changelog","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#version-10-current","title":"Version 1.0 (Current)","text":"<ul> <li>Initial release</li> <li>Covers ArgoCD 2.9+</li> <li>Kubernetes 1.28+ compatible</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#planned-updates","title":"Planned Updates","text":"<ul> <li>v1.1 (Q1 2026): Add Argo Rollouts integration</li> <li>v1.2 (Q2 2026): Multi-cluster GitOps patterns</li> <li>v1.3 (Q3 2026): Advanced security (RBAC, SSO)</li> </ul>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#feedback-welcome","title":"Feedback Welcome","text":"<p>Found an issue or have suggestions? - Open issue: https://github.com/paruff/fawkes/issues - Email: dojo@fawkes-platform.io - Slack: #dojo-feedback</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#conclusion","title":"\ud83c\udfac Conclusion","text":"<p>Congratulations! You've completed Module 6 and learned the fundamentals of GitOps with ArgoCD.</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#whats-next","title":"What's Next?","text":"<p>You're now ready to: 1. \u2705 Deploy applications using GitOps patterns 2. \u2705 Configure ArgoCD sync policies appropriately 3. \u2705 Troubleshoot common ArgoCD issues 4. \u2705 Understand how GitOps improves DORA metrics</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#continue-your-journey","title":"Continue Your Journey","text":"<p>Module 7 Preview: Advanced ArgoCD Patterns - Helm chart deployments with ArgoCD - Kustomize advanced patterns - ApplicationSets for multi-cluster - App of Apps pattern - Monorepo vs polyrepo strategies</p> <p>Green Belt Roadmap: - Module 6: Introduction to GitOps \u2705 (You are here) - Module 7: Advanced ArgoCD Patterns - Module 8: Multi-Cluster &amp; Multi-Tenant GitOps - Module 9: Progressive Delivery with Argo Rollouts</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#take-action-now","title":"Take Action Now","text":"<ol> <li>Complete the lab - Deploy your first ArgoCD application today</li> <li>Submit artifacts - Get your completion badge</li> <li>Join the community - Share your experience in Mattermost</li> <li>Schedule Module 7 - Keep your momentum going</li> </ol>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#appendix-a-quick-reference","title":"\ud83d\udcd6 Appendix A: Quick Reference","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#essential-argocd-cli-commands","title":"Essential ArgoCD CLI Commands","text":"<pre><code># Login\nargocd login &lt;server&gt; --username admin --password &lt;pwd&gt;\n\n# Application Management\nargocd app create &lt;name&gt;          # Create application\nargocd app list                   # List all applications\nargocd app get &lt;name&gt;             # Get application details\nargocd app sync &lt;name&gt;            # Sync application\nargocd app delete &lt;name&gt;          # Delete application\n\n# Monitoring\nargocd app logs &lt;name&gt;            # View application logs\nargocd app diff &lt;name&gt;            # Show differences\nargocd app history &lt;name&gt;         # Show sync history\nargocd app manifests &lt;name&gt;       # Show generated manifests\n\n# Troubleshooting\nargocd app get &lt;name&gt; --refresh         # Refresh from Git\nargocd app get &lt;name&gt; --hard-refresh    # Hard refresh (clear cache)\nargocd app rollback &lt;name&gt; &lt;revision&gt;   # Rollback to revision\nargocd app terminate-op &lt;name&gt;          # Terminate sync operation\n\n# Repository Management\nargocd repo add &lt;url&gt;             # Add repository\nargocd repo list                  # List repositories\nargocd repo get &lt;url&gt;             # Get repository details\n\n# Project Management\nargocd proj create &lt;name&gt;         # Create project\nargocd proj list                  # List projects\nargocd proj get &lt;name&gt;            # Get project details\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#common-sync-policies","title":"Common Sync Policies","text":"<pre><code># Manual sync only\nsyncPolicy: {}\n\n# Auto-sync on Git changes\nsyncPolicy:\n  automated: {}\n\n# Auto-sync + correct manual changes\nsyncPolicy:\n  automated:\n    selfHeal: true\n\n# Auto-sync + delete removed resources\nsyncPolicy:\n  automated:\n    prune: true\n\n# Complete automation\nsyncPolicy:\n  automated:\n    prune: true\n    selfHeal: true\n    allowEmpty: false\n  syncOptions:\n  - CreateNamespace=true\n  - PruneLast=true\n  retry:\n    limit: 5\n    backoff:\n      duration: 5s\n      maxDuration: 3m\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#health-status-reference","title":"Health Status Reference","text":"Icon Status Meaning \ud83d\udfe2 Healthy All resources operational \ud83d\udfe1 Progressing Resources being created/updated \ud83d\udfe0 Degraded Some resources unhealthy \ud83d\udfe1 Suspended Application suspended \u26aa Missing Resources not found \ud83d\udd34 Unknown Cannot determine health"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#appendix-b-gitops-glossary","title":"\ud83d\udcd6 Appendix B: GitOps Glossary","text":"<p>Application: ArgoCD's representation of a Kubernetes application (set of resources)</p> <p>Automated Sync: ArgoCD automatically syncs when Git changes</p> <p>Declarative: Desired state is described, not the steps to achieve it</p> <p>Desired State: The state defined in Git repository</p> <p>Drift: Difference between desired state (Git) and actual state (cluster)</p> <p>GitOps: Operations paradigm using Git as single source of truth</p> <p>Health Status: ArgoCD's assessment of application health</p> <p>Live State: Current state of resources in the cluster</p> <p>Manual Sync: User must explicitly trigger sync operation</p> <p>Out of Sync: Desired state differs from live state</p> <p>Prune: Delete resources removed from Git</p> <p>Pull-Based: Cluster agents pull changes (vs push from CI/CD)</p> <p>Reconciliation: Process of making live state match desired state</p> <p>Self-Heal: Automatically correct manual changes to cluster</p> <p>Source of Truth: Authoritative definition of system state (Git)</p> <p>Sync: Operation that applies desired state to cluster</p> <p>Target State: Another term for desired state</p>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#appendix-c-troubleshooting-flowchart","title":"\ud83d\udcd6 Appendix C: Troubleshooting Flowchart","text":"<pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Issue Occurs    \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Check App Status\u2502\n                    \u2502  argocd app get  \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502                         \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   OutOfSync?   \u2502        \u2502  Unhealthy?   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502                         \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  argocd app    \u2502        \u2502  Check Pod    \u2502\n        \u2502  diff          \u2502        \u2502  Status       \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502                         \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  Manual Sync?  \u2502        \u2502  Check Logs   \u2502\n        \u2502  argocd app    \u2502        \u2502  kubectl logs \u2502\n        \u2502  sync          \u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n                \u2502                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502  Fix Issue    \u2502\n        \u2502  Hard Refresh? \u2502         \u2502  Update Git   \u2502\n        \u2502  --hard-refresh\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n                \u2502                         \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   Issue Resolved \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#appendix-d-integration-examples","title":"\ud83d\udcd6 Appendix D: Integration Examples","text":""},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#argocd-jenkins","title":"ArgoCD + Jenkins","text":"<pre><code>// Jenkinsfile snippet\nstage('Update Manifest') {\n    steps {\n        script {\n            sh \"\"\"\n                git clone https://github.com/org/manifests.git\n                cd manifests\n                sed -i 's|image:.*|image: ${DOCKER_IMAGE}:${BUILD_NUMBER}|' deployment.yaml\n                git add deployment.yaml\n                git commit -m \"Update image to ${BUILD_NUMBER}\"\n                git push\n            \"\"\"\n            // ArgoCD will automatically sync\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#argocd-github-actions","title":"ArgoCD + GitHub Actions","text":"<pre><code>name: Update Manifest\non:\n  push:\n    branches: [main]\n\njobs:\n  update:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout manifest repo\n        uses: actions/checkout@v3\n        with:\n          repository: org/manifests\n          token: ${{ secrets.MANIFEST_TOKEN }}\n\n      - name: Update image tag\n        run: |\n          sed -i \"s|image:.*|image: myapp:${{ github.sha }}|\" deployment.yaml\n          git config user.name \"GitHub Actions\"\n          git config user.email \"actions@github.com\"\n          git add deployment.yaml\n          git commit -m \"Update to ${{ github.sha }}\"\n          git push\n</code></pre>"},{"location":"dojo/modules/green-belt/module-09-gitops-argocd/#argocd-slack-notifications","title":"ArgoCD + Slack Notifications","text":"<pre><code># argocd-notifications ConfigMap\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-notifications-cm\ndata:\n  service.slack: |\n    token: $slack-token\n\n  template.app-deployed: |\n    message: |\n      \u2705 *{{.app.metadata.name}}* deployed successfully\n      \ud83d\udce6 Revision: `{{.app.status.sync.revision}}`\n      \ud83d\udd17 &lt;{{.context.argocdUrl}}/applications/{{.app.metadata.name}}|View Application&gt;\n\n  template.app-health-degraded: |\n    message: |\n      \u26a0\ufe0f *{{.app.metadata.name}}* health degraded\n      Status: {{.app.status.health.status}}\n      \ud83d\udd17 &lt;{{.context.argocdUrl}}/applications/{{.app.metadata.name}}|View Application&gt;\n\n  trigger.on-deployed: |\n    - when: app.status.operationState.phase in ['Succeeded']\n      send: [app-deployed]\n\n  trigger.on-health-degraded: |\n    - when: app.status.health.status == 'Degraded'\n      send: [app-health-degraded]\n</code></pre> <p>\ud83c\udf89 Module 6 Complete!</p> <p>You've mastered the fundamentals of GitOps with ArgoCD. You're now equipped to deploy applications declaratively and improve your DORA metrics through automated, Git-driven deployments.</p> <p>Remember: GitOps is not just about tools\u2014it's about culture. It's about trusting Git as your single source of truth and embracing automation over manual intervention.</p> <p>See you in Module 7: Advanced ArgoCD Patterns! \ud83d\ude80</p> <p>Fawkes Dojo - Where Platform Engineers Are Forged Version 1.0 | Last Updated: October 2025 License: MIT | https://github.com/paruff/fawkes</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/","title":"Fawkes Dojo Module 10: Deployment Strategies","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe2 Green Belt - GitOps &amp; Deployment Module: 2 of 4 (Green Belt) Duration: 60 minutes Difficulty: Intermediate Prerequisites: - Module 9: GitOps with ArgoCD complete - Understanding of Kubernetes Deployments - Familiarity with service routing - Basic knowledge of load balancing</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Understand different deployment strategies and when to use each</li> <li>\u2705 Implement blue-green deployments with Kubernetes</li> <li>\u2705 Configure canary deployments with traffic splitting</li> <li>\u2705 Execute rolling updates with zero downtime</li> <li>\u2705 Implement recreate deployments for stateful apps</li> <li>\u2705 Use feature flags for progressive rollouts</li> <li>\u2705 Choose the right strategy for different scenarios</li> </ol> <p>DORA Capabilities Addressed: - \u2713 CD2: Automate deployment process (advanced) - \u2713 Work in Small Batches - \u2713 Team Experimentation</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-1-deployment-strategy-overview","title":"\ud83d\udcd6 Part 1: Deployment Strategy Overview","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#the-problem-high-risk-deployments","title":"The Problem: High-Risk Deployments","text":"<p>Traditional \"Big Bang\" deployment: <pre><code>Old Version (100% traffic) \u2192 SWITCH \u2192 New Version (100% traffic)\n                                \u2193\n                          If something breaks:\n                          ALL users affected\n                          Immediate rollback needed\n                          High stress, high risk\n</code></pre></p> <p>Result: Fear of deploying, slow release cycles, weekend deployments</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#the-solution-progressive-deployment-strategies","title":"The Solution: Progressive Deployment Strategies","text":"<p>Different strategies for different needs:</p> Strategy Risk Downtime Complexity Best For Recreate High Yes Low Development, stateful apps Rolling Update Medium No Low Most applications Blue-Green Low No Medium Production, quick rollback Canary Very Low No High Critical apps, gradual rollout A/B Testing Very Low No High Feature testing, experiments"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-2-blue-green-deployment","title":"\ud83d\udd35\ud83d\udfe2 Part 2: Blue-Green Deployment","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#what-is-blue-green","title":"What is Blue-Green?","text":"<p>Run two identical production environments: - Blue: Current production version - Green: New version being deployed</p> <p>Switch traffic from Blue \u2192 Green when ready.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Users     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Load Balancer/Router      \u2502\n\u2502   (Initially \u2192 Blue)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n   \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510\n   \u2502        \u2502\n\u250c\u2500\u2500\u25bc\u2500\u2500\u2510  \u250c\u2500\u25bc\u2500\u2500\u2500\u2510\n\u2502Blue \u2502  \u2502Green\u2502\n\u2502v1.0 \u2502  \u2502v2.0 \u2502\n\u2502100% \u2502  \u2502 0%  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2518\n\n[Deploy &amp; Test Green]\n        \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Switch Traffic     \u2502\n\u2502   Blue \u2192 Green       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Blue \u2502  \u2502Green\u2502\n\u2502v1.0 \u2502  \u2502v2.0 \u2502\n\u2502 0%  \u2502  \u2502100% \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#benefits","title":"Benefits","text":"<ul> <li>\u2705 Instant rollback (switch back to Blue)</li> <li>\u2705 Zero downtime</li> <li>\u2705 Test in production before switching</li> <li>\u2705 Simple conceptually</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#drawbacks","title":"Drawbacks","text":"<ul> <li>\u274c 2x infrastructure cost during deployment</li> <li>\u274c Database migrations tricky</li> <li>\u274c All-or-nothing switch</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-3-hands-on-lab-blue-green-deployment","title":"\ud83d\udee0\ufe0f Part 3: Hands-On Lab - Blue-Green Deployment","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#step-1-deploy-blue-environment","title":"Step 1: Deploy Blue Environment","text":"<p>Create <code>blue-deployment.yaml</code>:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-blue\n  labels:\n    app: myapp\n    version: blue\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n      version: blue\n  template:\n    metadata:\n      labels:\n        app: myapp\n        version: blue\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v1.0\n        ports:\n        - containerPort: 8080\n        env:\n        - name: VERSION\n          value: \"v1.0-blue\"\n        resources:\n          requests:\n            memory: \"128Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"256Mi\"\n            cpu: \"200m\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\nspec:\n  selector:\n    app: myapp\n    version: blue  # Points to blue initially\n  ports:\n  - port: 80\n    targetPort: 8080\n  type: LoadBalancer\n</code></pre> <p>Deploy: <pre><code>kubectl apply -f blue-deployment.yaml\n\n# Verify\nkubectl get pods -l version=blue\nkubectl get svc myapp\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#step-2-deploy-green-environment","title":"Step 2: Deploy Green Environment","text":"<p>Create <code>green-deployment.yaml</code>:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-green\n  labels:\n    app: myapp\n    version: green\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n      version: green\n  template:\n    metadata:\n      labels:\n        app: myapp\n        version: green\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v2.0  # New version\n        ports:\n        - containerPort: 8080\n        env:\n        - name: VERSION\n          value: \"v2.0-green\"\n        resources:\n          requests:\n            memory: \"128Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"256Mi\"\n            cpu: \"200m\"\n</code></pre> <p>Deploy Green (without switching traffic): <pre><code>kubectl apply -f green-deployment.yaml\n\n# Verify both running\nkubectl get pods -l app=myapp\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#step-3-test-green-environment","title":"Step 3: Test Green Environment","text":"<p>Create a test service to access Green directly:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-green-test\nspec:\n  selector:\n    app: myapp\n    version: green\n  ports:\n  - port: 80\n    targetPort: 8080\n  type: LoadBalancer\n</code></pre> <p>Test Green: <pre><code>kubectl apply -f green-test-service.yaml\n\n# Get test service URL\nTEST_URL=$(kubectl get svc myapp-green-test -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')\n\n# Run tests\ncurl http://$TEST_URL/health\ncurl http://$TEST_URL/version\n# Should return: v2.0-green\n\n# Run load test\nab -n 1000 -c 10 http://$TEST_URL/\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#step-4-switch-traffic-to-green","title":"Step 4: Switch Traffic to Green","text":"<p>Update the main service selector:</p> <pre><code># Patch service to point to green\nkubectl patch service myapp -p '{\"spec\":{\"selector\":{\"version\":\"green\"}}}'\n\n# Verify switch\nkubectl get svc myapp -o yaml | grep version\n# Should show: version: green\n\n# Test from user perspective\nPROD_URL=$(kubectl get svc myapp -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')\ncurl http://$PROD_URL/version\n# Should return: v2.0-green\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#step-5-rollback-if-needed","title":"Step 5: Rollback if Needed","text":"<p>If issues found, instant rollback:</p> <pre><code># Switch back to blue\nkubectl patch service myapp -p '{\"spec\":{\"selector\":{\"version\":\"blue\"}}}'\n\n# Verify\ncurl http://$PROD_URL/version\n# Should return: v1.0-blue\n\n# Total rollback time: ~5 seconds!\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#step-6-clean-up-old-version","title":"Step 6: Clean Up Old Version","text":"<p>Once confident in Green:</p> <pre><code># Scale down blue\nkubectl scale deployment myapp-blue --replicas=0\n\n# Or delete entirely\nkubectl delete deployment myapp-blue\nkubectl delete service myapp-green-test\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-4-rolling-update-deployment","title":"\ud83d\udd04 Part 4: Rolling Update Deployment","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#what-is-rolling-update","title":"What is Rolling Update?","text":"<p>Gradually replace pods with new version, one (or few) at a time.</p> <pre><code>Initial State:\n[v1] [v1] [v1] [v1] [v1]  (5 pods)\n\nStep 1:\n[v1] [v1] [v1] [v1] [v2]  (1 pod updated)\n                    \u2191\n                 New pod\n\nStep 2:\n[v1] [v1] [v1] [v2] [v2]  (2 pods updated)\n\nStep 3:\n[v1] [v1] [v2] [v2] [v2]  (3 pods updated)\n\nStep 4:\n[v1] [v2] [v2] [v2] [v2]  (4 pods updated)\n\nStep 5:\n[v2] [v2] [v2] [v2] [v2]  (All pods updated)\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#benefits_1","title":"Benefits","text":"<ul> <li>\u2705 Zero downtime</li> <li>\u2705 Gradual rollout (detect issues early)</li> <li>\u2705 No extra infrastructure needed</li> <li>\u2705 Built into Kubernetes</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#drawbacks_1","title":"Drawbacks","text":"<ul> <li>\u274c Both versions run simultaneously</li> <li>\u274c Rollback slower than blue-green</li> <li>\u274c May cause issues if versions incompatible</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#implementing-rolling-update","title":"Implementing Rolling Update","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  replicas: 5\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1        # Max 1 extra pod during update\n      maxUnavailable: 1  # Max 1 pod can be unavailable\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v2.0\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 3\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#controlling-rolling-update-speed","title":"Controlling Rolling Update Speed","text":"<pre><code>strategy:\n  type: RollingUpdate\n  rollingUpdate:\n    maxSurge: 2        # Update 2 pods at a time\n    maxUnavailable: 0  # Keep all pods available\n\n# This means:\n# - Always maintain at least 5 pods available\n# - Can temporarily have up to 7 pods (5 + 2 surge)\n# - Faster rollout but more resources used\n</code></pre> <p>Conservative rollout: <pre><code>strategy:\n  type: RollingUpdate\n  rollingUpdate:\n    maxSurge: 1\n    maxUnavailable: 0\n\n# This means:\n# - Update only 1 pod at a time\n# - Never reduce capacity\n# - Slower but safer\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#performing-rolling-update","title":"Performing Rolling Update","text":"<pre><code># Update image version\nkubectl set image deployment/myapp myapp=myapp:v2.0\n\n# Watch the rollout\nkubectl rollout status deployment/myapp\n\n# Expected output:\nWaiting for deployment \"myapp\" rollout to finish: 1 out of 5 new replicas have been updated...\nWaiting for deployment \"myapp\" rollout to finish: 2 out of 5 new replicas have been updated...\nWaiting for deployment \"myapp\" rollout to finish: 3 out of 5 new replicas have been updated...\nWaiting for deployment \"myapp\" rollout to finish: 4 out of 5 new replicas have been updated...\nWaiting for deployment \"myapp\" rollout to finish: 4 of 5 updated replicas are available...\ndeployment \"myapp\" successfully rolled out\n\n# Verify\nkubectl get pods -l app=myapp\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#pausing-and-resuming-rollout","title":"Pausing and Resuming Rollout","text":"<pre><code># Start rollout\nkubectl set image deployment/myapp myapp=myapp:v2.0\n\n# Pause after first pod\nkubectl rollout pause deployment/myapp\n\n# Verify mixed versions\nkubectl get pods -l app=myapp -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.spec.containers[0].image}{\"\\n\"}{end}'\n\n# Run smoke tests on new version\n# If good, resume\nkubectl rollout resume deployment/myapp\n\n# If bad, rollback\nkubectl rollout undo deployment/myapp\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-5-canary-deployment","title":"\ud83d\udc26 Part 5: Canary Deployment","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#what-is-canary","title":"What is Canary?","text":"<p>Release new version to small subset of users first, gradually increase if successful.</p> <pre><code>Phase 1: 5% canary\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n95% \u2192 [v1] [v1] [v1] ... (19 pods)\n 5% \u2192 [v2]                (1 pod)\n\nPhase 2: 25% canary (if healthy)\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n75% \u2192 [v1] [v1] [v1] ... (15 pods)\n25% \u2192 [v2] [v2] [v2] ... (5 pods)\n\nPhase 3: 50% canary\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n50% \u2192 [v1] [v1] ... (10 pods)\n50% \u2192 [v2] [v2] ... (10 pods)\n\nPhase 4: 100% canary\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  0% \u2192 (Blue removed)\n100% \u2192 [v2] [v2] ... (20 pods)\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#benefits_2","title":"Benefits","text":"<ul> <li>\u2705 Lowest risk (expose to small % first)</li> <li>\u2705 Real user feedback before full rollout</li> <li>\u2705 Can monitor metrics for issues</li> <li>\u2705 Gradual, controlled rollout</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#drawbacks_2","title":"Drawbacks","text":"<ul> <li>\u274c Complex to implement correctly</li> <li>\u274c Need sophisticated traffic routing</li> <li>\u274c Requires monitoring and analysis</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#canary-with-native-kubernetes","title":"Canary with Native Kubernetes","text":"<p>Basic canary using ReplicaSet ratios:</p> <pre><code># Deploy baseline (v1.0)\nkubectl apply -f - &lt;&lt;EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-baseline\nspec:\n  replicas: 19  # 95% of traffic\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n        version: v1.0\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v1.0\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-canary\nspec:\n  replicas: 1  # 5% of traffic\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n        version: v2.0\n        canary: \"true\"\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v2.0\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\nspec:\n  selector:\n    app: myapp  # Matches both versions\n  ports:\n  - port: 80\n    targetPort: 8080\nEOF\n</code></pre> <p>Problem with this approach: Traffic split not guaranteed (depends on load balancer).</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#canary-with-istio-advanced","title":"Canary with Istio (Advanced)","text":"<p>For precise traffic control:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: myapp\nspec:\n  hosts:\n  - myapp\n  http:\n  - match:\n    - headers:\n        x-canary:\n          exact: \"true\"\n    route:\n    - destination:\n        host: myapp\n        subset: canary\n  - route:\n    - destination:\n        host: myapp\n        subset: baseline\n      weight: 95\n    - destination:\n        host: myapp\n        subset: canary\n      weight: 5\n---\napiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: myapp\nspec:\n  host: myapp\n  subsets:\n  - name: baseline\n    labels:\n      version: v1.0\n  - name: canary\n    labels:\n      version: v2.0\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-6-recreate-deployment","title":"\ud83d\udd28 Part 6: Recreate Deployment","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#what-is-recreate","title":"What is Recreate?","text":"<p>Shut down all old pods, then start new ones.</p> <pre><code>Phase 1: Running\n[v1] [v1] [v1] [v1] [v1]\n\nPhase 2: Terminate all\n[  ] [  ] [  ] [  ] [  ]  \u2190 DOWNTIME\n\nPhase 3: Start new\n[v2] [v2] [v2] [v2] [v2]\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#when-to-use","title":"When to Use","text":"<ul> <li>\u2705 Development/test environments</li> <li>\u2705 Stateful apps that can't run mixed versions</li> <li>\u2705 Database migrations that break compatibility</li> <li>\u2705 When downtime is acceptable</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#drawbacks_3","title":"Drawbacks","text":"<ul> <li>\u274c Downtime (seconds to minutes)</li> <li>\u274c All-or-nothing deployment</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#implementation","title":"Implementation","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  replicas: 3\n  strategy:\n    type: Recreate  # Simple!\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v2.0\n</code></pre> <pre><code># Update deployment\nkubectl apply -f deployment.yaml\n\n# Observe behavior\nkubectl get pods -w\n\n# Output:\nmyapp-v1-abc  1/1  Running      0  5m\nmyapp-v1-def  1/1  Running      0  5m\nmyapp-v1-ghi  1/1  Running      0  5m\nmyapp-v1-abc  1/1  Terminating  0  5m\nmyapp-v1-def  1/1  Terminating  0  5m\nmyapp-v1-ghi  1/1  Terminating  0  5m\nmyapp-v1-abc  0/1  Terminating  0  5m\nmyapp-v1-def  0/1  Terminating  0  5m\nmyapp-v1-ghi  0/1  Terminating  0  5m\nmyapp-v2-jkl  0/1  Pending      0  0s\nmyapp-v2-mno  0/1  Pending      0  0s\nmyapp-v2-pqr  0/1  Pending      0  0s\nmyapp-v2-jkl  0/1  ContainerCreating  0  1s\nmyapp-v2-mno  0/1  ContainerCreating  0  1s\nmyapp-v2-pqr  0/1  ContainerCreating  0  1s\nmyapp-v2-jkl  1/1  Running      0  10s\nmyapp-v2-mno  1/1  Running      0  10s\nmyapp-v2-pqr  1/1  Running      0  10s\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-7-choosing-the-right-strategy","title":"\ud83c\udfaf Part 7: Choosing the Right Strategy","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#decision-matrix","title":"Decision Matrix","text":"Scenario Recommended Strategy Reason Development environment Recreate or Rolling Fast, simple Stateless web app Rolling Update or Blue-Green Zero downtime, safe Critical production app Canary Gradual, low risk Microservice Rolling Update Standard, works well Database migration Blue-Green or Recreate Handle schema changes Breaking API changes Blue-Green with versioning Quick rollback Feature testing Canary or A/B Real user feedback Overnight batch job Recreate Downtime acceptable"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#example-decision-tree","title":"Example Decision Tree","text":"<pre><code>START\n  \u2502\n  \u25bc\nCan you accept downtime?\n  \u2502\n  \u251c\u2500 YES \u2192 Recreate \u2705\n  \u2502\n  \u2514\u2500 NO\n      \u2502\n      \u25bc\n  Is this super critical?\n      \u2502\n      \u251c\u2500 YES \u2192 Canary \ud83d\udc26\n      \u2502\n      \u2514\u2500 NO\n          \u2502\n          \u25bc\n      Need instant rollback?\n          \u2502\n          \u251c\u2500 YES \u2192 Blue-Green \ud83d\udd35\ud83d\udfe2\n          \u2502\n          \u2514\u2500 NO \u2192 Rolling Update \ud83d\udd04\n</code></pre>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-8-practical-exercise","title":"\ud83d\udcaa Part 8: Practical Exercise","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#exercise-implement-multiple-deployment-strategies","title":"Exercise: Implement Multiple Deployment Strategies","text":"<p>Objective: Deploy same application using 3 different strategies</p> <p>Scenario: You have a web application with: - Frontend (stateless) - API (stateless) - Database (stateful)</p> <p>Requirements: 1. Deploy frontend with Blue-Green 2. Deploy API with Canary (10% \u2192 50% \u2192 100%) 3. Deploy database with Recreate (maintenance window) 4. Document decision reasoning 5. Demonstrate rollback for each</p> <p>Starter Template:</p> <pre><code># frontend-bluegreen.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend-blue\n# TODO: Complete blue-green setup\n\n---\n# api-canary.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-baseline\n# TODO: Complete canary setup\n\n---\n# database-recreate.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: database\nspec:\n  strategy:\n    type: Recreate\n# TODO: Complete recreate setup\n</code></pre> <p>Validation Criteria: - [ ] Frontend: Blue and Green deployed, traffic switchable - [ ] API: Canary at 10%, metrics monitored, promotable - [ ] Database: Recreate strategy, downtime measured - [ ] All: Rollback procedures documented and tested - [ ] Decision matrix: Justify each strategy choice</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-9-knowledge-check","title":"\ud83c\udf93 Part 9: Knowledge Check","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#quiz-questions","title":"Quiz Questions","text":"<ol> <li>What is the main benefit of Blue-Green deployment?</li> <li>[ ] Lowest cost</li> <li>[x] Instant rollback</li> <li>[ ] No infrastructure changes</li> <li> <p>[ ] Automatic testing</p> </li> <li> <p>In a Rolling Update, what does maxSurge: 2 mean?</p> </li> <li>[ ] Maximum 2 pods total</li> <li>[ ] Update 2 pods per minute</li> <li>[x] Can have 2 extra pods temporarily during update</li> <li> <p>[ ] Must have 2 pods available</p> </li> <li> <p>When should you use Recreate strategy?</p> </li> <li>[ ] Production critical apps</li> <li>[ ] Never, it's deprecated</li> <li>[x] When downtime is acceptable or for incompatible versions</li> <li> <p>[ ] Only for initial deployment</p> </li> <li> <p>What's the primary advantage of Canary deployment?</p> </li> <li>[ ] Fastest deployment</li> <li>[ ] Simplest to implement</li> <li>[x] Lowest risk with gradual rollout</li> <li> <p>[ ] Requires least infrastructure</p> </li> <li> <p>In Blue-Green, when do you delete the Blue environment?</p> </li> <li>[ ] Immediately after switching</li> <li>[ ] Never</li> <li>[x] After Green is validated in production</li> <li> <p>[ ] Before deploying Green</p> </li> <li> <p>What's required for precise canary traffic control?</p> </li> <li>[ ] Multiple data centers</li> <li>[x] Advanced routing (like Istio or ingress controller)</li> <li>[ ] Minimum 100 pods</li> <li> <p>[ ] Manual intervention</p> </li> <li> <p>Which strategy has the highest infrastructure cost during deployment?</p> </li> <li>[x] Blue-Green</li> <li>[ ] Rolling Update</li> <li>[ ] Canary</li> <li> <p>[ ] Recreate</p> </li> <li> <p>What's the main drawback of Rolling Update?</p> </li> <li>[ ] Requires downtime</li> <li>[ ] Very complex</li> <li>[x] Both versions run simultaneously</li> <li>[ ] Can't rollback</li> </ol> <p>Answers: 1-B, 2-C, 3-C, 4-C, 5-C, 6-B, 7-A, 8-C</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#part-10-module-summary-next-steps","title":"\ud83c\udfaf Part 10: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#what-you-learned","title":"What You Learned","text":"<p>\u2705 Deployment Strategies: Blue-Green, Rolling, Canary, Recreate \u2705 Blue-Green: Instant rollback with parallel environments \u2705 Rolling Update: Gradual replacement with zero downtime \u2705 Canary: Progressive rollout with risk mitigation \u2705 Decision Making: Choose right strategy for scenario \u2705 Implementation: Hands-on with Kubernetes</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#dora-capabilities-achieved","title":"DORA Capabilities Achieved","text":"<ul> <li>\u2705 CD2: Automated deployment (advanced patterns)</li> <li>\u2705 Work in Small Batches: Gradual rollouts</li> <li>\u2705 Team Experimentation: Safe testing in production</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>No one-size-fits-all - Different apps need different strategies</li> <li>Balance risk and complexity - More safety = more complexity</li> <li>Zero downtime is achievable - Most strategies support it</li> <li>Rollback is critical - Always have an escape hatch</li> <li>Test in production - Canary and Blue-Green enable this safely</li> </ol>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#real-world-impact","title":"Real-World Impact","text":"<p>\"After implementing deployment strategies: - Deployment confidence: 60% \u2192 95% - Production incidents from deploys: 15 per month \u2192 2 per month - Rollback time: 30 minutes \u2192 30 seconds (Blue-Green) - User impact from bad deploys: 100% \u2192 5% (Canary)</p> <p>We now deploy during business hours with confidence.\" - Platform Team, Financial Services</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#documentation","title":"Documentation","text":"<ul> <li>Kubernetes Deployment Strategies</li> <li>Istio Traffic Management</li> <li>Argo Rollouts</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#tools","title":"Tools","text":"<ul> <li>Flagger - Progressive delivery operator</li> <li>Spinnaker - Multi-cloud CD platform</li> <li>Argo Rollouts - Advanced K8s deployments</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#module-completion","title":"\ud83c\udfc5 Module Completion","text":""},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#assessment-checklist","title":"Assessment Checklist","text":"<ul> <li>[ ] Conceptual Understanding</li> <li>[ ] Explain each deployment strategy</li> <li>[ ] Choose appropriate strategy for scenarios</li> <li> <p>[ ] Understand trade-offs</p> </li> <li> <p>[ ] Practical Skills</p> </li> <li>[ ] Implement Blue-Green deployment</li> <li>[ ] Configure Rolling Update parameters</li> <li>[ ] Set up basic Canary deployment</li> <li> <p>[ ] Execute rollback procedures</p> </li> <li> <p>[ ] Hands-On Lab</p> </li> <li>[ ] Deploy using multiple strategies</li> <li>[ ] Switch traffic between versions</li> <li> <p>[ ] Perform successful rollback</p> </li> <li> <p>[ ] Quiz</p> </li> <li>[ ] Score 80% or higher (6/8 questions)</li> </ul>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#certification-credit","title":"Certification Credit","text":"<p>Upon completion, you earn: - 5 points toward Green Belt certification (50% complete) - Badge: \"Deployment Strategist\" - Skill Unlocked: Advanced Deployment Patterns</p>"},{"location":"dojo/modules/green-belt/module-10-deployment-strategies/#green-belt-progress","title":"\ud83c\udf96\ufe0f Green Belt Progress","text":"<pre><code>Green Belt: GitOps &amp; Deployment\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModule 9:  GitOps with ArgoCD     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 25% \u2713\nModule 10: Deployment Strategies  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 50% \u2713\nModule 11: Progressive Delivery   \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\nModule 12: Rollback &amp; Incident    \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n</code></pre> <p>Halfway to Green Belt! \ud83c\udf89</p> <p>Next Module Preview: Module 11 - Progressive Delivery (Automated canary analysis, metrics-driven rollout, Argo Rollouts)</p> <p>\ud83c\udf89 Congratulations! You now know how to deploy applications safely using multiple strategies!</p> <p>Ready for Module 11? Let's learn Progressive Delivery with automated analysis! \ud83d\ude80</p> <p>Fawkes Dojo - Where Platform Engineers Are Forged Version 1.0 | Last Updated: October 2025 License: MIT | https://github.com/paruff/fawkes</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/","title":"Fawkes Dojo Module 11: Progressive Delivery","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe2 Green Belt - GitOps &amp; Deployment Module: 3 of 4 (Green Belt) Duration: 60 minutes Difficulty: Advanced Prerequisites: - Module 9 &amp; 10 complete - Understanding of canary deployments - Familiarity with Prometheus metrics - Basic knowledge of automated analysis</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Understand progressive delivery vs continuous delivery</li> <li>\u2705 Implement automated canary analysis with metrics</li> <li>\u2705 Configure Argo Rollouts for progressive deployment</li> <li>\u2705 Set up automatic promotion and rollback based on metrics</li> <li>\u2705 Use analysis templates for decision-making</li> <li>\u2705 Implement traffic shaping and weighted routing</li> <li>\u2705 Monitor and visualize progressive rollouts</li> </ol> <p>DORA Capabilities Addressed: - \u2713 CD2: Automate deployment process (fully automated) - \u2713 Team Experimentation - \u2713 Monitoring and Observability (deployment metrics)</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-1-what-is-progressive-delivery","title":"\ud83d\udcd6 Part 1: What is Progressive Delivery?","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#continuous-delivery-vs-progressive-delivery","title":"Continuous Delivery vs Progressive Delivery","text":"<p>Continuous Delivery: <pre><code>Code \u2192 Build \u2192 Test \u2192 Deploy to Production\n                              \u2193\n                    All users get new version\n                    Hope it works! \ud83e\udd1e\n</code></pre></p> <p>Progressive Delivery: <pre><code>Code \u2192 Build \u2192 Test \u2192 Deploy to 5% users\n                              \u2193\n                        Analyze metrics\n                              \u2193\n                     Healthy? \u2192 Deploy to 25%\n                              \u2193\n                        Analyze metrics\n                              \u2193\n                     Healthy? \u2192 Deploy to 50%\n                              \u2193\n                        Analyze metrics\n                              \u2193\n                     Healthy? \u2192 Deploy to 100%\n\n                     Unhealthy? \u2192 Automatic Rollback \u2705\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#key-differences","title":"Key Differences","text":"Aspect Continuous Delivery Progressive Delivery Deployment All-at-once Gradual, phased Risk High (all users affected) Low (small % affected) Rollback Manual, reactive Automated, proactive Analysis Post-deployment During deployment Decision Human judgment Metrics-driven Speed Fast (minutes) Controlled (hours)"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#progressive-delivery-components","title":"Progressive Delivery Components","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Progressive Delivery System                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502     Traffic Management                       \u2502  \u2502\n\u2502  \u2502  \u2022 Istio / Nginx / Traefik                  \u2502  \u2502\n\u2502  \u2502  \u2022 Weighted routing (5% \u2192 25% \u2192 50% \u2192 100%)\u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                   \u2502                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502     Metrics Collection                       \u2502  \u2502\n\u2502  \u2502  \u2022 Prometheus (error rate, latency, etc.)   \u2502  \u2502\n\u2502  \u2502  \u2022 Custom business metrics                  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                   \u2502                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502     Analysis Engine                          \u2502  \u2502\n\u2502  \u2502  \u2022 Argo Rollouts / Flagger                  \u2502  \u2502\n\u2502  \u2502  \u2022 Compares baseline vs canary              \u2502  \u2502\n\u2502  \u2502  \u2022 Automated decision: promote or rollback  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                   \u2502                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502     Notification &amp; Observability             \u2502  \u2502\n\u2502  \u2502  \u2022 Slack / PagerDuty alerts                 \u2502  \u2502\n\u2502  \u2502  \u2022 Grafana dashboards                       \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-2-argo-rollouts","title":"\ud83c\udfaf Part 2: Argo Rollouts","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#what-is-argo-rollouts","title":"What is Argo Rollouts?","text":"<p>Argo Rollouts is a Kubernetes controller that provides advanced deployment strategies with automated analysis.</p> <p>Key Features: - \ud83c\udfaf Canary deployments with traffic shaping - \ud83d\udd35\ud83d\udfe2 Blue-Green deployments - \ud83d\udcca Automated metric analysis - \u23f8\ufe0f Manual approval gates - \ud83d\udd04 Automatic rollback on failure - \ud83d\udcc8 Integration with Prometheus, Datadog, etc.</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#installing-argo-rollouts","title":"Installing Argo Rollouts","text":"<pre><code># Install Argo Rollouts controller\nkubectl create namespace argo-rollouts\nkubectl apply -n argo-rollouts -f https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml\n\n# Install kubectl plugin\ncurl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-linux-amd64\nchmod +x kubectl-argo-rollouts-linux-amd64\nsudo mv kubectl-argo-rollouts-linux-amd64 /usr/local/bin/kubectl-argo-rollouts\n\n# Verify installation\nkubectl argo rollouts version\n</code></pre>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-3-hands-on-lab-progressive-canary","title":"\ud83d\udee0\ufe0f Part 3: Hands-On Lab - Progressive Canary","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#step-1-deploy-baseline-application","title":"Step 1: Deploy Baseline Application","text":"<p>Create <code>rollout.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\nspec:\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\n    name: http\n  selector:\n    app: myapp\n---\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: myapp\nspec:\n  replicas: 5\n  strategy:\n    canary:\n      steps:\n      - setWeight: 20    # Step 1: 20% traffic to canary\n      - pause: {duration: 2m}  # Wait 2 minutes\n      - setWeight: 40    # Step 2: 40% traffic\n      - pause: {duration: 2m}\n      - setWeight: 60    # Step 3: 60% traffic\n      - pause: {duration: 2m}\n      - setWeight: 80    # Step 4: 80% traffic\n      - pause: {duration: 2m}\n      # Step 5: 100% (automatic)\n  revisionHistoryLimit: 2\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: argoproj/rollouts-demo:blue\n        ports:\n        - name: http\n          containerPort: 8080\n          protocol: TCP\n        resources:\n          requests:\n            memory: 32Mi\n            cpu: 5m\n</code></pre> <p>Deploy: <pre><code>kubectl apply -f rollout.yaml\n\n# Check status\nkubectl argo rollouts get rollout myapp --watch\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#step-2-update-to-trigger-rollout","title":"Step 2: Update to Trigger Rollout","text":"<pre><code># Update image to new version\nkubectl argo rollouts set image myapp myapp=argoproj/rollouts-demo:yellow\n\n# Watch the progressive rollout\nkubectl argo rollouts get rollout myapp --watch\n</code></pre> <p>Expected Output: <pre><code>Name:            myapp\nNamespace:       default\nStatus:          \u0965 Paused\nMessage:         CanaryPauseStep\nStrategy:        Canary\n  Step:          1/8\n  SetWeight:     20\n  ActualWeight:  20\nImages:          argoproj/rollouts-demo:blue (stable)\n                 argoproj/rollouts-demo:yellow (canary)\nReplicas:\n  Desired:       5\n  Current:       6\n  Updated:       1\n  Ready:         6\n  Available:     6\n\nNAME                           KIND        STATUS     AGE  INFO\n\u27f3 myapp                        Rollout     \u0965 Paused   5m\n\u251c\u2500\u2500# revision:2\n\u2502  \u2514\u2500\u2500\u29c9 myapp-789746c88d       ReplicaSet  \u2714 Healthy  30s  canary\n\u2502     \u2514\u2500\u2500\u25a1 myapp-789746c88d-x  Pod         \u2714 Running  30s  ready:1/1\n\u2514\u2500\u2500# revision:1\n   \u2514\u2500\u2500\u29c9 myapp-6c5c5d8f9b       ReplicaSet  \u2714 Healthy  5m   stable\n      \u251c\u2500\u2500\u25a1 myapp-6c5c5d8f9b-a  Pod         \u2714 Running  5m   ready:1/1\n      \u251c\u2500\u2500\u25a1 myapp-6c5c5d8f9b-b  Pod         \u2714 Running  5m   ready:1/1\n      \u251c\u2500\u2500\u25a1 myapp-6c5c5d8f9b-c  Pod         \u2714 Running  5m   ready:1/1\n      \u2514\u2500\u2500\u25a1 myapp-6c5c5d8f9b-d  Pod         \u2714 Running  5m   ready:1/1\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#step-3-manual-promotion","title":"Step 3: Manual Promotion","text":"<pre><code># Promote to next step\nkubectl argo rollouts promote myapp\n\n# Or skip all pauses and go to 100%\nkubectl argo rollouts promote myapp --full\n</code></pre>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#step-4-rollback-if-issues","title":"Step 4: Rollback if Issues","text":"<pre><code># Abort rollout and revert to stable\nkubectl argo rollouts abort myapp\n\n# Or undo to previous revision\nkubectl argo rollouts undo myapp\n</code></pre>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-4-automated-analysis","title":"\ud83d\udcca Part 4: Automated Analysis","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#analysis-templates","title":"Analysis Templates","text":"<p>Define success criteria using metrics:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: AnalysisTemplate\nmetadata:\n  name: success-rate\nspec:\n  args:\n  - name: service-name\n  metrics:\n  - name: success-rate\n    interval: 1m\n    successCondition: result[0] &gt;= 0.95\n    failureLimit: 3\n    provider:\n      prometheus:\n        address: http://prometheus:9090\n        query: |\n          sum(rate(\n            http_requests_total{\n              service=\"{{args.service-name}}\",\n              status!~\"5..\"\n            }[5m]\n          ))\n          /\n          sum(rate(\n            http_requests_total{\n              service=\"{{args.service-name}}\"\n            }[5m]\n          ))\n  - name: latency\n    interval: 1m\n    successCondition: result[0] &lt;= 500\n    failureLimit: 3\n    provider:\n      prometheus:\n        address: http://prometheus:9090\n        query: |\n          histogram_quantile(0.95,\n            sum(rate(\n              http_request_duration_seconds_bucket{\n                service=\"{{args.service-name}}\"\n              }[5m]\n            )) by (le)\n          ) * 1000\n</code></pre>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#integrating-analysis-with-rollout","title":"Integrating Analysis with Rollout","text":"<pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: myapp\nspec:\n  replicas: 5\n  strategy:\n    canary:\n      steps:\n      - setWeight: 20\n      - pause: {duration: 1m}\n      - analysis:\n          templates:\n          - templateName: success-rate\n          args:\n          - name: service-name\n            value: myapp\n      - setWeight: 40\n      - pause: {duration: 1m}\n      - analysis:\n          templates:\n          - templateName: success-rate\n          args:\n          - name: service-name\n            value: myapp\n      - setWeight: 60\n      - pause: {duration: 1m}\n      - analysis:\n          templates:\n          - templateName: success-rate\n          args:\n          - name: service-name\n            value: myapp\n      - setWeight: 80\n      - pause: {duration: 1m}\n      - analysis:\n          templates:\n          - templateName: success-rate\n          args:\n          - name: service-name\n            value: myapp\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v1.0\n        ports:\n        - containerPort: 8080\n</code></pre> <p>How it works: 1. Deploy 20% canary 2. Wait 1 minute 3. Run analysis (check success rate and latency) 4. If analysis passes \u2192 proceed to 40% 5. If analysis fails 3 times \u2192 automatic rollback 6. Repeat for each step</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-5-advanced-analysis-patterns","title":"\ud83c\udfaf Part 5: Advanced Analysis Patterns","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#baseline-vs-canary-comparison","title":"Baseline vs Canary Comparison","text":"<p>Compare canary metrics against baseline:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: AnalysisTemplate\nmetadata:\n  name: compare-baseline\nspec:\n  args:\n  - name: service-name\n  - name: baseline-hash\n  - name: canary-hash\n  metrics:\n  - name: error-rate-comparison\n    interval: 1m\n    successCondition: result[0] &lt;= 1.25  # Canary error rate &lt; 125% of baseline\n    failureLimit: 3\n    provider:\n      prometheus:\n        address: http://prometheus:9090\n        query: |\n          (sum(rate(\n            http_requests_total{\n              service=\"{{args.service-name}}\",\n              version=\"{{args.canary-hash}}\",\n              status=~\"5..\"\n            }[5m]\n          )) or vector(0))\n          /\n          (sum(rate(\n            http_requests_total{\n              service=\"{{args.service-name}}\",\n              version=\"{{args.baseline-hash}}\",\n              status=~\"5..\"\n            }[5m]\n          )) or vector(0))\n  - name: latency-comparison\n    interval: 1m\n    successCondition: result[0] &lt;= 1.2  # Canary latency &lt; 120% of baseline\n    failureLimit: 3\n    provider:\n      prometheus:\n        address: http://prometheus:9090\n        query: |\n          (histogram_quantile(0.95,\n            sum(rate(\n              http_request_duration_seconds_bucket{\n                service=\"{{args.service-name}}\",\n                version=\"{{args.canary-hash}}\"\n              }[5m]\n            )) by (le)\n          ))\n          /\n          (histogram_quantile(0.95,\n            sum(rate(\n              http_request_duration_seconds_bucket{\n                service=\"{{args.service-name}}\",\n                version=\"{{args.baseline-hash}}\"\n              }[5m]\n            )) by (le)\n          ))\n</code></pre>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#custom-business-metrics","title":"Custom Business Metrics","text":"<pre><code>apiVersion: argoproj.io/v1alpha1\nkind: AnalysisTemplate\nmetadata:\n  name: business-metrics\nspec:\n  args:\n  - name: service-name\n  metrics:\n  - name: revenue-per-request\n    interval: 2m\n    successCondition: result[0] &gt;= 0.95  # Revenue shouldn't drop &gt;5%\n    failureLimit: 2\n    provider:\n      prometheus:\n        address: http://prometheus:9090\n        query: |\n          sum(rate(\n            revenue_total{service=\"{{args.service-name}}\"}[5m]\n          ))\n          /\n          sum(rate(\n            http_requests_total{service=\"{{args.service-name}}\"}[5m]\n          ))\n\n  - name: conversion-rate\n    interval: 2m\n    successCondition: result[0] &gt;= 0.02  # At least 2% conversion\n    failureLimit: 2\n    provider:\n      prometheus:\n        address: http://prometheus:9090\n        query: |\n          sum(rate(\n            conversions_total{service=\"{{args.service-name}}\"}[5m]\n          ))\n          /\n          sum(rate(\n            page_views_total{service=\"{{args.service-name}}\"}[5m]\n          ))\n</code></pre>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#external-analysis-providers","title":"External Analysis Providers","text":"<p>Datadog: <pre><code>metrics:\n- name: datadog-error-rate\n  provider:\n    datadog:\n      apiVersion: v1\n      interval: 5m\n      query: |\n        avg:trace.http.request.errors{service:{{args.service-name}}}\n        .as_rate()\n</code></pre></p> <p>New Relic: <pre><code>metrics:\n- name: newrelic-apdex\n  provider:\n    newRelic:\n      profile: my-newrelic-account\n      query: |\n        SELECT apdex(duration)\n        FROM Transaction\n        WHERE appName = '{{args.service-name}}'\n</code></pre></p> <p>Custom Web API: <pre><code>metrics:\n- name: custom-health-check\n  provider:\n    web:\n      url: https://my-health-api.com/check?service={{args.service-name}}\n      jsonPath: \"{$.health.status}\"\n  successCondition: result == \"healthy\"\n</code></pre></p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-6-traffic-management","title":"\ud83c\udf10 Part 6: Traffic Management","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#traffic-shaping-with-istio","title":"Traffic Shaping with Istio","text":"<p>For precise traffic control:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: myapp\nspec:\n  replicas: 5\n  strategy:\n    canary:\n      canaryService: myapp-canary\n      stableService: myapp-stable\n      trafficRouting:\n        istio:\n          virtualService:\n            name: myapp\n            routes:\n            - primary\n      steps:\n      - setWeight: 10\n      - pause: {duration: 2m}\n      - setWeight: 20\n      - pause: {duration: 2m}\n      - setWeight: 30\n      - pause: {duration: 2m}\n      - setWeight: 50\n      - pause: {}  # Manual approval\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v2.0\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-stable\nspec:\n  selector:\n    app: myapp\n  ports:\n  - port: 80\n    targetPort: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-canary\nspec:\n  selector:\n    app: myapp\n  ports:\n  - port: 80\n    targetPort: 8080\n---\napiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: myapp\nspec:\n  hosts:\n  - myapp\n  http:\n  - name: primary\n    route:\n    - destination:\n        host: myapp-stable\n      weight: 100\n    - destination:\n        host: myapp-canary\n      weight: 0\n</code></pre> <p>Argo Rollouts automatically updates weights in VirtualService!</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#header-based-routing","title":"Header-Based Routing","text":"<p>Route specific users to canary:</p> <pre><code>strategy:\n  canary:\n    trafficRouting:\n      istio:\n        virtualService:\n          name: myapp\n    canaryMetadata:\n      annotations:\n        role: canary\n    stableMetadata:\n      annotations:\n        role: stable\n    steps:\n    - setCanaryScale:\n        weight: 25\n    - setHeaderRoute:\n        name: canary-by-header\n        match:\n        - headerName: X-Canary\n          headerValue:\n            exact: \"true\"\n    - pause: {}\n</code></pre> <p>Now users with <code>X-Canary: true</code> header get canary version!</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-7-observability-and-monitoring","title":"\ud83d\udcc8 Part 7: Observability and Monitoring","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#rollout-dashboard","title":"Rollout Dashboard","text":"<p>Access Argo Rollouts dashboard:</p> <pre><code>kubectl argo rollouts dashboard\n\n# Open browser to http://localhost:3100\n</code></pre> <p>Dashboard shows: - Current rollout status - Traffic weights - Analysis results - Pod health - Rollout history</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Create custom Grafana dashboard:</p> <pre><code>{\n  \"dashboard\": {\n    \"title\": \"Progressive Delivery\",\n    \"panels\": [\n      {\n        \"title\": \"Canary vs Stable Success Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(rate(http_requests_total{version=\\\"canary\\\",status!~\\\"5..\\\"}[5m])) / sum(rate(http_requests_total{version=\\\"canary\\\"}[5m]))\",\n            \"legendFormat\": \"Canary\"\n          },\n          {\n            \"expr\": \"sum(rate(http_requests_total{version=\\\"stable\\\",status!~\\\"5..\\\"}[5m])) / sum(rate(http_requests_total{version=\\\"stable\\\"}[5m]))\",\n            \"legendFormat\": \"Stable\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Rollout Progress\",\n        \"targets\": [\n          {\n            \"expr\": \"argo_rollouts_info{rollout=\\\"myapp\\\"}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Analysis Status\",\n        \"targets\": [\n          {\n            \"expr\": \"argo_rollouts_analysis_run_phase{rollout=\\\"myapp\\\"}\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Argo Rollouts exposes metrics:</p> <pre><code># Rollout phase (Progressing, Paused, Healthy, etc.)\nargo_rollouts_info{namespace=\"default\",rollout=\"myapp\"}\n\n# Current step\nargo_rollouts_phase{namespace=\"default\",rollout=\"myapp\"}\n\n# Analysis run results\nargo_rollouts_analysis_run_metric_phase{\n  namespace=\"default\",\n  rollout=\"myapp\",\n  metric=\"success-rate\"\n}\n\n# Rollout duration\nargo_rollouts_rollout_duration_seconds{namespace=\"default\",rollout=\"myapp\"}\n</code></pre>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-8-practical-exercise","title":"\ud83d\udcaa Part 8: Practical Exercise","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#exercise-implement-full-progressive-delivery","title":"Exercise: Implement Full Progressive Delivery","text":"<p>Objective: Deploy with automated analysis and rollback</p> <p>Scenario: You have a critical e-commerce application. Implement progressive delivery with: 1. 4-step canary (10% \u2192 25% \u2192 50% \u2192 100%) 2. Automated analysis at each step 3. Check: error rate, latency, conversion rate 4. Automatic rollback if metrics degrade 5. Manual approval before 100%</p> <p>Requirements: 1. Create Rollout with canary strategy 2. Define AnalysisTemplate with 3 metrics 3. Configure traffic routing (Istio or Nginx) 4. Integrate with Prometheus 5. Set up Slack notifications 6. Test rollback scenario</p> <p>Starter Template:</p> <pre><code># rollout.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: ecommerce-app\nspec:\n  replicas: 10\n  strategy:\n    canary:\n      steps:\n      - setWeight: 10\n      - pause: {duration: 2m}\n      - analysis:\n          templates:\n          - templateName: ecommerce-health\n      # TODO: Add remaining steps\n  # TODO: Complete configuration\n\n---\n# analysis-template.yaml\napiVersion: argoproj.io/v1alpha1\nkind: AnalysisTemplate\nmetadata:\n  name: ecommerce-health\nspec:\n  # TODO: Define metrics\n  metrics:\n  - name: error-rate\n    # TODO: Configure Prometheus query\n  - name: latency-p95\n    # TODO: Configure Prometheus query\n  - name: conversion-rate\n    # TODO: Configure Prometheus query\n</code></pre> <p>Validation Criteria: - [ ] Rollout deploys progressively (10% \u2192 25% \u2192 50% \u2192 100%) - [ ] Analysis runs at each step - [ ] Metrics collected from Prometheus - [ ] Automatic promotion if healthy - [ ] Automatic rollback if unhealthy - [ ] Manual approval before 100% - [ ] Slack notification on rollback - [ ] Dashboard shows real-time status</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-9-knowledge-check","title":"\ud83c\udf93 Part 9: Knowledge Check","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#quiz-questions","title":"Quiz Questions","text":"<ol> <li>What's the main difference between CD and Progressive Delivery?</li> <li>[ ] Speed of deployment</li> <li>[x] Automated analysis and gradual rollout</li> <li>[ ] Number of environments</li> <li> <p>[ ] Cost</p> </li> <li> <p>What does Argo Rollouts use to make promotion decisions?</p> </li> <li>[ ] Random selection</li> <li>[ ] Time-based only</li> <li>[x] Metrics analysis and success conditions</li> <li> <p>[ ] Manual approval only</p> </li> <li> <p>In an AnalysisTemplate, what is failureLimit?</p> </li> <li>[ ] Maximum deployment failures allowed</li> <li>[x] Number of times metric can fail before rollback</li> <li>[ ] Timeout duration</li> <li> <p>[ ] Percentage threshold</p> </li> <li> <p>What happens if analysis fails during a canary rollout?</p> </li> <li>[ ] Deployment pauses indefinitely</li> <li>[ ] Continues to next step anyway</li> <li>[x] Automatic rollback to stable version</li> <li> <p>[ ] Manual intervention required</p> </li> <li> <p>Which traffic management option provides most precise control?</p> </li> <li>[ ] Kubernetes Service</li> <li>[x] Istio VirtualService</li> <li>[ ] NodePort</li> <li> <p>[ ] LoadBalancer</p> </li> <li> <p>What is the purpose of baseline vs canary comparison?</p> </li> <li>[ ] Save costs</li> <li>[x] Detect regressions by comparing versions</li> <li>[ ] Speed up deployment</li> <li> <p>[ ] Reduce complexity</p> </li> <li> <p>When should you use manual approval gates?</p> </li> <li>[ ] Every deployment</li> <li>[ ] Never, always automate</li> <li>[x] Before high-risk steps like 100% rollout</li> <li> <p>[ ] Only in development</p> </li> <li> <p>What metric provider can Argo Rollouts integrate with?</p> </li> <li>[ ] Only Prometheus</li> <li>[ ] Only Datadog</li> <li>[ ] Only custom webhooks</li> <li>[x] Multiple providers (Prometheus, Datadog, New Relic, etc.)</li> </ol> <p>Answers: 1-B, 2-C, 3-B, 4-C, 5-B, 6-B, 7-C, 8-D</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#part-10-module-summary-next-steps","title":"\ud83c\udfaf Part 10: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#what-you-learned","title":"What You Learned","text":"<p>\u2705 Progressive Delivery: Automated, metrics-driven rollouts \u2705 Argo Rollouts: Advanced Kubernetes deployment controller \u2705 Automated Analysis: Decision-making based on metrics \u2705 Traffic Shaping: Precise control with Istio/Nginx \u2705 Rollback Automation: Automatic revert on failure \u2705 Observability: Monitoring rollout health</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#dora-capabilities-achieved","title":"DORA Capabilities Achieved","text":"<ul> <li>\u2705 CD2: Fully automated deployment with safety</li> <li>\u2705 Team Experimentation: Safe to test in production</li> <li>\u2705 Monitoring: Deployment metrics integrated</li> </ul>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Automate decisions - Let metrics drive promotion/rollback</li> <li>Compare versions - Baseline vs canary reveals regressions</li> <li>Start small - 5-10% canary catches most issues</li> <li>Multiple metrics - Error rate + latency + business metrics</li> <li>Manual gates for critical steps - Humans approve 100% rollout</li> </ol>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#real-world-impact","title":"Real-World Impact","text":"<p>\"After implementing progressive delivery: - Bad deploy detection: 30 minutes \u2192 2 minutes - User impact from bad deploys: 100% \u2192 5% - Manual rollbacks: 15 per month \u2192 0 per month - Deployment confidence: 70% \u2192 98% - Mean time to detect issues: 20 min \u2192 2 min</p> <p>We deploy to production during business hours without fear.\" - SRE Team, E-Commerce Platform</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#documentation","title":"Documentation","text":"<ul> <li>Argo Rollouts</li> <li>Flagger</li> <li>Progressive Delivery</li> </ul>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#tools","title":"Tools","text":"<ul> <li>Argo Rollouts</li> <li>Flagger</li> <li>Kayenta - Automated canary analysis</li> </ul>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#module-completion","title":"\ud83c\udfc5 Module Completion","text":""},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#assessment-checklist","title":"Assessment Checklist","text":"<ul> <li>[ ] Conceptual Understanding</li> <li>[ ] Explain progressive delivery vs CD</li> <li>[ ] Understand automated analysis</li> <li> <p>[ ] Know when to use manual gates</p> </li> <li> <p>[ ] Practical Skills</p> </li> <li>[ ] Configure Argo Rollouts</li> <li>[ ] Create AnalysisTemplates</li> <li>[ ] Integrate with Prometheus</li> <li>[ ] Set up traffic management</li> <li> <p>[ ] Test automated rollback</p> </li> <li> <p>[ ] Hands-On Lab</p> </li> <li>[ ] Deploy with progressive rollout</li> <li>[ ] Analysis runs successfully</li> <li>[ ] Automatic promotion works</li> <li> <p>[ ] Automatic rollback works</p> </li> <li> <p>[ ] Quiz</p> </li> <li>[ ] Score 80% or higher (6/8 questions)</li> </ul>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#certification-credit","title":"Certification Credit","text":"<p>Upon completion, you earn: - 5 points toward Green Belt certification (75% complete) - Badge: \"Progressive Delivery Expert\" - Skill Unlocked: Automated Canary Analysis</p>"},{"location":"dojo/modules/green-belt/module-11-progressive-delivery/#green-belt-progress","title":"\ud83c\udf96\ufe0f Green Belt Progress","text":"<pre><code>Green Belt: GitOps &amp; Deployment\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModule 9:  GitOps with ArgoCD     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 25% \u2713\nModule 10: Deployment Strategies  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 50% \u2713\nModule 11: Progressive Delivery   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 75% \u2713\nModule 12: Rollback &amp; Incident    \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n</code></pre> <p>Almost there! One more module to Green Belt! \ud83c\udf89</p> <p>Next Module Preview: Module 12 - Rollback &amp; Incident Response (Fast recovery, runbooks, postmortems)</p> <p>\ud83c\udf89 Congratulations! You now know how to implement fully automated, metrics-driven progressive delivery!</p> <p>Ready for the final Green Belt module? Let's learn incident response and rollback strategies! \ud83d\ude80</p> <p>Fawkes Dojo - Where Platform Engineers Are Forged Version 1.0 | Last Updated: October 2025 License: MIT | https://github.com/paruff/fawkes</p>"},{"location":"dojo/modules/green-belt/module-12-rollback-incident/","title":"Fawkes Dojo Module 12: Rollback &amp; Incident Response","text":""},{"location":"dojo/modules/green-belt/module-12-rollback-incident/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe2 Green Belt - GitOps &amp; Deployment (FINAL MODULE) Module: 4 of 4 (Green Belt) Duration: 60 minutes Difficulty: Advanced Prerequisites: - Modules 9, 10, 11 complete - Understanding of deployment strategies - Familiarity with incident management - Basic knowledge of observability</p>"},{"location":"dojo/modules/green-belt/module-12-rollback-incident/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Understand different rollback strategies and when to use each</li> <li>\u2705 Implement fast rollback procedures (&lt; 5 minutes)</li> <li>\u2705 Create and execute runbooks for common incidents</li> <li>\u2705 Practice incident response workflows</li> <li>\u2705 Conduct effective postmortems</li> <li>\u2705 Build rollback automation with GitOps</li> <li>\u2705 Improve MTTR (Mean Time to Restore) systematically</li> </ol> <p>DORA Capabilities Addressed: - \u2713 Mean Time to Restore (MTTR) - Elite target: &lt;1 hour - \u2713 Change Approval Process (lightweight) - \u2713 Incident Management</p>"},{"location":"dojo/modules/green-belt/module-12-rollback-incident/#part-1-the-cost-of-downtime","title":"\ud83d\udcd6 Part 1: The Cost of Downtime","text":""},{"location":"dojo/modules/green-belt/module-12-rollback-incident/#why-fast-recovery-matters","title":"Why Fast Recovery Matters","text":"<p>Downtime cost example (e-commerce site, $1M/day revenue):</p> Duration Revenue Loss Customer Impact Reputation Damage 5 minutes $3,472 Minimal None 30 minutes $20,833 Moderate Minor 2 hours $83,333 Significant Moderate 8 hours $333,333 Severe Major 24 hours $1,000,000"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/","title":"Module 1: Internal Delivery Platforms - What and Why","text":"<p>Belt Level: \ud83e\udd4b White Belt Duration: 60 minutes Prerequisites: Basic command line, Git, Docker knowledge DORA Capabilities: Continuous Delivery (introduction)</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#1-learning-objectives-3-minutes","title":"1. Learning Objectives (3 minutes)","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this module, you will be able to:</p> <ul> <li>\u2705 Define what an Internal Delivery Platform (IDP) is and explain its core components</li> <li>\u2705 Articulate why organizations need IDPs using concrete business metrics</li> <li>\u2705 Explain the \"Platform as a Product\" mindset and its benefits</li> <li>\u2705 Identify the key stakeholders and their needs in platform engineering</li> <li>\u2705 Navigate the Fawkes platform and understand its architecture</li> <li>\u2705 Recognize how Team Topologies concepts apply to platform teams</li> </ul>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#why-it-matters","title":"Why It Matters","text":"<p>The Problem: Modern software delivery involves dozens of tools, complex configurations, and countless decisions that slow teams down. According to the 2023 State of DevOps Report:</p> <ul> <li>Elite performers deploy 417 times more frequently than low performers</li> <li>They have a 5,788 times lower change failure rate</li> <li>Their lead time for changes is 6,570 times faster</li> </ul> <p>The Solution: Internal Delivery Platforms abstract away complexity and provide \"golden paths\" that enable teams to move fast while maintaining quality and security.</p> <p>Your Role: Understanding IDPs is the foundation for everything else in this dojo. You can't improve what you don't understand.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#success-criteria","title":"Success Criteria","text":"<p>You've mastered this module when you can:</p> <ul> <li>Explain to a colleague why your organization needs a platform (in business terms)</li> <li>Navigate the Fawkes Backstage portal confidently</li> <li>Identify which Fawkes components serve which developer needs</li> <li>Articulate the difference between \"platform\" and \"just some scripts\"</li> </ul>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#2-theory-concepts-15-minutes","title":"2. Theory &amp; Concepts (15 minutes)","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#video-what-is-an-internal-delivery-platform-7-minutes","title":"\ud83d\udcfa Video: What is an Internal Delivery Platform? (7 minutes)","text":"<p>[VIDEO PLACEHOLDER] Script Summary: - Opening: Show developer frustration with 12-step deployment process - Definition: IDP as \"self-service platform that provides golden paths\" - Key components: Portal, CI/CD, Observability, Infrastructure - Platform as Product: treating developers as customers - Fawkes tour: Show actual platform in action - Closing: \"A platform that makes the right thing the easy thing\"</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#what-is-an-internal-delivery-platform","title":"What is an Internal Delivery Platform?","text":"<p>An Internal Delivery Platform (IDP) is a curated set of tools, services, and self-service capabilities that application teams use to deliver and manage their software with minimal friction.</p> <p>Think of it as \"paved roads for software delivery\"\u2014just as cities build roads so citizens don't have to navigate rough terrain, platforms build golden paths so developers don't have to navigate infrastructure complexity.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#the-three-characteristics-of-an-idp","title":"The Three Characteristics of an IDP","text":"<ol> <li> <p>Self-Service: Developers can provision resources, deploy applications, and access tools without waiting for tickets or manual intervention</p> </li> <li> <p>Curated &amp; Opinionated: The platform team makes thoughtful decisions about tools, patterns, and workflows, reducing cognitive load for app teams</p> </li> <li> <p>Built on Standards: Uses industry-standard tools and practices, avoiding vendor lock-in and enabling portability</p> </li> </ol>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#what-an-idp-is-not","title":"What an IDP is NOT","text":"<p>\u274c Not a PaaS: Unlike Heroku or Cloud Foundry, IDPs give developers more control and flexibility \u274c Not just CI/CD: CI/CD is one component, but IDPs include much more (observability, security, governance) \u274c Not \"throw tools over the wall\": True platforms treat developers as customers and measure satisfaction \u274c Not one-size-fits-all: Platforms provide flexibility for different application types and team maturity levels</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#the-platform-as-a-product-mindset","title":"The Platform as a Product Mindset","text":"<p>Traditional IT: \"Here are some tools. Figure it out yourself.\" Platform Engineering: \"What do you need to be productive? Let me build that for you.\"</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#key-principles","title":"Key Principles","text":"<p>1. Developers are Your Customers - Understand their pain points through interviews and surveys - Measure satisfaction with NPS (Net Promoter Score) - Iterate based on feedback, not assumptions</p> <p>2. Build for the 80% Use Case - Provide golden paths for common scenarios - Allow escape hatches for advanced users - Don't try to solve every edge case immediately</p> <p>3. Measure Platform Value - Track adoption rates (% of teams using the platform) - Monitor time saved (before vs. after metrics) - Calculate cost efficiency (infrastructure + personnel)</p> <p>4. Treat It Like a Product - Maintain a roadmap based on customer needs - Version releases and communicate changes - Provide documentation and support</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#team-topologies-enabling-teams","title":"Team Topologies &amp; Enabling Teams","text":"<p>The book Team Topologies by Matthew Skelton and Manuel Pais introduces four fundamental team types. Platform teams are Enabling Teams.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#the-four-team-types","title":"The Four Team Types","text":"<ol> <li>Stream-Aligned Teams: Product/feature teams that deliver value to customers</li> <li>Enabling Teams: Help stream-aligned teams overcome obstacles (platform teams!)</li> <li>Complicated Subsystem Teams: Specialists for complex subsystems</li> <li>Platform Teams: Provide internal services to reduce cognitive load</li> </ol>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#platform-team-responsibilities","title":"Platform Team Responsibilities","text":"<p>As a platform engineer, your job is to:</p> <ul> <li>Reduce cognitive load: Abstract away infrastructure complexity</li> <li>Enable autonomy: Give teams self-service capabilities</li> <li>Accelerate delivery: Remove blockers and reduce lead time</li> <li>Ensure quality: Build in security, testing, and observability</li> <li>Continuously improve: Treat the platform as a product that evolves</li> </ul>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#why-organizations-need-idps","title":"Why Organizations Need IDPs","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#the-developer-productivity-crisis","title":"The Developer Productivity Crisis","text":"<p>Modern developers spend 70-80% of their time on non-value-added activities:</p> <ul> <li>Waiting for environments to be provisioned</li> <li>Debugging CI/CD failures</li> <li>Figuring out deployment procedures</li> <li>Managing infrastructure configurations</li> <li>Coordinating with 5+ teams for a single deployment</li> </ul>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#the-business-impact","title":"The Business Impact","text":"<p>Without a platform: - Slower time to market: Weeks or months to deploy new services - Higher operational costs: Manual work doesn't scale - Increased risk: No standardization leads to security vulnerabilities - Developer attrition: Frustrated developers leave for better experiences</p> <p>With a platform: - Faster deployments: From weeks to minutes - Lower costs: Automation reduces manual work by 60-80% - Better security: Security built into golden paths - Happier developers: NPS increases by 30-50 points</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#real-world-example-spotify","title":"Real-World Example: Spotify","text":"<p>Spotify's Backstage (which Fawkes uses!) reduced their time to: - Provision a new service: From 4 weeks \u2192 5 minutes - Deploy to production: From 2 hours \u2192 10 minutes - Onboard a new developer: From 2 weeks \u2192 1 day</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#fawkes-platform-architecture","title":"Fawkes Platform Architecture","text":"<p>Fawkes provides a complete IDP built on industry-standard open-source tools:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Developer Experience Layer                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Backstage Portal (Developer Portal)               \u2502 \u2502\n\u2502  \u2502  \u2022 Service Catalog  \u2022 TechDocs  \u2022 Scaffolder     \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Core Platform Services                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502   CI/CD      \u2502  \u2502 GitOps       \u2502  \u2502 Observability\u2502   \u2502\n\u2502  \u2502  (Jenkins)   \u2502  \u2502 (ArgoCD)     \u2502  \u2502 (Prometheus) \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Artifacts   \u2502  \u2502  Security    \u2502  \u2502 Collaboration\u2502   \u2502\n\u2502  \u2502  (Harbor)    \u2502  \u2502  (Trivy)     \u2502  \u2502 (Mattermost) \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Infrastructure &amp; Orchestration                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Kubernetes Clusters (AWS EKS)                     \u2502  \u2502\n\u2502  \u2502  \u2022 Multi-environment (dev, staging, prod)         \u2502  \u2502\n\u2502  \u2502  \u2022 Multi-tenant namespaces                        \u2502  \u2502\n\u2502  \u2502  \u2022 Infrastructure as Code (Terraform)             \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#key-fawkes-components","title":"Key Fawkes Components","text":"Component Purpose Technology Backstage Developer portal, service catalog Backstage by Spotify Jenkins CI/CD pipelines Jenkins with K8s agents ArgoCD GitOps continuous deployment ArgoCD Harbor Container registry Harbor registry Prometheus/Grafana Metrics &amp; monitoring Prometheus stack OpenSearch Log aggregation &amp; search OpenSearch Grafana Tempo Distributed tracing Grafana Tempo Mattermost Team collaboration Mattermost Focalboard Project tracking Focalboard"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#common-pitfalls-how-to-avoid-them","title":"Common Pitfalls &amp; How to Avoid Them","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#pitfall-1-building-in-isolation","title":"\u274c Pitfall 1: Building in Isolation","text":"<p>Problem: Platform team builds what they think developers need without asking them. Solution: Conduct regular developer interviews, track NPS, dogfood your own platform.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#pitfall-2-too-much-control","title":"\u274c Pitfall 2: Too Much Control","text":"<p>Problem: Platform so restrictive that developers route around it. Solution: Provide golden paths for 80% of cases, escape hatches for edge cases.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#pitfall-3-no-documentation","title":"\u274c Pitfall 3: No Documentation","text":"<p>Problem: Great platform, but no one knows how to use it. Solution: Documentation is a first-class feature. Use TechDocs, record videos, provide examples.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#pitfall-4-ignoring-feedback","title":"\u274c Pitfall 4: Ignoring Feedback","text":"<p>Problem: Developers complain but nothing changes. Solution: Public roadmap, regular releases, visible responsiveness to feedback.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#pitfall-5-no-metrics","title":"\u274c Pitfall 5: No Metrics","text":"<p>Problem: Can't prove platform value to leadership. Solution: Track DORA metrics, adoption rates, time saved, cost efficiency.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#3-demonstration-10-minutes","title":"3. Demonstration (10 minutes)","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#video-fawkes-platform-tour-10-minutes","title":"\ud83d\udcfa Video: Fawkes Platform Tour (10 minutes)","text":"<p>[VIDEO PLACEHOLDER] Script: Instructor walks through Fawkes platform showing:</p> <ol> <li>Backstage Home (1 min)</li> <li>Overview page, quick links</li> <li> <p>Component search</p> </li> <li> <p>Service Catalog (2 min)</p> </li> <li>Browse services</li> <li>View service details (APIs, docs, owner)</li> <li> <p>Dependencies visualization</p> </li> <li> <p>TechDocs (1 min)</p> </li> <li>Navigate documentation</li> <li> <p>Search functionality</p> </li> <li> <p>Create New Service (2 min)</p> </li> <li>Click \"Create\" \u2192 choose template</li> <li>Fill in service details</li> <li> <p>Show generated repository</p> </li> <li> <p>DORA Dashboard (2 min)</p> </li> <li>View deployment frequency</li> <li>Lead time for changes</li> <li> <p>Show live metrics</p> </li> <li> <p>CI/CD View (2 min)</p> </li> <li>Jenkins integration</li> <li>Pipeline status</li> <li>Build logs</li> </ol> <p>Key Message: \"Notice how everything you need is in one place. No jumping between 12 different tools.\"</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#key-takeaways-from-demo","title":"Key Takeaways from Demo","text":"<ol> <li>Single Pane of Glass: All your tools accessible from Backstage</li> <li>Self-Service: Create new services in minutes, not weeks</li> <li>Discoverability: Find services, docs, and owners easily</li> <li>Visibility: See deployments, metrics, and health in real-time</li> <li>Standardization: Every service follows the same patterns</li> </ol>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#4-hands-on-lab-20-minutes","title":"4. Hands-On Lab (20 minutes)","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#lab-overview","title":"Lab Overview","text":"<p>You'll explore the Fawkes Backstage portal, navigate the service catalog, and understand the platform architecture by completing a scavenger hunt.</p> <p>Time Estimate: 15-20 minutes Difficulty: Beginner Auto-Graded: Yes Points: 50</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#lab-environment","title":"Lab Environment","text":"<p>When you click \"Start Lab\", we'll provision: - \u2705 Access to Fawkes demo environment - \u2705 Read-only access to sample services - \u2705 Your personal lab notebook (Markdown file) - \u2705 Credentials in your Backstage profile</p> <p>Environment will be available for 24 hours from start time.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#lab-instructions","title":"Lab Instructions","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#part-1-navigate-backstage-15-points","title":"Part 1: Navigate Backstage (15 points)","text":"<ol> <li>Access Backstage (3 points)</li> <li>Click \"Start Lab\" button below</li> <li>Log in with your dojo credentials</li> <li>Find the \"Home\" page</li> </ol> <p>\u2705 Validation: We'll check that you logged in successfully</p> <ol> <li>Explore the Catalog (6 points)</li> <li>Click \"Catalog\" in the left sidebar</li> <li>Find a service called <code>sample-spring-boot-app</code></li> <li>Open its details page</li> <li>Find and click \"View Source\" to see its GitHub repo</li> </ol> <p>\u2705 Validation: We'll check that you visited the service page</p> <ol> <li>View Documentation (6 points)</li> <li>While on the <code>sample-spring-boot-app</code> page, click \"Docs\" tab</li> <li>Read the \"Getting Started\" documentation</li> <li>Notice the \"Edit on GitHub\" link</li> </ol> <p>\u2705 Validation: We'll check that you accessed TechDocs</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#part-2-understand-service-details-20-points","title":"Part 2: Understand Service Details (20 points)","text":"<ol> <li>Identify Service Owner (5 points)</li> <li>On the <code>sample-spring-boot-app</code> page, find the \"About\" section</li> <li>Note the owner (person or team)</li> <li>Find the Mattermost channel for support</li> </ol> <p>\ud83d\udcdd Submit: Who owns this service? (Type answer in lab notebook)</p> <ol> <li>Explore Dependencies (5 points)</li> <li>Click the \"Dependencies\" tab</li> <li>Identify what APIs this service depends on</li> </ol> <p>\ud83d\udcdd Submit: How many dependencies does this service have?</p> <ol> <li>Check CI/CD Status (5 points)</li> <li>Click the \"CI/CD\" tab</li> <li>View the latest Jenkins pipeline run</li> <li>Note whether the build passed or failed</li> </ol> <p>\ud83d\udcdd Submit: What was the status of the last build?</p> <ol> <li>Review DORA Metrics (5 points)</li> <li>Navigate to \"DORA Metrics\" from the left sidebar</li> <li>Find the deployment frequency for the last 7 days</li> <li>Note the lead time for changes</li> </ol> <p>\ud83d\udcdd Submit: What is the deployment frequency? (e.g., \"5 per week\")</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#part-3-platform-architecture-understanding-15-points","title":"Part 3: Platform Architecture Understanding (15 points)","text":"<ol> <li>Identify Platform Components (10 points)</li> <li>Navigate to \"Platform Services\" from the left sidebar</li> <li>You should see tiles for Jenkins, ArgoCD, Harbor, Grafana, etc.</li> <li>Click on each one to see its status</li> </ol> <p>\ud83d\udcdd Submit: List the 5 platform services you found (comma-separated)</p> <ol> <li>Explore a Deployment (5 points)</li> <li>Click on \"ArgoCD\" tile to open ArgoCD</li> <li>Browse the applications</li> <li>Find the <code>sample-spring-boot-app</code> in the list</li> </ol> <p>\ud83d\udcdd Submit: What is the sync status of the sample app in ArgoCD?</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#lab-submission","title":"Lab Submission","text":"<p>Once you've completed all tasks:</p> <ol> <li>Open your lab notebook (automatically created in your namespace)</li> <li>Ensure all answers are recorded</li> <li>Click \"Submit Lab\" button in Backstage</li> </ol> <p>Auto-grading will run within 1 minute. You'll see: - \u2705 Checks that passed (green) - \u274c Checks that failed (red) with hints - Final score out of 50 points - Option to retry if score &lt; 40</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#troubleshooting-hints","title":"Troubleshooting Hints","text":"<p>Can't log in to Backstage? - Verify you're using your dojo username (not email) - Try incognito/private browsing mode - Check #dojo-support in Mattermost</p> <p>Can't find a service? - Use the search bar (top right) - Check that catalog loaded (refresh if empty) - Try filtering by \"Kind: Component\"</p> <p>ArgoCD or other tools not opening? - Some links open in new tabs (check pop-up blocker) - You may need to accept security warnings (self-signed certs in demo environment)</p> <p>Lab not grading? - Ensure you clicked \"Submit Lab\" button - Wait up to 60 seconds for auto-grading - Check that all required answers are in your lab notebook</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#5-knowledge-check-5-minutes","title":"5. Knowledge Check (5 minutes)","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#quiz-internal-delivery-platforms-fundamentals","title":"Quiz: Internal Delivery Platforms Fundamentals","text":"<p>Instructions: Answer all 10 questions. You need 8/10 (80%) to pass. Unlimited attempts allowed.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-1","title":"Question 1","text":"<p>What is the primary purpose of an Internal Delivery Platform?</p> <ul> <li>[ ] A) Replace all existing tools with a single monolithic system</li> <li>[x] B) Provide self-service golden paths that reduce cognitive load for developers</li> <li>[ ] C) Control everything developers do to enforce policies</li> <li>[ ] D) Eliminate the need for DevOps or platform engineers</li> </ul> <p>Explanation: IDPs are about enabling developers through self-service and curated tools, not controlling or replacing everything.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-2","title":"Question 2","text":"<p>According to Team Topologies, what type of team is a platform team?</p> <ul> <li>[ ] A) Stream-aligned team</li> <li>[x] B) Enabling team</li> <li>[ ] C) Complicated subsystem team</li> <li>[ ] D) Infrastructure team</li> </ul> <p>Explanation: Platform teams are enabling teams that help stream-aligned teams overcome obstacles and reduce cognitive load.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-3","title":"Question 3","text":"<p>What does \"Platform as a Product\" mean?</p> <ul> <li>[ ] A) Selling your platform to external customers</li> <li>[x] B) Treating internal developers as customers and measuring their satisfaction</li> <li>[ ] C) Using product management tools to track platform development</li> <li>[ ] D) Making the platform a commercial product</li> </ul> <p>Explanation: It means treating developers as customers, understanding their needs, and measuring satisfaction\u2014just like a real product.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-4","title":"Question 4","text":"<p>Which of these is NOT a characteristic of a well-designed IDP?</p> <ul> <li>[ ] A) Self-service capabilities</li> <li>[ ] B) Opinionated but flexible</li> <li>[x] C) Forces all teams to use exactly the same tools with no exceptions</li> <li>[ ] D) Built on industry standards</li> </ul> <p>Explanation: Good platforms are opinionated but provide escape hatches. Forcing everyone into identical workflows leads to teams routing around the platform.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-5","title":"Question 5","text":"<p>What is Backstage in the Fawkes platform?</p> <ul> <li>[ ] A) The CI/CD pipeline tool</li> <li>[x] B) The developer portal that provides a single pane of glass</li> <li>[ ] C) The Kubernetes orchestration system</li> <li>[ ] D) The monitoring and observability tool</li> </ul> <p>Explanation: Backstage is the developer portal\u2014the single interface where developers access all platform services.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-6","title":"Question 6","text":"<p>Why do organizations invest in Internal Delivery Platforms?</p> <ul> <li>[ ] A) Because it's a trendy thing to do</li> <li>[ ] B) To give platform teams more control</li> <li>[x] C) To accelerate delivery, reduce costs, and improve developer experience</li> <li>[ ] D) To replace cloud providers</li> </ul> <p>Explanation: IDPs deliver business value through faster delivery, lower costs, better security, and improved developer satisfaction.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-7","title":"Question 7","text":"<p>What does \"golden path\" mean in platform engineering?</p> <ul> <li>[x] A) The recommended, easy-to-follow path for common use cases</li> <li>[ ] B) The most expensive way to deploy applications</li> <li>[ ] C) A strict requirement that all teams must follow</li> <li>[ ] D) The path used only by senior engineers</li> </ul> <p>Explanation: A golden path is the easy, paved road for the 80% use case\u2014making the right thing the easy thing.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-8","title":"Question 8","text":"<p>Which metric is NOT typically used to measure platform success?</p> <ul> <li>[ ] A) Developer Net Promoter Score (NPS)</li> <li>[ ] B) Platform adoption rate</li> <li>[ ] C) Time saved per deployment</li> <li>[x] D) Number of tickets closed by the platform team</li> </ul> <p>Explanation: Platform success is about developer outcomes (NPS, adoption, time saved), not just operational metrics like ticket volume.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-9","title":"Question 9","text":"<p>In Fawkes, which tool is responsible for GitOps-based deployments?</p> <ul> <li>[ ] A) Jenkins</li> <li>[x] B) ArgoCD</li> <li>[ ] C) Harbor</li> <li>[ ] D) Backstage</li> </ul> <p>Explanation: ArgoCD manages GitOps-style continuous deployment, syncing Git repos to Kubernetes clusters.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#question-10","title":"Question 10","text":"<p>What is a common pitfall when building an IDP?</p> <ul> <li>[x] A) Building in isolation without talking to developers</li> <li>[ ] B) Using industry-standard open-source tools</li> <li>[ ] C) Providing documentation and examples</li> <li>[ ] D) Measuring platform adoption and satisfaction</li> </ul> <p>Explanation: Building without developer input is the #1 pitfall\u2014you end up solving the wrong problems.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#quiz-results","title":"Quiz Results","text":"<p>Score: X / 10</p> <ul> <li>\u2705 Passed (8+): Great job! You're ready to move to the next section.</li> <li>\u274c Not Yet (&lt;8): Review the content and try again. Focus on areas you missed.</li> </ul> <p>Incorrect answers? Each question links back to the relevant section for review.</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#6-reflection-next-steps-5-minutes","title":"6. Reflection &amp; Next Steps (5 minutes)","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#what-you-learned","title":"What You Learned","text":"<p>Congratulations! \ud83c\udf89 You've completed Module 1. Let's recap:</p> <p>\u2705 You now understand: - What an Internal Delivery Platform is and why it matters - The \"Platform as a Product\" mindset - How Team Topologies applies to platform teams - The Fawkes platform architecture and components - How to navigate Backstage and find information</p> <p>\u2705 You can now: - Explain the business value of IDPs to colleagues - Navigate the Fawkes Backstage portal confidently - Identify the core components of the platform - Find service owners, documentation, and dependencies</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#how-this-connects-to-your-work","title":"How This Connects to Your Work","text":"<p>For Developers: - You now understand why your company invested in a platform - You know where to find docs, who to ask for help, and how to deploy apps - You can take advantage of golden paths instead of reinventing the wheel</p> <p>For Platform Engineers: - You understand your role as an \"enabling team\" - You know how to treat developers as customers - You can articulate the value of the platform to stakeholders</p> <p>For Leaders: - You can explain how platforms accelerate delivery and reduce costs - You understand the metrics that matter (DORA, NPS, adoption) - You can make the case for platform investments</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#reflection-questions","title":"Reflection Questions","text":"<p>Take 2 minutes to think about:</p> <ol> <li>What surprised you most about IDPs?</li> <li> <p>Was there a concept that changed your perspective?</p> </li> <li> <p>How does your current workflow compare?</p> </li> <li> <p>Are you using a platform? Doing things manually? Somewhere in between?</p> </li> <li> <p>What would improve your developer experience?</p> </li> <li> <p>If you could wave a magic wand, what would you change?</p> </li> <li> <p>Who could benefit from this knowledge?</p> </li> <li>Think of 2-3 colleagues who should go through this module</li> </ol>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#additional-resources","title":"Additional Resources","text":"<p>\ud83d\udcda Further Reading: - Team Topologies Book - Foundation for platform thinking - Backstage Documentation - Learn more about Backstage - Platform Engineering Community - Join the community - DORA Research - Dive into the research behind DORA metrics</p> <p>\ud83c\udfa5 Videos to Watch: - \"What is Platform Engineering?\" by Luca Galante (10 min) - \"Spotify's Backstage Journey\" (15 min) - \"Building a Platform as a Product\" by Camille Fournier (30 min)</p> <p>\ud83d\udcac Community: - Join <code>#dojo-white-belt</code> in Mattermost - Share your \"aha!\" moments - Help others who are just starting</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#preview-module-2","title":"Preview: Module 2","text":"<p>Next Up: DORA Metrics - The North Star</p> <p>In Module 2, you'll learn: - The Four Key Metrics (Deployment Frequency, Lead Time, MTTR, Change Failure Rate) - Why these metrics matter to your business - How Fawkes automatically tracks DORA metrics - How to interpret your team's metrics and drive improvement</p> <p>Time: 60 minutes Hands-On: Build your first DORA dashboard</p> <p>Get Ready: Think about your team's current deployment process. How long does it take? How often do you deploy? How often do deployments fail?</p>"},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#module-completion","title":"Module Completion","text":""},{"location":"dojo/modules/white-belt/module-01-what-is-idp/#youve-completed-module-1","title":"\u2705 You've Completed Module 1!","text":"<p>Next Steps: 1. \u2705 Mark this module complete in your Backstage profile 2. \ud83d\udcca View your progress on the Dojo dashboard 3. \ud83d\udcac Share your completion in <code>#dojo-achievements</code> (optional but encouraged!) 4. \u27a1\ufe0f Continue to Module 2 when ready</p> <p>Time Investment: 60 minutes Skills Gained: Platform fundamentals, Backstage navigation Progress: 1 of 4 modules toward White Belt (25% complete)</p> <p>Questions or Issues? - \ud83d\udcac Ask in <code>#dojo-white-belt</code> on Mattermost - \ud83d\udce7 Email: dojo@fawkes.io - \ud83d\udc1b Report bugs: GitHub Issues</p> <p>Feedback? - Rate this module (takes 30 seconds) - Suggest improvements - Help us make the dojo better!</p> <p>Module Author: Fawkes Learning Team Last Updated: October 2025 Version: 1.0</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/","title":"Module 2: DORA Metrics - The North Star","text":"<p>Belt Level: \ud83e\udd4b White Belt Duration: 60 minutes Prerequisites: Module 1 completed DORA Capabilities: Monitoring and Observability, Continuous Delivery</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#1-learning-objectives-3-minutes","title":"1. Learning Objectives (3 minutes)","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this module, you will be able to:</p> <ul> <li>\u2705 Explain the Four Key Metrics and why they predict software delivery performance</li> <li>\u2705 Differentiate between Elite, High, Medium, and Low performers using data</li> <li>\u2705 Calculate each DORA metric for your team</li> <li>\u2705 Interpret DORA metrics dashboards and identify improvement opportunities</li> <li>\u2705 Understand how Fawkes automates DORA metrics collection</li> <li>\u2705 Articulate the business impact of improving these metrics</li> </ul>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#why-it-matters","title":"Why It Matters","text":"<p>The Research: The DORA (DevOps Research and Assessment) team spent 9 years studying 32,000+ organizations to answer one question:</p> <p>\"What separates high-performing software teams from everyone else?\"</p> <p>The Discovery: Just four metrics predict organizational performance better than any other measures. Organizations that excel at these metrics are:</p> <ul> <li>2x more likely to exceed profitability goals</li> <li>2x more likely to exceed productivity goals</li> <li>2x more likely to exceed customer satisfaction goals</li> <li>50% more likely to have higher market share</li> </ul> <p>Your Opportunity: These aren't vanity metrics\u2014they're predictive indicators of success. Understanding and improving them is literally your competitive advantage.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#success-criteria","title":"Success Criteria","text":"<p>You've mastered this module when you can:</p> <ul> <li>Explain each metric to a non-technical executive in business terms</li> <li>Look at a DORA dashboard and immediately spot problems</li> <li>Calculate metrics for your own team</li> <li>Recommend specific improvements based on metric trends</li> <li>Understand how platform engineering improves all four metrics</li> </ul>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#2-theory-concepts-15-minutes","title":"2. Theory &amp; Concepts (15 minutes)","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#video-the-four-key-metrics-explained-7-minutes","title":"\ud83d\udcfa Video: The Four Key Metrics Explained (7 minutes)","text":"<p>[VIDEO PLACEHOLDER] See detailed script in supporting document</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#the-four-key-metrics","title":"The Four Key Metrics","text":"<p>DORA identified four metrics that matter most for software delivery performance:</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#1-deployment-frequency-df","title":"1. \ud83d\ude80 Deployment Frequency (DF)","text":"<p>Definition: How often does your organization deploy code to production?</p> <p>Why It Matters: Deployment frequency is a proxy for batch size. Small, frequent deployments mean: - Lower risk (less can go wrong) - Faster feedback (find problems sooner) - Faster time to market (features reach customers quickly) - Better team morale (see your work in production)</p> <p>Performance Levels: - Elite: Multiple deployments per day (on-demand) - High: Between once per day and once per week - Medium: Between once per week and once per month - Low: Between once per month and once every six months</p> <p>Example: - Low Performer: \"We deploy every 2 months during maintenance windows\" - Elite Performer: \"We deploy 50+ times per day automatically\"</p> <p>How Fawkes Tracks It: Every ArgoCD sync to production is recorded as a deployment event.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#2-lead-time-for-changes-lt","title":"2. \u23f1\ufe0f Lead Time for Changes (LT)","text":"<p>Definition: How long does it take for a commit to go from version control to running in production?</p> <p>Why It Matters: Lead time measures efficiency. Short lead times mean: - Faster feature delivery to customers - Quicker response to market changes - Reduced work-in-progress inventory - Higher developer satisfaction</p> <p>Performance Levels: - Elite: Less than one hour - High: Between one day and one week - Medium: Between one month and six months - Low: More than six months</p> <p>Example: - Low Performer: \"I wrote this code 3 months ago. Still waiting for QA approval.\" - Elite Performer: \"I committed code 20 minutes ago. It's already in production.\"</p> <p>How Fawkes Tracks It: Measures time from Git commit to successful ArgoCD sync in production.</p> <p>Important: This is NOT \"time to write code.\" It's \"time code sits waiting\" in your process.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#3-time-to-restore-service-mttr","title":"3. \ud83d\udd27 Time to Restore Service (MTTR)","text":"<p>Definition: How long does it take to restore service when an incident occurs?</p> <p>Why It Matters: MTTR measures resilience. Fast recovery means: - Less customer impact from incidents - Lower stress for on-call engineers - Better SLAs and reliability - Confidence to move fast (you can recover quickly)</p> <p>Performance Levels: - Elite: Less than one hour - High: Less than one day - Medium: Between one day and one week - Low: More than one week</p> <p>Example: - Low Performer: \"Production is down. We need a 5-hour emergency change board meeting.\" - Elite Performer: \"Production issue detected. Automatic rollback completed in 4 minutes.\"</p> <p>How Fawkes Tracks It: Measures time from incident creation (Alertmanager) to resolution (successful deployment or rollback).</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#4-change-failure-rate-cfr","title":"4. \u274c Change Failure Rate (CFR)","text":"<p>Definition: What percentage of deployments cause failures in production?</p> <p>Why It Matters: CFR measures quality. Low failure rates mean: - Sustainable velocity (not breaking things constantly) - Lower operational burden - Better customer experience - More time for feature development (less firefighting)</p> <p>Performance Levels: - Elite: 0-15% - High: 16-30% - Medium: 16-30% - Low: 16-30%</p> <p>Note: 2023 research collapsed High/Medium/Low into same range. Elite performers stand out with &lt;15%.</p> <p>Example: - Low Performer: \"Every Friday deployment requires weekend hotfixes.\" - Elite Performer: \"We deploy 100 times per week with 5% failure rate.\"</p> <p>How Fawkes Tracks It: Compares successful deployments to failed deployments (rollbacks, incidents within 24 hours of deploy).</p> <p>Important: Some failure is expected and healthy! 0% might mean you're too risk-averse.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#the-performance-spectrum","title":"The Performance Spectrum","text":"<p>Here's how teams compare across the four metrics:</p> Performance Deployment Freq Lead Time MTTR Change Fail Rate Elite On-demand (multiple/day) &lt; 1 hour &lt; 1 hour 0-15% High 1/day - 1/week 1 day - 1 week &lt; 1 day 16-30% Medium 1/week - 1/month 1 week - 1 month 1 day - 1 week 16-30% Low 1/month - 6/months 1 month - 6 months &gt; 1 week 16-30% <p>Key Insight: Elite performers are 417x faster at deploying and 6,570x faster at going from commit to production than low performers!</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#why-these-four-metrics","title":"Why These Four Metrics?","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#they-balance-speed-and-stability","title":"They Balance Speed and Stability","text":"<p>Speed Metrics: - Deployment Frequency - Lead Time for Changes</p> <p>Stability Metrics: - Time to Restore Service - Change Failure Rate</p> <p>You can't optimize for speed alone (you'll break everything) or stability alone (you'll move too slowly). Elite performers excel at all four simultaneously.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#theyre-predictive-not-descriptive","title":"They're Predictive, Not Descriptive","text":"<p>These metrics don't just describe performance\u2014they predict business outcomes:</p> <ul> <li>Profitability: Teams with high DORA metrics are 2x more likely to exceed profitability targets</li> <li>Market Share: 50% more likely to have higher market share</li> <li>Productivity: 2x more likely to exceed productivity goals</li> <li>Customer Satisfaction: 2x more likely to have happy customers</li> </ul>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#they-focus-on-outcomes-not-activities","title":"They Focus on Outcomes, Not Activities","text":"<p>Bad metrics: Lines of code written, hours worked, tickets closed Good metrics (DORA): How fast you deliver value and how reliably</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#the-business-case-for-dora-metrics","title":"The Business Case for DORA Metrics","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#scenario-legacy-bank-vs-digital-startup","title":"Scenario: Legacy Bank vs. Digital Startup","text":"<p>Legacy Bank (Low Performer): - Deploys every 3 months - Lead time: 4 months from idea to production - MTTR: 3 days (requires emergency change approval) - CFR: 25% (1 in 4 releases has issues)</p> <p>Impact: - New credit card feature takes 1 year to launch (competitors launch in 6 weeks) - When mobile app crashes, customers can't access accounts for 3 days - Developer turnover: 35% annually (frustration with slow process)</p> <p>Digital Startup (Elite Performer): - Deploys 20x per day - Lead time: 2 hours from commit to production - MTTR: 15 minutes (automated rollback) - CFR: 8% (rigorous testing catches issues)</p> <p>Impact: - New feature ideas tested with customers within days - Production incidents resolved in minutes, not days - Developer retention: 95% (engineers love working there)</p> <p>Result: Startup captures 30% market share in 2 years despite having 1/100th the resources.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#how-platform-engineering-improves-dora-metrics","title":"How Platform Engineering Improves DORA Metrics","text":"<p>A well-designed platform (like Fawkes) directly improves all four metrics:</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#deployment-frequency","title":"Deployment Frequency \u2191","text":"<ul> <li>Automation: CI/CD pipelines remove manual deployment steps</li> <li>Self-Service: Teams deploy when ready, no waiting for tickets</li> <li>Reduced Fear: Good testing and rollback make deployments safe</li> </ul>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#lead-time","title":"Lead Time \u2193","text":"<ul> <li>Automated Testing: No waiting for manual QA</li> <li>Fast Pipelines: Optimized builds complete in minutes</li> <li>Simplified Process: Golden paths remove decision paralysis</li> </ul>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#mttr","title":"MTTR \u2193","text":"<ul> <li>Observability: Know immediately when things break</li> <li>Quick Rollback: Automated rollback via GitOps</li> <li>Runbooks: Standardized incident response</li> </ul>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#change-failure-rate","title":"Change Failure Rate \u2193","text":"<ul> <li>Quality Gates: Automated security scanning, testing</li> <li>Consistent Patterns: Golden paths reduce errors</li> <li>Progressive Delivery: Canary deployments catch issues early</li> </ul> <p>The Platform Advantage: Manual processes hit scaling limits. Platforms enable teams to improve metrics continuously.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#common-misconceptions","title":"Common Misconceptions","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#we-cant-measure-that-in-our-organization","title":"\u274c \"We can't measure that in our organization\"","text":"<p>Reality: If you deploy software, you can measure these metrics. Start simple with manual tracking if needed.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#our-industry-is-different-this-doesnt-apply","title":"\u274c \"Our industry is different; this doesn't apply\"","text":"<p>Reality: DORA research spans every industry from finance to gaming to healthcare. The metrics apply universally.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#we-need-to-slow-down-to-improve-quality","title":"\u274c \"We need to slow down to improve quality\"","text":"<p>Reality: Elite performers deploy MORE frequently AND have LOWER change failure rates. Speed and stability go together.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#our-legacy-systems-prevent-us-from-improving","title":"\u274c \"Our legacy systems prevent us from improving\"","text":"<p>Reality: Legacy systems are a constraint, not an excuse. Many elite performers maintain legacy systems.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#leadership-only-cares-about-features-not-metrics","title":"\u274c \"Leadership only cares about features, not metrics\"","text":"<p>Reality: These metrics predict revenue, market share, and profitability. Leadership should care.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#100-success-rate-is-the-goal","title":"\u274c \"100% success rate is the goal\"","text":"<p>Reality: Some failure is healthy. Elite performers have 8-15% CFR because they're taking appropriate risks.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#how-fawkes-automates-dora-metrics","title":"How Fawkes Automates DORA Metrics","text":"<p>Fawkes collects DORA metrics automatically from your CI/CD pipeline:</p> <pre><code>Developer commits code\n    \u2193\nGit webhook triggers Jenkins pipeline\n    \u2193 (Lead Time measurement starts)\nJenkins builds, tests, packages\n    \u2193\nArtifact pushed to Harbor registry\n    \u2193\nArgoCD detects new image version\n    \u2193\nArgoCD syncs to Kubernetes (Deployment event recorded)\n    \u2193 (Lead Time measurement ends)\nPrometheus records metrics\n    \u2193\nGrafana dashboard updates in real-time\n    \u2193\nAlertmanager detects any incidents\n    \u2193 (MTTR measurement if incident occurs)\n</code></pre> <p>Data Sources: - Git: Commit timestamps (lead time start) - Jenkins: Build results (quality signals) - ArgoCD: Deployment events (DF, lead time end, CFR) - Prometheus/Alertmanager: Incident detection and resolution (MTTR)</p> <p>No Manual Work Required: Metrics update automatically with every deployment.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#3-demonstration-10-minutes","title":"3. Demonstration (10 minutes)","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#video-navigating-fawkes-dora-dashboards-10-minutes","title":"\ud83d\udcfa Video: Navigating Fawkes DORA Dashboards (10 minutes)","text":"<p>[VIDEO PLACEHOLDER] See detailed script in supporting document</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#key-takeaways-from-demo","title":"Key Takeaways from Demo","text":"<ol> <li>Real-Time Updates: Metrics update with every deployment</li> <li>Multiple Views: Team-level, service-level, and organization-level dashboards</li> <li>Drill-Down Capability: Click any metric to see underlying data</li> <li>Trend Analysis: Compare current period to previous periods</li> <li>Actionable Insights: Dashboard highlights improvement opportunities</li> </ol>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#4-hands-on-lab-20-minutes","title":"4. Hands-On Lab (20 minutes)","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#lab-overview","title":"Lab Overview","text":"<p>You'll analyze DORA metrics for a sample application, identify performance bottlenecks, and make recommendations for improvement.</p> <p>Time Estimate: 20 minutes Difficulty: Beginner Auto-Graded: Partially (calculations auto-checked; recommendations manually reviewed) Points: 60</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#lab-environment","title":"Lab Environment","text":"<p>When you click \"Start Lab\", we'll provision: - \u2705 Access to Grafana DORA dashboards - \u2705 Sample data for 3 months (90 days) - \u2705 3 different teams with varying performance levels - \u2705 Lab notebook for your analysis</p> <p>Environment will be available for 24 hours from start time.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#lab-instructions","title":"Lab Instructions","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#part-1-calculate-metrics-30-points","title":"Part 1: Calculate Metrics (30 points)","text":"<p>You'll analyze \"Team Alpha's\" performance over the last 30 days.</p> <p>Given Data (available in dashboard): - Total deployments to production: 45 - Total commits: 180 - Failed deployments (rollbacks): 7 - Incidents reported: 3 - Average time from commit to production: 6 hours - Average time to resolve incidents: 2 hours</p> <ol> <li>Calculate Deployment Frequency (10 points)</li> </ol> <p>Formula: <code>Total deployments / Days in period</code></p> <p>\ud83d\udcdd Submit: What is Team Alpha's deployment frequency? (deployments per day)</p> <p>\u2705 Validation: Auto-checked against correct calculation</p> <ol> <li>Calculate Lead Time for Changes (10 points)</li> </ol> <p>Given: Average time from commit to production = 6 hours</p> <p>\ud83d\udcdd Submit: What is Team Alpha's lead time? Express in hours.</p> <p>\u2705 Validation: Auto-checked</p> <ol> <li>Calculate Change Failure Rate (10 points)</li> </ol> <p>Formula: <code>(Failed deployments / Total deployments) \u00d7 100</code></p> <p>\ud83d\udcdd Submit: What is Team Alpha's change failure rate? Express as a percentage.</p> <p>\u2705 Validation: Auto-checked against correct calculation</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#part-2-performance-classification-15-points","title":"Part 2: Performance Classification (15 points)","text":"<ol> <li>Classify Team Alpha's Performance (15 points)</li> </ol> <p>Based on the metrics you calculated, classify Team Alpha according to DORA performance levels:</p> <p>\ud83d\udcdd Submit:    - Deployment Frequency Level: [Elite/High/Medium/Low]    - Lead Time Level: [Elite/High/Medium/Low]    - Change Failure Rate Level: [Elite/High/Medium/Low]    - Overall Classification: [Elite/High/Medium/Low]</p> <p>\u2705 Validation: Auto-checked against DORA thresholds</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#part-3-compare-teams-15-points","title":"Part 3: Compare Teams (15 points)","text":"<ol> <li>Analyze Team Bravo vs. Team Charlie (15 points)</li> </ol> <p>Open the \"Team Comparison\" dashboard and compare Team Bravo and Team Charlie.</p> <p>Team Bravo:    - DF: 0.3 per day (9 per month)    - LT: 3 days    - MTTR: 4 hours    - CFR: 10%</p> <p>Team Charlie:    - DF: 2.5 per day (75 per month)    - LT: 45 minutes    - MTTR: 30 minutes    - CFR: 18%</p> <p>\ud83d\udcdd Submit:    - Which team is the higher performer overall? [Bravo/Charlie]    - What is Team Charlie's biggest weakness? [DF/LT/MTTR/CFR]    - If Team Bravo could improve one metric, which would have the biggest impact? [DF/LT/MTTR/CFR]    - Explain your reasoning (2-3 sentences)</p> <p>\u2705 Validation: Reasoning manually reviewed by instructors</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#part-4-identify-improvement-opportunities-bonus","title":"Part 4: Identify Improvement Opportunities (Bonus)","text":"<ol> <li>Recommend Improvements for Team Alpha (Bonus: +10 points)</li> </ol> <p>Based on Team Alpha's metrics:    - DF: 1.5 per day (High)    - LT: 6 hours (Elite)    - MTTR: 2 hours (Elite)    - CFR: 15.6% (Elite)</p> <p>\ud83d\udcdd Submit:    - Team Alpha is performing at Elite level across all metrics. However, what could they do to push even further? (3-5 specific recommendations)</p> <p>Examples of good recommendations:    - \"Reduce deployment frequency variability (some days have 5 deploys, others have 0)\"    - \"Investigate the 7 failed deployments to find common root causes\"    - \"Implement chaos engineering to practice MTTR scenarios\"</p> <p>\u2705 Validation: Manually reviewed for thoughtfulness and actionability</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#lab-submission","title":"Lab Submission","text":"<p>Once you've completed all tasks:</p> <ol> <li>Review your calculations in the lab notebook</li> <li>Ensure all required answers are recorded</li> <li>Click \"Submit Lab\" button</li> </ol> <p>Grading: - Parts 1-2: Auto-graded immediately (45 points) - Parts 3-4: Reviewed within 24 hours by instructors (15 + 10 points) - Passing score: 48/60 (80%)</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#troubleshooting-hints","title":"Troubleshooting Hints","text":"<p>Can't access Grafana? - Click \"Open Grafana\" from lab instructions - Use provided credentials (auto-populated) - Try incognito mode if having authentication issues</p> <p>Calculations not matching? - Double-check your formulas - Ensure you're using correct time periods (30 days) - Round to 2 decimal places</p> <p>Don't understand a metric? - Review the Theory &amp; Concepts section - Check the DORA handbook link in resources - Ask in #dojo-white-belt on Mattermost</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#5-knowledge-check-5-minutes","title":"5. Knowledge Check (5 minutes)","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#quiz-dora-metrics-mastery","title":"Quiz: DORA Metrics Mastery","text":"<p>Instructions: Answer all 10 questions. You need 8/10 (80%) to pass. Unlimited attempts allowed.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-1","title":"Question 1","text":"<p>Which metric measures \"how often\" you deploy to production?</p> <ul> <li>[x] A) Deployment Frequency</li> <li>[ ] B) Lead Time for Changes</li> <li>[ ] C) Mean Time to Restore</li> <li>[ ] D) Change Failure Rate</li> </ul> <p>Explanation: Deployment Frequency measures how often deployments occur.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-2","title":"Question 2","text":"<p>An elite performer's Lead Time for Changes is:</p> <ul> <li>[x] A) Less than one hour</li> <li>[ ] B) Between one day and one week</li> <li>[ ] C) Less than one day</li> <li>[ ] D) Between one hour and one day</li> </ul> <p>Explanation: Elite performers have lead times less than one hour from commit to production.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-3","title":"Question 3","text":"<p>What does MTTR stand for?</p> <ul> <li>[ ] A) Mean Time To Release</li> <li>[ ] B) Mean Time To Recover</li> <li>[x] C) Mean Time To Restore (Service)</li> <li>[ ] D) Mean Time To Rollback</li> </ul> <p>Explanation: MTTR is Mean Time To Restore Service\u2014how long it takes to recover from incidents.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-4","title":"Question 4","text":"<p>Elite performers have a Change Failure Rate of:</p> <ul> <li>[x] A) 0-15%</li> <li>[ ] B) 16-30%</li> <li>[ ] C) Less than 5%</li> <li>[ ] D) 31-45%</li> </ul> <p>Explanation: Elite performers maintain a CFR of 0-15%, significantly better than other performers.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-5","title":"Question 5","text":"<p>Which statement is TRUE about DORA metrics?</p> <ul> <li>[ ] A) You must choose between speed (DF/LT) and stability (MTTR/CFR)</li> <li>[x] B) Elite performers excel at all four metrics simultaneously</li> <li>[ ] C) Only deployment frequency matters</li> <li>[ ] D) These metrics only apply to startups, not enterprises</li> </ul> <p>Explanation: Elite performers are fast AND stable\u2014they excel at all four metrics at once.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-6","title":"Question 6","text":"<p>Your team deploys once per month. What performance level is this?</p> <ul> <li>[ ] A) Elite</li> <li>[ ] B) High</li> <li>[x] C) Medium</li> <li>[ ] D) Low</li> </ul> <p>Explanation: Once per month is Medium performance (between once per week and once per month).</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-7","title":"Question 7","text":"<p>Lead Time for Changes measures:</p> <ul> <li>[ ] A) Time spent writing code</li> <li>[x] B) Time from commit to production</li> <li>[ ] C) Time in code review</li> <li>[ ] D) Time spent in planning</li> </ul> <p>Explanation: Lead time is commit to production\u2014how long code waits in your process.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-8","title":"Question 8","text":"<p>Why do DORA metrics matter to business leaders?</p> <ul> <li>[ ] A) They're required for compliance</li> <li>[x] B) They predict profitability, market share, and customer satisfaction</li> <li>[ ] C) They make engineers look good</li> <li>[ ] D) They're easy to game</li> </ul> <p>Explanation: DORA metrics are predictive of business outcomes\u20142x more likely to exceed profitability goals, etc.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-9","title":"Question 9","text":"<p>A team has 20 deployments and 5 failures in a month. What's their CFR?</p> <ul> <li>[ ] A) 5%</li> <li>[ ] B) 15%</li> <li>[x] C) 25%</li> <li>[ ] D) 50%</li> </ul> <p>Explanation: CFR = (5 failures / 20 deploys) \u00d7 100 = 25%</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#question-10","title":"Question 10","text":"<p>How does a platform like Fawkes improve DORA metrics?</p> <ul> <li>[ ] A) By forcing teams to deploy more frequently</li> <li>[ ] B) By hiding failure metrics</li> <li>[x] C) By automating pipelines, testing, and providing fast feedback</li> <li>[ ] D) By reducing the number of engineers needed</li> </ul> <p>Explanation: Platforms improve metrics through automation, quality gates, and fast feedback loops\u2014making the right things easy.</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#quiz-results","title":"Quiz Results","text":"<p>Score: X / 10</p> <ul> <li>\u2705 Passed (8+): Excellent! You understand DORA metrics deeply.</li> <li>\u274c Not Yet (&lt;8): Review the content and try again.</li> </ul>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#6-reflection-next-steps-5-minutes","title":"6. Reflection &amp; Next Steps (5 minutes)","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#what-you-learned","title":"What You Learned","text":"<p>Congratulations! \ud83c\udf89 You've completed Module 2. Let's recap:</p> <p>\u2705 You now understand: - The Four Key Metrics and what they measure - Why these metrics predict business success - How to calculate and interpret DORA metrics - The difference between Elite and Low performers - How Fawkes automates metrics collection</p> <p>\u2705 You can now: - Analyze DORA dashboards and spot issues - Make data-driven recommendations for improvement - Explain metrics to business stakeholders - Use metrics to prioritize platform improvements</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#how-this-connects-to-your-work","title":"How This Connects to Your Work","text":"<p>For Developers: - You understand what \"good\" looks like (Elite benchmarks) - You can advocate for improvements using data - You know how to track your team's progress</p> <p>For Platform Engineers: - You can measure platform impact objectively - You know which improvements matter most - You can demonstrate ROI to leadership</p> <p>For Leaders: - You have a data-driven framework for investment decisions - You can benchmark against industry standards - You can track improvement over time</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#real-world-application-exercise","title":"Real-World Application Exercise","text":"<p>This Week, Try This:</p> <ol> <li>Measure Your Current State</li> <li>Track deployments for one week</li> <li>Calculate your team's current DORA metrics</li> <li> <p>Be honest\u2014no judgment, just data</p> </li> <li> <p>Identify One Improvement</p> </li> <li>Pick the metric with the most room for improvement</li> <li>Brainstorm 3 concrete actions to improve it</li> <li> <p>Estimate impact and effort</p> </li> <li> <p>Share Your Findings</p> </li> <li>Present current state to your team (5 min standup)</li> <li>Discuss: \"What's our biggest bottleneck?\"</li> <li>Agree on one improvement to try</li> </ol>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#reflection-questions","title":"Reflection Questions","text":"<p>Take 2 minutes to think about:</p> <ol> <li>Which metric surprised you most?</li> <li> <p>Did your team's performance match your intuition?</p> </li> <li> <p>What's your team's biggest opportunity?</p> </li> <li> <p>Which metric, if improved, would have the most impact?</p> </li> <li> <p>What's blocking improvement?</p> </li> <li> <p>Technical debt? Process issues? Cultural resistance?</p> </li> <li> <p>Who needs to know this?</p> </li> <li>Which leader should see your team's DORA metrics?</li> </ol>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#additional-resources","title":"Additional Resources","text":"<p>\ud83d\udcda Further Reading: - DORA State of DevOps Report - Annual research findings - Accelerate Book - The foundational research - DORA Quick Check - Assess your team in 5 minutes - Google Cloud DORA Resources - Implementation guides</p> <p>\ud83c\udfa5 Videos to Watch: - \"DORA Metrics Explained\" by Dr. Nicole Forsgren (15 min) - \"Why DORA Metrics Matter\" by Gene Kim (20 min) - \"Implementing DORA Metrics\" by Charity Majors (30 min)</p> <p>\ud83d\udee0\ufe0f Tools: - Four Keys Project - Open source DORA metrics tool - Sleuth - Commercial DORA tracking (Fawkes alternative) - LinearB - Engineering intelligence platform</p> <p>\ud83d\udcac Community: - Share your team's metrics (anonymously!) in <code>#dojo-metrics</code> - Join the DORA community discussions - Help others interpret their data</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#preview-module-3","title":"Preview: Module 3","text":"<p>Next Up: GitOps Principles</p> <p>In Module 3, you'll learn: - What GitOps is and why it's transforming deployments - Declarative infrastructure and desired state - How ArgoCD implements GitOps - Pull-based vs. push-based deployments - Making your first GitOps change</p> <p>Time: 60 minutes Hands-On: Make a GitOps deployment using ArgoCD</p> <p>Get Ready: Think about how your team currently deploys applications. Who has access? How is it documented? What could go wrong?</p>"},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#module-completion","title":"Module Completion","text":""},{"location":"dojo/modules/white-belt/module-02-dora-metrics/#youve-completed-module-2","title":"\u2705 You've Completed Module 2!","text":"<p>Next Steps: 1. \u2705 Mark this module complete in your Backstage profile 2. \ud83d\udcca View your progress on the Dojo dashboard 3. \ud83d\udcac Share your DORA metrics insights in <code>#dojo-achievements</code> 4. \u27a1\ufe0f Continue to Module 3 when ready</p> <p>Time Investment: 60 minutes Skills Gained: DORA metrics analysis, performance benchmarking Progress: 2 of 4 modules toward White Belt (50% complete)</p> <p>Questions or Issues? - \ud83d\udcac Ask in <code>#dojo-white-belt</code> on Mattermost - \ud83d\udce7 Email: dojo@fawkes.io - \ud83d\udc1b Report bugs: GitHub Issues</p> <p>Feedback? - Rate this module (takes 30 seconds) - What worked well? What could be better? - Help us improve the learning experience!</p> <p>Module Author: Fawkes Learning Team Last Updated: October 2025 Version: 1.0 Based On: DORA State of DevOps 2023 Report</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/","title":"Module 3: GitOps Principles","text":"<p>Belt Level: \ud83e\udd4b White Belt Duration: 60 minutes Prerequisites: Module 1 &amp; 2 completed, Git basics Learning Path: Module 3 of 20 (White Belt: Modules 1-4)</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#module-overview","title":"\ud83d\udccb Module Overview","text":"<p>GitOps is a revolutionary approach to infrastructure and application deployment. Instead of running commands to make changes, you declare your desired state in Git, and automation ensures reality matches that declaration. This module teaches you the principles, benefits, and practices of GitOps.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#learning-objectives","title":"Learning Objectives","text":"<p>By completing this module, you will be able to:</p> <ol> <li>Define GitOps and explain its core principles</li> <li>Differentiate between push-based and pull-based deployment models</li> <li>Describe how Git becomes the single source of truth for infrastructure</li> <li>Explain the benefits of GitOps for DORA metrics and reliability</li> <li>Navigate the Fawkes GitOps repository structure</li> <li>Make a GitOps-driven deployment change in the hands-on lab</li> </ol>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#why-this-matters","title":"Why This Matters","text":"<p>GitOps is a fundamental practice in modern platform engineering: - Netflix deploys 1000+ times per day using GitOps - Weaveworks reported 2x faster deployments with GitOps - DORA research shows GitOps directly improves all four key metrics - 90% of cloud-native teams use or plan to use GitOps (CNCF Survey 2024)</p> <p>Understanding GitOps is essential for elite delivery performance.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#section-1-the-gitops-paradigm-15-minutes","title":"\ud83d\udcda Section 1: The GitOps Paradigm (15 minutes)","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#the-traditional-way-imperative-operations","title":"The Traditional Way: Imperative Operations","text":"<p>Before GitOps, deployments were imperative (manual commands):</p> <pre><code># Deployment by running commands\nkubectl apply -f deployment.yaml\nkubectl set image deployment/myapp myapp=v2.0\nkubectl scale deployment/myapp --replicas=5\nhelm upgrade myapp ./chart --set image.tag=v2.0\nterraform apply\n</code></pre> <p>Problems: - \u274c No audit trail - Who made what change, when, and why? - \u274c Configuration drift - Production differs from documented state - \u274c No rollback - Can't easily revert to previous working state - \u274c Knowledge silos - Only certain people know how to deploy - \u274c Error-prone - Manual commands = human mistakes - \u274c No code review - Infrastructure changes not peer-reviewed</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#the-gitops-way-declarative-state","title":"The GitOps Way: Declarative State","text":"<p>With GitOps, you declare desired state in Git:</p> <pre><code># In Git repository: apps/prod/myapp/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  replicas: 5\n  template:\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v2.0\n</code></pre> <p>GitOps operator (like ArgoCD) continuously: 1. Watches Git for changes 2. Compares Git state with cluster state 3. Applies differences automatically 4. Heals any manual changes (self-healing)</p> <p>Benefits: - \u2705 Complete audit trail - Every change is a Git commit - \u2705 No drift - System automatically returns to Git state - \u2705 Easy rollback - <code>git revert</code> restores previous state - \u2705 Knowledge sharing - Git repository documents everything - \u2705 Reliable - Automation eliminates human error - \u2705 Code review - All changes via pull requests</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#four-principles-of-gitops","title":"Four Principles of GitOps","text":"<p>The OpenGitOps working group defines four core principles:</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#1-declarative","title":"1. Declarative","text":"<p>Definition: System's desired state is expressed declaratively (what, not how).</p> <p>Example: <pre><code># Declarative (GitOps) - Describe WHAT you want\nreplicas: 5\nimage: myapp:v2.0\n\n# vs. Imperative - Describe HOW to achieve it\nkubectl scale --replicas=5\nkubectl set image deployment/myapp myapp=v2.0\n</code></pre></p> <p>Why it matters: Declarative is idempotent (run multiple times = same result), easier to understand, and automation-friendly.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#2-versioned-and-immutable","title":"2. Versioned and Immutable","text":"<p>Definition: Desired state is stored in Git, providing version history and immutability.</p> <p>Benefits: - Every change has a commit SHA (immutable reference) - Full history of who changed what, when, and why - Easy to see what production looked like at any point in time - Rollback is just a <code>git revert</code></p> <p>Example: <pre><code># View deployment history\ngit log apps/prod/myapp/deployment.yaml\n\n# See what changed\ngit diff HEAD~1 apps/prod/myapp/deployment.yaml\n\n# Rollback to previous version\ngit revert HEAD\n</code></pre></p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#3-pulled-automatically","title":"3. Pulled Automatically","text":"<p>Definition: Software agents automatically pull desired state from Git (not pushed).</p> <p>Pull Model (GitOps): <pre><code>Git Repository (source of truth)\n        \u2191\n        \u2502 Pull changes\n        \u2502 (every 3 minutes)\n        \u2502\n    GitOps Agent (ArgoCD)\n        \u2502\n        \u2193 Apply to cluster\n        \u2502\n    Kubernetes Cluster\n</code></pre></p> <p>Push Model (Traditional CI/CD): <pre><code>CI/CD System (Jenkins)\n        \u2502\n        \u2193 Push changes\n        \u2502 (when triggered)\n        \u2502\n    Kubernetes Cluster\n</code></pre></p> <p>Why Pull is Better: - \u2705 More secure - Cluster credentials not in CI/CD system - \u2705 Self-healing - Detects and corrects drift automatically - \u2705 Better failure handling - Retries automatically - \u2705 Audit trail - All changes go through Git (no backdoors)</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#4-continuously-reconciled","title":"4. Continuously Reconciled","text":"<p>Definition: Software agents continuously ensure actual state matches desired state.</p> <p>Reconciliation Loop: <pre><code>1. Fetch desired state from Git\n2. Compare with actual state in cluster\n3. If different, apply changes\n4. Wait (e.g., 3 minutes)\n5. Repeat from step 1\n</code></pre></p> <p>Self-Healing Example: <pre><code># Someone manually changes replicas\nkubectl scale deployment/myapp --replicas=10\n\n# Within 3 minutes, GitOps operator detects drift\n# and reverts to Git-declared state (5 replicas)\n</code></pre></p> <p>Benefits: - Prevents configuration drift - Recovers from manual mistakes automatically - Ensures production always matches Git - Reduces operational toil</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#section-2-gitops-and-dora-metrics-15-minutes","title":"\ud83d\udcda Section 2: GitOps and DORA Metrics (15 minutes)","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#how-gitops-improves-deployment-frequency","title":"How GitOps Improves Deployment Frequency","text":"<p>Deployment Frequency: How often you deploy to production</p> <p>Without GitOps: - Manual deployments require coordination - Fear of breaking production slows deploys - Need specific people with kubectl access - Result: Weekly or monthly deployments</p> <p>With GitOps: - Merge to main branch \u2192 automatic deployment - Git PR process provides confidence - Any developer can merge (with approval) - Result: Multiple deployments per day</p> <p>Example Flow: <pre><code># Developer workflow\ngit checkout -b feature/new-endpoint\n# Make changes to application code\ngit commit -m \"Add new API endpoint\"\ngit push origin feature/new-endpoint\n# Create pull request\n# After approval and merge to main:\n# \u2192 CI builds and pushes image\n# \u2192 Updates GitOps repo with new image tag\n# \u2192 ArgoCD deploys automatically (within 3 minutes)\n</code></pre></p> <p>Impact: Fawkes teams average 10-20 deployments/day with GitOps vs. 2-3/week without.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#how-gitops-reduces-lead-time-for-changes","title":"How GitOps Reduces Lead Time for Changes","text":"<p>Lead Time for Changes: Time from commit to production</p> <p>Without GitOps: <pre><code>Commit \u2192 Wait for CI \u2192 Manual deployment steps \u2192 Production\n        (10 min)      (30-60 min manual work)\nTotal: 40-70 minutes\n</code></pre></p> <p>With GitOps: <pre><code>Commit \u2192 CI builds \u2192 Update GitOps repo \u2192 ArgoCD syncs \u2192 Production\n        (10 min)    (1 min)              (3 min)\nTotal: 14 minutes\n</code></pre></p> <p>Key Difference: Elimination of manual deployment steps.</p> <p>Fawkes Optimization: Using webhooks instead of polling reduces sync time to &lt;30 seconds.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#how-gitops-lowers-change-failure-rate","title":"How GitOps Lowers Change Failure Rate","text":"<p>Change Failure Rate: % of deployments causing failures</p> <p>Without GitOps: - Manual kubectl commands prone to errors - No code review of infrastructure changes - Difficult to test changes before production - Configuration drift introduces unknowns - Result: 15-20% failure rate typical</p> <p>With GitOps: - Declarative configs easier to review - Pull requests catch errors before merge - Can test in staging (identical GitOps workflow) - No drift means fewer surprises - Result: 3-5% failure rate achievable</p> <p>Safety Mechanisms: 1. Git History: Every change reviewed and auditable 2. Dry Run: ArgoCD shows what will change before applying 3. Progressive Sync: Gradual rollout with health checks 4. Automatic Rollback: Failed deployments auto-revert</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#how-gitops-improves-time-to-restore-service","title":"How GitOps Improves Time to Restore Service","text":"<p>Time to Restore Service: Time to recover from failure</p> <p>Without GitOps: <pre><code>Incident detected \u2192 Find person with access \u2192 Figure out what changed \u2192\nRun commands to fix \u2192 Hope it works\nTotal: 30-60 minutes (or more)\n</code></pre></p> <p>With GitOps: <pre><code>Incident detected \u2192 git revert HEAD \u2192 ArgoCD syncs \u2192 Service restored\nTotal: 3-5 minutes\n</code></pre></p> <p>Example: <pre><code># Quick rollback\ngit log --oneline  # Find commit to revert to\ngit revert abc123  # Creates new commit that undoes abc123\ngit push           # ArgoCD automatically applies rollback\n</code></pre></p> <p>Fawkes Average MTTR: 4 minutes with GitOps vs. 45 minutes without.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#section-3-gitops-repository-structure-15-minutes","title":"\ud83d\udcda Section 3: GitOps Repository Structure (15 minutes)","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#the-mono-repo-pattern","title":"The Mono-repo Pattern","text":"<p>Fawkes uses a mono-repo approach where all environments and applications live in one repository.</p> <p>Benefits: - Single source of truth - Easy to see all environments - Shared modules and configurations - Consistent tooling</p> <p>Structure: <pre><code>fawkes-gitops/\n\u251c\u2500\u2500 apps/                       # Application deployments\n\u2502   \u251c\u2500\u2500 dev/                    # Development environment\n\u2502   \u2502   \u251c\u2500\u2500 team-a/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 service-1/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ingress.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 service-2/\n\u2502   \u2502   \u2514\u2500\u2500 team-b/\n\u2502   \u251c\u2500\u2500 staging/                # Staging environment\n\u2502   \u2502   \u2514\u2500\u2500 team-a/\n\u2502   \u2514\u2500\u2500 prod/                   # Production environment\n\u2502       \u2514\u2500\u2500 team-a/\n\u251c\u2500\u2500 platform/                   # Platform components\n\u2502   \u251c\u2500\u2500 backstage/\n\u2502   \u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2502   \u2514\u2500\u2500 service.yaml\n\u2502   \u251c\u2500\u2500 jenkins/\n\u2502   \u251c\u2500\u2500 argocd/\n\u2502   \u2514\u2500\u2500 prometheus/\n\u251c\u2500\u2500 infrastructure/             # Infrastructure resources\n\u2502   \u251c\u2500\u2500 namespaces/\n\u2502   \u2502   \u251c\u2500\u2500 team-a-dev.yaml\n\u2502   \u2502   \u251c\u2500\u2500 team-a-staging.yaml\n\u2502   \u2502   \u2514\u2500\u2500 team-a-prod.yaml\n\u2502   \u251c\u2500\u2500 rbac/\n\u2502   \u251c\u2500\u2500 network-policies/\n\u2502   \u2514\u2500\u2500 resource-quotas/\n\u2514\u2500\u2500 argocd-apps/               # ArgoCD Application definitions\n    \u251c\u2500\u2500 dev-apps.yaml\n    \u251c\u2500\u2500 staging-apps.yaml\n    \u2514\u2500\u2500 prod-apps.yaml\n</code></pre></p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#directory-responsibilities","title":"Directory Responsibilities","text":"<p><code>apps/</code> - Application Deployments - One directory per environment (dev, staging, prod) - Team-based organization - Contains Kubernetes manifests or Kustomize/Helm references</p> <p><code>platform/</code> - Platform Components - Fawkes platform services (Backstage, Jenkins, ArgoCD, etc.) - Usually deployed once (not per environment) - Managed by platform team</p> <p><code>infrastructure/</code> - Infrastructure Resources - Namespaces, RBAC, network policies - Resource quotas and limits - Applied before applications</p> <p><code>argocd-apps/</code> - ArgoCD Applications - Defines what ArgoCD should deploy - ApplicationSets for deploying multiple apps - Points to directories in <code>apps/</code>, <code>platform/</code>, <code>infrastructure/</code></p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#environment-promotion-pattern","title":"Environment Promotion Pattern","text":"<p>Dev \u2192 Staging \u2192 Prod promotion via Git:</p> <pre><code># Deploy to dev (automatic on merge)\ngit checkout main\ngit merge feature-branch\ngit push\n# \u2192 ArgoCD deploys to dev\n\n# After testing in dev, promote to staging\ncp apps/dev/team-a/service-1/deployment.yaml \\\n   apps/staging/team-a/service-1/deployment.yaml\ngit commit -m \"Promote service-1 to staging\"\ngit push\n# \u2192 ArgoCD deploys to staging\n\n# After testing in staging, promote to prod\ncp apps/staging/team-a/service-1/deployment.yaml \\\n   apps/prod/team-a/service-1/deployment.yaml\ngit commit -m \"Promote service-1 to production\"\ngit push\n# \u2192 ArgoCD deploys to prod\n</code></pre> <p>Better Approach: Kustomize Overlays (covered in Green Belt)</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#gitops-repository-best-practices","title":"GitOps Repository Best Practices","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#1-separate-application-code-from-deployment-config","title":"1. Separate Application Code from Deployment Config","text":"<p>Anti-pattern: Kubernetes manifests in application repository <pre><code>myapp/\n\u251c\u2500\u2500 src/           # Application code\n\u251c\u2500\u2500 deployment.yaml  # \u274c Deployment config mixed with code\n\u2514\u2500\u2500 service.yaml\n</code></pre></p> <p>Best Practice: Separate repositories <pre><code>myapp/             # Application code repository\n\u2514\u2500\u2500 src/\n\nfawkes-gitops/     # Deployment config repository\n\u2514\u2500\u2500 apps/dev/team-a/myapp/\n    \u251c\u2500\u2500 deployment.yaml  # \u2705 Deployment config separate\n    \u2514\u2500\u2500 service.yaml\n</code></pre></p> <p>Why: Allows deploying same app code to multiple environments with different configs.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#2-use-meaningful-commit-messages","title":"2. Use Meaningful Commit Messages","text":"<p>Bad: <pre><code>git commit -m \"update\"\ngit commit -m \"fix\"\n</code></pre></p> <p>Good: <pre><code>git commit -m \"Scale myapp from 3 to 5 replicas to handle increased load\"\ngit commit -m \"Update myapp to v2.1.3 (fixes memory leak)\"\n</code></pre></p> <p>Why: Commit messages are your audit trail and rollback documentation.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#3-keep-files-small-and-focused","title":"3. Keep Files Small and Focused","text":"<p>Anti-pattern: One giant <code>all-resources.yaml</code> <pre><code># \u274c 500 lines containing everything\napiVersion: apps/v1\nkind: Deployment\n# ... 200 lines\n---\napiVersion: v1\nkind: Service\n# ... 100 lines\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\n# ... 200 lines\n</code></pre></p> <p>Best Practice: One file per resource type <pre><code>myapp/\n\u251c\u2500\u2500 kustomization.yaml  # \u2705 Small, focused files\n\u251c\u2500\u2500 deployment.yaml\n\u251c\u2500\u2500 service.yaml\n\u2514\u2500\u2500 ingress.yaml\n</code></pre></p> <p>Why: Easier to review, understand, and modify. Better Git diffs.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#4-use-kustomize-for-environment-differences","title":"4. Use Kustomize for Environment Differences","text":"<p>Instead of copying entire files per environment, use Kustomize overlays:</p> <pre><code>base/                      # Common configuration\n\u251c\u2500\u2500 kustomization.yaml\n\u251c\u2500\u2500 deployment.yaml\n\u2514\u2500\u2500 service.yaml\n\noverlays/\n\u251c\u2500\u2500 dev/                  # Dev-specific overrides\n\u2502   \u2514\u2500\u2500 kustomization.yaml  # replicas: 1, resources: small\n\u251c\u2500\u2500 staging/              # Staging-specific overrides\n\u2502   \u2514\u2500\u2500 kustomization.yaml  # replicas: 3, resources: medium\n\u2514\u2500\u2500 prod/                 # Prod-specific overrides\n    \u2514\u2500\u2500 kustomization.yaml  # replicas: 10, resources: large\n</code></pre> <p>Why: DRY principle - define once, override only what differs.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#5-never-commit-secrets-to-git","title":"5. Never Commit Secrets to Git","text":"<p>Wrong (example with placeholder): <pre><code># \u274c NEVER commit real secrets\napiVersion: v1\nkind: Secret\nmetadata:\n  name: database-password\ndata:\n  password: PLACEHOLDER_BASE64_VALUE  # base64 is NOT encryption\n</code></pre></p> <p>Right: Use Sealed Secrets or External Secrets Operator <pre><code># \u2705 Encrypted secret safe for Git\napiVersion: bitnami.com/v1alpha1\nkind: SealedSecret\nmetadata:\n  name: database-password\nspec:\n  encryptedData:\n    password: AgAAAA...REDACTED_EXAMPLE  # Encrypted; only decryptable by controller\n</code></pre></p> <p>Why: Git history is forever. Committed secrets are compromised secrets.</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#section-4-gitops-in-action-with-argocd-10-minutes","title":"\ud83d\udcda Section 4: GitOps in Action with ArgoCD (10 minutes)","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#argocd-the-gitops-operator","title":"ArgoCD: The GitOps Operator","text":"<p>ArgoCD is Fawkes' GitOps continuous delivery tool. It: - Watches Git repositories for changes - Compares desired state (Git) with actual state (Kubernetes) - Applies differences automatically - Provides UI for visualizing deployments</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#application-health-states","title":"Application Health States","text":"<p>ArgoCD tracks application health:</p> <p>\ud83d\udfe2 Healthy - All resources running as expected - Deployments have desired replicas ready - Services have endpoints - Ingresses configured correctly</p> <p>\ud83d\udfe1 Progressing - Deployment in progress - New pods starting up - Rolling update ongoing - Health checks not yet passing</p> <p>\ud83d\udfe0 Degraded - Partially working - Some replicas not ready - Some pods crashing - Service partially available</p> <p>\ud83d\udd34 Missing - Resource doesn't exist - Deleted manually - Never created - Configuration error</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#sync-status","title":"Sync Status","text":"<p>ArgoCD compares Git vs. Kubernetes:</p> <p>\u2705 Synced - Git matches cluster - No differences detected - Latest commit deployed</p> <p>\u274c OutOfSync - Git differs from cluster - Someone made manual changes, OR - New commit not yet deployed</p> <p>\ud83d\udd04 Syncing - Applying changes - ArgoCD deploying Git changes - Resources being created/updated</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#hands-on-viewing-your-application-in-argocd","title":"Hands-On: Viewing Your Application in ArgoCD","text":"<p>Access ArgoCD UI: <pre><code># Get ArgoCD URL\necho \"https://argocd.fawkes.local\"\n\n# Login credentials provided in lab\nUsername: admin\nPassword: [provided in lab environment]\n</code></pre></p> <p>Navigate to Your Application: 1. Click on <code>Applications</code> in left sidebar 2. Find application: <code>dojo-learner-[yourname]-myapp</code> 3. Observe the application topology (visual graph)</p> <p>Understanding the Topology: <pre><code>Application\n    \u2193\nDeployment\n    \u2193\nReplicaSet\n    \u2193\nPod \u2192 Service \u2192 Ingress\n</code></pre></p> <p>Key Information: - Sync Status: Is Git in sync with cluster? - Health Status: Are resources healthy? - Last Sync: When was last deployment? - Git Commit: Which commit is deployed?</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#making-a-gitops-change","title":"Making a GitOps Change","text":"<p>Scenario: Scale your application from 1 to 3 replicas</p> <p>Step 1: Clone GitOps Repository <pre><code>git clone https://github.com/fawkes-dojo/gitops-lab\ncd gitops-lab\n</code></pre></p> <p>Step 2: Make Change <pre><code># Edit deployment file\nvim apps/dojo/learner-[yourname]/myapp/deployment.yaml\n\n# Change replicas from 1 to 3\nspec:\n  replicas: 3  # Changed from 1\n</code></pre></p> <p>Step 3: Commit and Push <pre><code>git add apps/dojo/learner-[yourname]/myapp/deployment.yaml\ngit commit -m \"Scale myapp to 3 replicas for load testing\"\ngit push origin main\n</code></pre></p> <p>Step 4: Watch ArgoCD Sync <pre><code># ArgoCD detects change within 3 minutes (or immediately with webhooks)\n# Watch in ArgoCD UI:\n# 1. Sync Status changes to \"OutOfSync\"\n# 2. ArgoCD automatically syncs (if auto-sync enabled)\n# 3. New pods appear in topology\n# 4. Sync Status returns to \"Synced\"\n</code></pre></p> <p>Step 5: Verify <pre><code># Check pods\nkubectl get pods -n dojo-learner-[yourname]\n\n# Should see 3 pods running\nNAME                     READY   STATUS    AGE\nmyapp-7d8f5c9b8d-abc12   1/1     Running   2m\nmyapp-7d8f5c9b8d-def34   1/1     Running   2m\nmyapp-7d8f5c9b8d-ghi56   1/1     Running   2m\n</code></pre></p> <p>Congratulations! You just made your first GitOps deployment! \ud83c\udf89</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#hands-on-lab-gitops-workflow-15-minutes","title":"\ud83e\uddea Hands-On Lab: GitOps Workflow (15 minutes)","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#lab-objectives","title":"Lab Objectives","text":"<p>In this lab, you will: 1. Make a GitOps change (update image version) 2. Create a pull request for code review 3. Observe ArgoCD sync the change 4. Practice rollback using <code>git revert</code></p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#lab-setup","title":"Lab Setup","text":"<p>Your lab environment includes: - Personal namespace: <code>dojo-learner-[yourname]</code> - Sample application: <code>myapp</code> - GitOps repository access - ArgoCD UI access</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#task-1-update-application-version","title":"Task 1: Update Application Version","text":"<p>Scenario: Deploy v2.0 of myapp which includes new features.</p> <pre><code># 1. Create feature branch\ngit checkout -b update-myapp-v2\n\n# 2. Edit deployment\nvim apps/dojo/learner-[yourname]/myapp/deployment.yaml\n\n# 3. Change image tag\nspec:\n  template:\n    spec:\n      containers:\n      - name: myapp\n        image: fawkes/myapp:v2.0  # Changed from v1.0\n\n# 4. Commit change\ngit add apps/dojo/learner-[yourname]/myapp/deployment.yaml\ngit commit -m \"Update myapp to v2.0 - adds new API endpoints\"\n\n# 5. Push branch\ngit push origin update-myapp-v2\n</code></pre>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#task-2-create-pull-request","title":"Task 2: Create Pull Request","text":"<p>In GitHub: 1. Navigate to <code>https://github.com/fawkes-dojo/gitops-lab</code> 2. Click \"Pull Requests\" \u2192 \"New Pull Request\" 3. Base: <code>main</code>, Compare: <code>update-myapp-v2</code> 4. Title: \"Update myapp to v2.0\" 5. Description:    <pre><code>## Changes\n- Updates myapp from v1.0 to v2.0\n- Adds new /api/v2/health endpoint\n- Improves response time by 30%\n\n## Testing\n- Tested in local environment\n- All tests pass\n- Ready for deployment\n\n## Rollback Plan\n- If issues, revert this commit\n- Previous version: v1.0 (commit abc123)\n</code></pre> 6. Click \"Create Pull Request\"</p> <p>Code Review: - Wait for peer review (or auto-approve in lab) - Address any feedback - Once approved, click \"Merge Pull Request\"</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#task-3-observe-argocd-sync","title":"Task 3: Observe ArgoCD Sync","text":"<p>After merge:</p> <pre><code># Watch ArgoCD detect change\n# In ArgoCD UI:\n# 1. Application shows \"OutOfSync\"\n# 2. After ~30 seconds (or up to 3 min), sync begins\n# 3. Observe pod replacement in topology\n# 4. Application returns to \"Synced\" and \"Healthy\"\n\n# Verify from command line\nkubectl get pods -n dojo-learner-[yourname] -w\n\n# Watch pods terminate and new ones start\n# Old pod (v1.0):\nmyapp-abc123-xyz  1/1  Terminating  5m\n# New pod (v2.0):\nmyapp-def456-uvw  0/1  ContainerCreating  0s\nmyapp-def456-uvw  1/1  Running  15s\n\n# Verify new version\nkubectl describe pod -n dojo-learner-[yourname] myapp-def456-uvw | grep Image:\n# Should show: Image: fawkes/myapp:v2.0\n</code></pre>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#task-4-practice-rollback","title":"Task 4: Practice Rollback","text":"<p>Scenario: v2.0 has a bug. Rollback to v1.0 immediately.</p> <pre><code># 1. Find commit to revert\ngit log --oneline -5\n# Example output:\n# def456 Update myapp to v2.0\n# abc123 Scale myapp to 3 replicas\n# 789xyz Initial deployment\n\n# 2. Revert the v2.0 update\ngit revert def456\n\n# 3. Git opens editor for commit message\n# Default message is fine, save and close\n\n# 4. Push revert\ngit push origin main\n\n# 5. Watch ArgoCD sync rollback\n# Within 3 minutes:\n# - Pods replaced with v1.0\n# - Application healthy again\n# - MTTR: ~3 minutes! \ud83c\udf89\n</code></pre>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#task-5-verify-rollback","title":"Task 5: Verify Rollback","text":"<pre><code># Check image version\nkubectl describe pod -n dojo-learner-[yourname] [pod-name] | grep Image:\n# Should show: Image: fawkes/myapp:v1.0\n\n# Check application health\ncurl https://myapp-learner-[yourname].fawkes.local/health\n# Should respond with v1.0 health check\n</code></pre> <p>Lab Complete! You've experienced the full GitOps workflow: - Made a change via Git - Code review via pull request - Automated deployment via ArgoCD - Fast rollback via git revert</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#knowledge-check-5-minutes","title":"\u2705 Knowledge Check (5 minutes)","text":"<p>Test your understanding with these questions:</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#question-1-core-principles","title":"Question 1: Core Principles","text":"<p>What are the four principles of GitOps?</p> Click to reveal answer  1. **Declarative** - Desired state expressed declaratively 2. **Versioned and Immutable** - Stored in Git with full history 3. **Pulled Automatically** - Software agents pull from Git 4. **Continuously Reconciled** - Automatic drift detection and correction"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#question-2-pull-vs-push","title":"Question 2: Pull vs. Push","text":"<p>What's the key difference between GitOps (pull) and traditional CI/CD (push)?</p> Click to reveal answer  **Pull (GitOps)**: - GitOps operator runs inside cluster - Pulls desired state from Git - No cluster credentials in CI/CD - Self-healing and drift detection  **Push (Traditional)**: - CI/CD system pushes changes to cluster - Requires cluster credentials in CI/CD - No automatic drift detection - Manual healing required"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#question-3-dora-impact","title":"Question 3: DORA Impact","text":"<p>How does GitOps improve Lead Time for Changes?</p> Click to reveal answer  GitOps reduces lead time by: 1. **Eliminating manual steps** - No manual kubectl commands 2. **Automation** - Merge to Git \u2192 automatic deployment 3. **Faster feedback** - See changes in cluster within minutes 4. **Reduced errors** - Declarative configs less error-prone  **Typical improvement**: 40-70 min \u2192 10-15 min lead time"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#question-4-repository-structure","title":"Question 4: Repository Structure","text":"<p>Why should application code and deployment configs be in separate repositories?</p> Click to reveal answer  **Benefits of separation**: 1. **Deploy same app to multiple environments** with different configs 2. **Different access controls** - More people can deploy than modify code 3. **Independent versioning** - App version \u2260 deployment config version 4. **Clear separation of concerns** - Developers focus on code, platform team on deployment 5. **Easier rollbacks** - Revert deployment without touching app code"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#question-5-secrets-management","title":"Question 5: Secrets Management","text":"<p>Why should you never commit Kubernetes Secrets to Git, even base64-encoded?</p> Click to reveal answer  **Reasons**: 1. **Base64 is encoding, not encryption** - Easily decoded 2. **Git history is forever** - Can't truly delete from history 3. **Access control** - Anyone with Git access gets secrets 4. **Rotation complexity** - Hard to rotate secrets in Git history  **Instead use**: - Sealed Secrets (encrypted in Git) - External Secrets Operator (fetches from Vault/AWS Secrets Manager) - Never commit raw secrets"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#question-6-practical-application","title":"Question 6: Practical Application","text":"<p>Your application is experiencing high load. You need to scale from 3 to 10 replicas. What's the GitOps way to do this?</p> Click to reveal answer  **GitOps approach**: <pre><code># 1. Edit deployment in Git\nvim apps/prod/myapp/deployment.yaml\n# Change: replicas: 10\n\n# 2. Commit and push\ngit commit -m \"Scale myapp to 10 replicas for high load\"\ngit push\n\n# 3. ArgoCD syncs automatically (within 3 min)\n# 4. Verify scaling occurred\n</code></pre>  **NOT GitOps** (anti-pattern): <pre><code># \u274c Don't do this:\nkubectl scale deployment/myapp --replicas=10\n# This creates drift - Git still says 3, cluster has 10\n</code></pre>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#module-summary","title":"\ud83c\udf93 Module Summary","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>GitOps = Git as Source of Truth</li> <li>All configuration in Git</li> <li>Automated deployment from Git</li> <li> <p>Self-healing and drift detection</p> </li> <li> <p>Four Core Principles</p> </li> <li>Declarative</li> <li>Versioned and Immutable</li> <li>Pulled Automatically</li> <li> <p>Continuously Reconciled</p> </li> <li> <p>DORA Benefits</p> </li> <li>Increased deployment frequency</li> <li>Reduced lead time</li> <li>Lower change failure rate</li> <li> <p>Faster time to restore service</p> </li> <li> <p>Best Practices</p> </li> <li>Separate app code from deployment config</li> <li>Meaningful commit messages</li> <li>Never commit secrets</li> <li>Use Kustomize for environment differences</li> <li> <p>Small, focused files</p> </li> <li> <p>ArgoCD Workflow</p> </li> <li>Make changes in Git</li> <li>Pull request for review</li> <li>ArgoCD detects and syncs</li> <li>Monitor in ArgoCD UI</li> <li>Rollback via <code>git revert</code></li> </ol>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#what-youve-learned","title":"What You've Learned","text":"<p>\u2705 Define GitOps and its four principles \u2705 Explain pull vs. push deployment models \u2705 Describe how GitOps improves DORA metrics \u2705 Navigate GitOps repository structure \u2705 Make GitOps-driven changes \u2705 Practice rollback procedures</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#time-investment","title":"Time Investment","text":"<ul> <li>Theory: 45 minutes</li> <li>Hands-On Lab: 15 minutes</li> <li>Knowledge Check: 5 minutes</li> <li>Total: ~60 minutes</li> </ul>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#next-steps","title":"Next Steps","text":"<p>Module 4: Your First Deployment awaits! You'll: - Use Backstage to create a new service from template - Deploy your application using GitOps - Configure CI/CD pipeline - View DORA metrics for your deployment</p> <p>Continue to Module 4 \u2192 Your First Deployment</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#official-documentation","title":"Official Documentation","text":"<ul> <li>OpenGitOps Principles</li> <li>ArgoCD Documentation</li> <li>GitOps Working Group</li> </ul>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#articles-videos","title":"Articles &amp; Videos","text":"<ul> <li>What is GitOps? - Weaveworks</li> <li>GitOps Tech Talk - CNCF (30 min)</li> <li>ArgoCD Tutorial - TechWorld with Nana (20 min)</li> </ul>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#books","title":"Books","text":"<ul> <li>GitOps and Kubernetes by Billy Yuen, et al.</li> <li>Continuous Delivery by Jez Humble - Foundation for GitOps</li> </ul>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#practice","title":"Practice","text":"<ul> <li>ArgoCD Katacoda Tutorial - Interactive lab</li> <li>GitOps Playground - Local GitOps environment</li> <li>Fawkes Dojo Lab Environment - Continue practicing!</li> </ul>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#community","title":"Community","text":"<ul> <li>ArgoCD Slack - Ask questions</li> <li>GitOps Days - Annual conference</li> <li>#gitops on Kubernetes Slack - General discussion</li> </ul>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#module-completion","title":"\ud83c\udfaf Module Completion","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#assessment-results","title":"Assessment Results","text":"<p>Your lab work has been automatically graded:</p> <ul> <li>\u2705 GitOps Change: Successfully updated image version</li> <li>\u2705 Pull Request: Created PR with proper description</li> <li>\u2705 Deployment: ArgoCD synced changes successfully</li> <li>\u2705 Rollback: Demonstrated git revert workflow</li> <li>\u2705 Knowledge Check: Passed (need 80%+ to proceed)</li> </ul>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#module-3-score-auto-calculated-50-points","title":"Module 3 Score: [AUTO-CALCULATED] / 50 points","text":"<p>Breakdown: - Theory Understanding (Knowledge Check): 20 points - Hands-On Lab Completion: 20 points - Code Quality (commit messages, PR description): 10 points</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#certificate-progress","title":"Certificate Progress","text":"<p>White Belt Progress: 3 of 4 modules complete (75%)</p> <p>Modules completed: - \u2705 Module 1: Internal Delivery Platforms - What and Why - \u2705 Module 2: DORA Metrics - The North Star - \u2705 Module 3: GitOps Principles</p> <p>Next module: - \u23f3 Module 4: Your First Deployment</p> <p>Continue to Module 4 to complete White Belt requirements!</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#feedback-support","title":"\ud83d\udcac Feedback &amp; Support","text":""},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#how-was-this-module","title":"How was this module?","text":"<p>Rate this module (helps us improve): - \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent - \u2b50\u2b50\u2b50\u2b50 Good - \u2b50\u2b50\u2b50 Average - \u2b50\u2b50 Needs Improvement - \u2b50 Poor</p> <p>Share feedback: Feedback Form</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#need-help","title":"Need Help?","text":"<p>Stuck on something? We're here to help!</p> <ul> <li>Mattermost: Join <code>#dojo-white-belt</code> channel</li> <li>Office Hours: Wednesdays 2-3 PM ET, Fridays 10-11 AM ET</li> <li>Discussion Forum: GitHub Discussions</li> <li>Documentation: GitOps Guide</li> </ul>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#common-issues","title":"Common Issues","text":"<p>Issue: ArgoCD not syncing changes - Check if auto-sync is enabled - Verify Git repository connection - Check ArgoCD logs: <code>kubectl logs -n argocd deploy/argocd-application-controller</code></p> <p>Issue: Can't access ArgoCD UI - Verify ingress configuration - Check ArgoCD service: <code>kubectl get svc -n argocd</code> - Try port-forward: <code>kubectl port-forward -n argocd svc/argocd-server 8080:443</code></p> <p>Issue: Git push rejected - Verify you have write access to repository - Check if branch is protected - Ensure you're pushing to correct remote</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#achievement-unlocked","title":"\ud83c\udfc6 Achievement Unlocked!","text":"<p>\ud83c\udf93 GitOps Practitioner</p> <p>You've completed Module 3 and demonstrated: - Understanding of GitOps core principles - Ability to make GitOps-driven changes - Knowledge of ArgoCD workflow - Proficiency in Git-based rollbacks</p> <p>Share your achievement: - LinkedIn: \"Just completed GitOps Principles module in @Fawkes Dojo! #GitOps #PlatformEngineering\" - Twitter: \"Learned GitOps with hands-on ArgoCD practice at @FawkesIDP dojo \ud83d\ude80 #DevOps #GitOps\"</p> <p>Next milestone: Complete Module 4 to earn your White Belt Certification! \ud83e\udd4b</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#your-dojo-progress","title":"\ud83d\udcca Your Dojo Progress","text":"<pre><code>White Belt Journey: \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 75%\n\nCompleted:\n\u2705 Module 1: What is an IDP (60 min)\n\u2705 Module 2: DORA Metrics (60 min)\n\u2705 Module 3: GitOps Principles (60 min)\n\nRemaining:\n\u23f3 Module 4: Your First Deployment (60 min)\n\u23f3 White Belt Assessment (30 min)\n\nTotal Time Invested: 3 hours\nEstimated Time to White Belt: 1.5 hours\n\nKeep going! You're 75% of the way to your first certification! \ud83d\udcaa\n</code></pre>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#ready-for-module-4","title":"\ud83c\udfaf Ready for Module 4?","text":"<p>Module 4: Your First Deployment brings together everything you've learned:</p> <p>You'll learn to: - Create a service using Backstage templates - Configure CI/CD pipeline (Jenkins) - Deploy using GitOps (ArgoCD) - Monitor with observability tools - View DORA metrics for your service</p> <p>Prerequisites: Modules 1, 2, and 3 complete \u2705</p> <p>Estimated time: 60 minutes</p> <p>Start Module 4 Now \u2192</p>"},{"location":"dojo/modules/white-belt/module-03-gitops-principles/#module-notes","title":"\ud83d\udcdd Module Notes","text":"<p>Module: GitOps Principles Version: 1.0 Last Updated: October 8, 2025 Author: Fawkes Platform Team Contributors: View Contributors</p> <p>Module Changelog: - v1.0 (2025-10-08): Initial release</p> <p>Feedback &amp; Improvements: This module is continuously improved based on learner feedback. If you have suggestions, please open an issue or discuss in <code>#dojo-feedback</code> channel.</p> <p>\u00a9 2025 Fawkes Platform | Licensed under MIT License</p> <p>Platform: https://fawkes.io GitHub: https://github.com/paruff/fawkes Community: https://community.fawkes.io</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/","title":"Module 4: Your First Deployment","text":"<p>Belt Level: \ud83e\udd4b White Belt Duration: 60 minutes Prerequisites: Modules 1, 2, and 3 completed DORA Capabilities: Continuous Delivery, Deployment Automation</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#1-learning-objectives-3-minutes","title":"1. Learning Objectives (3 minutes)","text":""},{"location":"dojo/modules/white-belt/module-04-first-deployment/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this module, you will be able to:</p> <ul> <li>\u2705 Deploy an application using Fawkes golden path templates</li> <li>\u2705 Navigate the deployment pipeline from code to production</li> <li>\u2705 Monitor deployment progress through Backstage, Jenkins, and ArgoCD</li> <li>\u2705 Verify application health and accessibility</li> <li>\u2705 Understand how DORA metrics are automatically captured</li> <li>\u2705 Troubleshoot common deployment issues</li> </ul>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#why-it-matters","title":"Why It Matters","text":"<p>The Milestone: This is the moment you've been building toward\u2014your first end-to-end deployment on the Fawkes platform.</p> <p>Real-World Impact: According to DORA research, organizations that master deployment automation: - Deploy 417 times more frequently than low performers - Have 5,788 times lower change failure rates - Reduce lead time from months to minutes</p> <p>Your Journey: In the next hour, you'll experience what elite performers do dozens of times per day\u2014safely deploying code to production with full observability.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#success-criteria","title":"Success Criteria","text":"<p>You've mastered this module when you can:</p> <ul> <li>Deploy an application end-to-end without assistance</li> <li>Explain each stage of the deployment pipeline</li> <li>Find and interpret deployment logs across tools</li> <li>Identify when a deployment succeeded or failed</li> <li>Access your deployed application</li> </ul>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#2-theory-concepts-15-minutes","title":"2. Theory &amp; Concepts (15 minutes)","text":""},{"location":"dojo/modules/white-belt/module-04-first-deployment/#video-the-fawkes-deployment-pipeline-7-minutes","title":"\ud83d\udcfa Video: The Fawkes Deployment Pipeline (7 minutes)","text":"<p>[VIDEO PLACEHOLDER] Script Summary: - Opening: Show the full deployment pipeline diagram - Code commit \u2192 Jenkins build \u2192 Harbor registry \u2192 ArgoCD sync - Each stage explained with real-time visualization - Observability: Where to find logs and metrics at each stage - DORA metrics: How they're automatically captured - Closing: \"From commit to production in minutes, not months\"</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#the-fawkes-deployment-pipeline","title":"The Fawkes Deployment Pipeline","text":"<p>When you deploy on Fawkes, your code flows through a carefully orchestrated pipeline:</p> <pre><code>Developer \u2192 Git \u2192 Jenkins \u2192 Harbor \u2192 ArgoCD \u2192 Kubernetes \u2192 \ud83c\udf89\n   You     SCM    CI/CD    Registry  GitOps   Cluster    Live!\n</code></pre> <p>Let's break down each stage:</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#stage-1-code-commit-git","title":"Stage 1: Code Commit (Git)","text":"<p>What Happens: You push code to a Git repository (GitHub, GitLab, etc.)</p> <p>Behind the Scenes: - Git webhook triggers Jenkins - Commit SHA becomes the version identifier - Timestamp recorded (start of lead time measurement)</p> <p>Your Role: <code>git push origin main</code></p> <p>Time: &lt; 1 second</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#stage-2-build-test-jenkins","title":"Stage 2: Build &amp; Test (Jenkins)","text":"<p>What Happens: Jenkins automatically builds and tests your code</p> <p>Behind the Scenes: 1. Checkout: Jenkins clones your repository 2. Build: Compiles code, runs tests 3. Security Scan: Checks for vulnerabilities (Trivy) 4. Quality Check: SonarQube analysis (if configured) 5. Package: Creates container image 6. Push: Uploads image to Harbor registry</p> <p>Your Role: None! It's automated by the golden path pipeline.</p> <p>Time: 3-8 minutes (depending on project size)</p> <p>Success Indicators: - \u2705 All tests pass - \u2705 No critical security vulnerabilities - \u2705 Code quality meets threshold - \u2705 Container image tagged with commit SHA</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#stage-3-registry-storage-harbor","title":"Stage 3: Registry Storage (Harbor)","text":"<p>What Happens: Your container image is stored in Harbor registry</p> <p>Behind the Scenes: - Image tagged: <code>harbor.fawkes.local/myapp:abc123</code> - Vulnerability scan runs automatically - Image signed (cryptographic verification) - Available for deployment</p> <p>Your Role: None! Fully automated.</p> <p>Time: &lt; 30 seconds</p> <p>Important: The image is immutable\u2014same image moves through all environments (dev \u2192 staging \u2192 prod). This ensures consistency.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#stage-4-gitops-deployment-argocd","title":"Stage 4: GitOps Deployment (ArgoCD)","text":"<p>What Happens: ArgoCD detects the new image and deploys to Kubernetes</p> <p>Behind the Scenes: 1. Detection: ArgoCD polls Git repository every 3 minutes (or webhook triggers immediately) 2. Sync: Compares desired state (Git) with actual state (Kubernetes) 3. Apply: Creates/updates Kubernetes resources 4. Health Check: Monitors pod startup and readiness 5. Metrics: Records deployment event for DORA metrics</p> <p>Your Role: Review sync status in ArgoCD UI</p> <p>Time: 1-5 minutes (depending on pod startup time)</p> <p>Success Indicators: - \u2705 Sync status: \"Synced\" - \u2705 Health status: \"Healthy\" - \u2705 Pods running: All replicas ready</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#stage-5-running-application-kubernetes","title":"Stage 5: Running Application (Kubernetes)","text":"<p>What Happens: Your application runs in Kubernetes, accessible via ingress</p> <p>Behind the Scenes: - Pods scheduled across nodes for HA - Service provides stable network endpoint - Ingress routes traffic from external load balancer - Probes monitor health (liveness, readiness) - Metrics collected by Prometheus - Logs shipped to OpenSearch - Traces sent to Grafana Tempo</p> <p>Your Role: Access application, verify functionality</p> <p>Time: Immediate once pods are ready</p> <p>Success Indicators: - \u2705 Application responds to requests - \u2705 Health check endpoints return 200 OK - \u2705 No errors in logs</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#golden-path-templates","title":"Golden Path Templates","text":"<p>Fawkes provides golden path templates\u2014pre-configured application scaffolds that include everything you need:</p> <p>What's Included: - \u2705 Application code structure - \u2705 Dockerfile (container image build) - \u2705 Jenkinsfile (CI/CD pipeline) - \u2705 Kubernetes manifests (deployment, service, ingress) - \u2705 Helm chart (configuration management) - \u2705 README with instructions - \u2705 Automated testing setup - \u2705 Monitoring and observability configuration</p> <p>Why Golden Paths? - Consistency: Every app follows the same patterns - Best Practices: Security, testing, monitoring built-in - Speed: Start from working example, customize as needed - Learning: See how the pieces fit together</p> <p>Available Templates (in Fawkes MVP): - <code>spring-boot-api</code>: Java REST API with Spring Boot - <code>python-flask-api</code>: Python REST API with Flask - <code>nodejs-express-api</code>: Node.js REST API with Express - <code>static-website</code>: Static HTML/CSS/JS site</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#dora-metrics-automatic-capture","title":"DORA Metrics: Automatic Capture","text":"<p>Every deployment automatically updates your DORA metrics:</p> <p>Deployment Frequency: - Incremented when ArgoCD successfully syncs to production - Visible in real-time on DORA dashboard</p> <p>Lead Time for Changes: - Start: Git commit timestamp - End: ArgoCD sync completion timestamp - Calculated automatically, no manual tracking</p> <p>Change Failure Rate: - If deployment rolls back within 24 hours \u2192 counted as failure - If incident created within 24 hours of deploy \u2192 counted as failure - Visible as percentage on dashboard</p> <p>Mean Time to Restore (MTTR): - Start: Incident created timestamp - End: Incident resolved timestamp (successful deploy or rollback) - Only measured if incident occurs</p> <p>No Manual Work Required: The platform captures everything automatically.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#common-deployment-patterns","title":"Common Deployment Patterns","text":""},{"location":"dojo/modules/white-belt/module-04-first-deployment/#pattern-1-direct-to-production-mvp","title":"Pattern 1: Direct to Production (MVP)","text":"<p><pre><code>Git \u2192 Jenkins \u2192 Harbor \u2192 ArgoCD \u2192 Production\n</code></pre> When to Use: MVP, small teams, low-risk changes Risk Level: Medium (no staging environment)</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#pattern-2-dev-production-recommended","title":"Pattern 2: Dev \u2192 Production (Recommended)","text":"<p><pre><code>Git \u2192 Jenkins \u2192 Harbor \u2192 ArgoCD \u2192 Dev \u2192 Production\n</code></pre> When to Use: Small teams, moderate risk Risk Level: Low (dev environment for testing)</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#pattern-3-full-pipeline-enterprise","title":"Pattern 3: Full Pipeline (Enterprise)","text":"<p><pre><code>Git \u2192 Jenkins \u2192 Harbor \u2192 ArgoCD \u2192 Dev \u2192 Staging \u2192 Production\n</code></pre> When to Use: Large teams, high-risk changes, compliance requirements Risk Level: Very Low (multiple validation stages)</p> <p>Fawkes MVP: Uses Pattern 1 or 2 by default. Pattern 3 configured in production.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#troubleshooting-where-to-look","title":"Troubleshooting: Where to Look","text":"<p>Build Failed: - Where: Jenkins build logs - How: Click on build number in Jenkins UI - Common Issues: Test failures, dependency errors, Docker build errors</p> <p>Image Scan Failed: - Where: Harbor UI \u2192 Images \u2192 Scan Results - How: Click on image tag, view vulnerabilities - Common Issues: Critical CVEs in base image or dependencies</p> <p>Deployment Failed: - Where: ArgoCD UI \u2192 Application \u2192 Events - How: Check sync status and pod events - Common Issues: Image pull errors, insufficient resources, configuration errors</p> <p>Application Not Responding: - Where: Kubernetes pod logs, Grafana dashboards - How: <code>kubectl logs &lt;pod-name&gt;</code> or Backstage component view - Common Issues: Application crashes, database connection failures, port misconfigurations</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#3-demonstration-10-minutes","title":"3. Demonstration (10 minutes)","text":""},{"location":"dojo/modules/white-belt/module-04-first-deployment/#video-deploying-the-sample-application-10-minutes","title":"\ud83d\udcfa Video: Deploying the Sample Application (10 minutes)","text":"<p>[VIDEO PLACEHOLDER] Script: Instructor performs a complete deployment showing:</p> <p>Part 1: Create from Template (2 min) - Open Backstage - Click \"Create\" \u2192 \"Choose a template\" - Select \"Spring Boot API\" template - Fill in details: name, description, repository - Click \"Create\" - Show generated repository in GitHub</p> <p>Part 2: Trigger Build (2 min) - Show Jenkins detecting the new repository - Build starts automatically - Walk through build stages in Jenkins UI - Show build logs for each stage - Highlight test results and security scan</p> <p>Part 3: Image Registry (1 min) - Switch to Harbor UI - Show new image with commit SHA tag - Open vulnerability scan results - Explain image signing</p> <p>Part 4: ArgoCD Deployment (3 min) - Open ArgoCD UI - Show application appearing in list - Watch sync in real-time - Explain \"Out of Sync\" \u2192 \"Syncing\" \u2192 \"Synced\" \u2192 \"Healthy\" - Show Kubernetes resources created</p> <p>Part 5: Access Application (1 min) - Get application URL from Backstage - Open in browser, show it works - Make a test API call</p> <p>Part 6: Observe Metrics (1 min) - Open DORA dashboard - Show deployment frequency incremented - Show lead time calculated - Point out where to find logs, traces, metrics</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#key-takeaways-from-demo","title":"Key Takeaways from Demo","text":"<ol> <li>It's Fast: From template creation to live app in ~10 minutes</li> <li>It's Automated: You push code, platform handles the rest</li> <li>It's Observable: Every stage visible in appropriate tool</li> <li>It's Safe: Multiple quality gates (tests, scans, health checks)</li> <li>It's Measurable: DORA metrics update automatically</li> </ol>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#4-hands-on-lab-25-minutes","title":"4. Hands-On Lab (25 minutes)","text":""},{"location":"dojo/modules/white-belt/module-04-first-deployment/#lab-overview","title":"Lab Overview","text":"<p>You'll deploy your first application on Fawkes using a golden path template, monitor its progress through the pipeline, and verify it's running successfully.</p> <p>Time Estimate: 20-25 minutes Difficulty: Beginner Auto-Graded: Yes Points: 100</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#lab-environment","title":"Lab Environment","text":"<p>When you click \"Start Lab\", we'll provision: - \u2705 Access to Backstage (create templates) - \u2705 Git repository for your application - \u2705 Jenkins pipeline (automatic) - \u2705 ArgoCD application (automatic) - \u2705 Kubernetes namespace: <code>dojo-learner-{username}</code> - \u2705 Application URL (via ingress)</p> <p>Environment will be available for 24 hours from start time.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#lab-instructions","title":"Lab Instructions","text":""},{"location":"dojo/modules/white-belt/module-04-first-deployment/#part-1-create-application-from-template-5-minutes","title":"Part 1: Create Application from Template (5 minutes)","text":"<p>Step 1: Access Backstage</p> <pre><code># Your lab credentials will be displayed here after clicking \"Start Lab\"\n# Navigate to: https://backstage.fawkes-dojo.internal\n</code></pre> <p>Step 2: Create New Component</p> <ol> <li>Click \"Create\" in the left sidebar</li> <li>Click \"Choose a template\"</li> <li>Select \"Spring Boot REST API\" template</li> <li>Click \"Choose\"</li> </ol> <p>Step 3: Fill in Application Details</p> <ul> <li>Name: <code>my-first-app</code> (use your username if <code>my-first-app</code> is taken)</li> <li>Description: <code>My first deployment on Fawkes</code></li> <li>Owner: Select your username from dropdown</li> <li>Repository: <code>github.com/fawkes-dojo/{your-username}/my-first-app</code></li> </ul> <p>Click \"Next\"</p> <p>Step 4: Review and Create</p> <ul> <li>Review the repository location</li> <li>Click \"Create\"</li> <li>Wait for template to be generated (~30 seconds)</li> <li>Click \"Open in catalog\" when complete</li> </ul> <p>\u2705 Validation: We'll check that you created a component in Backstage</p> <p>\ud83d\udcdd Submit: Component name and URL</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#part-2-monitor-the-build-8-minutes","title":"Part 2: Monitor the Build (8 minutes)","text":"<p>Step 5: Find Your Jenkins Build</p> <ol> <li>In Backstage, on your component page, click the \"CI/CD\" tab</li> <li>You should see a Jenkins build triggered automatically</li> <li>Click on the build number (e.g., \"#1\")</li> <li>This opens Jenkins UI</li> </ol> <p>Step 6: Watch Build Progress</p> <p>Observe the build stages: 1. Checkout: Jenkins clones your repository 2. Build: Compiles code, runs tests 3. Test: Executes unit tests 4. Security Scan: Trivy scans for vulnerabilities 5. Docker Build: Creates container image 6. Push to Harbor: Uploads image</p> <p>Wait for build to complete (~5-8 minutes). You can move to the next part while waiting.</p> <p>Step 7: Review Build Results</p> <p>Once complete, note: - Build status (hopefully \"Success\" \u2705) - Build duration - Test results (how many tests ran, passed/failed) - Security scan results (vulnerabilities found)</p> <p>\u2705 Validation: We'll check that your build completed successfully</p> <p>\ud83d\udcdd Submit: Build number and status</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#part-3-verify-image-in-harbor-3-minutes","title":"Part 3: Verify Image in Harbor (3 minutes)","text":"<p>Step 8: Access Harbor Registry</p> <ol> <li>Navigate to: <code>https://harbor.fawkes-dojo.internal</code></li> <li>Log in with your dojo credentials</li> <li>Click on \"Projects\" \u2192 \"dojo-apps\"</li> <li>Find your application: <code>my-first-app</code></li> </ol> <p>Step 9: Inspect Image</p> <ol> <li>Click on your app name</li> <li>You should see one image tagged with commit SHA (e.g., <code>abc123</code>)</li> <li>Click on the tag</li> <li>Review vulnerability scan results</li> <li>Note the image size and creation time</li> </ol> <p>\u2705 Validation: We'll check that your image exists in Harbor</p> <p>\ud83d\udcdd Submit: Image tag (commit SHA)</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#part-4-monitor-argocd-deployment-5-minutes","title":"Part 4: Monitor ArgoCD Deployment (5 minutes)","text":"<p>Step 10: Access ArgoCD</p> <ol> <li>Return to Backstage, click \"Deployment\" tab</li> <li>Click \"Open in ArgoCD\" link</li> <li>Or navigate directly to: <code>https://argocd.fawkes-dojo.internal</code></li> </ol> <p>Step 11: Watch Deployment Sync</p> <ol> <li>Find your application: <code>my-first-app</code></li> <li>Observe sync status:</li> <li>Out of Sync: ArgoCD detected new image</li> <li>Syncing: Applying changes to Kubernetes</li> <li>Synced: Desired state matches actual state</li> <li>Observe health status:</li> <li>Progressing: Pods starting</li> <li>Healthy: All pods ready</li> <li>Click on your app to see detailed view</li> </ol> <p>Step 12: Inspect Kubernetes Resources</p> <p>In ArgoCD detailed view, you should see: - Deployment: Your application deployment - Service: Network endpoint for your app - Ingress: External URL routing - Pods: Individual application instances (should be 2 replicas)</p> <p>Wait for all resources to show \"Healthy\" status.</p> <p>\u2705 Validation: We'll check that your app is synced and healthy in ArgoCD</p> <p>\ud83d\udcdd Submit: ArgoCD sync status and health status</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#part-5-access-your-application-4-minutes","title":"Part 5: Access Your Application (4 minutes)","text":"<p>Step 13: Get Application URL</p> <ol> <li>In Backstage, on your component page, find the \"Links\" section</li> <li>Click on \"Application URL\"</li> <li>Or construct manually: <code>https://my-first-app.dojo-learner-{username}.fawkes-dojo.internal</code></li> </ol> <p>Step 14: Test Application</p> <p>Your Spring Boot app exposes these endpoints:</p> <pre><code># Health check\ncurl https://my-first-app.dojo-learner-{username}.fawkes-dojo.internal/actuator/health\n\n# Should return:\n# {\"status\":\"UP\"}\n\n# Sample API endpoint\ncurl https://my-first-app.dojo-learner-{username}.fawkes-dojo.internal/api/hello\n\n# Should return:\n# {\"message\":\"Hello from Fawkes!\",\"timestamp\":\"2025-10-08T...\"}\n</code></pre> <p>Step 15: Verify in Browser</p> <ol> <li>Open application URL in browser</li> <li>You should see a welcome page</li> <li>Navigate to <code>/swagger-ui.html</code> to see API documentation</li> </ol> <p>\u2705 Validation: We'll check that your application responds with HTTP 200</p> <p>\ud83d\udcdd Submit: Screenshot of application running in browser OR response from <code>/actuator/health</code></p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#part-6-review-dora-metrics-3-minutes","title":"Part 6: Review DORA Metrics (3 minutes)","text":"<p>Step 16: Check Your Metrics</p> <ol> <li>In Backstage, click \"DORA Metrics\" in left sidebar</li> <li>Filter by your component: <code>my-first-app</code></li> <li>Observe:</li> <li>Deployment Frequency: Should show 1 deployment</li> <li>Lead Time: Time from commit to deployment (likely 10-15 minutes)</li> <li>Change Failure Rate: Should be 0% (successful deployment)</li> <li>MTTR: N/A (no incidents)</li> </ol> <p>Step 17: Explore Observability</p> <ol> <li>Click \"Logs\" tab \u2192 Opens OpenSearch Dashboards</li> <li>Search for: <code>kubernetes.namespace_name:\"dojo-learner-{username}\"</code></li> <li>You should see application startup logs</li> <li>Click \"Metrics\" tab \u2192 Opens Grafana</li> <li>View pod CPU, memory, network metrics</li> <li>Click \"Traces\" tab \u2192 Opens Grafana Tempo</li> <li>View distributed traces (if application makes external calls)</li> </ol> <p>\u2705 Validation: We'll check that metrics were recorded</p> <p>\ud83d\udcdd Submit: Your lead time for changes (in minutes)</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#lab-submission","title":"Lab Submission","text":"<p>Once you've completed all parts:</p> <ol> <li>Ensure all answers are recorded in your lab notebook</li> <li>Double-check that your application is still running</li> <li>Click \"Submit Lab\" button in Backstage</li> </ol> <p>Grading: - Part 1 (Component created): 15 points - Part 2 (Build completed): 20 points - Part 3 (Image in Harbor): 15 points - Part 4 (ArgoCD synced): 20 points - Part 5 (App responding): 20 points - Part 6 (Metrics recorded): 10 points</p> <p>Passing score: 80/100 (80%)</p> <p>Auto-grading runs within 2 minutes. You'll see: - \u2705 Checks that passed (green) - \u274c Checks that failed (red) with hints - Final score - Option to retry if score &lt; 80</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#troubleshooting-hints","title":"Troubleshooting Hints","text":"<p>Build Failed in Jenkins? - Click on build number \u2192 \"Console Output\" - Look for red error messages - Common fix: Tests might fail on first run; click \"Rebuild\"</p> <p>Image Not in Harbor? - Check Jenkins logs for \"Push to Harbor\" stage - Verify Jenkins completed successfully - Wait 1-2 minutes after build completes</p> <p>ArgoCD Stuck \"Out of Sync\"? - Click \"Refresh\" in ArgoCD - If still stuck, click \"Sync\" \u2192 \"Synchronize\" - ArgoCD polls every 3 minutes; you can force manual sync</p> <p>Pods Not Starting? - In ArgoCD, click on pod \u2192 \"Logs\" - Look for error messages (image pull errors, crashes) - Common issue: Image tag mismatch (check Harbor vs. deployment manifest)</p> <p>Application Not Responding? - Verify pods are \"Running\" in ArgoCD - Check pod logs for errors - Verify ingress configuration (ArgoCD \u2192 Ingress resource)</p> <p>Can't Access Application URL? - Verify ingress is \"Healthy\" in ArgoCD - Check ingress annotations - Try health check endpoint first: <code>/actuator/health</code></p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#5-knowledge-check-5-minutes","title":"5. Knowledge Check (5 minutes)","text":""},{"location":"dojo/modules/white-belt/module-04-first-deployment/#quiz-first-deployment-mastery","title":"Quiz: First Deployment Mastery","text":"<p>Instructions: Answer all 10 questions. You need 8/10 (80%) to pass. Unlimited attempts allowed.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-1","title":"Question 1","text":"<p>What triggers a Jenkins build in the Fawkes platform?</p> <ul> <li>[ ] A) Manual button click in Backstage</li> <li>[x] B) Git webhook when code is pushed</li> <li>[ ] C) Scheduled cron job every hour</li> <li>[ ] D) ArgoCD detecting a configuration change</li> </ul> <p>Explanation: When you push code to Git, a webhook automatically triggers Jenkins to start the CI/CD pipeline. This ensures every code change is built and tested.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-2","title":"Question 2","text":"<p>In which component is your container image stored after the build?</p> <ul> <li>[ ] A) Jenkins</li> <li>[x] B) Harbor</li> <li>[ ] C) ArgoCD</li> <li>[ ] D) Kubernetes</li> </ul> <p>Explanation: Harbor is the container registry where Docker images are stored after Jenkins builds them. Harbor also scans images for vulnerabilities.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-3","title":"Question 3","text":"<p>What does ArgoCD do in the deployment pipeline?</p> <ul> <li>[ ] A) Builds the container image</li> <li>[ ] B) Runs unit tests</li> <li>[x] C) Deploys applications to Kubernetes using GitOps</li> <li>[ ] D) Scans code for security vulnerabilities</li> </ul> <p>Explanation: ArgoCD implements GitOps\u2014it continuously monitors Git repositories and ensures Kubernetes cluster state matches the desired state defined in Git.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-4","title":"Question 4","text":"<p>What is a \"golden path template\" in Fawkes?</p> <ul> <li>[ ] A) The fastest route to production</li> <li>[x] B) A pre-configured application scaffold with best practices built-in</li> <li>[ ] C) A deployment checklist</li> <li>[ ] D) A security policy document</li> </ul> <p>Explanation: Golden path templates are pre-built application templates that include everything needed for CI/CD, monitoring, and deployment\u2014so you can start from a working example.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-5","title":"Question 5","text":"<p>When is the \"lead time for changes\" measurement started?</p> <ul> <li>[x] A) When code is committed to Git</li> <li>[ ] B) When Jenkins build starts</li> <li>[ ] C) When ArgoCD begins syncing</li> <li>[ ] D) When pods become ready</li> </ul> <p>Explanation: Lead time starts at the Git commit timestamp and ends when the deployment completes. This measures how long code waits in your process.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-6","title":"Question 6","text":"<p>What does it mean when ArgoCD shows \"Out of Sync\"?</p> <ul> <li>[ ] A) The application is broken</li> <li>[ ] B) Jenkins build failed</li> <li>[x] C) Desired state (Git) differs from actual state (Kubernetes)</li> <li>[ ] D) The database is down</li> </ul> <p>Explanation: \"Out of Sync\" means Git has changes that aren't yet applied to Kubernetes. ArgoCD will automatically sync, or you can trigger it manually.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-7","title":"Question 7","text":"<p>How can you verify your application is healthy after deployment?</p> <ul> <li>[ ] A) Check if ArgoCD shows \"Synced\"</li> <li>[ ] B) Call the application's health endpoint</li> <li>[ ] C) Look at pod status in ArgoCD</li> <li>[x] D) All of the above</li> </ul> <p>Explanation: You should verify all three: ArgoCD sync status, pod health, and application response. A healthy deployment shows green across all checks.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-8","title":"Question 8","text":"<p>Where do you find logs if your application crashes after deployment?</p> <ul> <li>[ ] A) Jenkins build logs</li> <li>[ ] B) Harbor scan results</li> <li>[x] C) Kubernetes pod logs (via ArgoCD or kubectl)</li> <li>[ ] D) Git commit history</li> </ul> <p>Explanation: Pod logs show application runtime errors. Access them via ArgoCD UI \u2192 click pod \u2192 \"Logs\", or use <code>kubectl logs &lt;pod-name&gt;</code>.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-9","title":"Question 9","text":"<p>What does Jenkins do during the \"Security Scan\" stage?</p> <ul> <li>[ ] A) Tests application functionality</li> <li>[x] B) Scans container image for known vulnerabilities</li> <li>[ ] C) Checks code style</li> <li>[ ] D) Deploys to production</li> </ul> <p>Explanation: Jenkins uses Trivy to scan container images for CVEs (Common Vulnerabilities and Exposures) in base images and dependencies.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#question-10","title":"Question 10","text":"<p>Why does the same container image move through all environments (dev \u2192 staging \u2192 prod)?</p> <ul> <li>[ ] A) To save disk space</li> <li>[ ] B) To make builds faster</li> <li>[x] C) To ensure consistency\u2014what you test is what you deploy</li> <li>[ ] D) It's a Fawkes requirement, not a best practice</li> </ul> <p>Explanation: Immutable deployments mean the exact same artifact (container image) progresses through environments. You never rebuild for production\u2014you promote the tested image.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#quiz-results","title":"Quiz Results","text":"<p>Score: X / 10</p> <ul> <li>\u2705 Passed (8+): Excellent! You understand the deployment pipeline.</li> <li>\u274c Not Yet (&lt;8): Review the theory section and try again.</li> </ul> <p>Incorrect answers? Each question links back to the relevant section for review.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#6-reflection-next-steps-5-minutes","title":"6. Reflection &amp; Next Steps (5 minutes)","text":""},{"location":"dojo/modules/white-belt/module-04-first-deployment/#what-you-learned","title":"What You Learned","text":"<p>Congratulations! \ud83c\udf89 You've completed your first deployment on Fawkes. Let's recap:</p> <p>\u2705 You now know: - The complete deployment pipeline from code to production - How Jenkins, Harbor, ArgoCD, and Kubernetes work together - Where to find logs, metrics, and traces at each stage - How DORA metrics are automatically captured - What golden path templates provide - How to troubleshoot common deployment issues</p> <p>\u2705 You can now: - Deploy applications end-to-end without assistance - Monitor deployment progress across multiple tools - Verify application health and functionality - Interpret success/failure at each pipeline stage</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#how-this-connects-to-your-work","title":"How This Connects to Your Work","text":"<p>For Developers: - You can now deploy code multiple times per day - No more waiting for ops team to deploy for you - Immediate feedback on every change - Full visibility into deployment status</p> <p>For Platform Engineers: - You understand how the golden path works - You can help teams troubleshoot deployment issues - You see how observability is built into the pipeline</p> <p>For Leaders: - You've seen how automation enables high deployment frequency - You understand how DORA metrics are captured automatically - You can articulate the business value of the platform</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#real-world-application-exercise","title":"Real-World Application Exercise","text":"<p>This Week, Try This:</p> <ol> <li>Deploy a Real Feature</li> <li>Pick a small feature or bug fix from your backlog</li> <li>Deploy it using the Fawkes platform</li> <li> <p>Measure your lead time (commit to production)</p> </li> <li> <p>Compare Before and After</p> </li> <li>How long did deployments take before Fawkes?</li> <li>How long now?</li> <li> <p>Calculate time saved</p> </li> <li> <p>Share Your Experience</p> </li> <li>Demo your deployed app to your team (5 min standup)</li> <li>Show the DORA metrics dashboard</li> <li>Discuss: \"What would we need to deploy 10x per day?\"</li> </ol>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#reflection-questions","title":"Reflection Questions","text":"<p>Take 2 minutes to think about:</p> <ol> <li>What surprised you most?</li> <li>Was the deployment faster or slower than expected?</li> <li> <p>Which part was easiest? Hardest?</p> </li> <li> <p>What would you change?</p> </li> <li>If you could modify the golden path template, what would you add?</li> <li> <p>What additional automation would be helpful?</p> </li> <li> <p>What's your next deployment?</p> </li> <li>What will you deploy next on Fawkes?</li> <li> <p>Can you deploy to production confidently now?</p> </li> <li> <p>How does this compare to your current process?</p> </li> <li>What manual steps does Fawkes eliminate?</li> <li>What new capabilities does it provide?</li> </ol>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#additional-resources","title":"Additional Resources","text":"<p>\ud83d\udcda Further Reading: - Deployment Strategies - Blue-green, canary, rolling - Golden Path Templates - Creating custom templates - Troubleshooting Guide - Common issues and fixes - GitOps Best Practices - ArgoCD patterns</p> <p>\ud83c\udfa5 Videos to Watch: - \"Advanced Deployment Patterns\" (15 min) - \"Customizing Golden Path Templates\" (20 min) - \"Zero-Downtime Deployments\" (10 min)</p> <p>\ud83d\udee0\ufe0f Hands-On Practice: - Deploy the Python Flask template - Deploy the Node.js Express template - Customize a template (add database, change ports) - Practice rolling back a deployment</p> <p>\ud83d\udcac Community: - Share your first deployment in <code>#dojo-achievements</code> - Help others in <code>#dojo-white-belt</code> - Ask questions in daily office hours</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#preview-white-belt-assessment","title":"Preview: White Belt Assessment","text":"<p>You've Completed All 4 White Belt Modules!</p> <p>Next up is the White Belt Assessment (2 hours): - Deploy 2 additional applications (different languages) - Written exam (30 questions covering modules 1-4) - Practical troubleshooting scenario - Passing score: 80%</p> <p>What You'll Need to Do: 1. Deploy a Python application 2. Deploy a Node.js application 3. Troubleshoot a broken deployment 4. Answer questions on platform concepts 5. Demonstrate DORA metrics knowledge</p> <p>Get Ready: - Review all 4 modules - Practice deploying different templates - Make sure you understand the full pipeline - Be comfortable with troubleshooting</p> <p>When You're Ready: Click \"Start White Belt Assessment\" in your Dojo dashboard.</p>"},{"location":"dojo/modules/white-belt/module-04-first-deployment/#module-completion","title":"Module Completion","text":""},{"location":"dojo/modules/white-belt/module-04-first-deployment/#youve-completed-module-4","title":"\u2705 You've Completed Module 4!","text":"<p>Next Steps: 1. \u2705 Mark this module complete in your Backstage profile 2. \ud83d\udcca View your progress on the Dojo dashboard 3. \ud83d\udcac Share your first deployment in <code>#dojo-achievements</code>! 4. \u27a1\ufe0f Prepare for White Belt Assessment when ready</p> <p>Time Investment: 60 minutes Skills Gained: End-to-end deployment, pipeline understanding, troubleshooting Progress: 4 of 4 modules complete (100% - Ready for White Belt Assessment!)</p> <p>Deployment Count: 1 \ud83d\ude80 Lead Time: ~15 minutes (from commit to production) DORA Metrics: Automatically captured \u2705</p> <p>Questions or Issues? - \ud83d\udcac Ask in <code>#dojo-white-belt</code> on Mattermost - \ud83d\udce7 Email: dojo@fawkes.io - \ud83d\udc1b Report bugs: GitHub Issues</p> <p>Feedback? - Rate this module (takes 30 seconds) - What worked well? What could be better? - Help us improve the learning experience!</p> <p>Module Author: Fawkes Learning Team Last Updated: October 2025 Version: 1.0</p> <p>\ud83c\udf89 Congratulations on your first deployment! You're well on your way to becoming a platform engineering expert.</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/","title":"Fawkes Dojo Module 5: Continuous Integration Fundamentals","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe1 Yellow Belt - CI/CD Mastery Module: 1 of 4 (Yellow Belt) Duration: 60 minutes Difficulty: Intermediate Prerequisites: - White Belt certification complete - Basic understanding of Git workflows - Familiarity with build tools (Maven, npm, etc.) - Command line comfort</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Explain the principles and benefits of Continuous Integration</li> <li>\u2705 Understand Jenkins architecture and core concepts</li> <li>\u2705 Create your first Jenkinsfile (Pipeline as Code)</li> <li>\u2705 Configure build stages: checkout, build, test, package</li> <li>\u2705 Implement basic error handling and notifications</li> <li>\u2705 Understand how CI improves DORA metrics</li> <li>\u2705 Troubleshoot common CI pipeline failures</li> </ol> <p>DORA Capabilities Addressed: - \u2713 CD3: Implement continuous integration - \u2713 CD1: Use version control for all production artifacts - \u2713 CD5: Trunk-based development methods</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-1-what-is-continuous-integration","title":"\ud83d\udcd6 Part 1: What is Continuous Integration?","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#the-problem-integration-hell","title":"The Problem: Integration Hell","text":"<p>Traditional development workflow: <pre><code>Developer A writes code for 2 weeks \u2192 Commits\nDeveloper B writes code for 2 weeks \u2192 Commits\nDeveloper C writes code for 2 weeks \u2192 Commits\n                \u2193\n        Integration Day (Friday)\n                \u2193\n      Merge conflicts, broken tests\n      Incompatible changes, missing dependencies\n                \u2193\n        Weekend fixing integration issues\n</code></pre></p> <p>Result: - Integration becomes painful and risky - Feedback delayed by weeks - Bugs found late, expensive to fix - Releases delayed, stress increases</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#continuous-integration-solution","title":"Continuous Integration Solution","text":"<p>\"Integrate early, integrate often\"</p> <pre><code>Developer A: Commits multiple times per day\n         \u2193\n    Automated Build + Test\n         \u2193\n    Immediate Feedback (5-10 min)\n         \u2193\n    Fix issues immediately\n         \u2193\n    Always in releasable state\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#core-ci-principles","title":"Core CI Principles","text":"<ol> <li>Maintain a Single Source Repository</li> <li>All code in version control</li> <li>One repo truth source</li> <li> <p>Branches short-lived (&lt;1 day)</p> </li> <li> <p>Automate the Build</p> </li> <li>One command builds everything</li> <li>No manual steps</li> <li> <p>Repeatable and reliable</p> </li> <li> <p>Make Your Build Self-Testing</p> </li> <li>Automated unit tests</li> <li>Integration tests</li> <li> <p>Build fails if tests fail</p> </li> <li> <p>Everyone Commits to Mainline Every Day</p> </li> <li>Small, frequent commits</li> <li>Merge conflicts minimized</li> <li> <p>Continuous integration (the name!)</p> </li> <li> <p>Every Commit Should Build on Integration Machine</p> </li> <li>Not \"works on my machine\"</li> <li>Clean environment every time</li> <li> <p>Same as production</p> </li> <li> <p>Keep the Build Fast</p> </li> <li>Target: &lt;10 minutes</li> <li>Developers wait for feedback</li> <li> <p>Slow builds = ignored builds</p> </li> <li> <p>Test in Clone of Production Environment</p> </li> <li>Same OS, same dependencies</li> <li>Containers/VMs for consistency</li> <li> <p>\"Shift left\" on environment issues</p> </li> <li> <p>Make it Easy to Get Latest Deliverables</p> </li> <li>Artifacts automatically published</li> <li>Always available for testing</li> <li> <p>Clear versioning</p> </li> <li> <p>Everyone Can See What's Happening</p> </li> <li>Build status visible to all</li> <li>Radiator dashboards</li> <li> <p>Notifications on failures</p> </li> <li> <p>Automate Deployment</p> <ul> <li>One-click deployment</li> <li>Continuous Delivery (next step)</li> <li>Reduces human error</li> </ul> </li> </ol>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#ci-impact-on-dora-metrics","title":"CI Impact on DORA Metrics","text":"DORA Metric CI Impact Data Deployment Frequency Enables multiple deploys/day with confidence Elite: Multiple per day Lead Time for Changes Reduces commit-to-deploy from days to minutes Elite: &lt;1 hour Change Failure Rate Catches bugs before production Elite: 0-15% MTTR Small changes = easier rollback Elite: &lt;1 hour <p>Research shows: Teams with CI are 2x more likely to be high performers on DORA metrics.</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-2-jenkins-architecture","title":"\ud83c\udfd7\ufe0f Part 2: Jenkins Architecture","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#what-is-jenkins","title":"What is Jenkins?","text":"<p>Jenkins is an open-source automation server that enables CI/CD pipelines.</p> <p>Key Features: - Pipeline as Code (Jenkinsfile) - 1,800+ plugins for integration - Distributed builds (controller + agents) - Kubernetes-native (Fawkes uses Kubernetes Plugin) - Web UI for monitoring and management</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#jenkins-architecture-in-fawkes","title":"Jenkins Architecture in Fawkes","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Fawkes Platform (Kubernetes)              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502      Jenkins Controller (Master)             \u2502  \u2502\n\u2502  \u2502  \u2022 Manages pipelines                         \u2502  \u2502\n\u2502  \u2502  \u2022 Schedules builds                          \u2502  \u2502\n\u2502  \u2502  \u2022 Stores configuration                      \u2502  \u2502\n\u2502  \u2502  \u2022 Serves Web UI                             \u2502  \u2502\n\u2502  \u2502  \u2022 Kubernetes Plugin installed               \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                  \u2502                                  \u2502\n\u2502                  \u2502 (Schedules agents)               \u2502\n\u2502                  \u25bc                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Dynamic Build Agents (Pods)                 \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502  \u2502  \u2502 Java     \u2502  \u2502 Node.js  \u2502  \u2502 Python   \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502 Agent    \u2502  \u2502 Agent    \u2502  \u2502 Agent    \u2502   \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502  \u2502  \u2022 Created on-demand                         \u2502  \u2502\n\u2502  \u2502  \u2022 Isolated namespaces                       \u2502  \u2502\n\u2502  \u2502  \u2022 Auto-deleted after build                  \u2502  \u2502\n\u2502  \u2502  \u2022 Resource limits enforced                  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502      Supporting Services                     \u2502  \u2502\n\u2502  \u2502  \u2022 Git Repository (Source)                   \u2502  \u2502\n\u2502  \u2502  \u2022 Harbor (Artifact Registry)                \u2502  \u2502\n\u2502  \u2502  \u2022 SonarQube (Code Quality)                  \u2502  \u2502\n\u2502  \u2502  \u2022 Trivy (Security Scanning)                 \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#jenkins-controller-vs-agents","title":"Jenkins Controller vs. Agents","text":"<p>Controller (Master): - Orchestrates builds - Manages plugins and configuration - Serves Web UI - Should NOT run builds (security + resource management)</p> <p>Agents (Slaves/Pods): - Execute actual build work - Ephemeral in Kubernetes - Isolated from each other - Deleted after build completes</p> <p>Fawkes Advantage: Using Kubernetes Plugin, agents are dynamic pods. No pre-provisioned VMs needed!</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#pipeline-as-code-jenkinsfile","title":"Pipeline as Code: Jenkinsfile","text":"<p>Modern Jenkins uses declarative pipelines defined in <code>Jenkinsfile</code>:</p> <p>Benefits: - \u2705 Version controlled with code - \u2705 Code review for pipeline changes - \u2705 Consistent across projects - \u2705 Auditable (Git history) - \u2705 Portable across Jenkins instances</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-3-hands-on-lab-your-first-pipeline","title":"\ud83d\udee0\ufe0f Part 3: Hands-On Lab - Your First Pipeline","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#lab-scenario","title":"Lab Scenario","text":"<p>You'll create a CI pipeline for a sample Java Spring Boot application that: 1. Checks out code from Git 2. Compiles the application 3. Runs unit tests 4. Packages as Docker image 5. Pushes to Harbor registry</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#step-1-access-your-lab-environment","title":"Step 1: Access Your Lab Environment","text":"<pre><code># Access Jenkins in Fawkes platform\nkubectl port-forward -n jenkins svc/jenkins 8080:8080\n\n# Get Jenkins admin password\nkubectl get secret -n jenkins jenkins-admin -o jsonpath=\"{.data.password}\" | base64 -d\n\n# Open Jenkins UI\n# URL: http://localhost:8080\n# Username: admin\n# Password: (from above command)\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#step-2-create-your-first-pipeline-job","title":"Step 2: Create Your First Pipeline Job","text":"<p>In Jenkins UI:</p> <ol> <li>Click \"New Item\"</li> <li>Name: <code>my-first-pipeline</code></li> <li>Type: \"Pipeline\"</li> <li>Click \"OK\"</li> </ol> <p>Pipeline Configuration: - Scroll to \"Pipeline\" section - Definition: \"Pipeline script\" - Paste the following script:</p> <pre><code>pipeline {\n    agent {\n        kubernetes {\n            yaml '''\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    jenkins: agent\nspec:\n  containers:\n  - name: maven\n    image: maven:3.8-openjdk-17\n    command:\n    - sleep\n    args:\n    - infinity\n  - name: docker\n    image: docker:24-dind\n    securityContext:\n      privileged: true\n'''\n        }\n    }\n\n    stages {\n        stage('Checkout') {\n            steps {\n                echo 'Checking out source code...'\n                git branch: 'main',\n                    url: 'https://github.com/fawkes-platform/sample-spring-boot.git'\n            }\n        }\n\n        stage('Build') {\n            steps {\n                container('maven') {\n                    echo 'Building application...'\n                    sh 'mvn clean compile'\n                }\n            }\n        }\n\n        stage('Test') {\n            steps {\n                container('maven') {\n                    echo 'Running tests...'\n                    sh 'mvn test'\n                }\n            }\n        }\n\n        stage('Package') {\n            steps {\n                container('maven') {\n                    echo 'Packaging application...'\n                    sh 'mvn package -DskipTests'\n                }\n            }\n        }\n    }\n\n    post {\n        success {\n            echo '\u2705 Pipeline succeeded!'\n        }\n        failure {\n            echo '\u274c Pipeline failed!'\n        }\n        always {\n            echo '\ud83c\udfc1 Pipeline completed'\n        }\n    }\n}\n</code></pre> <ol> <li>Click \"Save\"</li> <li>Click \"Build Now\"</li> </ol>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#step-3-watch-your-pipeline-execute","title":"Step 3: Watch Your Pipeline Execute","text":"<p>In the Jenkins UI: - Click on the build number (e.g., #1) - Click \"Console Output\" to see logs in real-time - Watch as stages progress: Checkout \u2192 Build \u2192 Test \u2192 Package</p> <p>Expected Output: <pre><code>Started by user admin\nRunning in Durability level: MAX_SURVIVABILITY\n[Pipeline] Start of Pipeline\n[Pipeline] podTemplate\n[Pipeline] {\n[Pipeline] node\nCreated Pod: jenkins-agent-xxxxx\nAgent maven-xxxxx is provisioned from template maven\n[Pipeline] {\n[Pipeline] stage (Checkout)\n[Pipeline] { (Checkout)\n[Pipeline] echo\nChecking out source code...\n[Pipeline] git\nCloning repository https://github.com/fawkes-platform/sample-spring-boot.git\n...\n[Pipeline] stage (Build)\n[Pipeline] { (Build)\n[Pipeline] container\n[Pipeline] {\n[Pipeline] echo\nBuilding application...\n[Pipeline] sh\n+ mvn clean compile\n[INFO] Scanning for projects...\n[INFO] Building sample-app 1.0.0\n...\n[INFO] BUILD SUCCESS\n...\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#step-4-understanding-the-jenkinsfile","title":"Step 4: Understanding the Jenkinsfile","text":"<p>Let's break down each section:</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#agent-definition","title":"Agent Definition","text":"<p><pre><code>agent {\n    kubernetes {\n        yaml '''\n        ...\n        '''\n    }\n}\n</code></pre> - Tells Jenkins to run this pipeline on a Kubernetes pod - Defines container images needed (Maven, Docker) - Containers are ephemeral - created for this build, deleted after</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#stages","title":"Stages","text":"<p><pre><code>stages {\n    stage('Checkout') { ... }\n    stage('Build') { ... }\n    stage('Test') { ... }\n    stage('Package') { ... }\n}\n</code></pre> - Sequential steps in your pipeline - Each stage appears as a column in Jenkins UI - Stages fail fast - if one fails, subsequent stages don't run</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#steps","title":"Steps","text":"<p><pre><code>steps {\n    container('maven') {\n        sh 'mvn clean compile'\n    }\n}\n</code></pre> - Actual commands executed - <code>container('maven')</code> - runs inside Maven container - <code>sh</code> - executes shell command - Can use <code>echo</code>, <code>git</code>, custom plugins</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#post-actions","title":"Post Actions","text":"<p><pre><code>post {\n    success { ... }\n    failure { ... }\n    always { ... }\n}\n</code></pre> - Runs after all stages complete - <code>success</code> - only if pipeline succeeded - <code>failure</code> - only if pipeline failed - <code>always</code> - regardless of outcome - Perfect for notifications, cleanup</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-4-understanding-build-stages","title":"\ud83d\udcca Part 4: Understanding Build Stages","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#standard-ci-pipeline-stages","title":"Standard CI Pipeline Stages","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Checkout \u2502 \u2192 \u2502 Build \u2502 \u2192 \u2502 Test \u2502 \u2192 \u2502 Package \u2502 \u2192 \u2502 Publish\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     2s           3m          2m          1m            30s\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#stage-1-checkout","title":"Stage 1: Checkout","text":"<p>Purpose: Get source code from version control</p> <pre><code>stage('Checkout') {\n    steps {\n        git branch: 'main',\n            url: 'https://github.com/org/repo.git',\n            credentialsId: 'github-credentials'\n    }\n}\n</code></pre> <p>Best Practices: - Always specify branch explicitly - Use shallow clone for speed: <code>git clone --depth 1</code> - Store credentials in Jenkins Credentials Store (never in Jenkinsfile!)</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#stage-2-buildcompile","title":"Stage 2: Build/Compile","text":"<p>Purpose: Compile source code, resolve dependencies</p> <pre><code>stage('Build') {\n    steps {\n        container('maven') {\n            sh '''\n                mvn clean compile \\\n                    -DskipTests \\\n                    -B \\\n                    --batch-mode\n            '''\n        }\n    }\n}\n</code></pre> <p>Key Flags: - <code>-DskipTests</code> - Skip tests during compile (run separately) - <code>-B</code> / <code>--batch-mode</code> - Non-interactive, better for CI logs - <code>clean</code> - Remove previous build artifacts</p> <p>Build Duration Targets: - Small projects: &lt;2 minutes - Medium projects: 2-5 minutes - Large projects: 5-10 minutes - If &gt;10 minutes, optimize (covered in Module 6)</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#stage-3-test","title":"Stage 3: Test","text":"<p>Purpose: Run automated tests, verify functionality</p> <pre><code>stage('Test') {\n    steps {\n        container('maven') {\n            sh 'mvn test'\n        }\n    }\n    post {\n        always {\n            junit 'target/surefire-reports/**/*.xml'\n        }\n    }\n}\n</code></pre> <p>Test Types in CI: - Unit Tests: Fast (&lt;1s each), no external dependencies - Integration Tests: Slower (1-10s), may use database/APIs - Contract Tests: Verify API contracts between services</p> <p>Best Practices: - Run unit tests in every build (fast feedback) - Run integration tests in parallel or on schedule - Fail build if tests fail (quality gate) - Publish test reports with <code>junit</code> step</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#stage-4-package","title":"Stage 4: Package","text":"<p>Purpose: Create deployable artifact (JAR, Docker image, etc.)</p> <pre><code>stage('Package') {\n    steps {\n        container('maven') {\n            sh 'mvn package -DskipTests'\n        }\n        container('docker') {\n            sh '''\n                docker build -t myapp:${BUILD_NUMBER} .\n                docker tag myapp:${BUILD_NUMBER} myapp:latest\n            '''\n        }\n    }\n}\n</code></pre> <p>Artifact Versioning: - Use <code>${BUILD_NUMBER}</code> - Jenkins build number (e.g., <code>myapp:142</code>) - Use <code>${GIT_COMMIT}</code> - Git commit SHA (e.g., <code>myapp:abc1234</code>) - Use semantic versioning for releases (e.g., <code>myapp:1.2.3</code>)</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#stage-5-publish-optional-for-module-5","title":"Stage 5: Publish (Optional for Module 5)","text":"<p>Purpose: Push artifacts to registry</p> <pre><code>stage('Publish') {\n    steps {\n        container('docker') {\n            sh '''\n                docker login harbor.fawkes.internal -u ${HARBOR_USER} -p ${HARBOR_PASS}\n                docker push harbor.fawkes.internal/myapp:${BUILD_NUMBER}\n            '''\n        }\n    }\n}\n</code></pre> <p>We'll cover this in detail in Module 8: Artifact Management</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-5-error-handling-debugging","title":"\ud83d\udd0d Part 5: Error Handling &amp; Debugging","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#common-pipeline-failures","title":"Common Pipeline Failures","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#issue-1-checkout-fails","title":"Issue 1: Checkout Fails","text":"<p>Error: <pre><code>ERROR: Error cloning remote repo 'origin'\nhudson.plugins.git.GitException: Command \"git fetch\" returned status code 128\n</code></pre></p> <p>Causes: - Repository URL incorrect - No access credentials configured - Network issues</p> <p>Solutions: <pre><code>// Option 1: Use credentials\ngit branch: 'main',\n    url: 'https://github.com/org/private-repo.git',\n    credentialsId: 'github-pat'\n\n// Option 2: Use SSH\ngit branch: 'main',\n    url: 'git@github.com:org/private-repo.git',\n    credentialsId: 'github-ssh-key'\n\n// Option 3: Check connectivity\nsh 'git ls-remote https://github.com/org/repo.git HEAD'\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#issue-2-build-fails","title":"Issue 2: Build Fails","text":"<p>Error: <pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.8.1:compile\n[ERROR] Compilation failure: Compilation failure:\n[ERROR] /src/main/java/App.java:[10,8] cannot find symbol\n</code></pre></p> <p>Causes: - Compilation errors in code - Missing dependencies - Wrong Java version</p> <p>Solutions: <pre><code>// Specify Java version\nstage('Build') {\n    steps {\n        container('maven') {\n            sh '''\n                java -version\n                mvn -version\n                mvn clean compile\n            '''\n        }\n    }\n}\n\n// Use specific Maven image\nagent {\n    kubernetes {\n        yaml '''\n        containers:\n        - name: maven\n          image: maven:3.8-openjdk-17  # Specific version\n        '''\n    }\n}\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#issue-3-tests-fail","title":"Issue 3: Tests Fail","text":"<p>Error: <pre><code>[ERROR] Tests run: 10, Failures: 2, Errors: 0, Skipped: 0\n[INFO] BUILD FAILURE\n</code></pre></p> <p>Causes: - Actual bugs in code (good thing CI caught it!) - Test environment not set up correctly - Flaky tests (tests that randomly fail)</p> <p>Solutions: <pre><code>stage('Test') {\n    steps {\n        container('maven') {\n            // Run with detailed output\n            sh 'mvn test -X'  // Debug mode\n\n            // Or continue on failure to see all test results\n            sh 'mvn test || true'\n        }\n    }\n    post {\n        always {\n            // Always publish test results\n            junit 'target/surefire-reports/**/*.xml'\n\n            // Archive failed test logs\n            archiveArtifacts artifacts: 'target/surefire-reports/**',\n                             allowEmptyArchive: true\n        }\n    }\n}\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#issue-4-resource-limits","title":"Issue 4: Resource Limits","text":"<p>Error: <pre><code>java.lang.OutOfMemoryError: Java heap space\n</code></pre></p> <p>Causes: - Build requires more memory than allocated - Memory leak in build process</p> <p>Solutions: <pre><code>agent {\n    kubernetes {\n        yaml '''\n        containers:\n        - name: maven\n          image: maven:3.8-openjdk-17\n          resources:\n            requests:\n              memory: \"2Gi\"\n              cpu: \"1000m\"\n            limits:\n              memory: \"4Gi\"\n              cpu: \"2000m\"\n          env:\n          - name: MAVEN_OPTS\n            value: \"-Xmx3g\"  # Increase heap size\n        '''\n    }\n}\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#debugging-techniques","title":"Debugging Techniques","text":"<p>1. Add Verbose Logging <pre><code>stage('Debug') {\n    steps {\n        sh '''\n            echo \"Current directory: $(pwd)\"\n            echo \"Files present:\"\n            ls -la\n            echo \"Java version:\"\n            java -version\n            echo \"Maven version:\"\n            mvn -version\n            echo \"Environment variables:\"\n            env | sort\n        '''\n    }\n}\n</code></pre></p> <p>2. Use Try-Catch <pre><code>stage('Build with Error Handling') {\n    steps {\n        script {\n            try {\n                sh 'mvn clean compile'\n            } catch (Exception e) {\n                echo \"Build failed with error: ${e.message}\"\n                // Send notification, mark unstable, etc.\n                currentBuild.result = 'UNSTABLE'\n            }\n        }\n    }\n}\n</code></pre></p> <p>3. Access Agent Shell <pre><code>// Add this stage temporarily for debugging\nstage('Debug Shell') {\n    steps {\n        container('maven') {\n            sh 'sleep 3600'  // Keeps container alive for 1 hour\n        }\n    }\n}\n\n// Then connect to pod:\n// kubectl exec -it &lt;pod-name&gt; -c maven -- /bin/bash\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-6-ci-best-practices","title":"\ud83c\udfaf Part 6: CI Best Practices","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#1-keep-builds-fast","title":"1. Keep Builds Fast","text":"<p>Target: &lt;10 minutes total</p> <p>Techniques: - Run only essential tests in CI (unit tests) - Parallelize independent stages - Cache dependencies - Use incremental compilation</p> <pre><code>pipeline {\n    options {\n        timestamps()\n        timeout(time: 10, unit: 'MINUTES')  // Fail if &gt;10 min\n    }\n\n    stages {\n        stage('Parallel Tests') {\n            parallel {\n                stage('Unit Tests') {\n                    steps {\n                        sh 'mvn test'\n                    }\n                }\n                stage('Linting') {\n                    steps {\n                        sh 'mvn checkstyle:check'\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#2-fail-fast","title":"2. Fail Fast","text":"<p>Stop pipeline as soon as a critical issue is found.</p> <pre><code>pipeline {\n    options {\n        skipDefaultCheckout()  // Don't checkout until needed\n    }\n\n    stages {\n        stage('Pre-Flight Checks') {\n            steps {\n                // Check if branch name follows convention\n                script {\n                    if (!env.BRANCH_NAME.matches(/(main|develop|feature\\/.+)/)) {\n                        error(\"Invalid branch name: ${env.BRANCH_NAME}\")\n                    }\n                }\n            }\n        }\n\n        stage('Checkout') {\n            steps {\n                checkout scm\n            }\n        }\n\n        // ... rest of pipeline\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#3-notifications","title":"3. Notifications","text":"<p>Keep team informed of build status.</p> <pre><code>post {\n    success {\n        slackSend(\n            color: 'good',\n            message: \"\u2705 Build #${BUILD_NUMBER} succeeded\\nBranch: ${env.BRANCH_NAME}\"\n        )\n    }\n\n    failure {\n        slackSend(\n            color: 'danger',\n            message: \"\u274c Build #${BUILD_NUMBER} failed\\nBranch: ${env.BRANCH_NAME}\\nSee: ${BUILD_URL}\"\n        )\n\n        // Email on failure\n        emailext(\n            subject: \"Build Failed: ${env.JOB_NAME} #${BUILD_NUMBER}\",\n            body: \"Check console output at ${BUILD_URL}\",\n            to: \"${env.CHANGE_AUTHOR_EMAIL}\"\n        )\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#4-environment-variables","title":"4. Environment Variables","text":"<p>Use environment variables for configuration.</p> <pre><code>pipeline {\n    environment {\n        APP_NAME = 'my-spring-boot-app'\n        HARBOR_REGISTRY = 'harbor.fawkes.internal'\n        JAVA_VERSION = '17'\n        MAVEN_OPTS = '-Xmx2g -XX:+UseG1GC'\n    }\n\n    stages {\n        stage('Build') {\n            steps {\n                sh \"\"\"\n                    echo \"Building ${APP_NAME} with Java ${JAVA_VERSION}\"\n                    mvn clean package\n                \"\"\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#5-shared-libraries-preview","title":"5. Shared Libraries (Preview)","text":"<p>Reuse pipeline code across projects.</p> <pre><code>// In Jenkinsfile\n@Library('fawkes-pipeline-library') _\n\nfawkesJavaPipeline {\n    gitRepo = 'https://github.com/org/repo.git'\n    javaVersion = '17'\n    runTests = true\n    publishArtifacts = true\n}\n</code></pre> <p>We'll cover this in Module 6: Golden Path Pipelines</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-7-ci-impact-on-dora-metrics","title":"\ud83d\udcc8 Part 7: CI Impact on DORA Metrics","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#how-ci-improves-each-metric","title":"How CI Improves Each Metric","text":"<p>1. Deployment Frequency <pre><code>Without CI:\n- Manual testing before each deploy\n- Fear of breaking production\n- Result: Deploy 1x per month\n\nWith CI:\n- Automated testing on every commit\n- Confidence in code quality\n- Result: Deploy 10x per day\n</code></pre></p> <p>2. Lead Time for Changes <pre><code>Without CI:\nCommit \u2192 Manual build (30 min) \u2192 Manual test (2 hours) \u2192 Package (30 min)\n= 3+ hours before deploy-ready\n\nWith CI:\nCommit \u2192 Auto build (3 min) \u2192 Auto test (2 min) \u2192 Auto package (1 min)\n= 6 minutes before deploy-ready\n</code></pre></p> <p>3. Change Failure Rate <pre><code>Without CI:\n- No automated testing\n- Bugs reach production\n- Result: 30% of deploys fail\n\nWith CI:\n- Automated tests catch 80% of bugs\n- Code review before merge\n- Result: 5% of deploys fail\n</code></pre></p> <p>4. MTTR (Mean Time to Restore) <pre><code>Without CI:\n- Large commits, hard to isolate issue\n- Manual rollback process\n- Result: 2+ hours to restore\n\nWith CI:\n- Small commits, easy to identify culprit\n- Automated rollback\n- Result: 10 minutes to restore\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#measuring-ci-effectiveness","title":"Measuring CI Effectiveness","text":"<p>Track these metrics in your Jenkins/Fawkes dashboard:</p> <pre><code>// Add to pipeline for metrics collection\npost {\n    always {\n        script {\n            def buildDuration = currentBuild.duration / 1000  // seconds\n            def buildResult = currentBuild.result ?: 'SUCCESS'\n\n            // Send to Prometheus\n            sh \"\"\"mayhem\n                curl -X POST http://prometheus-pushgateway:9091/metrics/job/jenkins \\\n                    --data-binary @- &lt;&lt;EOF\n# TYPE jenkins_build_duration_seconds gauge\njenkins_build_duration_seconds{job=\"${env.JOB_NAME}\",result=\"${buildResult}\"} ${buildDuration}\n\n# TYPE jenkins_build_result counter\njenkins_build_result{job=\"${env.JOB_NAME}\",result=\"${buildResult}\"} 1\nEOF\n            \"\"\"\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-8-practical-exercise","title":"\ud83d\udcaa Part 8: Practical Exercise","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#exercise-build-your-first-real-pipeline","title":"Exercise: Build Your First Real Pipeline","text":"<p>Objective: Create a CI pipeline for a sample application</p> <p>Scenario: You have a Java Spring Boot REST API that needs CI.</p> <p>Requirements: 1. Checkout code from Git 2. Compile with Maven 3. Run unit tests 4. Package as JAR 5. Build Docker image 6. Send Slack notification on failure</p> <p>Starter Code:</p> <pre><code>pipeline {\n    agent {\n        kubernetes {\n            yaml '''\napiVersion: v1\nkind: Pod\nspec:\n  containers:\n  - name: maven\n    image: maven:3.8-openjdk-17\n    command: ['sleep']\n    args: ['infinity']\n  - name: docker\n    image: docker:24-dind\n    securityContext:\n      privileged: true\n    command: ['sleep']\n    args: ['infinity']\n'''\n        }\n    }\n\n    stages {\n        // TODO: Add your stages here\n        // 1. Checkout\n        // 2. Build\n        // 3. Test\n        // 4. Package\n        // 5. Docker Build\n    }\n\n    post {\n        // TODO: Add notifications\n    }\n}\n</code></pre> <p>Validation Criteria: - [ ] Pipeline runs successfully - [ ] All stages complete in &lt;8 minutes - [ ] Test results published to Jenkins - [ ] Docker image created - [ ] Notification sent (Slack or email)</p> <p>Submission: 1. Save your Jenkinsfile to Git repository 2. Run pipeline successfully (screenshot) 3. Show console output 4. Submit repository link</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-9-knowledge-check","title":"\ud83c\udf93 Part 9: Knowledge Check","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#quiz-questions","title":"Quiz Questions","text":"<ol> <li>What is the primary goal of Continuous Integration?</li> <li>[ ] Deploy to production automatically</li> <li>[x] Integrate code changes frequently and catch issues early</li> <li>[ ] Write better documentation</li> <li> <p>[ ] Reduce server costs</p> </li> <li> <p>How often should developers commit to mainline in CI?</p> </li> <li>[ ] Once per week</li> <li>[ ] Once per sprint</li> <li>[x] At least once per day</li> <li> <p>[ ] Only when feature is complete</p> </li> <li> <p>What is the recommended maximum build time?</p> </li> <li>[ ] 30 minutes</li> <li>[x] 10 minutes</li> <li>[ ] 1 hour</li> <li> <p>[ ] As long as it takes</p> </li> <li> <p>In Jenkins Kubernetes Plugin, what happens to build agents after build?</p> </li> <li>[ ] They remain running for next build</li> <li>[x] They are automatically deleted</li> <li>[ ] They are paused</li> <li> <p>[ ] They are archived</p> </li> <li> <p>Which stage should run first in a CI pipeline?</p> </li> <li>[ ] Test</li> <li>[ ] Package</li> <li>[x] Checkout</li> <li> <p>[ ] Deploy</p> </li> <li> <p>What does \"fail fast\" mean in CI?</p> </li> <li>[ ] Make builds run faster</li> <li>[x] Stop pipeline immediately when critical issue found</li> <li>[ ] Skip tests to save time</li> <li> <p>[ ] Deploy even if tests fail</p> </li> <li> <p>What file defines Jenkins Pipeline as Code?</p> </li> <li>[ ] pipeline.yaml</li> <li>[x] Jenkinsfile</li> <li>[ ] build.xml</li> <li> <p>[ ] ci-config.json</p> </li> <li> <p>Which DORA metric is most directly improved by CI?</p> </li> <li>[ ] Deployment Frequency</li> <li>[x] Lead Time for Changes</li> <li>[ ] MTTR</li> <li>[ ] All of the above</li> </ol> <p>Answers: 1-B, 2-C, 3-B, 4-B, 5-C, 6-B, 7-B, 8-D</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#part-10-module-summary-next-steps","title":"\ud83c\udfaf Part 10: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#what-you-learned","title":"What You Learned","text":"<p>\u2705 CI Principles: Early integration, automated builds, fast feedback \u2705 Jenkins Architecture: Controller, agents, Kubernetes plugin \u2705 Pipeline as Code: Jenkinsfile structure and syntax \u2705 Build Stages: Checkout, build, test, package workflow \u2705 Troubleshooting: Common failures and debugging techniques \u2705 Best Practices: Fast builds, fail fast, notifications \u2705 DORA Impact: How CI improves all four key metrics</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#dora-capabilities-achieved","title":"DORA Capabilities Achieved","text":"<ul> <li>\u2705 CD3: Continuous Integration implemented</li> <li>\u2705 CD1: Version control for production artifacts</li> <li>\u2705 CD5: Trunk-based development support</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>CI is about feedback speed - The faster you know about problems, the cheaper they are to fix</li> <li>Automate everything - If it can be automated, it should be automated</li> <li>Keep builds fast - Developers won't wait for slow builds</li> <li>Fail fast - Don't waste time on builds that will fail anyway</li> <li>Make failures visible - Everyone should see broken builds immediately</li> </ol>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#real-world-impact","title":"Real-World Impact","text":"<p>\"Before CI, our integration process took 2-3 days and often failed. After implementing CI with Jenkins: - Build time: 3 hours \u2192 8 minutes - Integration time: 3 days \u2192 Continuous - Bug detection: Post-production \u2192 Pre-commit - Deploy confidence: Low \u2192 High</p> <p>We went from monthly releases to daily deploys.\" - Engineering Team, SaaS Company</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#official-documentation","title":"Official Documentation","text":"<ul> <li>Jenkins Documentation</li> <li>Pipeline Syntax</li> <li>Kubernetes Plugin</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#learning-resources","title":"Learning Resources","text":"<ul> <li>Martin Fowler: Continuous Integration</li> <li>Continuous Delivery Book by Jez Humble</li> <li>Jenkins Pipeline Tutorial</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#community","title":"Community","text":"<ul> <li>Jenkins Community</li> <li>Jenkins Slack</li> <li>Fawkes Mattermost - #yellow-belt channel</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#module-completion","title":"\ud83c\udfc5 Module Completion","text":""},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#assessment-checklist","title":"Assessment Checklist","text":"<p>To complete this module, you must:</p> <ul> <li>[ ] Conceptual Understanding</li> <li>[ ] Explain the 10 principles of CI</li> <li>[ ] Describe Jenkins controller vs. agent architecture</li> <li> <p>[ ] Explain how CI improves DORA metrics</p> </li> <li> <p>[ ] Practical Skills</p> </li> <li>[ ] Create a Jenkinsfile from scratch</li> <li>[ ] Configure Kubernetes agent pod template</li> <li>[ ] Implement checkout, build, test, package stages</li> <li>[ ] Add error handling and notifications</li> <li> <p>[ ] Debug a failed pipeline</p> </li> <li> <p>[ ] Hands-On Lab</p> </li> <li>[ ] Complete the first pipeline lab</li> <li>[ ] Pipeline runs successfully (&lt;10 min)</li> <li>[ ] All tests pass</li> <li> <p>[ ] Docker image created</p> </li> <li> <p>[ ] Quiz</p> </li> <li>[ ] Score 80% or higher (6/8 questions)</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#certification-credit","title":"Certification Credit","text":"<p>Upon completion, you earn: - 5 points toward Yellow Belt certification (25% complete) - Badge: \"CI Practitioner\" - Skill Unlocked: Jenkins Pipeline Creation</p>"},{"location":"dojo/modules/yellow-belt/module-05-ci-fundamentals/#yellow-belt-progress","title":"\ud83c\udf96\ufe0f Yellow Belt Progress","text":"<pre><code>Yellow Belt: CI/CD Mastery\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModule 5: CI Fundamentals        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 25% \u2713\nModule 6: Golden Path Pipelines  \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\nModule 7: Security &amp; Quality     \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\nModule 8: Artifact Management    \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n</code></pre> <p>Next Module Preview: Module 6 - Building Golden Path Pipelines (Shared libraries, pipeline templates, optimization)</p> <p>\ud83c\udf89 Congratulations! You've completed Module 5 and learned the fundamentals of Continuous Integration with Jenkins.</p> <p>You're now ready to build production-ready CI pipelines. Continue to Module 6 to learn how to create reusable, optimized pipeline templates!</p> <p>Fawkes Dojo - Where Platform Engineers Are Forged Version 1.0 | Last Updated: October 2025 License: MIT | https://github.com/paruff/fawkes</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/","title":"Fawkes Dojo Module 6: Building Golden Path Pipelines","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe1 Yellow Belt - CI/CD Mastery Module: 2 of 4 (Yellow Belt) Duration: 60 minutes Difficulty: Intermediate Prerequisites: - Module 5: CI Fundamentals complete - Basic Groovy syntax understanding - Experience with at least one programming language - Jenkins pipeline creation experience</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Understand the concept of \"Golden Path\" in platform engineering</li> <li>\u2705 Create reusable Jenkins Shared Libraries</li> <li>\u2705 Build pipeline templates for multiple languages (Java, Python, Node.js)</li> <li>\u2705 Implement pipeline optimization techniques</li> <li>\u2705 Configure build caching for faster builds</li> <li>\u2705 Use parallel execution to reduce build time</li> <li>\u2705 Measure and improve pipeline performance</li> </ol> <p>DORA Capabilities Addressed: - \u2713 CD1: Version control for all production artifacts - \u2713 CD4: Trunk-based development - \u2713 Continuous Integration (advanced) - \u2713 Code Review</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#part-1-what-is-a-golden-path","title":"\ud83d\udcd6 Part 1: What is a Golden Path?","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#the-problem-pipeline-proliferation","title":"The Problem: Pipeline Proliferation","text":"<p>Without Golden Paths: <pre><code>Team A: Creates Java pipeline (500 lines)\nTeam B: Creates Java pipeline (480 lines, slightly different)\nTeam C: Creates Java pipeline (520 lines, more differences)\nTeam D: Creates Python pipeline from scratch\nTeam E: Copies Team A's pipeline, modifies it\n\nResult:\n- 50 similar but different pipelines\n- Security update needed \u2192 Update 50 pipelines manually\n- New best practice \u2192 Adoption takes months\n- No consistency across teams\n- High maintenance burden\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#golden-path-solution","title":"Golden Path Solution","text":"<p>\"The easiest path should also be the best path\"</p> <pre><code>Golden Path Template (Java)\n      \u2193\n   Maintained by Platform Team\n      \u2193\n   Used by 50 teams\n      \u2193\n   Update once \u2192 All teams benefit\n      \u2193\n   Consistency + Best Practices Built-In\n</code></pre> <p>Golden Path Characteristics: 1. Opinionated: Embeds best practices by default 2. Easy to Use: 5-10 lines to get started 3. Batteries Included: Security, testing, quality gates built-in 4. Customizable: Escape hatches for edge cases 5. Self-Service: Teams can use without platform team help 6. Maintained: Platform team keeps it updated</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#golden-path-in-practice","title":"Golden Path in Practice","text":"<p>Instead of this (200-line Jenkinsfile): <pre><code>pipeline {\n    agent { kubernetes { yaml '''...''' } }\n    stages {\n        stage('Checkout') { ... }\n        stage('Build') { ... }\n        stage('Test') { ... }\n        stage('Security Scan') { ... }\n        stage('Quality Gate') { ... }\n        stage('Package') { ... }\n        stage('Publish') { ... }\n    }\n    post { ... }\n}\n</code></pre></p> <p>Teams write this (10-line Jenkinsfile): <pre><code>@Library('fawkes-pipelines') _\n\ngoldenPathJava {\n    gitRepo = 'https://github.com/myteam/myapp.git'\n    javaVersion = '17'\n    skipTests = false\n}\n</code></pre></p> <p>Result: 95% less boilerplate, 100% best practices</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#part-2-jenkins-shared-libraries","title":"\ud83c\udfd7\ufe0f Part 2: Jenkins Shared Libraries","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#what-are-shared-libraries","title":"What are Shared Libraries?","text":"<p>Jenkins Shared Libraries are reusable Groovy code that can be imported into any Jenkinsfile.</p> <p>Benefits: - \ud83c\udfaf DRY Principle: Don't Repeat Yourself - \ud83d\udd12 Security: Centralized credential management - \ud83d\udce6 Versioning: Tag releases, rollback if needed - \ud83e\uddea Testable: Unit test your pipeline logic - \ud83d\udcda Documentation: Single source of truth</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#shared-library-structure","title":"Shared Library Structure","text":"<pre><code>fawkes-pipeline-library/\n\u251c\u2500\u2500 vars/                          # Global variables (pipeline steps)\n\u2502   \u251c\u2500\u2500 goldenPathJava.groovy     # Java pipeline template\n\u2502   \u251c\u2500\u2500 goldenPathPython.groovy   # Python pipeline template\n\u2502   \u251c\u2500\u2500 goldenPathNode.groovy     # Node.js pipeline template\n\u2502   \u2514\u2500\u2500 notifySlack.groovy        # Slack notification helper\n\u251c\u2500\u2500 src/                           # Shared classes and utilities\n\u2502   \u2514\u2500\u2500 com/\n\u2502       \u2514\u2500\u2500 fawkes/\n\u2502           \u2514\u2500\u2500 pipeline/\n\u2502               \u251c\u2500\u2500 Docker.groovy\n\u2502               \u251c\u2500\u2500 Maven.groovy\n\u2502               \u2514\u2500\u2500 Security.groovy\n\u251c\u2500\u2500 resources/                     # Non-Groovy resources\n\u2502   \u251c\u2500\u2500 pod-templates/\n\u2502   \u2502   \u251c\u2500\u2500 java-agent.yaml\n\u2502   \u2502   \u251c\u2500\u2500 python-agent.yaml\n\u2502   \u2502   \u2514\u2500\u2500 node-agent.yaml\n\u2502   \u2514\u2500\u2500 scripts/\n\u2502       \u2514\u2500\u2500 docker-build.sh\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#part-3-hands-on-lab-create-your-first-shared-library","title":"\ud83d\udee0\ufe0f Part 3: Hands-On Lab - Create Your First Shared Library","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#step-1-set-up-shared-library-repository","title":"Step 1: Set Up Shared Library Repository","text":"<pre><code># Create new Git repository\nmkdir fawkes-pipeline-library\ncd fawkes-pipeline-library\n\n# Create directory structure\nmkdir -p vars\nmkdir -p src/com/fawkes/pipeline\nmkdir -p resources/pod-templates\n\n# Initialize Git\ngit init\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#step-2-create-java-golden-path","title":"Step 2: Create Java Golden Path","text":"<p>Create <code>vars/goldenPathJava.groovy</code>:</p> <pre><code>#!/usr/bin/env groovy\n\ndef call(Map config = [:]) {\n    // Default configuration\n    def defaults = [\n        gitRepo: '',\n        gitBranch: 'main',\n        gitCredentials: 'github-credentials',\n        javaVersion: '17',\n        mavenVersion: '3.8',\n        skipTests: false,\n        runSecurityScan: true,\n        dockerRegistry: 'harbor.fawkes.internal',\n        slackChannel: '#builds'\n    ]\n\n    // Merge user config with defaults\n    config = defaults + config\n\n    // Validate required parameters\n    if (!config.gitRepo) {\n        error(\"gitRepo is required\")\n    }\n\n    pipeline {\n        agent {\n            kubernetes {\n                yaml \"\"\"\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    jenkins: agent\n    app: ${env.JOB_NAME}\nspec:\n  containers:\n  - name: maven\n    image: maven:${config.mavenVersion}-openjdk-${config.javaVersion}\n    command: ['sleep']\n    args: ['infinity']\n    resources:\n      requests:\n        memory: \"2Gi\"\n        cpu: \"1000m\"\n      limits:\n        memory: \"4Gi\"\n        cpu: \"2000m\"\n  - name: docker\n    image: docker:24-dind\n    securityContext:\n      privileged: true\n    command: ['sleep']\n    args: ['infinity']\n\"\"\"\n            }\n        }\n\n        options {\n            timestamps()\n            timeout(time: 15, unit: 'MINUTES')\n            buildDiscarder(logRotator(numToKeepStr: '10'))\n        }\n\n        environment {\n            APP_NAME = \"${env.JOB_NAME}\".split('/')[0]\n            BUILD_VERSION = \"${env.BUILD_NUMBER}\"\n            GIT_COMMIT_SHORT = sh(\n                script: \"git rev-parse --short HEAD\",\n                returnStdout: true\n            ).trim()\n        }\n\n        stages {\n            stage('Checkout') {\n                steps {\n                    script {\n                        echo \"\ud83d\udd04 Checking out ${config.gitRepo}...\"\n                        git branch: config.gitBranch,\n                            url: config.gitRepo,\n                            credentialsId: config.gitCredentials\n                    }\n                }\n            }\n\n            stage('Build') {\n                steps {\n                    container('maven') {\n                        script {\n                            echo \"\ud83d\udd28 Building application...\"\n                            sh \"\"\"\n                                mvn clean compile \\\n                                    -DskipTests \\\n                                    -B \\\n                                    --batch-mode \\\n                                    --no-transfer-progress\n                            \"\"\"\n                        }\n                    }\n                }\n            }\n\n            stage('Test') {\n                when {\n                    expression { !config.skipTests }\n                }\n                steps {\n                    container('maven') {\n                        script {\n                            echo \"\ud83e\uddea Running tests...\"\n                            sh \"\"\"\n                                mvn test \\\n                                    -B \\\n                                    --batch-mode \\\n                                    --no-transfer-progress\n                            \"\"\"\n                        }\n                    }\n                }\n                post {\n                    always {\n                        junit 'target/surefire-reports/**/*.xml'\n                    }\n                }\n            }\n\n            stage('Security Scan') {\n                when {\n                    expression { config.runSecurityScan }\n                }\n                steps {\n                    container('maven') {\n                        script {\n                            echo \"\ud83d\udd12 Running security scan...\"\n                            sh \"\"\"\n                                mvn dependency-check:check \\\n                                    -DfailBuildOnCVSS=7\n                            \"\"\"\n                        }\n                    }\n                }\n            }\n\n            stage('Package') {\n                steps {\n                    container('maven') {\n                        script {\n                            echo \"\ud83d\udce6 Packaging application...\"\n                            sh \"\"\"\n                                mvn package \\\n                                    -DskipTests \\\n                                    -B \\\n                                    --batch-mode \\\n                                    --no-transfer-progress\n                            \"\"\"\n                        }\n                    }\n                }\n            }\n\n            stage('Docker Build') {\n                steps {\n                    container('docker') {\n                        script {\n                            echo \"\ud83d\udc33 Building Docker image...\"\n                            def imageName = \"${config.dockerRegistry}/${env.APP_NAME}\"\n                            def imageTag = \"${env.BUILD_VERSION}-${env.GIT_COMMIT_SHORT}\"\n\n                            sh \"\"\"\n                                docker build \\\n                                    -t ${imageName}:${imageTag} \\\n                                    -t ${imageName}:latest \\\n                                    .\n                            \"\"\"\n\n                            // Store for later stages\n                            env.DOCKER_IMAGE = \"${imageName}:${imageTag}\"\n                        }\n                    }\n                }\n            }\n\n            stage('Publish') {\n                steps {\n                    container('docker') {\n                        script {\n                            echo \"\ud83d\udce4 Publishing Docker image...\"\n                            withCredentials([\n                                usernamePassword(\n                                    credentialsId: 'harbor-credentials',\n                                    usernameVariable: 'DOCKER_USER',\n                                    passwordVariable: 'DOCKER_PASS'\n                                )\n                            ]) {\n                                sh \"\"\"\n                                    echo \\$DOCKER_PASS | docker login ${config.dockerRegistry} -u \\$DOCKER_USER --password-stdin\n                                    docker push ${env.DOCKER_IMAGE}\n                                    docker push ${config.dockerRegistry}/${env.APP_NAME}:latest\n                                \"\"\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        post {\n            success {\n                script {\n                    notifySlack(\n                        channel: config.slackChannel,\n                        color: 'good',\n                        message: \"\u2705 Build #${env.BUILD_NUMBER} succeeded\\n\ud83d\udce6 Image: ${env.DOCKER_IMAGE}\"\n                    )\n                }\n            }\n\n            failure {\n                script {\n                    notifySlack(\n                        channel: config.slackChannel,\n                        color: 'danger',\n                        message: \"\u274c Build #${env.BUILD_NUMBER} failed\\n\ud83d\udd17 ${env.BUILD_URL}\"\n                    )\n                }\n            }\n\n            always {\n                cleanWs()\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#step-3-create-helper-functions","title":"Step 3: Create Helper Functions","text":"<p>Create <code>vars/notifySlack.groovy</code>:</p> <pre><code>#!/usr/bin/env groovy\n\ndef call(Map config = [:]) {\n    if (!config.channel || !config.message) {\n        error(\"channel and message are required\")\n    }\n\n    def color = config.color ?: 'warning'\n\n    try {\n        slackSend(\n            channel: config.channel,\n            color: color,\n            message: config.message,\n            tokenCredentialId: 'slack-token'\n        )\n    } catch (Exception e) {\n        echo \"Warning: Failed to send Slack notification: ${e.message}\"\n        // Don't fail build if notification fails\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#step-4-configure-in-jenkins","title":"Step 4: Configure in Jenkins","text":"<p>Add Shared Library to Jenkins:</p> <ol> <li>Go to Jenkins \u2192 Manage Jenkins \u2192 Configure System</li> <li>Scroll to \"Global Pipeline Libraries\"</li> <li>Click \"Add\"</li> <li>Configure:</li> <li>Name: <code>fawkes-pipelines</code></li> <li>Default version: <code>main</code></li> <li>Retrieval method: \"Modern SCM\"</li> <li>Source Code Management: Git</li> <li>Project Repository: <code>https://github.com/fawkes/pipeline-library.git</code></li> <li>Credentials: (if private repo)</li> <li>\u2705 Check \"Load implicitly\" (makes it available to all pipelines)</li> <li>Save</li> </ol>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#step-5-use-golden-path-in-your-project","title":"Step 5: Use Golden Path in Your Project","text":"<p>Create <code>Jenkinsfile</code> in your application repository:</p> <pre><code>@Library('fawkes-pipelines') _\n\ngoldenPathJava {\n    gitRepo = 'https://github.com/myteam/my-spring-boot-app.git'\n    javaVersion = '17'\n    skipTests = false\n    runSecurityScan = true\n    slackChannel = '#my-team'\n}\n</code></pre> <p>That's it! 6 lines instead of 200+.</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#part-4-creating-templates-for-multiple-languages","title":"\ud83d\udcca Part 4: Creating Templates for Multiple Languages","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#python-golden-path","title":"Python Golden Path","text":"<p>Create <code>vars/goldenPathPython.groovy</code>:</p> <pre><code>#!/usr/bin/env groovy\n\ndef call(Map config = [:]) {\n    def defaults = [\n        gitRepo: '',\n        gitBranch: 'main',\n        pythonVersion: '3.11',\n        skipTests: false,\n        runLinting: true,\n        dockerRegistry: 'harbor.fawkes.internal'\n    ]\n\n    config = defaults + config\n\n    if (!config.gitRepo) {\n        error(\"gitRepo is required\")\n    }\n\n    pipeline {\n        agent {\n            kubernetes {\n                yaml \"\"\"\napiVersion: v1\nkind: Pod\nspec:\n  containers:\n  - name: python\n    image: python:${config.pythonVersion}-slim\n    command: ['sleep']\n    args: ['infinity']\n  - name: docker\n    image: docker:24-dind\n    securityContext:\n      privileged: true\n    command: ['sleep']\n    args: ['infinity']\n\"\"\"\n            }\n        }\n\n        options {\n            timestamps()\n            timeout(time: 15, unit: 'MINUTES')\n        }\n\n        stages {\n            stage('Checkout') {\n                steps {\n                    git branch: config.gitBranch,\n                        url: config.gitRepo\n                }\n            }\n\n            stage('Setup') {\n                steps {\n                    container('python') {\n                        sh '''\n                            python -m pip install --upgrade pip\n                            pip install -r requirements.txt\n                        '''\n                    }\n                }\n            }\n\n            stage('Lint') {\n                when {\n                    expression { config.runLinting }\n                }\n                steps {\n                    container('python') {\n                        sh '''\n                            pip install flake8 black\n                            flake8 . --max-line-length=88\n                            black --check .\n                        '''\n                    }\n                }\n            }\n\n            stage('Test') {\n                when {\n                    expression { !config.skipTests }\n                }\n                steps {\n                    container('python') {\n                        sh '''\n                            pip install pytest pytest-cov\n                            pytest --cov=. --cov-report=xml --cov-report=html\n                        '''\n                    }\n                }\n                post {\n                    always {\n                        publishHTML([\n                            allowMissing: false,\n                            alwaysLinkToLastBuild: true,\n                            keepAll: true,\n                            reportDir: 'htmlcov',\n                            reportFiles: 'index.html',\n                            reportName: 'Coverage Report'\n                        ])\n                    }\n                }\n            }\n\n            stage('Docker Build &amp; Push') {\n                steps {\n                    container('docker') {\n                        script {\n                            def imageName = \"${config.dockerRegistry}/${env.JOB_NAME}\"\n                            def imageTag = \"${env.BUILD_NUMBER}\"\n\n                            sh \"\"\"\n                                docker build -t ${imageName}:${imageTag} .\n                                docker push ${imageName}:${imageTag}\n                            \"\"\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#nodejs-golden-path","title":"Node.js Golden Path","text":"<p>Create <code>vars/goldenPathNode.groovy</code>:</p> <pre><code>#!/usr/bin/env groovy\n\ndef call(Map config = [:]) {\n    def defaults = [\n        gitRepo: '',\n        gitBranch: 'main',\n        nodeVersion: '20',\n        skipTests: false,\n        runLinting: true,\n        packageManager: 'npm'  // or 'yarn', 'pnpm'\n    ]\n\n    config = defaults + config\n\n    pipeline {\n        agent {\n            kubernetes {\n                yaml \"\"\"\napiVersion: v1\nkind: Pod\nspec:\n  containers:\n  - name: node\n    image: node:${config.nodeVersion}-alpine\n    command: ['sleep']\n    args: ['infinity']\n  - name: docker\n    image: docker:24-dind\n    securityContext:\n      privileged: true\n    command: ['sleep']\n    args: ['infinity']\n\"\"\"\n            }\n        }\n\n        stages {\n            stage('Checkout') {\n                steps {\n                    git branch: config.gitBranch,\n                        url: config.gitRepo\n                }\n            }\n\n            stage('Install Dependencies') {\n                steps {\n                    container('node') {\n                        script {\n                            def installCmd = config.packageManager == 'npm' ? 'npm ci' :\n                                           config.packageManager == 'yarn' ? 'yarn install --frozen-lockfile' :\n                                           'pnpm install --frozen-lockfile'\n                            sh installCmd\n                        }\n                    }\n                }\n            }\n\n            stage('Lint') {\n                when {\n                    expression { config.runLinting }\n                }\n                steps {\n                    container('node') {\n                        sh \"${config.packageManager} run lint\"\n                    }\n                }\n            }\n\n            stage('Test') {\n                when {\n                    expression { !config.skipTests }\n                }\n                steps {\n                    container('node') {\n                        sh \"${config.packageManager} test\"\n                    }\n                }\n            }\n\n            stage('Build') {\n                steps {\n                    container('node') {\n                        sh \"${config.packageManager} run build\"\n                    }\n                }\n            }\n\n            stage('Docker Build &amp; Push') {\n                steps {\n                    container('docker') {\n                        script {\n                            def imageName = \"${env.JOB_NAME}\"\n                            sh \"\"\"\n                                docker build -t ${imageName}:${env.BUILD_NUMBER} .\n                                docker push ${imageName}:${env.BUILD_NUMBER}\n                            \"\"\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#part-5-pipeline-optimization-techniques","title":"\u26a1 Part 5: Pipeline Optimization Techniques","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#technique-1-parallel-execution","title":"Technique 1: Parallel Execution","text":"<p>Run independent stages simultaneously:</p> <pre><code>stage('Parallel Quality Checks') {\n    parallel {\n        stage('Unit Tests') {\n            steps {\n                container('maven') {\n                    sh 'mvn test'\n                }\n            }\n        }\n        stage('Linting') {\n            steps {\n                container('maven') {\n                    sh 'mvn checkstyle:check'\n                }\n            }\n        }\n        stage('Security Scan') {\n            steps {\n                container('maven') {\n                    sh 'mvn dependency-check:check'\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>Before: 6 minutes (2min + 2min + 2min sequential) After: 2 minutes (all run in parallel) Improvement: 3x faster \u26a1</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#technique-2-build-caching","title":"Technique 2: Build Caching","text":"<p>Cache Maven dependencies between builds:</p> <pre><code>pipeline {\n    agent {\n        kubernetes {\n            yaml '''\nspec:\n  containers:\n  - name: maven\n    image: maven:3.8-openjdk-17\n    volumeMounts:\n    - name: maven-cache\n      mountPath: /root/.m2\n  volumes:\n  - name: maven-cache\n    persistentVolumeClaim:\n      claimName: maven-cache-pvc\n'''\n        }\n    }\n}\n</code></pre> <p>Before: 3 minutes downloading dependencies every build After: 10 seconds (cached) Improvement: 18x faster on dependencies \u26a1</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#technique-3-incremental-builds","title":"Technique 3: Incremental Builds","text":"<p>Only rebuild what changed:</p> <pre><code>stage('Incremental Build') {\n    steps {\n        script {\n            def changedFiles = sh(\n                script: \"git diff --name-only HEAD~1\",\n                returnStdout: true\n            ).trim()\n\n            if (changedFiles.contains('src/')) {\n                echo \"Source changed, full build\"\n                sh 'mvn clean package'\n            } else if (changedFiles.contains('pom.xml')) {\n                echo \"Dependencies changed, rebuild\"\n                sh 'mvn clean package'\n            } else {\n                echo \"Only docs changed, skip build\"\n                currentBuild.result = 'SUCCESS'\n                return\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#technique-4-smarter-test-execution","title":"Technique 4: Smarter Test Execution","text":"<p>Run only affected tests:</p> <pre><code>stage('Smart Testing') {\n    steps {\n        script {\n            // Use tools like Laika or Maven Test Selection\n            sh '''\n                mvn test \\\n                    -Dtest=$(git diff --name-only HEAD~1 | \\\n                             grep 'src/test' | \\\n                             sed 's/.*\\\\/\\\\(.*\\\\)\\\\.java/\\\\1/' | \\\n                             tr '\\\\n' ',')\n            '''\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#technique-5-resource-optimization","title":"Technique 5: Resource Optimization","text":"<p>Right-size your build agents:</p> <pre><code>// Small builds\nresources:\n  requests:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n  limits:\n    memory: \"1Gi\"\n    cpu: \"1000m\"\n\n// Medium builds\nresources:\n  requests:\n    memory: \"2Gi\"\n    cpu: \"1000m\"\n  limits:\n    memory: \"4Gi\"\n    cpu: \"2000m\"\n\n// Large builds\nresources:\n  requests:\n    memory: \"8Gi\"\n    cpu: \"4000m\"\n  limits:\n    memory: \"16Gi\"\n    cpu: \"8000m\"\n</code></pre> <p>Benefit: Faster scheduling, lower costs, better resource utilization</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#part-6-measuring-pipeline-performance","title":"\ud83d\udcc8 Part 6: Measuring Pipeline Performance","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#build-time-metrics","title":"Build Time Metrics","text":"<p>Track and visualize build performance:</p> <pre><code>post {\n    always {\n        script {\n            // Calculate stage durations\n            def stageDurations = [:]\n            currentBuild.rawBuild.getActions(FlowExecutionAction).each { action -&gt;\n                action.getNodes().each { node -&gt;\n                    if (node.displayName != null) {\n                        def duration = node.getDurationMillis() / 1000\n                        stageDurations[node.displayName] = duration\n                    }\n                }\n            }\n\n            // Send to Prometheus\n            stageDurations.each { stage, duration -&gt;\n                sh \"\"\"\n                    curl -X POST http://prometheus-pushgateway:9091/metrics/job/jenkins/stage/${stage} \\\\\n                        --data-binary @- &lt;&lt;EOF\n# TYPE jenkins_stage_duration_seconds gauge\njenkins_stage_duration_seconds{job=\"${env.JOB_NAME}\",stage=\"${stage}\"} ${duration}\nEOF\n                \"\"\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#key-metrics-to-track","title":"Key Metrics to Track","text":"<pre><code># Average build time\navg(jenkins_build_duration_seconds{job=\"my-app\"})\n\n# Build success rate\nsum(rate(jenkins_build_result{result=\"SUCCESS\"}[7d])) /\nsum(rate(jenkins_build_result[7d])) * 100\n\n# Slowest pipeline stages\ntopk(5, avg(jenkins_stage_duration_seconds) by (stage))\n\n# Build time trend\nrate(jenkins_build_duration_seconds[1d])\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#create-grafana-dashboard","title":"Create Grafana Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Pipeline Performance\",\n    \"panels\": [\n      {\n        \"title\": \"Average Build Time\",\n        \"targets\": [\n          {\n            \"expr\": \"avg(jenkins_build_duration_seconds) by (job)\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Build Success Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(rate(jenkins_build_result{result='SUCCESS'}[7d])) / sum(rate(jenkins_build_result[7d])) * 100\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#part-7-practical-exercise","title":"\ud83d\udcaa Part 7: Practical Exercise","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#exercise-create-a-multi-language-golden-path","title":"Exercise: Create a Multi-Language Golden Path","text":"<p>Objective: Build a shared library that supports Java, Python, and Node.js</p> <p>Requirements: 1. Create <code>vars/goldenPath.groovy</code> that auto-detects language 2. Support configuration for each language 3. Include parallel testing and linting 4. Implement build caching 5. Add performance metrics 6. Create comprehensive documentation</p> <p>Starter Template:</p> <pre><code>// vars/goldenPath.groovy\ndef call(Map config = [:]) {\n    // Auto-detect language\n    def language = detectLanguage()\n\n    echo \"\ud83d\udd0d Detected language: ${language}\"\n\n    switch(language) {\n        case 'java':\n            goldenPathJava(config)\n            break\n        case 'python':\n            goldenPathPython(config)\n            break\n        case 'node':\n            goldenPathNode(config)\n            break\n        default:\n            error(\"Unsupported language: ${language}\")\n    }\n}\n\ndef detectLanguage() {\n    // TODO: Implement language detection\n    // Check for pom.xml, requirements.txt, package.json\n}\n</code></pre> <p>Validation Criteria: - [ ] Auto-detects language correctly - [ ] All three language templates work - [ ] Build time &lt;8 minutes for sample apps - [ ] Caching reduces build time by 50%+ - [ ] Metrics sent to Prometheus - [ ] Documentation includes usage examples</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#part-8-knowledge-check","title":"\ud83c\udf93 Part 8: Knowledge Check","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#quiz-questions","title":"Quiz Questions","text":"<ol> <li>What is a \"Golden Path\" in platform engineering?</li> <li>[ ] The fastest build configuration</li> <li>[x] An opinionated, easy-to-use template with best practices built-in</li> <li>[ ] A deployment strategy</li> <li> <p>[ ] A security scanning tool</p> </li> <li> <p>Where do you put reusable pipeline steps in a Shared Library?</p> </li> <li>[ ] src/ directory</li> <li>[x] vars/ directory</li> <li>[ ] resources/ directory</li> <li> <p>[ ] lib/ directory</p> </li> <li> <p>What is the benefit of parallel execution in pipelines?</p> </li> <li>[ ] Uses less resources</li> <li>[ ] More reliable</li> <li>[x] Reduces total build time</li> <li> <p>[ ] Easier to debug</p> </li> <li> <p>How can you cache Maven dependencies between builds?</p> </li> <li>[ ] Use a faster Maven mirror</li> <li>[x] Mount a persistent volume to /root/.m2</li> <li>[ ] Download dependencies manually</li> <li> <p>[ ] Skip dependency resolution</p> </li> <li> <p>What should you do with build performance metrics?</p> </li> <li>[ ] Ignore them</li> <li>[ ] Only check when builds are slow</li> <li>[x] Send to Prometheus and visualize in Grafana</li> <li> <p>[ ] Store in Jenkins only</p> </li> <li> <p>What's the recommended maximum build time?</p> </li> <li>[ ] 30 minutes</li> <li>[x] 10 minutes</li> <li>[ ] 1 hour</li> <li> <p>[ ] 5 minutes</p> </li> <li> <p>Which stage can typically be parallelized?</p> </li> <li>[ ] Checkout</li> <li>[ ] Build</li> <li>[x] Tests and linting</li> <li> <p>[ ] Docker push</p> </li> <li> <p>What's the main benefit of Pipeline as Code?</p> </li> <li>[x] Version controlled, code reviewed, consistent</li> <li>[ ] Faster builds</li> <li>[ ] Less disk space</li> <li>[ ] Better UI</li> </ol> <p>Answers: 1-B, 2-B, 3-C, 4-B, 5-C, 6-B, 7-C, 8-A</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#part-9-module-summary-next-steps","title":"\ud83c\udfaf Part 9: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#what-you-learned","title":"What You Learned","text":"<p>\u2705 Golden Paths: Opinionated templates that make easy = best \u2705 Shared Libraries: Reusable pipeline code in <code>vars/</code> and <code>src/</code> \u2705 Multi-Language Support: Java, Python, Node.js templates \u2705 Optimization: Parallel execution, caching, incremental builds \u2705 Performance Metrics: Track and improve build times \u2705 Best Practices: DRY, testable, maintainable pipelines</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#dora-capabilities-achieved","title":"DORA Capabilities Achieved","text":"<ul> <li>\u2705 CD1: Version control for production artifacts (advanced)</li> <li>\u2705 CD4: Trunk-based development support</li> <li>\u2705 Code Review: Pipeline changes reviewed like code</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Golden Paths reduce toil - Write once, use everywhere</li> <li>Shared Libraries enable reuse - Don't copy-paste pipelines</li> <li>Optimization matters - 10-minute builds vs 30-minute builds = happier developers</li> <li>Measure everything - Can't improve what you don't measure</li> <li>Maintainability &gt; Brevity - Readable pipelines are better than clever pipelines</li> </ol>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#real-world-impact","title":"Real-World Impact","text":"<p>\"After implementing Golden Path pipelines: - Pipeline creation time: 2 days \u2192 10 minutes - Average build time: 25 minutes \u2192 7 minutes - Pipelines maintained: 50 \u2192 3 templates - Security update rollout: 2 weeks \u2192 1 day</p> <p>Our developers now spend time building features, not maintaining pipelines.\" - Platform Engineering Team, Tech Company</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#documentation","title":"Documentation","text":"<ul> <li>Jenkins Shared Libraries</li> <li>Pipeline Best Practices</li> <li>Kubernetes Plugin Guide</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#examples","title":"Examples","text":"<ul> <li>Fabric8 Pipeline Library</li> <li>CloudBees Pipeline Template Catalog</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#community","title":"Community","text":"<ul> <li>Jenkins Community Forums</li> <li>Fawkes #yellow-belt Mattermost</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#module-completion","title":"\ud83c\udfc5 Module Completion","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#assessment-checklist","title":"Assessment Checklist","text":"<ul> <li>[ ] Conceptual Understanding</li> <li>[ ] Explain Golden Path philosophy</li> <li>[ ] Describe Shared Library structure</li> <li> <p>[ ] Understand pipeline optimization techniques</p> </li> <li> <p>[ ] Practical Skills</p> </li> <li>[ ] Create a Shared Library repository</li> <li>[ ] Build Golden Path template for at least one language</li> <li>[ ] Implement parallel execution</li> <li>[ ] Configure build caching</li> <li> <p>[ ] Add performance metrics collection</p> </li> <li> <p>[ ] Hands-On Lab</p> </li> <li>[ ] Create reusable pipeline template</li> <li>[ ] Reduce build time by 50%+ through optimization</li> <li> <p>[ ] Successfully use template in 3 different projects</p> </li> <li> <p>[ ] Quiz</p> </li> <li>[ ] Score 80% or higher (6/8 questions)</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#certification-credit","title":"Certification Credit","text":"<p>Upon completion, you earn: - 5 points toward Yellow Belt certification (50% complete) - Badge: \"Golden Path Architect\" - Skill Unlocked: Shared Library Development</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#yellow-belt-progress","title":"\ud83c\udf96\ufe0f Yellow Belt Progress","text":"<pre><code>Yellow Belt: CI/CD Mastery\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModule 5: CI Fundamentals        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 25% \u2713\nModule 6: Golden Path Pipelines  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 50% \u2713\nModule 7: Security &amp; Quality     \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\nModule 8: Artifact Management    \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0%\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n</code></pre> <p>Halfway to Yellow Belt! \ud83c\udf89</p> <p>Next Module Preview: Module 7 - Security Scanning &amp; Quality Gates (SonarQube, Trivy, dependency scanning)</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#appendix-a-complete-shared-library-example","title":"\ud83d\udcd6 Appendix A: Complete Shared Library Example","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#full-repository-structure","title":"Full Repository Structure","text":"<pre><code>fawkes-pipeline-library/\n\u251c\u2500\u2500 vars/\n\u2502   \u251c\u2500\u2500 goldenPathJava.groovy\n\u2502   \u251c\u2500\u2500 goldenPathPython.groovy\n\u2502   \u251c\u2500\u2500 goldenPathNode.groovy\n\u2502   \u251c\u2500\u2500 goldenPath.groovy           # Auto-detect wrapper\n\u2502   \u251c\u2500\u2500 notifySlack.groovy\n\u2502   \u251c\u2500\u2500 runSecurityScan.groovy\n\u2502   \u2514\u2500\u2500 deployToKubernetes.groovy\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 com/\n\u2502       \u2514\u2500\u2500 fawkes/\n\u2502           \u2514\u2500\u2500 pipeline/\n\u2502               \u251c\u2500\u2500 Docker.groovy\n\u2502               \u251c\u2500\u2500 Git.groovy\n\u2502               \u251c\u2500\u2500 Maven.groovy\n\u2502               \u251c\u2500\u2500 Kubernetes.groovy\n\u2502               \u2514\u2500\u2500 Security.groovy\n\u251c\u2500\u2500 resources/\n\u2502   \u251c\u2500\u2500 pod-templates/\n\u2502   \u2502   \u251c\u2500\u2500 java-17.yaml\n\u2502   \u2502   \u251c\u2500\u2500 python-311.yaml\n\u2502   \u2502   \u251c\u2500\u2500 node-20.yaml\n\u2502   \u2502   \u2514\u2500\u2500 docker-dind.yaml\n\u2502   \u251c\u2500\u2500 scripts/\n\u2502   \u2502   \u251c\u2500\u2500 docker-build.sh\n\u2502   \u2502   \u251c\u2500\u2500 security-scan.sh\n\u2502   \u2502   \u2514\u2500\u2500 promote-artifact.sh\n\u2502   \u2514\u2500\u2500 config/\n\u2502       \u251c\u2500\u2500 sonarqube.properties\n\u2502       \u2514\u2500\u2500 checkstyle.xml\n\u251c\u2500\u2500 test/\n\u2502   \u2514\u2500\u2500 groovy/\n\u2502       \u2514\u2500\u2500 com/\n\u2502           \u2514\u2500\u2500 fawkes/\n\u2502               \u2514\u2500\u2500 pipeline/\n\u2502                   \u2514\u2500\u2500 DockerTest.groovy\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 README.md\n\u2502   \u251c\u2500\u2500 CONTRIBUTING.md\n\u2502   \u2514\u2500\u2500 examples/\n\u2502       \u251c\u2500\u2500 java-example.md\n\u2502       \u251c\u2500\u2500 python-example.md\n\u2502       \u2514\u2500\u2500 node-example.md\n\u251c\u2500\u2500 Jenkinsfile                     # For testing the library itself\n\u2514\u2500\u2500 VERSION\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#example-advanced-docker-helper-class","title":"Example: Advanced Docker Helper Class","text":"<p>Create <code>src/com/fawkes/pipeline/Docker.groovy</code>:</p> <pre><code>package com.fawkes.pipeline\n\nclass Docker implements Serializable {\n    def script\n\n    Docker(script) {\n        this.script = script\n    }\n\n    def build(Map config) {\n        def imageName = config.imageName ?: script.env.JOB_NAME\n        def imageTag = config.imageTag ?: script.env.BUILD_NUMBER\n        def dockerfile = config.dockerfile ?: 'Dockerfile'\n        def context = config.context ?: '.'\n        def buildArgs = config.buildArgs ?: [:]\n\n        script.echo \"\ud83d\udc33 Building Docker image: ${imageName}:${imageTag}\"\n\n        def buildArgsStr = buildArgs.collect { k, v -&gt; \"--build-arg ${k}=${v}\" }.join(' ')\n\n        script.sh \"\"\"\n            docker build \\\n                -f ${dockerfile} \\\n                -t ${imageName}:${imageTag} \\\n                ${buildArgsStr} \\\n                ${context}\n        \"\"\"\n\n        return \"${imageName}:${imageTag}\"\n    }\n\n    def push(String image, Map config = [:]) {\n        def registry = config.registry ?: 'harbor.fawkes.internal'\n        def credentialsId = config.credentialsId ?: 'harbor-credentials'\n\n        script.echo \"\ud83d\udce4 Pushing image: ${image}\"\n\n        script.withCredentials([\n            script.usernamePassword(\n                credentialsId: credentialsId,\n                usernameVariable: 'DOCKER_USER',\n                passwordVariable: 'DOCKER_PASS'\n            )\n        ]) {\n            script.sh \"\"\"\n                echo \\$DOCKER_PASS | docker login ${registry} -u \\$DOCKER_USER --password-stdin\n                docker push ${image}\n            \"\"\"\n        }\n    }\n\n    def scan(String image, Map config = [:]) {\n        def severity = config.severity ?: 'HIGH,CRITICAL'\n        def exitCode = config.exitCode ?: 1\n\n        script.echo \"\ud83d\udd12 Scanning image for vulnerabilities: ${image}\"\n\n        script.sh \"\"\"\n            trivy image \\\n                --severity ${severity} \\\n                --exit-code ${exitCode} \\\n                --no-progress \\\n                ${image}\n        \"\"\"\n    }\n\n    def tag(String sourceImage, String targetTag) {\n        script.echo \"\ud83c\udff7\ufe0f Tagging image: ${sourceImage} \u2192 ${targetTag}\"\n        script.sh \"docker tag ${sourceImage} ${targetTag}\"\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#using-the-helper-class","title":"Using the Helper Class","text":"<p>In <code>vars/goldenPathJava.groovy</code>:</p> <pre><code>@Library('fawkes-pipelines') _\nimport com.fawkes.pipeline.Docker\n\ndef call(Map config = [:]) {\n    pipeline {\n        agent { kubernetes { yaml '...' } }\n\n        stages {\n            // ... build stages ...\n\n            stage('Docker Operations') {\n                steps {\n                    container('docker') {\n                        script {\n                            def docker = new Docker(this)\n\n                            // Build\n                            def image = docker.build(\n                                imageName: \"${config.dockerRegistry}/${env.APP_NAME}\",\n                                imageTag: \"${env.BUILD_NUMBER}\",\n                                buildArgs: [\n                                    'BUILD_DATE': new Date().format('yyyy-MM-dd'),\n                                    'VCS_REF': env.GIT_COMMIT\n                                ]\n                            )\n\n                            // Scan\n                            docker.scan(image, severity: 'CRITICAL')\n\n                            // Tag\n                            docker.tag(image, \"${config.dockerRegistry}/${env.APP_NAME}:latest\")\n\n                            // Push\n                            docker.push(image)\n                            docker.push(\"${config.dockerRegistry}/${env.APP_NAME}:latest\")\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#appendix-b-testing-shared-libraries","title":"\ud83d\udcd6 Appendix B: Testing Shared Libraries","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#unit-testing-with-spock","title":"Unit Testing with Spock","text":"<p>Create <code>test/groovy/com/fawkes/pipeline/DockerTest.groovy</code>:</p> <pre><code>package com.fawkes.pipeline\n\nimport spock.lang.Specification\n\nclass DockerTest extends Specification {\n\n    def script = Mock()\n    Docker docker = new Docker(script)\n\n    def \"build should construct correct docker command\"() {\n        given:\n        def config = [\n            imageName: 'myapp',\n            imageTag: 'v1.0',\n            buildArgs: [APP_VERSION: '1.0.0']\n        ]\n\n        when:\n        docker.build(config)\n\n        then:\n        1 * script.sh(_ as String) &gt;&gt; { String cmd -&gt;\n            assert cmd.contains('docker build')\n            assert cmd.contains('-t myapp:v1.0')\n            assert cmd.contains('--build-arg APP_VERSION=1.0.0')\n        }\n    }\n\n    def \"scan should fail on critical vulnerabilities\"() {\n        given:\n        def image = 'myapp:v1.0'\n\n        when:\n        docker.scan(image)\n\n        then:\n        1 * script.sh(_ as String) &gt;&gt; { String cmd -&gt;\n            assert cmd.contains('trivy image')\n            assert cmd.contains('--severity HIGH,CRITICAL')\n            assert cmd.contains('--exit-code 1')\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#integration-testing","title":"Integration Testing","text":"<p>Create <code>Jenkinsfile</code> in library root:</p> <pre><code>// Test the shared library itself\n@Library('fawkes-pipelines@development') _\n\npipeline {\n    agent any\n\n    stages {\n        stage('Test Java Template') {\n            steps {\n                script {\n                    goldenPathJava {\n                        gitRepo = 'https://github.com/fawkes/sample-java-app.git'\n                        skipTests = true\n                    }\n                }\n            }\n        }\n\n        stage('Test Python Template') {\n            steps {\n                script {\n                    goldenPathPython {\n                        gitRepo = 'https://github.com/fawkes/sample-python-app.git'\n                        skipTests = true\n                    }\n                }\n            }\n        }\n\n        stage('Test Node Template') {\n            steps {\n                script {\n                    goldenPathNode {\n                        gitRepo = 'https://github.com/fawkes/sample-node-app.git'\n                        skipTests = true\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#appendix-c-advanced-optimization-patterns","title":"\ud83d\udcd6 Appendix C: Advanced Optimization Patterns","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#pattern-1-build-matrix","title":"Pattern 1: Build Matrix","text":"<p>Run builds for multiple versions in parallel:</p> <pre><code>def call(Map config = [:]) {\n    def javaVersions = config.javaVersions ?: ['11', '17', '21']\n\n    pipeline {\n        agent none\n\n        stages {\n            stage('Build Matrix') {\n                matrix {\n                    axes {\n                        axis {\n                            name 'JAVA_VERSION'\n                            values javaVersions\n                        }\n                    }\n\n                    agent {\n                        kubernetes {\n                            yaml \"\"\"\nspec:\n  containers:\n  - name: maven\n    image: maven:3.8-openjdk-\\${JAVA_VERSION}\n\"\"\"\n                        }\n                    }\n\n                    stages {\n                        stage('Build') {\n                            steps {\n                                container('maven') {\n                                    sh \"\"\"\n                                        echo \"Building with Java \\${JAVA_VERSION}\"\n                                        mvn clean package\n                                    \"\"\"\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#pattern-2-conditional-stages","title":"Pattern 2: Conditional Stages","text":"<p>Skip stages based on branch or file changes:</p> <pre><code>stage('Deploy to Production') {\n    when {\n        allOf {\n            branch 'main'\n            not { changeRequest() }\n            expression {\n                def changedFiles = sh(\n                    script: \"git diff --name-only HEAD~1\",\n                    returnStdout: true\n                ).trim()\n                return changedFiles.contains('src/')\n            }\n        }\n    }\n    steps {\n        echo \"Deploying to production...\"\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#pattern-3-dynamic-stage-generation","title":"Pattern 3: Dynamic Stage Generation","text":"<p>Generate stages based on configuration:</p> <pre><code>def generateTestStages(List&lt;String&gt; testSuites) {\n    def parallelStages = [:]\n\n    testSuites.each { suite -&gt;\n        parallelStages[\"Test ${suite}\"] = {\n            stage(\"Test ${suite}\") {\n                sh \"mvn test -Dtest=${suite}Test\"\n            }\n        }\n    }\n\n    return parallelStages\n}\n\npipeline {\n    stages {\n        stage('Parallel Tests') {\n            steps {\n                script {\n                    parallel generateTestStages(['Unit', 'Integration', 'E2E'])\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#pattern-4-build-artifact-promotion","title":"Pattern 4: Build Artifact Promotion","text":"<p>Progressive promotion through environments:</p> <pre><code>def promote(String artifact, String fromEnv, String toEnv) {\n    echo \"Promoting ${artifact} from ${fromEnv} to ${toEnv}\"\n\n    // Tag artifact\n    sh \"\"\"\n        docker pull ${artifact}:${fromEnv}\n        docker tag ${artifact}:${fromEnv} ${artifact}:${toEnv}\n        docker push ${artifact}:${toEnv}\n    \"\"\"\n\n    // Update manifest\n    sh \"\"\"\n        git clone https://github.com/org/gitops-manifests.git\n        cd gitops-manifests\n        sed -i 's|${artifact}:.*|${artifact}:${toEnv}|' ${toEnv}/deployment.yaml\n        git add .\n        git commit -m \"Promote ${artifact} to ${toEnv}\"\n        git push\n    \"\"\"\n}\n\n// Usage\nstage('Promote to Production') {\n    steps {\n        script {\n            promote(env.DOCKER_IMAGE, 'staging', 'production')\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#appendix-d-troubleshooting-guide","title":"\ud83d\udcd6 Appendix D: Troubleshooting Guide","text":""},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#issue-shared-library-not-found","title":"Issue: Shared Library Not Found","text":"<p>Error: <pre><code>ERROR: Library fawkes-pipelines not found\n</code></pre></p> <p>Solutions: 1. Check library name matches in Jenkins global config 2. Verify repository URL is correct 3. Check branch/tag specified exists 4. If using credentials, verify they're configured</p> <pre><code>// Use specific version\n@Library('fawkes-pipelines@v1.2.3') _\n\n// Use branch\n@Library('fawkes-pipelines@develop') _\n\n// Use commit SHA\n@Library('fawkes-pipelines@abc1234') _\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#issue-class-not-found-in-src","title":"Issue: Class Not Found in src/","text":"<p>Error: <pre><code>unable to resolve class com.fawkes.pipeline.Docker\n</code></pre></p> <p>Solutions: 1. Check package path matches directory structure 2. Ensure class is Serializable 3. Import correctly in calling code</p> <pre><code>// Correct import\nimport com.fawkes.pipeline.Docker\n\n// File must be: src/com/fawkes/pipeline/Docker.groovy\n// Class must implement Serializable\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#issue-variable-not-found-in-vars","title":"Issue: Variable Not Found in vars/","text":"<p>Error: <pre><code>No such DSL method 'goldenPathJava' found\n</code></pre></p> <p>Solutions: 1. Check file is in vars/ directory 2. Filename must match function name 3. Library must be imported</p> <pre><code>// vars/goldenPathJava.groovy defines goldenPathJava()\n@Library('fawkes-pipelines') _\ngoldenPathJava { ... }\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#issue-slow-library-loading","title":"Issue: Slow Library Loading","text":"<p>Problem: Pipeline takes 2+ minutes to start</p> <p>Solutions: 1. Enable library caching 2. Use specific version (not HEAD) 3. Reduce library size</p> <p>In Jenkins global config: <pre><code>\u2611 Cache fetched versions on controller for quick retrieval\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#issue-cannot-modify-immutable-objects","title":"Issue: Cannot Modify Immutable Objects","text":"<p>Error: <pre><code>Scripts not permitted to use method groovy.lang.GroovyObject\n</code></pre></p> <p>Solutions: 1. Approve script in Jenkins \u2192 Manage Jenkins \u2192 In-process Script Approval 2. Use <code>@NonCPS</code> annotation for methods that manipulate complex objects</p> <pre><code>@NonCPS\ndef parseJson(String json) {\n    def slurper = new JsonSlurper()\n    return slurper.parseText(json)\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#congratulations","title":"\ud83c\udf89 Congratulations!","text":"<p>You've completed Module 6: Building Golden Path Pipelines!</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#key-achievements","title":"Key Achievements","text":"<p>\u2705 Created reusable Shared Libraries \u2705 Built Golden Path templates for Java, Python, Node.js \u2705 Optimized pipelines with parallel execution and caching \u2705 Implemented performance monitoring \u2705 Reduced pipeline maintenance by 90%+</p>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#your-golden-path-journey","title":"Your Golden Path Journey","text":"<pre><code>Before Module 6:\n\ud83d\udc64 Writing 200+ line Jenkinsfiles for each project\n\ud83d\udd04 Copy-pasting pipeline code\n\ud83d\udc0c 30-minute builds\n\ud83d\ude30 Fear of changing pipelines\n\nAfter Module 6:\n\ud83d\udc65 10-line Jenkinsfiles using Golden Paths\n\u267b\ufe0f Reusable components in Shared Libraries\n\u26a1 8-minute builds with optimization\n\ud83d\ude0e Confident pipeline changes, tested in library\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#impact-on-dora-metrics","title":"Impact on DORA Metrics","text":"<ul> <li>Deployment Frequency: \u2b06\ufe0f Easier pipelines = more deploys</li> <li>Lead Time: \u2b07\ufe0f Faster builds = faster feedback</li> <li>Change Failure Rate: \u2b07\ufe0f Tested templates = fewer failures</li> <li>MTTR: \u2b07\ufe0f Consistent pipelines = easier debugging</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-06-golden-path/#whats-next","title":"\ud83d\udcc5 What's Next?","text":"<p>Continue Your Journey:</p> <ol> <li>\u2705 Complete Module 7: Security Scanning &amp; Quality Gates</li> <li>\u2705 Complete Module 8: Artifact Management</li> <li>\ud83c\udf93 Take Yellow Belt Certification Exam</li> <li>\ud83d\ude80 Advance to Green Belt (GitOps &amp; Deployment)</li> </ol> <p>Practice: - Implement Golden Paths for your team - Measure build time improvements - Share templates with community</p> <p>Community: - Share your Shared Library in #show-and-tell - Help others in #yellow-belt channel - Write a blog post about your experience</p> <p>Ready for Module 7? \ud83d\udd12</p> <p>Next up: Security Scanning &amp; Quality Gates - where you'll learn SonarQube, Trivy, dependency scanning, and building security into every pipeline!</p> <p>Fawkes Dojo - Where Platform Engineers Are Forged Version 1.0 | Last Updated: October 2025 License: MIT | https://github.com/paruff/fawkes</p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/","title":"Fawkes Dojo Module 7: Security Scanning &amp; Quality Gates","text":""},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe1 Yellow Belt - CI/CD Mastery Module: 3 of 4 (Yellow Belt) Duration: 60 minutes Difficulty: Intermediate Prerequisites: - Module 5 &amp; 6 complete - Understanding of CI/CD pipelines - Basic security awareness - Familiarity with code quality concepts</p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Understand \"Shift Left on Security\" principles</li> <li>\u2705 Implement static code analysis with SonarQube</li> <li>\u2705 Scan container images for vulnerabilities with Trivy</li> <li>\u2705 Detect secrets and sensitive data in code</li> <li>\u2705 Perform dependency scanning and SBOM generation</li> <li>\u2705 Configure quality gates that enforce standards</li> <li>\u2705 Integrate security scanning into Golden Path pipelines</li> </ol> <p>DORA Capabilities Addressed: - \u2713 CD6: Shift Left on Security - \u2713 CD8: Test Data Management - \u2713 Security &amp; Compliance Automation</p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#part-1-shift-left-on-security","title":"\ud83d\udcd6 Part 1: Shift Left on Security","text":""},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#the-traditional-security-approach-shift-right","title":"The Traditional Security Approach (Shift Right)","text":"<pre><code>Develop \u2192 Build \u2192 Test \u2192 Deploy \u2192 [SECURITY SCAN] \u2192 Production\n                                        \u2191\n                              Find issues AFTER deployment\n                              Expensive to fix\n                              Delays release\n</code></pre> <p>Problems: - Security as afterthought - Issues found late, expensive to fix - Security team bottleneck - Slow feedback (days/weeks)</p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#shift-left-on-security","title":"Shift Left on Security","text":"<pre><code>[SECURITY SCAN] \u2192 Develop \u2192 [SECURITY SCAN] \u2192 Build \u2192 [SECURITY SCAN] \u2192 Deploy\n      \u2191                            \u2191                         \u2191\n   IDE plugins            CI/CD Pipeline              Container scan\n   Immediate feedback     Fast feedback (5 min)       Pre-deploy check\n</code></pre> <p>Benefits: - \u2705 Catch issues early (cheaper to fix) - \u2705 Developer ownership of security - \u2705 Automated enforcement - \u2705 Faster feedback loops - \u2705 Reduced security team bottleneck</p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#cost-of-finding-bugs-by-stage","title":"Cost of Finding Bugs by Stage","text":"Stage Cost to Fix Time to Fix Impact IDE/Dev $1 Minutes None CI/CD $10 Hours Blocks build QA/Test $100 Days Delays release Production $1,000+ Weeks Customer impact, reputation damage <p>10x-100x cheaper to catch early!</p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#part-2-static-application-security-testing-sast","title":"\ud83c\udfd7\ufe0f Part 2: Static Application Security Testing (SAST)","text":""},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#what-is-sast","title":"What is SAST?","text":"<p>Static Analysis: Analyze source code without executing it</p> <p>Detects: - Security vulnerabilities (SQL injection, XSS, etc.) - Code quality issues (dead code, duplicates) - Code smells (complex methods, poor structure) - Technical debt - Coverage gaps</p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#sonarqube-in-fawkes","title":"SonarQube in Fawkes","text":"<p>SonarQube is the SAST tool integrated into Fawkes platform.</p> <p>Key Features: - 30+ language support - 5,000+ rules - Quality gates - Technical debt tracking - Security hotspots - Pull request decoration</p> <p>Architecture: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Jenkins Pipeline               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  sonar-scanner                   \u2502  \u2502\n\u2502  \u2502  \u2022 Analyzes code                 \u2502  \u2502\n\u2502  \u2502  \u2022 Sends to SonarQube server     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  SonarQube Server  \u2502\n        \u2502  \u2022 Stores results  \u2502\n        \u2502  \u2022 Applies rules   \u2502\n        \u2502  \u2022 Quality gates   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  PostgreSQL DB     \u2502\n        \u2502  \u2022 Historical data \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#part-3-hands-on-lab-implementing-security-scanning","title":"\ud83d\udee0\ufe0f Part 3: Hands-On Lab - Implementing Security Scanning","text":""},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#step-1-add-sonarqube-to-pipeline","title":"Step 1: Add SonarQube to Pipeline","text":"<p>Update your Golden Path pipeline:</p> <pre><code>// vars/goldenPathJava.groovy\nstage('Code Analysis') {\n    steps {\n        container('maven') {\n            withSonarQubeEnv('Fawkes-SonarQube') {\n                sh '''\n                    mvn sonar:sonar \\\n                        -Dsonar.projectKey=${JOB_NAME} \\\n                        -Dsonar.projectName=\"${JOB_NAME}\" \\\n                        -Dsonar.projectVersion=${BUILD_NUMBER} \\\n                        -Dsonar.sources=src/main/java \\\n                        -Dsonar.tests=src/test/java \\\n                        -Dsonar.java.binaries=target/classes \\\n                        -Dsonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml\n                '''\n            }\n        }\n    }\n}\n\nstage('Quality Gate') {\n    steps {\n        timeout(time: 5, unit: 'MINUTES') {\n            waitForQualityGate abortPipeline: true\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#step-2-configure-quality-gate","title":"Step 2: Configure Quality Gate","text":"<p>In SonarQube UI:</p> <ol> <li>Go to Quality Gates</li> <li>Create new gate: \"Fawkes Standard\"</li> <li>Add conditions:</li> </ol> <pre><code>Conditions:\n\u251c\u2500\u2500 Coverage &lt; 80% \u2192 FAILED\n\u251c\u2500\u2500 Duplicated Lines (%) &gt; 3% \u2192 FAILED\n\u251c\u2500\u2500 Maintainability Rating worse than A \u2192 FAILED\n\u251c\u2500\u2500 Reliability Rating worse than A \u2192 FAILED\n\u251c\u2500\u2500 Security Rating worse than A \u2192 FAILED\n\u251c\u2500\u2500 Security Hotspots Reviewed &lt; 100% \u2192 FAILED\n\u2514\u2500\u2500 New Critical Issues &gt; 0 \u2192 FAILED\n</code></pre> <ol> <li>Set as default gate</li> </ol>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#step-3-add-container-scanning-with-trivy","title":"Step 3: Add Container Scanning with Trivy","text":"<pre><code>stage('Container Security Scan') {\n    steps {\n        container('docker') {\n            script {\n                def imageName = \"${env.DOCKER_IMAGE}\"\n\n                echo \"\ud83d\udd12 Scanning image: ${imageName}\"\n\n                // Scan for vulnerabilities\n                sh \"\"\"\n                    trivy image \\\n                        --severity HIGH,CRITICAL \\\n                        --exit-code 1 \\\n                        --no-progress \\\n                        --format json \\\n                        --output trivy-report.json \\\n                        ${imageName}\n                \"\"\"\n\n                // Also generate human-readable report\n                sh \"\"\"\n                    trivy image \\\n                        --severity HIGH,CRITICAL \\\n                        --format table \\\n                        ${imageName}\n                \"\"\"\n            }\n        }\n    }\n    post {\n        always {\n            archiveArtifacts artifacts: 'trivy-report.json',\n                             allowEmptyArchive: true\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#step-4-secret-scanning","title":"Step 4: Secret Scanning","text":"<pre><code>stage('Secret Detection') {\n    steps {\n        container('maven') {\n            script {\n                echo \"\ud83d\udd0d Scanning for secrets...\"\n\n                // Install trufflehog\n                sh '''\n                    pip3 install trufflehog\n                '''\n\n                // Scan repository\n                sh '''\n                    trufflehog filesystem . \\\n                        --json \\\n                        --fail \\\n                        --no-update \\\n                        &gt; trufflehog-report.json || true\n                '''\n\n                // Check results\n                def report = readFile('trufflehog-report.json')\n                if (report.trim()) {\n                    error(\"\ud83d\udea8 Secrets detected in code! See trufflehog-report.json\")\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#step-5-dependency-scanning","title":"Step 5: Dependency Scanning","text":"<pre><code>stage('Dependency Scan') {\n    steps {\n        container('maven') {\n            script {\n                echo \"\ud83d\udce6 Scanning dependencies...\"\n\n                // OWASP Dependency Check\n                sh '''\n                    mvn dependency-check:check \\\n                        -DfailBuildOnCVSS=7 \\\n                        -DsuppressionFile=dependency-check-suppressions.xml\n                '''\n            }\n        }\n    }\n    post {\n        always {\n            publishHTML([\n                allowMissing: false,\n                alwaysLinkToLastBuild: true,\n                keepAll: true,\n                reportDir: 'target',\n                reportFiles: 'dependency-check-report.html',\n                reportName: 'Dependency Check Report'\n            ])\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#part-4-understanding-security-scan-results","title":"\ud83d\udcca Part 4: Understanding Security Scan Results","text":""},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#sonarqube-metrics-explained","title":"SonarQube Metrics Explained","text":"<p>1. Bugs \ud83d\udc1b - Code that is demonstrably wrong - Example: Null pointer dereference - Standard: 0 bugs</p> <p>2. Vulnerabilities \ud83d\udd13 - Security-related issues - Example: SQL injection risk - Standard: 0 vulnerabilities</p> <p>3. Code Smells \ud83d\udc43 - Maintainability issues - Example: Method too complex - Standard: &lt; 5% code smells</p> <p>4. Security Hotspots \ud83d\udd25 - Security-sensitive code requiring review - Example: Cryptographic operations - Standard: 100% reviewed</p> <p>5. Coverage \ud83d\udcca - % of code covered by tests - Standard: &gt; 80%</p> <p>6. Duplications \u00a9\ufe0f - Duplicate code blocks - Standard: &lt; 3%</p> <p>7. Technical Debt \ud83d\udcb8 - Time to fix all issues - Standard: &lt; 5% debt ratio</p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#trivy-severity-levels","title":"Trivy Severity Levels","text":"Severity CVSS Score Action Required CRITICAL 9.0-10.0 Block deployment immediately HIGH 7.0-8.9 Fix within 7 days MEDIUM 4.0-6.9 Fix within 30 days LOW 0.1-3.9 Fix when convenient UNKNOWN N/A Investigate <p>Trivy Output Example: <pre><code>myapp:1.0 (alpine 3.18.0)\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nTotal: 2 (HIGH: 1, CRITICAL: 1)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Library     \u2502 Vulnerability  \u2502 Severity \u2502  Installed Version \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 openssl        \u2502 CVE-2023-12345 \u2502 CRITICAL \u2502 3.0.8-r0          \u2502\n\u2502 curl           \u2502 CVE-2023-67890 \u2502 HIGH     \u2502 8.0.1-r0          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#part-5-configuring-quality-gates","title":"\ud83c\udfaf Part 5: Configuring Quality Gates","text":""},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#quality-gate-philosophy","title":"Quality Gate Philosophy","text":"<p>\"Quality gates should prevent bad code from progressing, not punish developers\"</p> <p>Good Quality Gates: - \u2705 Focus on new code (not legacy) - \u2705 Achievable standards - \u2705 Fast feedback (&lt;5 min) - \u2705 Clear remediation steps</p> <p>Bad Quality Gates: - \u274c Unrealistic standards (100% coverage) - \u274c Block on legacy debt - \u274c Slow feedback (&gt;30 min) - \u274c Vague error messages</p>"},{"location":"dojo/modules/yellow-belt/module-07-security-scanning/#recommended-quality-gates-by-stage","title":"Recommended Quality Gates by Stage","text":"<p>Development (IDE/PR): <pre><code>gates:\n  - New Bugs: 0\n  - New Vulnerabilities: 0\n  - New Code Coverage: &gt; 80%\n  - New Duplications: &lt; 3%\n</code></pre></p> <p>CI/CD (Main Branch): <pre><code>gates:\n  - Overall Bugs: &lt; 10\n  - Overall Vulnerabilities: 0\n  - Overall Coverage: &gt; 70%\n  - Security Hotspots Reviewed: 100%\n  - Maintainability Rating: \u2265 B\n</code></pre></p> <p>Production (Release): ```yaml</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/","title":"Fawkes Dojo Module 8: Artifact Management","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#module-overview","title":"\ud83c\udfaf Module Overview","text":"<p>Belt Level: \ud83d\udfe1 Yellow Belt - CI/CD Mastery Module: 4 of 4 (Yellow Belt - FINAL MODULE) Duration: 60 minutes Difficulty: Intermediate Prerequisites: - Modules 5, 6, 7 complete - Understanding of Docker and containers - Familiarity with versioning concepts - CI/CD pipeline experience</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#learning-objectives","title":"\ud83d\udcda Learning Objectives","text":"<p>By the end of this module, you will:</p> <ol> <li>\u2705 Understand the role of artifact registries in CI/CD</li> <li>\u2705 Configure Harbor container registry in Fawkes</li> <li>\u2705 Implement semantic versioning strategies</li> <li>\u2705 Manage artifact lifecycle and retention policies</li> <li>\u2705 Implement artifact promotion across environments</li> <li>\u2705 Secure artifacts with signing and scanning</li> <li>\u2705 Optimize storage costs and performance</li> </ol> <p>DORA Capabilities Addressed: - \u2713 CD1: Version control for production artifacts - \u2713 CD2: Automate deployment process - \u2713 Artifact Traceability</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-1-why-artifact-management-matters","title":"\ud83d\udcd6 Part 1: Why Artifact Management Matters","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#the-problem-ad-hoc-artifact-storage","title":"The Problem: Ad-Hoc Artifact Storage","text":"<p>Without proper artifact management: <pre><code>Team A: Stores Docker images on local machines\nTeam B: Uses random Docker Hub accounts\nTeam C: Rebuilds from source every time\nTeam D: No idea which version is in production\n\nResult:\n\u274c Can't reproduce builds\n\u274c Can't rollback reliably\n\u274c No audit trail\n\u274c Security vulnerabilities untracked\n\u274c Storage costs out of control\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#the-solution-centralized-artifact-registry","title":"The Solution: Centralized Artifact Registry","text":"<pre><code>                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502   Harbor Registry   \u2502\n                   \u2502  (Fawkes Platform)  \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                     \u2502                     \u2502\n   \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n   \u2502   Dev   \u2502          \u2502 Staging \u2502          \u2502  Prod   \u2502\n   \u2502 myapp:  \u2502          \u2502 myapp:  \u2502          \u2502 myapp:  \u2502\n   \u2502  dev-123\u2502          \u2502  stg-123\u2502          \u2502  v1.2.3 \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits: - \u2705 Single source of truth - \u2705 Immutable artifacts - \u2705 Complete audit trail - \u2705 Security scanning integrated - \u2705 Efficient storage with deduplication - \u2705 Role-based access control - \u2705 Replication for DR</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-2-harbor-container-registry","title":"\ud83c\udfd7\ufe0f Part 2: Harbor Container Registry","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#what-is-harbor","title":"What is Harbor?","text":"<p>Harbor is an open-source container registry that secures artifacts with policies and role-based access control.</p> <p>Key Features: - \ud83d\udc33 Docker/OCI image storage - \ud83d\udd12 Integrated security scanning (Trivy) - \ud83d\udcca Vulnerability management - \ud83c\udff7\ufe0f Image signing (Cosign/Notary) - \ud83d\udce6 Helm chart repository - \ud83d\udd10 RBAC and quota management - \ud83d\udcc8 Audit logging - \ud83c\udf0d Replication across registries</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#harbor-architecture-in-fawkes","title":"Harbor Architecture in Fawkes","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Harbor Registry                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502   Core     \u2502  \u2502  Registry  \u2502  \u2502   Trivy      \u2502  \u2502\n\u2502  \u2502  Service   \u2502  \u2502  (Storage) \u2502  \u2502   Scanner    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502         \u2502                \u2502                \u2502          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502           PostgreSQL Database                  \u2502 \u2502\n\u2502  \u2502  \u2022 Image metadata  \u2022 Scan results  \u2022 Audit    \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502        Object Storage (S3/MinIO)             \u2502  \u2502\n\u2502  \u2502     \u2022 Image layers  \u2022 Helm charts            \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-3-hands-on-lab-publishing-artifacts","title":"\ud83d\udee0\ufe0f Part 3: Hands-On Lab - Publishing Artifacts","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#step-1-configure-harbor-in-pipeline","title":"Step 1: Configure Harbor in Pipeline","text":"<pre><code>// vars/goldenPathJava.groovy (enhanced)\ndef call(Map config = [:]) {\n    def defaults = [\n        harborRegistry: 'harbor.fawkes.internal',\n        harborProject: 'library',\n        harborCredentials: 'harbor-robot-account',\n        imagePrefix: '',\n        pushToHarbor: true\n    ]\n\n    config = defaults + config\n\n    pipeline {\n        // ... agent configuration ...\n\n        environment {\n            HARBOR_REGISTRY = \"${config.harborRegistry}\"\n            HARBOR_PROJECT = \"${config.harborProject}\"\n            IMAGE_NAME = \"${config.imagePrefix}${env.JOB_NAME}\".replaceAll('/', '-')\n        }\n\n        stages {\n            // ... build stages ...\n\n            stage('Build Docker Image') {\n                steps {\n                    container('docker') {\n                        script {\n                            // Generate version tags\n                            def shortCommit = env.GIT_COMMIT.take(7)\n                            def buildTag = \"${env.BUILD_NUMBER}-${shortCommit}\"\n                            def latestTag = env.BRANCH_NAME == 'main' ? 'latest' : env.BRANCH_NAME\n\n                            env.IMAGE_TAG = buildTag\n                            env.IMAGE_FULL = \"${HARBOR_REGISTRY}/${HARBOR_PROJECT}/${IMAGE_NAME}:${buildTag}\"\n\n                            echo \"\ud83d\udc33 Building: ${env.IMAGE_FULL}\"\n                            sh \"\"\"\n                                docker build \\\n                                    --label \"version=${buildTag}\" \\\n                                    --label \"git-commit=${env.GIT_COMMIT}\" \\\n                                    --label \"build-url=${env.BUILD_URL}\" \\\n                                    --label \"built-by=fawkes-ci\" \\\n                                    -t ${env.IMAGE_FULL} \\\n                                    -t ${HARBOR_REGISTRY}/${HARBOR_PROJECT}/${IMAGE_NAME}:${latestTag} \\\n                                    .\n                            \"\"\"\n                        }\n                    }\n                }\n            }\n\n            stage('Push to Harbor') {\n                when {\n                    expression { config.pushToHarbor }\n                }\n                steps {\n                    container('docker') {\n                        script {\n                            withCredentials([\n                                usernamePassword(\n                                    credentialsId: config.harborCredentials,\n                                    usernameVariable: 'HARBOR_USER',\n                                    passwordVariable: 'HARBOR_PASS'\n                                )\n                            ]) {\n                                echo \"\ud83d\udce4 Pushing to Harbor...\"\n                                sh \"\"\"\n                                    echo \\$HARBOR_PASS | docker login ${HARBOR_REGISTRY} -u \\$HARBOR_USER --password-stdin\n                                    docker push ${env.IMAGE_FULL}\n\n                                    # Push additional tags\n                                    docker push ${HARBOR_REGISTRY}/${HARBOR_PROJECT}/${IMAGE_NAME}:${env.BRANCH_NAME}\n                                \"\"\"\n                            }\n                        }\n                    }\n                }\n            }\n\n            stage('Harbor Scan &amp; Sign') {\n                steps {\n                    script {\n                        // Trigger Harbor vulnerability scan\n                        sh \"\"\"\n                            curl -X POST \\\n                                -u \\$HARBOR_USER:\\$HARBOR_PASS \\\n                                \"${HARBOR_REGISTRY}/api/v2.0/projects/${HARBOR_PROJECT}/repositories/${IMAGE_NAME}/artifacts/${env.IMAGE_TAG}/scan\"\n                        \"\"\"\n\n                        // Wait for scan completion\n                        timeout(time: 5, unit: 'MINUTES') {\n                            waitUntil {\n                                def status = sh(\n                                    script: \"\"\"\n                                        curl -s -u \\$HARBOR_USER:\\$HARBOR_PASS \\\n                                            \"${HARBOR_REGISTRY}/api/v2.0/projects/${HARBOR_PROJECT}/repositories/${IMAGE_NAME}/artifacts/${env.IMAGE_TAG}\" \\\n                                            | jq -r '.scan_overview.\"application/vnd.scanner.adapter.vuln.report.harbor+json; version=1.0\".scan_status'\n                                    \"\"\",\n                                    returnStdout: true\n                                ).trim()\n                                return status == 'Success'\n                            }\n                        }\n\n                        echo \"\u2705 Harbor scan complete\"\n                    }\n                }\n            }\n        }\n\n        post {\n            success {\n                script {\n                    echo \"\"\"\n                    \u2705 Artifact published successfully!\n                    \ud83d\udce6 Image: ${env.IMAGE_FULL}\n                    \ud83d\udd17 Harbor: ${HARBOR_REGISTRY}/harbor/projects/${HARBOR_PROJECT}/repositories/${IMAGE_NAME}\n                    \"\"\"\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#step-2-verify-in-harbor-ui","title":"Step 2: Verify in Harbor UI","text":"<p>Access Harbor: <code>https://harbor.fawkes.internal</code></p> <p>Navigate to your image: 1. Projects \u2192 Your Project 2. Repositories \u2192 Your Image 3. Click on tag (e.g., <code>123-abc1234</code>)</p> <p>View Details: - \ud83d\udccb Vulnerabilities scan results - \ud83c\udff7\ufe0f Labels and metadata - \ud83d\udcca Layer information - \ud83d\udd12 Signature status - \ud83d\udcc8 Pull statistics</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-4-versioning-strategies","title":"\ud83d\udcca Part 4: Versioning Strategies","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#semantic-versioning-semver","title":"Semantic Versioning (SemVer)","text":"<p>Format: <code>MAJOR.MINOR.PATCH</code></p> <pre><code>v1.2.3\n\u2502 \u2502 \u2502\n\u2502 \u2502 \u2514\u2500 Patch: Bug fixes (backward compatible)\n\u2502 \u2514\u2500\u2500\u2500 Minor: New features (backward compatible)\n\u2514\u2500\u2500\u2500\u2500\u2500 Major: Breaking changes\n</code></pre> <p>Examples: - <code>v1.0.0</code> \u2192 Initial release - <code>v1.0.1</code> \u2192 Bug fix - <code>v1.1.0</code> \u2192 New feature added - <code>v2.0.0</code> \u2192 Breaking API change</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#tagging-strategy","title":"Tagging Strategy","text":"<p>Multiple tags per image:</p> <pre><code># Build number + commit (immutable reference)\nmyapp:142-abc1234\n\n# Semantic version (for releases)\nmyapp:v1.2.3\n\n# Environment-specific\nmyapp:dev\nmyapp:staging\nmyapp:production\n\n# Branch-based\nmyapp:main\nmyapp:feature-auth\n\n# Latest (moving target)\nmyapp:latest\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#implementing-versioning-in-pipeline","title":"Implementing Versioning in Pipeline","text":"<pre><code>def generateImageTags() {\n    def tags = []\n\n    // Always add build number + commit\n    def shortCommit = env.GIT_COMMIT.take(7)\n    tags.add(\"${env.BUILD_NUMBER}-${shortCommit}\")\n\n    // Add semantic version if tagged\n    if (env.TAG_NAME) {\n        tags.add(env.TAG_NAME)\n\n        // Also add major.minor\n        def semver = env.TAG_NAME =~ /v?(\\d+)\\.(\\d+)\\.(\\d+)/\n        if (semver) {\n            tags.add(\"v${semver[0][1]}.${semver[0][2]}\")\n            tags.add(\"v${semver[0][1]}\")\n        }\n    }\n\n    // Add branch name\n    tags.add(env.BRANCH_NAME.replaceAll('/', '-'))\n\n    // Add 'latest' for main branch\n    if (env.BRANCH_NAME == 'main') {\n        tags.add('latest')\n    }\n\n    return tags\n}\n\nstage('Build &amp; Tag') {\n    steps {\n        script {\n            def tags = generateImageTags()\n            def imageBase = \"${HARBOR_REGISTRY}/${HARBOR_PROJECT}/${IMAGE_NAME}\"\n\n            // Build with first tag\n            sh \"docker build -t ${imageBase}:${tags[0]} .\"\n\n            // Add additional tags\n            tags.drop(1).each { tag -&gt;\n                sh \"docker tag ${imageBase}:${tags[0]} ${imageBase}:${tag}\"\n            }\n\n            // Push all tags\n            tags.each { tag -&gt;\n                sh \"docker push ${imageBase}:${tag}\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-5-artifact-promotion","title":"\ud83d\udd04 Part 5: Artifact Promotion","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#environment-promotion-pattern","title":"Environment Promotion Pattern","text":"<p>Concept: Same artifact progresses through environments</p> <pre><code>Build \u2192 Dev \u2192 Test \u2192 Staging \u2192 Production\n \u2502       \u2502      \u2502       \u2502          \u2502\n v142    v142   v142    v142      v142\n         \u2193                         \u2193\n      promote               final promote\n</code></pre> <p>Never rebuild - same artifact, different tags/environment</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#implementing-promotion","title":"Implementing Promotion","text":"<pre><code>def promoteArtifact(Map config) {\n    def sourceTag = config.sourceTag\n    def targetTag = config.targetTag\n    def imageBase = \"${HARBOR_REGISTRY}/${HARBOR_PROJECT}/${IMAGE_NAME}\"\n\n    echo \"\ud83d\udd04 Promoting ${imageBase}:${sourceTag} \u2192 ${targetTag}\"\n\n    // Pull source image\n    sh \"docker pull ${imageBase}:${sourceTag}\"\n\n    // Re-tag for target environment\n    sh \"docker tag ${imageBase}:${sourceTag} ${imageBase}:${targetTag}\"\n\n    // Push to Harbor\n    sh \"docker push ${imageBase}:${targetTag}\"\n\n    // Update GitOps manifest\n    sh \"\"\"\n        git clone https://github.com/org/gitops-manifests.git\n        cd gitops-manifests\n\n        # Update image tag in manifest\n        yq eval -i '.spec.template.spec.containers[0].image = \"${imageBase}:${targetTag}\"' \\\n            environments/${targetTag}/deployment.yaml\n\n        git add .\n        git commit -m \"Promote ${IMAGE_NAME} to ${targetTag} (build ${sourceTag})\"\n        git push\n    \"\"\"\n\n    echo \"\u2705 Promotion complete\"\n}\n\n// Usage\nstage('Promote to Staging') {\n    when {\n        branch 'main'\n    }\n    steps {\n        script {\n            promoteArtifact(\n                sourceTag: \"${env.BUILD_NUMBER}-${env.GIT_COMMIT.take(7)}\",\n                targetTag: 'staging'\n            )\n        }\n    }\n}\n\nstage('Promote to Production') {\n    when {\n        tag pattern: \"v\\\\d+\\\\.\\\\d+\\\\.\\\\d+\", comparator: \"REGEXP\"\n    }\n    steps {\n        script {\n            promoteArtifact(\n                sourceTag: 'staging',\n                targetTag: 'production'\n            )\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#approval-gates","title":"Approval Gates","text":"<p>Add manual approval for production:</p> <pre><code>stage('Approve Production Deploy') {\n    when {\n        tag pattern: \"v\\\\d+\\\\.\\\\d+\\\\.\\\\d+\", comparator: \"REGEXP\"\n    }\n    steps {\n        script {\n            def approved = input(\n                message: 'Deploy to Production?',\n                parameters: [\n                    booleanParam(\n                        name: 'DEPLOY',\n                        defaultValue: false,\n                        description: 'Check to approve production deployment'\n                    ),\n                    text(\n                        name: 'NOTES',\n                        defaultValue: '',\n                        description: 'Deployment notes (optional)'\n                    )\n                ]\n            )\n\n            if (!approved.DEPLOY) {\n                error(\"Production deployment not approved\")\n            }\n\n            echo \"Deployment approved by: ${env.BUILD_USER}\"\n            echo \"Notes: ${approved.NOTES}\"\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-6-retention-policies","title":"\ud83d\uddc4\ufe0f Part 6: Retention Policies","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#why-retention-policies-matter","title":"Why Retention Policies Matter","text":"<p>Without retention: <pre><code>Day 1:   10 images  \u2192 1 GB\nDay 30:  300 images \u2192 30 GB\nDay 90:  900 images \u2192 90 GB\nDay 365: 3650 images \u2192 365 GB \ud83d\udcb8\ud83d\udcb8\ud83d\udcb8\n</code></pre></p> <p>With retention: <pre><code>Day 1:   10 images \u2192 1 GB\nDay 365: 100 images \u2192 10 GB \u2705\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#harbor-retention-rules","title":"Harbor Retention Rules","text":"<p>Configure in Harbor UI or via API:</p> <p>Example Policy: <pre><code>retention_policy:\n  - scope: \"**\"  # All repositories\n    rules:\n      # Keep production images indefinitely\n      - tag: \"production\"\n        retain: -1  # Forever\n\n      # Keep staging images for 30 days\n      - tag: \"staging\"\n        retain: 30\n\n      # Keep latest 10 dev images\n      - tag: \"dev-*\"\n        retain_count: 10\n\n      # Keep semantic versions for 1 year\n      - tag: \"v*.*.*\"\n        retain: 365\n\n      # Delete untagged images after 7 days\n      - tag: \"\"\n        retain: 7\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#implementing-retention-via-api","title":"Implementing Retention via API","text":"<pre><code>stage('Configure Retention') {\n    steps {\n        script {\n            def retentionPolicy = '''\n            {\n                \"rules\": [\n                    {\n                        \"disabled\": false,\n                        \"action\": \"retain\",\n                        \"tag_selectors\": [{\n                            \"kind\": \"doublestar\",\n                            \"decoration\": \"matches\",\n                            \"pattern\": \"production\"\n                        }],\n                        \"scope_selectors\": {\n                            \"repository\": [{\n                                \"kind\": \"doublestar\",\n                                \"decoration\": \"matches\",\n                                \"pattern\": \"**\"\n                            }]\n                        }\n                    },\n                    {\n                        \"disabled\": false,\n                        \"action\": \"retain\",\n                        \"tag_selectors\": [{\n                            \"kind\": \"doublestar\",\n                            \"decoration\": \"matches\",\n                            \"pattern\": \"v*.*.*\"\n                        }],\n                        \"scope_selectors\": {\n                            \"repository\": [{\n                                \"kind\": \"doublestar\",\n                                \"decoration\": \"matches\",\n                                \"pattern\": \"**\"\n                            }]\n                        },\n                        \"template\": \"retain_n\",\n                        \"params\": {\"n\": 10}\n                    }\n                ]\n            }\n            '''\n\n            sh \"\"\"\n                curl -X POST \\\n                    -H \"Content-Type: application/json\" \\\n                    -u \\$HARBOR_USER:\\$HARBOR_PASS \\\n                    -d '${retentionPolicy}' \\\n                    \"${HARBOR_REGISTRY}/api/v2.0/projects/${HARBOR_PROJECT}/retention\"\n            \"\"\"\n        }\n    }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-7-artifact-signing-verification","title":"\ud83d\udd12 Part 7: Artifact Signing &amp; Verification","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#why-sign-artifacts","title":"Why Sign Artifacts?","text":"<p>Without signing: <pre><code>\u274c Can't verify artifact authenticity\n\u274c Don't know who published it\n\u274c Can't detect tampering\n\u274c Supply chain vulnerable\n</code></pre></p> <p>With signing: <pre><code>\u2705 Cryptographically verify origin\n\u2705 Detect any modifications\n\u2705 Enforce only signed images run\n\u2705 Complete audit trail\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#signing-with-cosign","title":"Signing with Cosign","text":"<p>Install Cosign: <pre><code># In pipeline\ncurl -sSL https://github.com/sigstore/cosign/releases/download/v2.0.0/cosign-linux-amd64 \\\n    -o /usr/local/bin/cosign\nchmod +x /usr/local/bin/cosign\n</code></pre></p> <p>Generate Key Pair (one-time setup): <pre><code>cosign generate-key-pair\n# Creates: cosign.key (private) and cosign.pub (public)\n# Store private key in Jenkins credentials\n</code></pre></p> <p>Sign Image in Pipeline: <pre><code>stage('Sign Image') {\n    steps {\n        container('cosign') {\n            withCredentials([\n                file(credentialsId: 'cosign-private-key', variable: 'COSIGN_KEY'),\n                string(credentialsId: 'cosign-password', variable: 'COSIGN_PASSWORD')\n            ]) {\n                sh \"\"\"\n                    cosign sign \\\n                        --key \\${COSIGN_KEY} \\\n                        --yes \\\n                        ${env.IMAGE_FULL}\n                \"\"\"\n            }\n        }\n    }\n}\n</code></pre></p> <p>Verify Signature: <pre><code># In deployment pipeline\ncosign verify \\\n    --key cosign.pub \\\n    harbor.fawkes.internal/library/myapp:v1.2.3\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#kubernetes-admission-control","title":"Kubernetes Admission Control","text":"<p>Enforce only signed images:</p> <pre><code># Kyverno policy\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: verify-signed-images\nspec:\n  validationFailureAction: enforce\n  rules:\n  - name: verify-signature\n    match:\n      resources:\n        kinds:\n        - Pod\n    verifyImages:\n    - imageReferences:\n      - \"harbor.fawkes.internal/*\"\n      attestors:\n      - entries:\n        - keys:\n            publicKeys: |-\n              -----BEGIN PUBLIC KEY-----\n              [Your Cosign Public Key]\n              -----END PUBLIC KEY-----\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-8-monitoring-metrics","title":"\ud83d\udcc8 Part 8: Monitoring &amp; Metrics","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#key-artifact-metrics","title":"Key Artifact Metrics","text":"<pre><code># Artifact publish rate\nrate(artifacts_published_total[5m])\n\n# Artifact size over time\navg(artifact_size_bytes) by (repository)\n\n# Pull count by artifact\nsum(artifact_pulls_total) by (repository, tag)\n\n# Storage usage by project\nsum(storage_used_bytes) by (project)\n\n# Vulnerability count by severity\nsum(vulnerabilities_total) by (severity, repository)\n\n# Artifact age\ntime() - artifact_push_timestamp_seconds\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#grafana-dashboard","title":"Grafana Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Artifact Registry Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Daily Artifact Publishes\",\n        \"targets\": [{\n          \"expr\": \"sum(rate(artifacts_published_total[1d]))\"\n        }],\n        \"type\": \"graph\"\n      },\n      {\n        \"title\": \"Storage Usage by Project\",\n        \"targets\": [{\n          \"expr\": \"sum(storage_used_bytes) by (project) / 1024/1024/1024\"\n        }],\n        \"type\": \"piechart\",\n        \"unit\": \"GB\"\n      },\n      {\n        \"title\": \"Most Pulled Images\",\n        \"targets\": [{\n          \"expr\": \"topk(10, sum(rate(artifact_pulls_total[7d])) by (repository))\"\n        }],\n        \"type\": \"table\"\n      },\n      {\n        \"title\": \"Vulnerabilities by Severity\",\n        \"targets\": [{\n          \"expr\": \"sum(vulnerabilities_total) by (severity)\"\n        }],\n        \"type\": \"bargauge\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#alerting-rules","title":"Alerting Rules","text":"<pre><code>groups:\n  - name: artifact_alerts\n    rules:\n      - alert: HighVulnerabilityCount\n        expr: sum(vulnerabilities_total{severity=\"critical\"}) &gt; 10\n        for: 1h\n        annotations:\n          summary: \"High number of critical vulnerabilities\"\n          description: \"{{ $value }} critical vulnerabilities detected\"\n\n      - alert: StorageQuotaExceeded\n        expr: storage_used_bytes / storage_quota_bytes &gt; 0.9\n        for: 15m\n        annotations:\n          summary: \"Storage quota 90% full\"\n          description: \"Project {{ $labels.project }} is at {{ $value }}% capacity\"\n\n      - alert: ArtifactNotPulled\n        expr: |\n          time() - artifact_last_pull_timestamp_seconds{tag=\"production\"} &gt; 86400*30\n        for: 1h\n        annotations:\n          summary: \"Production artifact not pulled in 30 days\"\n          description: \"{{ $labels.repository }}:{{ $labels.tag }} may be orphaned\"\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-9-practical-exercise","title":"\ud83d\udcaa Part 9: Practical Exercise","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#exercise-complete-artifact-lifecycle","title":"Exercise: Complete Artifact Lifecycle","text":"<p>Objective: Implement full artifact management lifecycle</p> <p>Requirements: 1. Build and tag Docker image with multiple tags 2. Push to Harbor with metadata labels 3. Trigger and verify Harbor security scan 4. Sign image with Cosign 5. Implement artifact promotion (dev \u2192 staging \u2192 prod) 6. Configure retention policy 7. Set up monitoring for artifact metrics</p> <p>Starter Template:</p> <pre><code>@Library('fawkes-pipelines') _\n\npipeline {\n    agent {\n        kubernetes {\n            yaml '''\napiVersion: v1\nkind: Pod\nspec:\n  containers:\n  - name: docker\n    image: docker:24-dind\n    securityContext:\n      privileged: true\n  - name: cosign\n    image: gcr.io/projectsigstore/cosign:latest\n'''\n        }\n    }\n\n    environment {\n        HARBOR_REGISTRY = 'harbor.fawkes.internal'\n        HARBOR_PROJECT = 'library'\n        IMAGE_NAME = 'myapp'\n    }\n\n    stages {\n        stage('Checkout') {\n            steps {\n                git 'https://github.com/myorg/myapp.git'\n            }\n        }\n\n        stage('Build &amp; Tag') {\n            steps {\n                // TODO: Build with multiple tags\n            }\n        }\n\n        stage('Push to Harbor') {\n            steps {\n                // TODO: Push all tags\n            }\n        }\n\n        stage('Scan &amp; Sign') {\n            steps {\n                // TODO: Trigger Harbor scan and sign with Cosign\n            }\n        }\n\n        stage('Promote to Staging') {\n            when {\n                branch 'main'\n            }\n            steps {\n                // TODO: Promote artifact\n            }\n        }\n    }\n}\n</code></pre> <p>Validation Criteria: - [ ] Image built and tagged correctly - [ ] All tags pushed to Harbor - [ ] Harbor scan completed successfully - [ ] Image signed with Cosign - [ ] Signature verifiable - [ ] Artifact promoted correctly - [ ] Retention policy configured - [ ] Metrics visible in Grafana</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-10-knowledge-check","title":"\ud83c\udf93 Part 10: Knowledge Check","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#quiz-questions","title":"Quiz Questions","text":"<ol> <li>What is the purpose of an artifact registry?</li> <li>[ ] Store source code</li> <li>[x] Store and manage build artifacts (images, packages)</li> <li>[ ] Run containers</li> <li> <p>[ ] Deploy applications</p> </li> <li> <p>What is semantic versioning format?</p> </li> <li>[ ] BUILD.DATE.TIME</li> <li>[x] MAJOR.MINOR.PATCH</li> <li>[ ] YEAR.MONTH.DAY</li> <li> <p>[ ] VERSION.RELEASE.BUILD</p> </li> <li> <p>Why should you use the same artifact across environments?</p> </li> <li>[ ] Save disk space</li> <li>[ ] Faster builds</li> <li>[x] Ensure consistency and avoid \"works on my machine\"</li> <li> <p>[ ] Easier to debug</p> </li> <li> <p>What does artifact signing provide?</p> </li> <li>[ ] Faster downloads</li> <li>[ ] Smaller file size</li> <li>[x] Verification of authenticity and integrity</li> <li> <p>[ ] Automatic deployment</p> </li> <li> <p>Why implement retention policies?</p> </li> <li>[x] Control storage costs and remove unused artifacts</li> <li>[ ] Make builds faster</li> <li>[ ] Improve security</li> <li> <p>[ ] All of the above</p> </li> <li> <p>What is artifact promotion?</p> </li> <li>[ ] Marketing the artifact</li> <li>[x] Moving same artifact through environments without rebuilding</li> <li>[ ] Upgrading to newer version</li> <li> <p>[ ] Deleting old versions</p> </li> <li> <p>What tool does Fawkes use for container registry?</p> </li> <li>[ ] Docker Hub</li> <li>[ ] Artifactory</li> <li>[x] Harbor</li> <li> <p>[ ] Nexus</p> </li> <li> <p>What is the benefit of tagging with build number + commit SHA?</p> </li> <li>[ ] Looks professional</li> <li>[ ] Required by Docker</li> <li>[x] Provides immutable, traceable reference</li> <li>[ ] Makes images smaller</li> </ol> <p>Answers: 1-B, 2-B, 3-C, 4-C, 5-A, 6-B, 7-C, 8-C</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#part-11-module-summary-next-steps","title":"\ud83c\udfaf Part 11: Module Summary &amp; Next Steps","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#what-you-learned","title":"What You Learned","text":"<p>\u2705 Artifact Registries: Centralized, secure storage for build artifacts \u2705 Harbor: Configuration and usage in Fawkes platform \u2705 Versioning: Semantic versioning and tagging strategies \u2705 Promotion: Moving artifacts through environments \u2705 Retention: Lifecycle management and cost optimization \u2705 Signing: Cryptographic verification with Cosign \u2705 Monitoring: Tracking artifact metrics and health</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#dora-capabilities-achieved","title":"DORA Capabilities Achieved","text":"<ul> <li>\u2705 CD1: Version control for production artifacts (complete)</li> <li>\u2705 CD2: Automated deployment with immutable artifacts</li> <li>\u2705 Traceability: Complete audit trail from build to production</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Artifacts are immutable - Never rebuild, always promote</li> <li>Tag everything - Multiple tags for different purposes</li> <li>Sign your artifacts - Prevent supply chain attacks</li> <li>Lifecycle management - Retention policies save money</li> <li>Monitor your registry - Track usage, vulnerabilities, costs</li> </ol>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#real-world-impact","title":"Real-World Impact","text":"<p>\"After implementing proper artifact management: - Build reproducibility: 60% \u2192 100% - Deployment confidence: 70% \u2192 95% - Storage costs: $5,000/month \u2192 $800/month - Time to rollback: 30 min \u2192 2 min - Supply chain security: Significantly improved with signing</p> <p>We can now trace every production artifact back to exact source code commit.\" - DevOps Team, E-Commerce Platform</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#yellow-belt-complete","title":"\ud83c\udf89 Yellow Belt Complete!","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#congratulations","title":"\ud83c\udfc6 Congratulations!","text":"<p>You've completed all four Yellow Belt modules: - \u2705 Module 5: CI Fundamentals - \u2705 Module 6: Golden Path Pipelines - \u2705 Module 7: Security Scanning &amp; Quality Gates - \u2705 Module 8: Artifact Management</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#yellow-belt-progress","title":"\ud83c\udf96\ufe0f Yellow Belt Progress","text":"<pre><code>Yellow Belt: CI/CD Mastery\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModule 5: CI Fundamentals        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 25% \u2713\nModule 6: Golden Path Pipelines  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 50% \u2713\nModule 7: Security &amp; Quality     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 75% \u2713\nModule 8: Artifact Management    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100% \u2713\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n</code></pre>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#yellow-belt-certification","title":"\ud83d\udcdc Yellow Belt Certification","text":"<p>You're now ready for the Yellow Belt Certification Exam!</p> <p>Exam Format: - 40 multiple choice questions - 3 hands-on challenges - 85% passing score required - 2-hour time limit</p> <p>Exam Challenges: 1. Build a production-ready CI/CD pipeline from scratch 2. Optimize existing pipeline to &lt;5 minute build time 3. Implement complete security scanning and artifact management</p> <p>Schedule Your Exam: - Visit Fawkes Dojo Portal - Navigate to Certifications \u2192 Yellow Belt - Click \"Schedule Exam\"</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#what-youve-achieved","title":"\ud83c\udf93 What You've Achieved","text":"<p>Skills Mastered: - \u2705 Jenkins pipeline development - \u2705 Shared library creation - \u2705 Security scanning integration - \u2705 Artifact management - \u2705 Pipeline optimization - \u2705 CI/CD best practices</p> <p>DORA Impact: - Deployment Frequency: Can deploy multiple times per day - Lead Time: Reduced to minutes with optimized pipelines - Change Failure Rate: Security gates prevent bad code - MTTR: Artifact management enables fast rollbacks</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#whats-next","title":"\ud83d\ude80 What's Next?","text":"<p>Option 1: Take Yellow Belt Certification Exam - Validate your learning - Earn \"Fawkes CI/CD Specialist\" badge - Get LinkedIn-verified credential</p> <p>Option 2: Continue to Green Belt - Module 9: GitOps with ArgoCD - Module 10: Deployment Strategies - Module 11: Progressive Delivery - Module 12: Rollback &amp; Incident Response</p> <p>Option 3: Practice &amp; Contribute - Apply learnings to your team's pipelines - Share your shared library with community - Write blog post about your journey - Help others in #yellow-belt channel</p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#tools-documentation","title":"Tools &amp; Documentation","text":"<ul> <li>Harbor Documentation</li> <li>Cosign Documentation</li> <li>Semantic Versioning</li> <li>OCI Image Spec</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#learning-resources","title":"Learning Resources","text":"<ul> <li>Artifact Management Best Practices</li> <li>Supply Chain Security</li> <li>Container Signing Tutorial</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#community","title":"Community","text":"<ul> <li>Fawkes Mattermost - #yellow-belt</li> <li>Share your certification achievement!</li> <li>Help newcomers in #white-belt</li> </ul>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#appendix-artifact-management-cheat-sheet","title":"\ud83d\udcd6 Appendix: Artifact Management Cheat Sheet","text":""},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#quick-reference-commands","title":"Quick Reference Commands","text":"<p>Harbor CLI (via API): <pre><code># List repositories\ncurl -u user:pass https://harbor.fawkes.internal/api/v2.0/projects/library/repositories\n\n# Get artifact details\ncurl -u user:pass https://harbor.fawkes.internal/api/v2.0/projects/library/repositories/myapp/artifacts/v1.2.3\n\n# Trigger scan\ncurl -X POST -u user:pass https://harbor.fawkes.internal/api/v2.0/projects/library/repositories/myapp/artifacts/v1.2.3/scan\n\n# Delete artifact\ncurl -X DELETE -u user:pass https://harbor.fawkes.internal/api/v2.0/projects/library/repositories/myapp/artifacts/v1.2.3\n</code></pre></p> <p>Cosign Commands: <pre><code># Sign image\ncosign sign --key cosign.key myapp:v1.2.3\n\n# Verify signature\ncosign verify --key cosign.pub myapp:v1.2.3\n\n# Attach SBOM\ncosign attach sbom --sbom sbom.json myapp:v1.2.3\n\n# Download SBOM\ncosign download sbom myapp:v1.2.3\n</code></pre></p> <p>Docker Tag Management: <pre><code># Create multiple tags\ndocker tag myapp:123 myapp:v1.2.3\ndocker tag myapp:123 myapp:latest\ndocker tag myapp:123 myapp:production\n\n# Push all tags\ndocker push --all-tags myapp\n</code></pre></p>"},{"location":"dojo/modules/yellow-belt/module-08-artifact-management/#final-thoughts","title":"\ud83c\udf8a Final Thoughts","text":"<p>You've completed an intensive journey through CI/CD mastery. You now have the skills to:</p> <ul> <li>Build production-ready pipelines</li> <li>Implement security at every stage</li> <li>Manage artifacts professionally</li> <li>Optimize for speed and reliability</li> <li>Lead CI/CD initiatives in your organization</li> </ul> <p>Your impact on DORA metrics will be significant!</p> <p>Ready to continue? \ud83d\udfe2</p> <p>Next up: Green Belt - GitOps &amp; Deployment</p> <p>Module 9: Introduction to GitOps with ArgoCD awaits! You'll learn declarative deployments, automated sync, and progressive delivery strategies.</p> <p>Fawkes Dojo - Where Platform Engineers Are Forged Version 1.0 | Last Updated: October 2025 License: MIT | https://github.com/paruff/fawkes</p> <p>\ud83c\udf89 Yellow Belt Complete - Congratulations, CI/CD Specialist! \ud83c\udf89</p>"},{"location":"explanation/","title":"Explanation","text":"<p>Explanation documentation is understanding-oriented. It clarifies concepts, provides background, and helps you understand why things work the way they do.</p>"},{"location":"explanation/#what-youll-find-here","title":"What You'll Find Here","text":"<p>Explanation content in Fawkes is designed to:</p> <ul> <li>Provide context and background knowledge</li> <li>Explain concepts, architecture decisions, and design choices</li> <li>Help you understand the \"why\" behind features</li> <li>Connect different parts of the platform together</li> </ul>"},{"location":"explanation/#core-concepts","title":"Core Concepts","text":"<p>The following explanatory content provides deep-dive understanding of Fawkes architectural decisions and design philosophy.</p>"},{"location":"explanation/#architecture-gitops","title":"Architecture &amp; GitOps","text":"Topic Description GitOps Strategy Why ArgoCD, the App-of-Apps pattern, and the shift from push to pull deployment GitOps Principles Declarative, version-controlled infrastructure - See Module 3: GitOps Principles Loosely Coupled Architecture Why independence matters - See Architecture"},{"location":"explanation/#containers-build-strategy","title":"Containers &amp; Build Strategy","text":"Topic Description Buildpacks Philosophy The trade-offs of Cloud Native Buildpacks vs. Dockerfiles for security and maintenance"},{"location":"explanation/#security-compliance","title":"Security &amp; Compliance","text":"Topic Description Zero Trust Model How Vault, Kyverno, and Istio/Ingress work together for defense in depth Policy as Code Tiers Understanding the Audit vs. Enforce governance model Shift Left Security Why early security testing matters - See Module 7: Security Scanning Zero Trust Architecture Modern security principles - See Module 19: Security Zero Trust"},{"location":"explanation/#observability","title":"Observability","text":"Topic Description Unified Telemetry The role of OpenTelemetry as the standard vs. vendor-specific agents"},{"location":"explanation/#platform-engineering","title":"Platform Engineering","text":"Topic Description Product Discovery &amp; Delivery Flow (IP3dP) How to treat your platform as a product with continuous discovery and measurement What is an Internal Developer Platform? Understanding IDPs and their value - See Module 1: What is IDP Platform as a Product Operating your platform with product thinking - See ADR-020 Golden Paths Paved roads for developer productivity - See Golden Path Usage"},{"location":"explanation/#dora-performance","title":"DORA &amp; Performance","text":"Topic Description Understanding DORA Metrics The four key metrics and why they matter - See Module 2: DORA Metrics Elite Performance What it means to be an elite performer - See Home page"},{"location":"explanation/#business-value","title":"Business Value","text":"Topic Description Status ROI of Platform Engineering Quantifying platform value See Business Case Developer Experience Why DX matters for business outcomes See DX Metrics ADR Risk Mitigation How platforms reduce organizational risk \ud83d\udea7 Coming soon"},{"location":"explanation/#how-this-differs-from-other-documentation","title":"How This Differs from Other Documentation","text":"Explanation How-To Guides Reference Discusses concepts Shows steps Lists specifications Provides background Solves problems Provides data Explains decisions Gives instructions Documents APIs Connects ideas Focuses on tasks Describes options"},{"location":"explanation/#architectural-decision-records","title":"Architectural Decision Records","text":"<p>For detailed rationale behind specific decisions, see our ADR collection.</p> <p>View ADRs  Explore Patterns </p>"},{"location":"explanation/architecture/gitops-strategy/","title":"GitOps Strategy: From Push to Pull","text":""},{"location":"explanation/architecture/gitops-strategy/#context","title":"Context","text":"<p>In traditional CI/CD pipelines, your build system (like Jenkins) has credentials to your production Kubernetes cluster and pushes changes directly. This \"push-based\" model has been the norm for decades, but it carries significant security and operational risks in cloud-native environments.</p> <p>GitOps inverts this model: instead of CI pushing to production, production pulls its desired state from Git. The cluster itself watches a Git repository and continuously reconciles reality with the declared state. This seemingly small shift has profound implications for security, auditability, and reliability.</p> <p>Fawkes adopted GitOps as a core architectural principle because it directly supports the behaviors that enable elite DORA performance: high deployment frequency, low change failure rate, and fast recovery time.</p>"},{"location":"explanation/architecture/gitops-strategy/#the-problem-why-push-based-cd-falls-short","title":"The Problem: Why Push-Based CD Falls Short","text":""},{"location":"explanation/architecture/gitops-strategy/#security-the-credential-problem","title":"Security: The Credential Problem","text":"<p>The Traditional Model: <pre><code>graph LR\n    A[Jenkins] --&gt;|Has K8s credentials| B[Production Cluster]\n    C[Developer] --&gt;|Triggers Build| A\n    style A fill:#ff6b6b</code></pre></p> <p>In push-based CI/CD: - Jenkins holds production credentials - If Jenkins is compromised, so is production - Credentials must be distributed - Every build agent needs cluster access - Blast radius is massive - A CI security breach means production breach - Credential rotation is painful - Update all CI configs when rotating</p>"},{"location":"explanation/architecture/gitops-strategy/#drift-configuration-divergence","title":"Drift: Configuration Divergence","text":"<p>When humans have <code>kubectl</code> access and deadlines loom, they make \"quick fixes\" directly in the cluster:</p> <pre><code># \"Just for now\" - Famous last words\nkubectl scale deployment critical-app --replicas=10\nkubectl set env deployment/api LOG_LEVEL=debug\n</code></pre> <p>The Result: - Production state diverges from Git - Git is no longer the source of truth - Disaster recovery becomes guesswork: \"What was the actual config?\" - Compliance audits fail: \"Show us the change approval for that scaling event\"</p>"},{"location":"explanation/architecture/gitops-strategy/#auditability-the-black-box-deployment","title":"Auditability: The Black Box Deployment","text":"<p>Push-based deployments create an audit gap: - Git shows code changes - Jenkins shows build execution - But the actual deployment? Often just a line in Jenkins logs - Question: \"Who changed the replica count from 3 to 5?\" - Answer: \u00af\\(\u30c4)/\u00af \"Could be anyone with kubectl access\"</p>"},{"location":"explanation/architecture/gitops-strategy/#rollback-the-manual-scramble","title":"Rollback: The Manual Scramble","text":"<p>When a bad deployment hits production in a push model:</p> <ol> <li>Find the previous good version (search through Jenkins jobs)</li> <li>Trigger a rebuild (hope dependencies haven't changed)</li> <li>Push again (cross fingers)</li> <li>Repeat if it fails again</li> </ol> <p>Time to Restore: 15-45 minutes (not elite)</p>"},{"location":"explanation/architecture/gitops-strategy/#the-solution-gitops-pull-model","title":"The Solution: GitOps Pull Model","text":""},{"location":"explanation/architecture/gitops-strategy/#how-argocd-changes-the-game","title":"How ArgoCD Changes the Game","text":"<pre><code>graph TB\n    A[Git Repository] --&gt;|Single Source of Truth| B[ArgoCD]\n    B --&gt;|Watches &amp; Syncs| C[Production Cluster]\n    B --&gt;|Watches &amp; Syncs| D[Staging Cluster]\n    B --&gt;|Watches &amp; Syncs| E[Dev Cluster]\n    F[Developer] --&gt;|Git Commit| A\n    G[Jenkins CI] --&gt;|Builds Image, Updates Manifest| A\n\n    style A fill:#4CAF50\n    style B fill:#2196F3</code></pre> <p>Key Principles:</p> <ol> <li>Git as Single Source of Truth</li> <li>Entire desired state lives in Git (applications, configs, infrastructure)</li> <li>Want to know production state? Read Git</li> <li> <p>Want to change production? Open a PR</p> </li> <li> <p>Declarative Configuration</p> </li> <li>Describe what you want, not how to get there</li> <li>ArgoCD figures out the <code>kubectl apply</code> dance</li> <li> <p>Idempotent: Apply the same config 100 times = same result</p> </li> <li> <p>Automated Sync</p> </li> <li>ArgoCD polls Git every 3 minutes (or use webhooks for instant sync)</li> <li>Detects drift and auto-corrects</li> <li> <p>No manual intervention needed</p> </li> <li> <p>Self-Healing</p> </li> <li>Someone does <code>kubectl edit</code> to \"fix\" something?</li> <li>ArgoCD reverts it back to Git state</li> <li>Want it to stick? Commit to Git</li> </ol>"},{"location":"explanation/architecture/gitops-strategy/#the-app-of-apps-pattern","title":"The App-of-Apps Pattern","text":"<p>A single ArgoCD \"Application\" manages other Applications - like a meta-deployment:</p> <pre><code># bootstrap/app-of-apps.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: platform-apps\n  namespace: argocd\nspec:\n  source:\n    repoURL: https://github.com/paruff/fawkes\n    path: platform/apps\n    targetRevision: main\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: argocd\n</code></pre> <p>What This Enables: - Deploy the entire platform with one Application - Add a new service? Just add a directory in <code>platform/apps/</code> - ArgoCD discovers and deploys it automatically - Remove a service? Delete its directory and it's undeployed</p> <p>The Bootstrap Process: 1. Install ArgoCD itself (one-time manual step) 2. Create the root App-of-Apps 3. Everything else (Jenkins, Backstage, Prometheus) deploys automatically 4. Never touch <code>kubectl</code> again (well, rarely)</p>"},{"location":"explanation/architecture/gitops-strategy/#security-model-shift","title":"Security Model Shift","text":"<p>Before (Push Model): <pre><code>CI System \u2192 Stores credentials \u2192 Deploys to cluster\n</code></pre></p> <p>After (Pull Model): <pre><code>CI System \u2192 Updates Git \u2192 ArgoCD (running IN cluster) syncs\n</code></pre></p> <p>Benefits: - \u2705 No credentials in CI - Jenkins doesn't need cluster access - \u2705 Credentials never leave cluster - ArgoCD uses in-cluster service account - \u2705 Reduced attack surface - Compromise CI \u2260 Compromise Production - \u2705 Easier credential rotation - Only ArgoCD service account to manage</p>"},{"location":"explanation/architecture/gitops-strategy/#trade-offs-what-you-gain-and-lose","title":"Trade-Offs: What You Gain and Lose","text":""},{"location":"explanation/architecture/gitops-strategy/#what-gitops-gives-you","title":"What GitOps Gives You","text":"Benefit Impact DORA Metric Audit Trail Complete Git history of who changed what, when, why All metrics (compliance reduces incidents) Fast Rollback <code>git revert</code> + auto-sync = 30-second rollback \u2b07\ufe0f Time to Restore Service Configuration as Code No more \"snowflake servers\" or tribal knowledge \u2b07\ufe0f Change Failure Rate Self-Healing Drift auto-corrected, no manual fixes \u2b07\ufe0f Time to Restore Service Preview Deployments Every PR can have ephemeral environment \u2b06\ufe0f Deployment Frequency Disaster Recovery Cluster dies? Rebuild and re-sync from Git \u2b07\ufe0f Time to Restore Service"},{"location":"explanation/architecture/gitops-strategy/#what-gitops-costs-you","title":"What GitOps Costs You","text":"Challenge Mitigation Learning Curve ArgoCD concepts (Applications, Sync Policies) require training. Mitigation: Fawkes Dojo has GitOps module Git as Bottleneck Emergency fixes must go through Git/PR process. Mitigation: \"Break-glass\" procedure for true emergencies, webhooks for instant sync Secret Management Can't commit secrets to Git. Mitigation: External Secrets Operator fetches from Vault (see ADR-015) Sync Delays Default 3-minute poll interval. Mitigation: Use webhooks for instant notification, or manual refresh for urgent changes Initial Complexity Setting up multi-cluster, RBAC, ApplicationSets. Mitigation: Fawkes provides bootstrap templates and onboarding guide"},{"location":"explanation/architecture/gitops-strategy/#the-cultural-shift","title":"The Cultural Shift","text":"<p>GitOps requires a mindset change:</p> Old Habit New Behavior \"I'll just <code>kubectl edit</code> this quickly\" \"I'll open a PR with the change\" \"Let me SSH and debug in prod\" \"I'll check Git to see the config\" \"The deployment failed, let me retry in Jenkins\" \"The sync failed, let me check ArgoCD UI for the diff\" \"What's running in production?\" \"What's in the <code>main</code> branch?\" <p>This is a feature, not a bug. Forcing changes through Git creates the paper trail that auditors love and future-you will thank.</p>"},{"location":"explanation/architecture/gitops-strategy/#why-argocd-over-alternatives","title":"Why ArgoCD Over Alternatives","text":""},{"location":"explanation/architecture/gitops-strategy/#the-landscape","title":"The Landscape","text":"<p>When Fawkes was designed, we evaluated: - Flux CD - CNCF Graduated, excellent tool, more modular - Spinnaker - Formerly used by Fawkes, powerful but heavyweight - Jenkins X - Opinionated, too tightly coupled to Jenkins - Helm alone - Not GitOps, manual processes</p>"},{"location":"explanation/architecture/gitops-strategy/#why-argocd-won","title":"Why ArgoCD Won","text":"<ol> <li>The UI Advantage</li> <li>Visual application topology (see dependencies at a glance)</li> <li>Diff view (Git vs. cluster side-by-side)</li> <li>Real-time sync status</li> <li> <p>Developer Experience: Devs troubleshoot faster with visuals</p> </li> <li> <p>Proven at Scale</p> </li> <li>Used by Intuit, Red Hat, IBM, Adobe</li> <li>15,000+ GitHub stars</li> <li> <p>CNCF Graduated (highest maturity)</p> </li> <li> <p>App-of-Apps Pattern</p> </li> <li>Elegant solution for managing platform</li> <li> <p>Mirrors Fawkes' \"platform of platforms\" architecture</p> </li> <li> <p>Argo Ecosystem</p> </li> <li>Argo Rollouts (canary deployments)</li> <li>Argo Events (event-driven automation)</li> <li>Argo Workflows (complex pipelines)</li> <li> <p>Integrated, not duct-taped together</p> </li> <li> <p>Backstage Integration</p> </li> <li>Official ArgoCD plugin shows deployment status in Backstage</li> <li>Developers see sync state in their service catalog</li> <li>Unified developer portal experience</li> </ol>"},{"location":"explanation/architecture/gitops-strategy/#what-about-flux","title":"What About Flux?","text":"<p>Flux is excellent and a valid choice. The decision was not dogmatic:</p> <p>Choose ArgoCD if: You value built-in UI, visual topology, and simpler mental model Choose Flux if: You prefer CLI-first, lower resource usage, GitOps Toolkit modularity</p> <p>Fawkes prioritized Developer Experience, and ArgoCD's UI is a significant UX advantage for troubleshooting and understanding system state.</p>"},{"location":"explanation/architecture/gitops-strategy/#historical-context-from-spinnaker-to-argocd","title":"Historical Context: From Spinnaker to ArgoCD","text":"<p>Fawkes 1.0 (2022-2023): Used Spinnaker for deployment orchestration</p> <p>Why We Left Spinnaker: - Operational Burden: 10+ microservices just to run Spinnaker itself - Resource Hungry: 4GB+ RAM for control plane - Configuration Complexity: Pipelines defined in UI or JSON, hard to version - Not GitOps-Native: Push model, required cloud credentials - Overkill: Multi-cloud deployment orchestration when we only needed Kubernetes</p> <p>What We Learned: Spinnaker is phenomenal if you're deploying to VMs, cloud functions, AND Kubernetes across multiple clouds. But for a Kubernetes-focused platform, ArgoCD gives 80% of the value with 20% of the operational cost.</p>"},{"location":"explanation/architecture/gitops-strategy/#practical-implications","title":"Practical Implications","text":""},{"location":"explanation/architecture/gitops-strategy/#for-developers","title":"For Developers","text":"<p>Q: How do I deploy my application? A: Merge your PR. ArgoCD syncs automatically.</p> <p>Q: How do I roll back a bad deployment? A: <code>git revert &lt;commit&gt;</code> and push. ArgoCD reverts in ~30 seconds.</p> <p>Q: Can I still use <code>kubectl</code> for debugging? A: Yes! Read-only commands are fine. But changes won't persist (ArgoCD reverts them).</p>"},{"location":"explanation/architecture/gitops-strategy/#for-platform-engineers","title":"For Platform Engineers","text":"<p>Q: How do I onboard a new service? A: Add a directory in <code>platform/apps/&lt;service&gt;/</code>. See the onboarding guide.</p> <p>Q: How do I handle secrets? A: Use External Secrets Operator to fetch from Vault. Never commit raw secrets to Git.</p> <p>Q: What about emergency fixes in production? A: Use <code>argocd app sync --force</code> for immediate sync, or manual <code>kubectl</code> with \"break-glass\" documentation.</p>"},{"location":"explanation/architecture/gitops-strategy/#for-consultants","title":"For Consultants","text":"<p>When a client asks \"Why can't we just use Jenkins for deployments?\":</p> <ol> <li>Security: Show the credential diagram (push vs. pull)</li> <li>Audit Trail: Demonstrate Git commit history as deployment log</li> <li>Rollback Speed: <code>git revert</code> vs. \"search Jenkins for old build\"</li> <li>Drift Prevention: Show how GitOps auto-corrects manual changes</li> <li>DORA Alignment: GitOps directly improves all four key metrics</li> </ol> <p>Objection Handling: - \"But we have Jenkins already!\" \u2192 Jenkins still does CI (build/test), ArgoCD does CD (deploy). Separation of concerns. - \"GitOps is too slow!\" \u2192 Webhooks give instant sync. Plus, slow and safe beats fast and fragile. - \"We need manual approval for production!\" \u2192 ArgoCD supports manual sync policies. Automation doesn't mean no governance.</p>"},{"location":"explanation/architecture/gitops-strategy/#related-reading","title":"Related Reading","text":"<ul> <li>How-To: Onboard a Service to ArgoCD</li> <li>How-To: Sync an ArgoCD Application</li> <li>ADR: ADR-003: ArgoCD for GitOps (detailed decision rationale)</li> <li>Tutorial: Module 9: GitOps with ArgoCD</li> <li>Reference: ArgoCD Best Practices</li> </ul>"},{"location":"explanation/architecture/gitops-strategy/#conclusion","title":"Conclusion","text":"<p>GitOps is not just a deployment tool\u2014it's an operational philosophy. By making Git the single source of truth and inverting the deployment model from push to pull, we gain security, auditability, and reliability.</p> <p>The shift from Spinnaker to ArgoCD wasn't about rejecting a tool; it was about right-sizing our architecture. ArgoCD gives us true GitOps in a Kubernetes-native way without the operational overhead of more general-purpose solutions.</p> <p>The Golden Path: Git \u2192 ArgoCD \u2192 Production. No sidesteps, no shortcuts, no SSH into production servers at 2am.</p>"},{"location":"explanation/containers/buildpacks-philosophy/","title":"Buildpacks Philosophy: Security and Convenience vs. Control","text":""},{"location":"explanation/containers/buildpacks-philosophy/#context","title":"Context","text":"<p>When you need to deploy an application to Kubernetes, you must create a container image. For decades, the answer has been simple: write a Dockerfile. But Fawkes takes a different approach for the Golden Path: Cloud Native Buildpacks (CNB).</p> <p>This choice surprises developers. \"Why can't I just write my own Dockerfile?\" The answer isn't that you can't\u2014it's that for 80% of applications, you shouldn't need to. Buildpacks trade manual control for automated maintenance, and in platform engineering, that's usually the right trade.</p> <p>This document explains the philosophy behind Buildpacks, not the mechanics (for that, see our How-To guide on debugging buildpack failures).</p>"},{"location":"explanation/containers/buildpacks-philosophy/#the-problem-dockerfile-sprawl-and-security-debt","title":"The Problem: Dockerfile Sprawl and Security Debt","text":""},{"location":"explanation/containers/buildpacks-philosophy/#the-traditional-dockerfile-approach","title":"The Traditional Dockerfile Approach","text":"<p>Every team writes their own container build logic:</p> <pre><code># Team A's Node.js Dockerfile\nFROM node:16-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --production\nCOPY . .\nEXPOSE 3000\nCMD [\"node\", \"server.js\"]\n</code></pre> <pre><code># Team B's Node.js Dockerfile (slightly different)\nFROM node:14\nRUN apt-get update &amp;&amp; apt-get install -y curl\nWORKDIR /usr/src/app\nCOPY package.json package-lock.json ./\nRUN npm install\nCOPY . .\nEXPOSE 8080\nCMD [\"npm\", \"start\"]\n</code></pre> <p>What's Wrong Here?</p> <ol> <li>Version Sprawl: Team A uses Node 16, Team B uses Node 14. Who's patching vulnerabilities?</li> <li>OS Differences: Alpine vs. Debian. Different CVE scan results, different behavior.</li> <li>Security Lag: Node 16 has a critical CVE. Who remembers to update 47 Dockerfiles?</li> <li>No Rebase: OS layer has vulnerability. Must rebuild every image? Or ignore it?</li> <li>Tribal Knowledge: Why <code>npm ci</code> vs <code>npm install</code>? Why <code>--production</code>? Lost when Team A member leaves.</li> </ol>"},{"location":"explanation/containers/buildpacks-philosophy/#the-os-patching-problem","title":"The OS Patching Problem","text":"<p>A critical vulnerability is discovered in <code>glibc</code> (the C library used by most Linux distros). Your images are affected.</p> <p>Dockerfile Approach: 1. Update base image tag in every Dockerfile (<code>FROM node:16.20.1</code> \u2192 <code>FROM node:16.20.2</code>) 2. Rebuild every application image 3. Re-test every application 4. Re-deploy every application 5. Hope you found all the Dockerfiles (did you check that archived repo?)</p> <p>Time to Patch: Days to weeks MTTR Impact: \u2b06\ufe0f (High) Deployment Frequency: \u2b07\ufe0f (Slowed by rebuild toil)</p>"},{"location":"explanation/containers/buildpacks-philosophy/#the-works-on-my-machine-syndrome","title":"The \"Works on My Machine\" Syndrome","text":"<p>Developers optimize for local development: <pre><code># \"I need curl for debugging\"\nRUN apt-get install -y curl wget netcat vim\n\n# \"I'll clean this up later\" (Narrator: They didn't)\nCOPY devtools.sh /usr/local/bin/\n</code></pre></p> <p>Result: - Production images bloated with debug tools - Larger attack surface - Slower image pulls - Container sprawl: 1GB+ images for 10MB applications</p>"},{"location":"explanation/containers/buildpacks-philosophy/#the-solution-cloud-native-buildpacks","title":"The Solution: Cloud Native Buildpacks","text":""},{"location":"explanation/containers/buildpacks-philosophy/#what-are-buildpacks","title":"What Are Buildpacks?","text":"<p>Buildpacks are pluggable, modular components that inspect your source code, detect the framework, install dependencies, and build an optimized container image\u2014without a Dockerfile.</p> <pre><code># No Dockerfile needed\npack build my-app --builder paketobuildpacks/builder:base\n\n# Buildpack detects: \"This is a Node.js app\"\n# Buildpack installs: Node.js runtime, npm dependencies\n# Buildpack configures: Start command, environment\n# Buildpack outputs: Optimized multi-layer image\n</code></pre> <p>The Magic: - Detection: Buildpacks analyze source code (<code>package.json</code> \u2192 Node.js, <code>pom.xml</code> \u2192 Java) - Installation: Install exactly what's needed (no <code>apt-get</code> required) - Caching: Smart layer caching (dependencies separate from app code) - Optimization: Production-ready defaults (minimal base images, non-root users)</p>"},{"location":"explanation/containers/buildpacks-philosophy/#the-rebase-superpower","title":"The Rebase Superpower","text":"<p>This is where Buildpacks shine:</p> <p>Scenario: A CVE is found in Ubuntu base layer.</p> <p>Buildpack Approach: 1. Paketo team publishes new base image (patched) 2. Run <code>pack rebase my-app:v1.2.3</code> (no source code needed!) 3. New image layers swapped in without rebuilding 4. Push updated image to registry 5. Deploy with confidence (app layers untouched)</p> <p>Time to Patch: Minutes MTTR Impact: \u2b07\ufe0f (Low) Deployment Frequency: Maintains high (no rebuild bottleneck)</p> <pre><code>graph TB\n    A[App Layers] --&gt;|Unchanged| B[New Image]\n    C[Old OS Layers] -.-&gt;|Replaced| D[Patched OS Layers]\n    D --&gt; B\n\n    style C fill:#ff6b6b\n    style D fill:#4CAF50</code></pre> <p>Why This Matters: - No app rebuild - Don't re-run tests, don't involve developers - No behavior change - App code and dependencies identical - Fast patching - Security team can patch without developer involvement - Supply chain security - Base images maintained by Paketo community, not random Dockerfiles</p>"},{"location":"explanation/containers/buildpacks-philosophy/#standardization-the-platform-advantage","title":"Standardization: The Platform Advantage","text":"<p>With Buildpacks, Fawkes enforces sensible defaults:</p> Aspect Dockerfile Chaos Buildpack Consistency Base Image <code>node:16-alpine</code>, <code>node:14</code>, <code>node:latest</code> (\ud83d\ude31) Paketo Node.js buildpack (curated, patched) User Often root (security risk) Non-root user (automatic) Dependency Caching Manually optimized (if at all) Automatic layer splitting Security Scanning Per-Dockerfile results Uniform scan results Start Command Hardcoded in Dockerfile Buildpack auto-detects (<code>npm start</code>, <code>java -jar</code>) <p>Developer Experience: - No Dockerfile to write - Just push code - No OS knowledge required - Don't need to know Alpine vs. Debian - No \"copy-paste from Stack Overflow\" - Buildpack handles it - Consistent behavior - All Node.js apps built the same way</p>"},{"location":"explanation/containers/buildpacks-philosophy/#trade-offs-what-you-gain-and-lose","title":"Trade-Offs: What You Gain and Lose","text":""},{"location":"explanation/containers/buildpacks-philosophy/#what-buildpacks-give-you","title":"What Buildpacks Give You","text":"Benefit Explanation DORA Impact Automated OS Patching Rebase without rebuild \u2b07\ufe0f MTTR (faster security patches) Supply Chain Security Curated, signed base images \u2b07\ufe0f Change Failure Rate (fewer vulnerabilities) Dependency Scanning Bill of Materials (SBOM) generated automatically Compliance (audit trail) Zero Dockerfile Maintenance No more \"update base image\" PRs across 50 repos \u2b06\ufe0f Deployment Frequency (less toil) Best Practice Enforcement Non-root users, minimal images, proper caching \u2b07\ufe0f Change Failure Rate (fewer misconfigurations) Framework-Specific Optimization Node.js buildpack knows Node.js best practices Performance (optimized startup, smaller images)"},{"location":"explanation/containers/buildpacks-philosophy/#what-buildpacks-cost-you","title":"What Buildpacks Cost You","text":"Challenge Mitigation Less Control Can't <code>RUN apt-get install custom-tool</code>. Mitigation: Use buildpack extensions or multi-stage builds with base buildpack image for edge cases Black Box Feeling \"What's the buildpack doing?\" Mitigation: <code>pack build --verbose</code> shows every step. Buildpacks are open source (inspect on GitHub) Framework Lock-In Only works if buildpack exists for your language. Mitigation: Paketo covers Java, Node.js, Python, Go, Ruby, PHP, .NET\u201490% of apps. Use Dockerfile for exotic stacks Debugging Learning Curve Different errors than Dockerfile failures. Mitigation: Debug guide and Fawkes Dojo training Build Time First build can be slower (detecting, caching setup). Mitigation: Subsequent builds very fast due to smart caching"},{"location":"explanation/containers/buildpacks-philosophy/#when-to-use-dockerfiles-anyway","title":"When to Use Dockerfiles Anyway","text":"<p>Buildpacks are the Golden Path, but not the Only Path:</p> <p>Use Buildpacks When: - \u2705 Standard web application (Node.js, Java, Python, Go, Ruby, PHP, .NET) - \u2705 Willing to follow framework conventions (<code>package.json</code>, <code>pom.xml</code>, etc.) - \u2705 Value security automation over customization</p> <p>Use Dockerfile When: - \u26a0\ufe0f Truly unique requirements (custom OS, exotic dependencies) - \u26a0\ufe0f Legacy app with specific build steps not automatable - \u26a0\ufe0f Polyglot app (Node.js + Python + Java in one container\u2014please don't) - \u26a0\ufe0f Embedded systems or non-standard architectures</p> <p>Fawkes Policy: Golden Path is Buildpacks. Dockerfile opt-out allowed with justification (architectural review required).</p>"},{"location":"explanation/containers/buildpacks-philosophy/#the-philosophy-platform-as-product","title":"The Philosophy: Platform as Product","text":""},{"location":"explanation/containers/buildpacks-philosophy/#the-paved-road-concept","title":"The \"Paved Road\" Concept","text":"<p>Buildpacks embody the Golden Path philosophy:</p> <ul> <li>Easy things should be easy - Deploying a standard Node.js app: zero config</li> <li>Hard things should be possible - Need custom build? Dockerfile escape hatch exists</li> <li>Safe by default - Security and best practices baked in, not opt-in</li> </ul> <pre><code>graph LR\n    A[Developer] --&gt;|Golden Path| B[Buildpack]\n    A --&gt;|Edge Case| C[Dockerfile]\n    B --&gt;|90% of apps| D[Production]\n    C --&gt;|10% of apps| D\n\n    style B fill:#4CAF50\n    style C fill:#FFA726</code></pre> <p>The Contract: - Platform team maintains buildpacks (updates, security patches, optimizations) - Developers follow conventions (standard project structure, framework best practices) - Everyone benefits (fast deploys, secure images, low cognitive load)</p>"},{"location":"explanation/containers/buildpacks-philosophy/#the-maintenance-burden-shift","title":"The Maintenance Burden Shift","text":"<p>Before Buildpacks (Dockerfile Era): <pre><code>Platform Team:\n- Writes \"recommended Dockerfile\" guide\n- Reviews 200 Dockerfiles in PRs\n- Manually reminds teams to update base images\n\nDevelopers:\n- Copy-paste Dockerfiles from other projects\n- Cargo-cult optimizations they don't understand\n- Ignore security patches (too much work)\n</code></pre></p> <p>After Buildpacks: <pre><code>Platform Team:\n- Maintains 1 buildpack configuration\n- Updates platform builder when patches released\n- Automatically rebases all images (via CI)\n\nDevelopers:\n- Write code\n- Push code\n- Deployments happen\n- (No Dockerfile to maintain)\n</code></pre></p> <p>Who Wins? Everyone. Platform team scales better. Developers ship faster. Security team sleeps better.</p>"},{"location":"explanation/containers/buildpacks-philosophy/#real-world-example-the-log4shell-response","title":"Real-World Example: The Log4Shell Response","text":"<p>In December 2021, the Log4Shell vulnerability (CVE-2021-44228) was discovered in Log4j, affecting millions of Java applications.</p>"},{"location":"explanation/containers/buildpacks-philosophy/#dockerfile-world-response","title":"Dockerfile World Response","text":"<ol> <li>Identify affected apps - Search 300 repos for <code>pom.xml</code> or <code>build.gradle</code> with Log4j</li> <li>Update dependencies - Each team updates their <code>pom.xml</code> (version 2.15.0)</li> <li>Rebuild images - <code>docker build</code> for each app (wait for CI)</li> <li>Re-test - Run full test suites (hours)</li> <li>Re-deploy - 300 deployments over 2 weeks</li> <li>Miss stragglers - That archived repo? Still vulnerable</li> </ol> <p>Time to Remediate: 2-3 weeks Human Effort: Hundreds of developer-hours</p>"},{"location":"explanation/containers/buildpacks-philosophy/#buildpack-world-response","title":"Buildpack World Response","text":"<ol> <li>Paketo team updates buildpack - Log4j version bumped in Java buildpack</li> <li>Platform team updates builder - <code>pack builder pull paketobuildpacks/builder:base</code></li> <li>CI triggers rebuilds - Automated pipeline rebuilds all Java apps (parallel)</li> <li>Automated testing - Smoke tests pass (no code changes)</li> <li>Automated deployment - GitOps syncs new images</li> <li>Complete coverage - Every Java app patched automatically</li> </ol> <p>Time to Remediate: 2-3 days Human Effort: One platform engineer</p> <p>This is the promise of Buildpacks: When a platform team of 3 can patch 300 applications faster than 300 developers, you've achieved leverage.</p>"},{"location":"explanation/containers/buildpacks-philosophy/#philosophical-underpinnings","title":"Philosophical Underpinnings","text":""},{"location":"explanation/containers/buildpacks-philosophy/#principle-1-convention-over-configuration","title":"Principle 1: Convention Over Configuration","text":"<p>Dockerfile Philosophy: \"Give developers full control; they'll make good choices.\" Reality: Developers copy-paste, cargo-cult, and move fast (breaking things).</p> <p>Buildpack Philosophy: \"Encode best practices; let developers override when necessary.\" Reality: 90% follow convention happily. 10% understand enough to safely override.</p>"},{"location":"explanation/containers/buildpacks-philosophy/#principle-2-separation-of-concerns","title":"Principle 2: Separation of Concerns","text":"<p>Dockerfile: Developer is responsible for OS, runtime, dependencies, app code, optimization, security.</p> <p>Buildpack:  - Platform Team: Maintains OS, runtime, build tools (centralized expertise) - Developer: Focuses on application code and business logic - Clear Boundary: <code>package.json</code> is the interface; everything below is abstracted</p>"},{"location":"explanation/containers/buildpacks-philosophy/#principle-3-scale-through-standardization","title":"Principle 3: Scale Through Standardization","text":"<p>The Formula: <pre><code>Operational Efficiency = (Standard Patterns) / (Custom Snowflakes)\n</code></pre></p> <p>100 unique Dockerfiles = 100 maintenance burdens 100 apps using 1 buildpack = 1 maintenance point</p> <p>This is why platforms exist: To amortize expertise across many teams.</p>"},{"location":"explanation/containers/buildpacks-philosophy/#addressing-common-objections","title":"Addressing Common Objections","text":""},{"location":"explanation/containers/buildpacks-philosophy/#but-im-a-senior-engineer-i-know-how-to-write-a-good-dockerfile","title":"\"But I'm a senior engineer; I know how to write a good Dockerfile!\"","text":"<p>Response: You probably do! And that's valuable for the 10% edge cases. But:</p> <ol> <li>Your team might not - Junior engineers copy your Dockerfile and miss subtleties</li> <li>You might leave - Tribal knowledge doesn't scale</li> <li>Security doesn't wait - Can you patch 50 Dockerfiles when a CVE drops at 5pm Friday?</li> </ol> <p>Buildpacks are for scale, not because we doubt your skills.</p>"},{"location":"explanation/containers/buildpacks-philosophy/#buildpacks-are-a-black-box-i-dont-trust-what-i-dont-understand","title":"\"Buildpacks are a black box; I don't trust what I don't understand.\"","text":"<p>Response:  1. Buildpacks are open source - Paketo Buildpacks on GitHub 2. Full transparency - Run <code>pack build --verbose</code> to see every command 3. SBOM generated - Bill of Materials shows exactly what's in your image 4. Inspectable - <code>pack inspect-image my-app</code> shows layers, buildpacks used, metadata</p> <p>Dockerfiles can be black boxes too - How many devs actually audit <code>node:16-alpine</code>?</p>"},{"location":"explanation/containers/buildpacks-philosophy/#what-if-i-need-to-install-a-system-package","title":"\"What if I need to install a system package?\"","text":"<p>Response: Buildpack extensions allow custom install steps:</p> <pre><code># buildpack.yml\n---\nnodejs:\n  version: 18\n\nextensions:\n  - name: install-custom-tool\n    run: |\n      apt-get update &amp;&amp; apt-get install -y my-tool\n</code></pre> <p>Or: Use Dockerfile for that app. Buildpacks are the default, not a prison.</p>"},{"location":"explanation/containers/buildpacks-philosophy/#our-build-is-too-customcomplex-for-a-buildpack","title":"\"Our build is too custom/complex for a buildpack.\"","text":"<p>Response: Probably true for 5-10% of apps. Those should use Dockerfiles. But:</p> <ol> <li>Are you sure? - 80% of \"we're special\" claims aren't (seen this repeatedly)</li> <li>Can it be simplified? - Complex builds often indicate architectural issues</li> <li>Can we contribute? - If it's a valid use case, propose a buildpack extension</li> </ol> <p>The goal isn't 100% buildpack adoption\u2014it's making the common case trivial.</p>"},{"location":"explanation/containers/buildpacks-philosophy/#related-reading","title":"Related Reading","text":"<ul> <li>How-To: Debug Buildpack Failures</li> <li>Tutorial: Module 6: Golden Path</li> <li>Reference: Paketo Buildpacks Documentation</li> <li>Reference: Cloud Native Buildpacks Specification</li> </ul>"},{"location":"explanation/containers/buildpacks-philosophy/#conclusion","title":"Conclusion","text":"<p>Buildpacks are a philosophical choice, not just a technical one. They represent a belief that:</p> <ol> <li>Automation beats manual toil - Even when you're good at the toil</li> <li>Centralized expertise scales - Better than distributed mediocrity</li> <li>Security is a platform concern - Not every team's homework</li> <li>Convention liberates - By removing low-level decisions, we free developers to focus on business value</li> </ol> <p>The question isn't \"Can I write a better Dockerfile than a buildpack?\" (you might). The question is \"Can I maintain 50 better Dockerfiles, patch them in hours during a CVE, and train my whole team to do the same?\" (you can't).</p> <p>Buildpacks are the Golden Path because they scale.</p> <p>And when you need to step off the Golden Path? Dockerfiles still exist. The door is always open\u2014we've just made it so most people don't need to walk through it.</p>"},{"location":"explanation/governance/policy-as-code-tiers/","title":"Policy as Code Tiers: Audit vs. Enforce","text":""},{"location":"explanation/governance/policy-as-code-tiers/#context","title":"Context","text":"<p>Security policies are necessary but enforcement is a spectrum, not binary. Enforcing every security best practice from day one would: - Block legitimate developer workflows - Create change resistance (\"Platform team said NO again\") - Slow down delivery (waiting for exceptions, workarounds) - Reduce platform adoption (developers route around strict controls)</p> <p>The solution is tiered policy enforcement: critical policies enforced immediately, important policies audited before enforced, best practices remain advisory.</p> <p>This document explains Fawkes' Policy-as-Code Tiers framework using Kyverno, and why gradual enforcement is better than \"big bang\" compliance.</p>"},{"location":"explanation/governance/policy-as-code-tiers/#the-problem-all-or-nothing-enforcement-fails","title":"The Problem: All-or-Nothing Enforcement Fails","text":""},{"location":"explanation/governance/policy-as-code-tiers/#scenario-1-the-zero-tolerance-trap","title":"Scenario 1: The Zero-Tolerance Trap","text":"<p>Platform Team Decision: \"All pods must be non-root, no exceptions. Security is non-negotiable.\"</p> <p>Week 1: Policy enforced across all namespaces</p> <p>Week 2: Developers revolt - Legacy app runs as root (vendor-provided image, can't change) - Database StatefulSets need elevated privileges - Debugging containers blocked (troubleshooting tools need root)</p> <p>Week 3: Platform team creates exception process - Developers submit tickets requesting policy exemptions - Platform team reviews each request manually - Ticket backlog: 40+ exception requests</p> <p>Week 4: Developers route around platform - Deploy to \"dev\" namespace (policies disabled to \"not slow down development\") - Promote to prod via kubectl (bypassing GitOps) - Shadow IT: Run workloads in separate clusters outside platform team control</p> <p>Outcome: Policy exists on paper, violated in practice. Worse security posture than gradual enforcement.</p>"},{"location":"explanation/governance/policy-as-code-tiers/#scenario-2-the-permissive-paralysis","title":"Scenario 2: The Permissive Paralysis","text":"<p>Platform Team Decision: \"We'll make policies advisory-only. Developers know best.\"</p> <p>Week 1: Policies in audit mode, violations logged</p> <p>Month 3: 10,000+ policy violations logged, nobody fixes them</p> <p>Month 6: Real security incident - Privileged container exploited - Attacker pivots to other workloads - Root cause: Container ran as root (policy violation ignored for 6 months)</p> <p>Outcome: Audit-only policies without enforcement roadmap = no improvement.</p>"},{"location":"explanation/governance/policy-as-code-tiers/#the-solution-tiered-enforcement-model","title":"The Solution: Tiered Enforcement Model","text":"<p>Fawkes uses a three-tier policy framework:</p> Tier Enforcement Scope Examples Tier 1: Critical \u2705 Enforce Immediate security risks No privileged escalation, no host network, approved registries only Tier 2: Important \u26a0\ufe0f Audit \u2192 Enforce Hardening and compliance Resource limits, non-root users, read-only root filesystem Tier 3: Best Practice \u2139\ufe0f Audit Only Operational excellence Recommended labels, deployment strategies, cost tagging <pre><code>graph LR\n    A[New Policy] --&gt;|Security Critical?| B{Tier 1}\n    B --&gt;|Yes| C[Enforce Immediately]\n    B --&gt;|No| D{Tier 2}\n    D --&gt;|Important| E[Audit \u2192 Enforce]\n    D --&gt;|Nice-to-Have| F[Audit Only]\n\n    style C fill:#ff6b6b\n    style E fill:#FFA726\n    style F fill:#4CAF50</code></pre>"},{"location":"explanation/governance/policy-as-code-tiers/#tier-1-critical-enforce-immediately","title":"Tier 1: Critical (Enforce Immediately)","text":"<p>Philosophy: Block obvious security holes that no legitimate workload should need.</p> <p>Examples:</p> <p>1. No Privileged Containers</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: disallow-privileged-containers\n  annotations:\n    policies.kyverno.io/tier: critical\n    policies.kyverno.io/severity: high\nspec:\n  validationFailureAction: Enforce  # Block deployment\n  background: true\n  rules:\n    - name: privileged-containers\n      match:\n        any:\n          - resources:\n              kinds:\n                - Pod\n      validate:\n        message: \"Privileged containers are not allowed\"\n        pattern:\n          spec:\n            containers:\n              - =(securityContext):\n                  =(privileged): \"false\"\n</code></pre> <p>Rationale: - Privileged containers can break out to host - Virtually no legitimate use case (0.1% of workloads) - Risk of blocking: Very low - Risk of allowing: Very high</p> <p>2. No Host Namespaces</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: disallow-host-namespaces\nspec:\n  validationFailureAction: Enforce\n  rules:\n    - name: host-namespaces\n      match:\n        any:\n          - resources:\n              kinds:\n                - Pod\n      validate:\n        message: \"Sharing host namespaces is not allowed\"\n        pattern:\n          spec:\n            =(hostNetwork): \"false\"\n            =(hostIPC): \"false\"\n            =(hostPID): \"false\"\n</code></pre> <p>Rationale: - Host network/PID/IPC access = container breakout vector - Legitimate use cases: &lt;1% (CNI plugins, monitoring agents) - Those exceptions: Platform team manages, not developers</p> <p>3. Images from Approved Registries Only</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: restrict-image-registries\nspec:\n  validationFailureAction: Enforce\n  rules:\n    - name: approved-registries\n      match:\n        any:\n          - resources:\n              kinds:\n                - Pod\n      validate:\n        message: \"Images must be from approved registries: harbor.fawkes.io, gcr.io/fawkes\"\n        pattern:\n          spec:\n            containers:\n              - image: \"harbor.fawkes.io/* | gcr.io/fawkes/*\"\n</code></pre> <p>Rationale: - Public Docker Hub images: unvetted, potential supply chain attacks - Approved registries: scanned for vulnerabilities, signed - Risk: Developer pulls <code>random/cryptominer:latest</code> (supply chain attack)</p> <p>Tier 1 Exception Process: Manual approval by security team, documented justification, time-limited exemption.</p>"},{"location":"explanation/governance/policy-as-code-tiers/#tier-2-important-audit-enforce","title":"Tier 2: Important (Audit \u2192 Enforce)","text":"<p>Philosophy: Security hardening that requires migration time for existing workloads.</p> <p>Rollout Process:</p> Phase Duration Action Developer Impact Phase 1: Audit Month 1-2 Log violations, no blocking None (visibility only) Phase 2: Alert Month 3 Weekly reports to teams Awareness Phase 3: Warn Month 4 Deployments succeed with warning Noise Phase 4: Enforce Month 5+ Block non-compliant deployments Compliance required <p>Examples:</p> <p>1. Require Resource Limits</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-resource-limits\n  annotations:\n    policies.kyverno.io/tier: important\nspec:\n  validationFailureAction: Audit  # Will become Enforce after migration period\n  background: true\n  rules:\n    - name: check-resource-limits\n      match:\n        any:\n          - resources:\n              kinds:\n                - Pod\n      validate:\n        message: \"CPU and memory limits are required\"\n        pattern:\n          spec:\n            containers:\n              - resources:\n                  limits:\n                    memory: \"?*\"\n                    cpu: \"?*\"\n</code></pre> <p>Why Gradual: - Legacy apps may not have limits set (works fine, but risky) - Impact analysis needed: What limits are appropriate? - Migration time: Teams need to test with limits, adjust</p> <p>Rollout: 1. Month 1 (Audit): Platform team identifies 120 pods without limits 2. Month 2 (Alert): Teams notified via Slack, given template configs 3. Month 3 (Warn): Deployments warn but succeed, countdown timer shown 4. Month 4 (Enforce): Policy enforced, non-compliant deployments blocked</p> <p>2. Non-Root Users</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-non-root\nspec:\n  validationFailureAction: Audit  # Gradual rollout\n  rules:\n    - name: non-root-user\n      match:\n        any:\n          - resources:\n              kinds:\n                - Pod\n      validate:\n        message: \"Containers must run as non-root user\"\n        pattern:\n          spec:\n            containers:\n              - securityContext:\n                  runAsNonRoot: true\n</code></pre> <p>Why Gradual: - Many images default to root user - Developer needs to rebuild image or override in security context - Migration: Takes time to rebuild images</p> <p>3. Read-Only Root Filesystem</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-read-only-root-filesystem\nspec:\n  validationFailureAction: Audit\n  rules:\n    - name: read-only-root-fs\n      match:\n        any:\n          - resources:\n              kinds:\n                - Pod\n      validate:\n        message: \"Root filesystem should be read-only\"\n        pattern:\n          spec:\n            containers:\n              - securityContext:\n                  readOnlyRootFilesystem: true\n</code></pre> <p>Why Gradual: - Apps that write to local filesystem must be refactored (write to emptyDir volume instead) - Requires code changes, testing</p> <p>Tier 2 Exception Process: Team lead approval, documented technical reason, review every 90 days.</p>"},{"location":"explanation/governance/policy-as-code-tiers/#tier-3-best-practice-audit-only","title":"Tier 3: Best Practice (Audit Only)","text":"<p>Philosophy: Encourage good practices but never block. Use visibility to drive cultural change.</p> <p>Examples:</p> <p>1. Recommended Labels</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: recommended-labels\nspec:\n  validationFailureAction: Audit  # Never enforced\n  rules:\n    - name: check-labels\n      match:\n        any:\n          - resources:\n              kinds:\n                - Deployment\n      validate:\n        message: \"Recommended labels missing: app.kubernetes.io/name, app.kubernetes.io/version, team\"\n        pattern:\n          metadata:\n            labels:\n              app.kubernetes.io/name: \"?*\"\n              app.kubernetes.io/version: \"?*\"\n              team: \"?*\"\n</code></pre> <p>Why Audit-Only: - Labels helpful for observability, cost allocation, ownership - But lack of labels doesn't create security risk - Carrot, not stick: Show teams their compliance score, let them improve voluntarily</p> <p>2. Deployment Strategies</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: recommended-deployment-strategy\nspec:\n  validationFailureAction: Audit\n  rules:\n    - name: rolling-update\n      match:\n        any:\n          - resources:\n              kinds:\n                - Deployment\n      validate:\n        message: \"Recommended strategy: RollingUpdate (not Recreate)\"\n        pattern:\n          spec:\n            strategy:\n              type: RollingUpdate\n</code></pre> <p>Why Audit-Only: - RollingUpdate preferred (zero-downtime deployments) - But Recreate valid for stateful apps, development environments - Education: Show metric \"85% of deployments use RollingUpdate\", team can improve</p> <p>3. Cost Allocation Tags</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: cost-allocation-tags\nspec:\n  validationFailureAction: Audit\n  rules:\n    - name: cost-center-label\n      match:\n        any:\n          - resources:\n              kinds:\n                - Deployment\n      validate:\n        message: \"Recommended label for cost tracking: cost-center\"\n        pattern:\n          metadata:\n            labels:\n              cost-center: \"?*\"\n</code></pre> <p>Why Audit-Only: - Helps finance team allocate cloud costs - But not a security requirement - Gradual adoption: Teams add cost-center labels for accurate chargeback</p>"},{"location":"explanation/governance/policy-as-code-tiers/#policy-lifecycle-from-audit-to-enforce","title":"Policy Lifecycle: From Audit to Enforce","text":""},{"location":"explanation/governance/policy-as-code-tiers/#the-migration-path","title":"The Migration Path","text":"<pre><code>graph LR\n    A[New Policy Created] --&gt;|Week 1| B[Audit Mode]\n    B --&gt;|Week 4| C[Analyze Violations]\n    C --&gt;|Week 5-8| D[Team Migration]\n    D --&gt;|Week 9| E{Ready?}\n    E --&gt;|Yes| F[Enforce Mode]\n    E --&gt;|No| G[Extend Timeline]\n    G --&gt; D\n\n    style F fill:#4CAF50</code></pre> <p>Example: \"Require Non-Root Users\" Policy</p> <p>Week 1-4: Audit Phase - Policy deployed in audit mode - Violations logged to PolicyReport CRD - Platform team analyzes impact</p> <p>Report: <pre><code>apiVersion: wgpolicyk8s.io/v1alpha2\nkind: PolicyReport\nmetadata:\n  name: require-non-root-violations\nsummary:\n  pass: 42\n  fail: 18  # 18 pods violating policy\n  warn: 0\n  error: 0\nresults:\n  - policy: require-non-root\n    rule: non-root-user\n    result: fail\n    resources:\n      - kind: Pod\n        namespace: api-gateway\n        name: api-pod-abc123\n    message: \"Container 'api' runs as root user\"\n</code></pre></p> <p>Week 5-8: Migration Phase 1. Communication: Email teams with violations    - \"Your <code>api-gateway</code> service runs as root. Here's how to fix...\"    - Link to documentation, example configs</p> <ol> <li> <p>Office Hours: Weekly drop-in sessions for teams needing help</p> </li> <li> <p>Tracking: Dashboard shows compliance trend</p> </li> <li>Week 5: 70% compliant</li> <li>Week 6: 80% compliant</li> <li>Week 7: 90% compliant</li> </ol> <p>Week 9: Enforcement Decision - \u2705 90%+ compliant \u2192 Switch to enforce mode - \u26a0\ufe0f &lt;90% compliant \u2192 Extend migration timeline</p> <p>Week 10+: Enforce Mode <pre><code>spec:\n  validationFailureAction: Enforce  # Now blocking\n</code></pre></p> <p>Remaining violations: Platform team works 1-on-1 with teams or grants time-limited exemptions.</p>"},{"location":"explanation/governance/policy-as-code-tiers/#governance-who-decides-what-tier","title":"Governance: Who Decides What Tier?","text":""},{"location":"explanation/governance/policy-as-code-tiers/#policy-review-board","title":"Policy Review Board","text":"<p>Members: - Platform Lead - Security Engineer - 2x Developer Representatives (rotates quarterly)</p> <p>Responsibilities: 1. Review new policies: Assign tier (Critical, Important, Best Practice) 2. Monitor audit-to-enforce transitions: Are teams ready? 3. Handle exception requests: Approve/deny Tier 1 exemptions 4. Quarterly policy review: Should Tier 2 policies move to Tier 1? Retire unused policies?</p> <p>Example Decision:</p> <p>Proposed Policy: \"All deployments must use Argo Rollouts for canary deployments\"</p> <p>Discussion: - Security: Not a security issue (Tier 3 at most) - Developer: This would block 80% of current deployments, high friction - Platform: Canary is best practice but not mandatory for low-traffic apps</p> <p>Decision: Tier 3 (Audit Only) - Encourage adoption via education - Show metric: \"Teams using canary have 50% lower CFR\" - Don't enforce (too disruptive for marginal benefit)</p>"},{"location":"explanation/governance/policy-as-code-tiers/#exception-request-process","title":"Exception Request Process","text":"<p>Tier 1 (Critical) Exception: 1. Submit ticket with justification 2. Security team reviews 3. Approval requires:    - Technical necessity (no alternative)    - Compensating controls (extra monitoring, isolated namespace)    - Time limit (expires in 90 days, must re-justify) 4. Documented in audit log</p> <p>Tier 2 (Important) Exception: 1. Team lead approves via annotation    <pre><code>metadata:\n  annotations:\n    policy.fawkes.io/exception: \"require-non-root\"\n    policy.fawkes.io/reason: \"Legacy vendor image, migration planned Q2\"\n    policy.fawkes.io/expires: \"2024-06-30\"\n</code></pre> 2. Reviewed quarterly 3. Exemption expires automatically, must renew</p> <p>Tier 3 (Best Practice) Exception: - No exception needed (audit-only) - Teams can ignore violations without approval</p>"},{"location":"explanation/governance/policy-as-code-tiers/#trade-offs-security-vs-velocity","title":"Trade-Offs: Security vs. Velocity","text":""},{"location":"explanation/governance/policy-as-code-tiers/#what-tiered-enforcement-gives-you","title":"What Tiered Enforcement Gives You","text":"Benefit Impact Gradual Adoption Teams adapt to policies over time, not shocked by \"big bang\" Developer Trust Platform team seen as partner, not blocker Higher Compliance 90%+ adoption vs. 50% with all-or-nothing enforcement Risk Mitigation Critical risks blocked immediately, lower risks addressed iteratively Continuous Improvement Policies evolve based on real-world usage, not theory"},{"location":"explanation/governance/policy-as-code-tiers/#what-tiered-enforcement-costs-you","title":"What Tiered Enforcement Costs You","text":"Challenge Mitigation Complexity Managing three tiers, transition timelines. Mitigation: Automation (policy reports, dashboards) Incomplete Security Tier 2/3 violations exist during migration. Mitigation: Acceptable risk for gradual improvement Communication Overhead Must explain tier decisions, migration plans. Mitigation: Transparent documentation, regular updates Exception Sprawl Teams request exemptions to avoid work. Mitigation: Time-limited exemptions, quarterly review <p>The Bet: 90% compliance with gradual enforcement beats 50% compliance with strict enforcement.</p>"},{"location":"explanation/governance/policy-as-code-tiers/#metrics-measuring-policy-success","title":"Metrics: Measuring Policy Success","text":""},{"location":"explanation/governance/policy-as-code-tiers/#compliance-dashboard","title":"Compliance Dashboard","text":"<pre><code>Fawkes Policy Compliance (November 2024)\n\nOverall Compliance: 87% (\u2191 5% vs. last month)\n\nTier 1 (Critical) - Enforced:\n  Compliance: 98%  \u2705\n  Violations: 3 (all approved exemptions)\n\nTier 2 (Important) - Audit \u2192 Enforce:\n  Compliance: 82%  \u26a0\ufe0f\n  Violations: 27\n  On Track to Enforce: March 2025\n\nTier 3 (Best Practice) - Audit Only:\n  Compliance: 65%  \u2139\ufe0f\n  Violations: 105\n  Trend: \u2191 10% over 6 months (voluntary adoption)\n\nTop Violations (Tier 2):\n  1. Missing resource limits (18 pods)\n  2. Non-root users (7 pods)\n  3. Read-only filesystem (2 pods)\n\nAction Items:\n  - Office hours scheduled for teams with resource limit violations\n  - Automated mutation policy proposed to add default limits\n</code></pre>"},{"location":"explanation/governance/policy-as-code-tiers/#policy-effectiveness-metrics","title":"Policy Effectiveness Metrics","text":"Metric Target Current Tier 1 Compliance &gt;95% 98% \u2705 Tier 2 Compliance &gt;85% before enforcement 82% \u26a0\ufe0f Tier 2 Enforcement Deadlines Met &gt;80% on-time 100% \u2705 Exception Requests (Tier 1) &lt;5 active 3 \u2705 Time to Remediate Violations &lt;30 days 22 days \u2705"},{"location":"explanation/governance/policy-as-code-tiers/#related-reading","title":"Related Reading","text":"<ul> <li>ADR: ADR-017: Kyverno Policy Engine</li> <li>Explanation: Zero Trust Security Model</li> <li>How-To: Troubleshoot Kyverno Violations</li> <li>Reference: Kyverno Policy Library</li> </ul>"},{"location":"explanation/governance/policy-as-code-tiers/#conclusion","title":"Conclusion","text":"<p>Security policies are necessary, but enforcement is an art, not a science.</p> <p>The tiered enforcement model recognizes that: 1. Not all policies are equal - Some prevent immediate breaches (enforce now), others harden over time (audit first) 2. Developers need migration time - Sudden enforcement creates resistance and shadow IT 3. Culture beats compliance - Gradual adoption builds trust, all-or-nothing breeds resentment 4. Perfect is the enemy of good - 90% compliance with partnership beats 50% compliance with force</p> <p>The Framework: - Tier 1 (Critical): Enforce immediately, exceptions rare - Tier 2 (Important): Audit \u2192 Enforce with migration timeline - Tier 3 (Best Practice): Audit only, encourage via visibility</p> <p>The Philosophy: Security is a journey, not a destination. Meet developers where they are, guide them to where they should be.</p> <p>This is Policy-as-Code with empathy.</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/","title":"Product Discovery and Delivery Flow: The IP3dP Concept","text":""},{"location":"explanation/idp/product-discovery-delivery-flow/#context","title":"Context","text":"<p>Most internal developer platforms (IDPs) fail not because of technical problems, but because of product problems: - Built features nobody uses - Solved problems teams don't have - Ignored the problems teams actually face - Failed to measure whether the platform improves developer productivity</p> <p>The Challenge: How do you treat your platform like a product when your \"customers\" (developers) can't choose a competitor and you have no revenue to measure success?</p> <p>Fawkes introduces the IP3dP framework: Internal Platform Product Discovery and Delivery Process\u2014a structured methodology for running your platform as a product, not a project.</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#the-problem-build-it-and-they-will-come-doesnt-work","title":"The Problem: \"Build It and They Will Come\" Doesn't Work","text":""},{"location":"explanation/idp/product-discovery-delivery-flow/#the-traditional-idp-anti-pattern","title":"The Traditional IDP Anti-Pattern","text":"<p>Month 1: Platform team decides \"We need a developer portal!\" Month 2-6: Build Backstage, integrate with GitHub, ArgoCD, Jenkins Month 7: Launch with fanfare, send Slack announcement Month 8: 12% adoption. Developers still use <code>kubectl</code> and Slack for everything. Month 9: Platform team confused: \"Why don't they use it?\"</p> <p>Root Cause: Nobody asked developers what problems they actually have.</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#the-feature-factory-trap","title":"The Feature Factory Trap","text":"<p>Platform team operates like a feature factory: 1. Stakeholder requests feature (\"We need Vault integration!\") 2. Team builds feature 3. Ship feature, move to next request 4. Repeat indefinitely</p> <p>Missing: - Discovery: Is this solving a real pain point? - Validation: Will developers actually use this? - Measurement: Did this improve productivity? - Iteration: How do we make it better?</p> <p>Result: A Frankenstein platform with 50 features, 5 actually used, and developers still frustrated.</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#the-metrics-mirage","title":"The Metrics Mirage","text":"<p>Platform teams measure the wrong things: - \u274c Deployment frequency (platform metric, not developer outcome) - \u274c Number of features shipped (output, not outcome) - \u274c Uptime of platform services (necessary but not sufficient)</p> <p>What Should Be Measured: - \u2705 Developer productivity (time from idea to production) - \u2705 Cognitive load (how many tools/concepts to learn) - \u2705 Task success rate (can devs complete common tasks?) - \u2705 Developer satisfaction (Net Promoter Score for internal platform)</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#the-solution-ip3dp-platform-as-product","title":"The Solution: IP3dP - Platform as Product","text":"<p>The IP3dP framework applies product management principles to platform engineering:</p> <pre><code>graph TB\n    A[Discovery] --&gt;|Problems| B[Prioritization]\n    B --&gt;|Roadmap| C[Delivery]\n    C --&gt;|Features| D[Measurement]\n    D --&gt;|Learnings| A\n\n    style A fill:#4CAF50\n    style B fill:#FF9800\n    style C fill:#2196F3\n    style D fill:#9C27B0</code></pre>"},{"location":"explanation/idp/product-discovery-delivery-flow/#the-four-phases","title":"The Four Phases","text":""},{"location":"explanation/idp/product-discovery-delivery-flow/#1-discovery-what-problems-do-developers-have","title":"1. Discovery: What Problems Do Developers Have?","text":"<p>Goal: Deeply understand developer pain points before building anything.</p> <p>Methods:</p> <p>User Research (Qualitative): - Developer Interviews: 1-on-1 conversations (30-45 min)   - \"Walk me through your last deployment\"   - \"What's the most frustrating part of your workflow?\"   - \"If you had a magic wand, what would you change?\"</p> <ul> <li>Shadowing: Sit with developers, observe their workflow</li> <li>Watch them struggle with <code>kubectl</code> copy-pasting from Slack</li> <li>See them waste 20 minutes finding the right config file</li> <li> <p>Notice they rebuild images unnecessarily because unclear when cache invalidated</p> </li> <li> <p>Surveys: Structured feedback at scale</p> </li> <li>SPACE Framework metrics (Satisfaction, Performance, Activity, Communication, Efficiency)</li> <li>Net Promoter Score: \"How likely are you to recommend this platform to a colleague?\"</li> </ul> <p>Data Analysis (Quantitative): - Platform Analytics: What features are used? What's ignored?   - Backstage: 80% use service catalog, 10% use docs, 2% use templates   - Jenkins: 60% of pipelines copy-pasted from \"blessed-pipeline\" repo (hint: make template)</p> <ul> <li>Support Tickets: What breaks? What confuses people?</li> <li>40% of tickets: \"How do I deploy to production?\" (hint: docs/onboarding problem)</li> <li> <p>25% of tickets: \"My build is slow\" (hint: buildpack caching issue)</p> </li> <li> <p>DORA Metrics Correlation: Does platform usage correlate with team performance?</p> </li> <li>Teams using GitOps: 3x higher deployment frequency</li> <li>Teams not using GitOps: Higher change failure rate</li> </ul> <p>Jobs-to-be-Done Framework:</p> <p>Instead of \"What features do you want?\", ask \"What job are you trying to do?\"</p> Developer Says What They Want Actual Job-to-be-Done Platform Solution \"I need a Kubernetes dashboard\" UI to see pods Monitor application health Grafana dashboard showing SLIs, not low-level K8s resources \"I need SSH access to pods\" Debug production Troubleshoot application issues Structured logs in Loki, traces in Tempo, ephemeral debug containers \"I need a faster build\" Reduce CI time Deploy changes quickly Buildpack layer caching, parallel test execution <p>Example Discovery Insight:</p> <p>Initial Request: \"We need a feature flag service\" Discovery Conversation: - Why do you need feature flags? - \"To deploy without breaking production\" - What breaks today when you deploy? - \"We push code Friday, it breaks, we roll back\" - Why Friday? Why not earlier in the week? - \"Deployment process takes 2 hours, only time we have is end-of-sprint\"</p> <p>Real Problem: Deployment is too slow and risky, so teams batch changes and deploy infrequently. Solution: Not feature flags\u2014fix deployment speed and reliability (canary deployments, automated rollback).</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#2-prioritization-what-should-we-build","title":"2. Prioritization: What Should We Build?","text":"<p>Goal: Choose high-impact problems to solve, not just loudest requests.</p> <p>Prioritization Framework: RICE</p> Factor Measurement Example Reach How many developers affected? 80% of teams deploy daily (high reach) Impact How much does it improve productivity? Saves 2 hours/week per developer (high impact) Confidence How certain are we this solves the problem? Validated via user interviews (80% confidence) Effort How long to build? 2 sprints (medium effort) <p>RICE Score = (Reach \u00d7 Impact \u00d7 Confidence) / Effort</p> <p>Example:</p> Initiative Reach Impact Confidence Effort RICE Score Priority Auto-deploy on merge 200 devs 3 (high) 90% 3 weeks 180 1 Custom Backstage theme 200 devs 1 (low) 100% 1 week 200 2 Vault auto-rotation 50 devs 3 (high) 70% 4 weeks 26 3 AI code assistant 200 devs 2 (med) 50% 8 weeks 25 4 <p>Decision: Build auto-deploy first (highest impact, reasonable effort).</p> <p>Ruthless De-Prioritization: - \"We won't build feature flags this quarter\" (low confidence it solves real problem) - \"We won't support Python 2.7\" (reach is 2 legacy apps, sunset them instead)</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#3-delivery-build-measure-learn","title":"3. Delivery: Build, Measure, Learn","text":"<p>Goal: Ship iteratively, get feedback fast, pivot if needed.</p> <p>Lean Delivery Approach:</p> <p>Week 1-2: Spike / Prototype - Build minimal proof-of-concept - Test with 2-3 friendly developer teams - Question: \"Does this solve your problem?\"</p> <p>Week 3-4: Alpha - Functional but rough - 10-20 early adopters - Measurement: Can they complete the task? Where do they struggle?</p> <p>Week 5-6: Beta - Polished UX, docs, error messages - Opt-in for all teams - Measurement: Adoption rate, support tickets</p> <p>Week 7-8: General Availability - Default for new services - Gradual rollout to existing services - Measurement: DORA metrics, developer satisfaction</p> <p>Example: GitOps Rollout</p> Phase Timeline Audience Success Criteria Prototype Week 1-2 2 teams Can deploy via Git commit (manual sync) Alpha Week 3-4 10 teams Auto-sync working, 80% uptime Beta Week 5-8 50 teams Self-service onboarding docs, &lt;5 min to onboard GA Week 9+ All teams Default for new services, 99.5% uptime <p>Feedback Loops: - Office Hours: Weekly drop-in for developers to ask questions - Retrospectives: After each phase, what worked? What didn't? - Metrics Dashboard: Real-time visibility into adoption, errors</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#4-measurement-did-it-work","title":"4. Measurement: Did It Work?","text":"<p>Goal: Quantify impact, not just activity.</p> <p>North Star Metric: Developer Productivity</p> <p>Operationalized as: - Lead Time for Changes (DORA) - Time from commit to production - Deployment Frequency (DORA) - How often teams deploy - Change Failure Rate (DORA) - % of deployments requiring rollback - Time to Restore Service (DORA) - MTTR for incidents</p> <p>SPACE Framework (Developer Experience)</p> Dimension Metric Target Satisfaction NPS, survey scores &gt;40 NPS Performance DORA metrics Elite tier (deploy multiple/day, &lt;15% CFR) Activity Commits, PRs, deploys Trending up over time Communication Slack messages, support tickets Trending down (less confusion) Efficiency Time to complete tasks &lt;5 min to deploy, &lt;30 min to onboard new service <p>Example Dashboard:</p> <pre><code>Fawkes Platform Health Dashboard\n\nDORA Metrics (This Month):\n  Deployment Frequency:     5.2 deploys/day/team  \u2191 30% vs. last month\n  Lead Time for Changes:    42 minutes            \u2193 15% vs. last month\n  Change Failure Rate:      8%                    \u2192 (stable)\n  MTTR:                     22 minutes            \u2193 40% vs. last month\n\nDeveloper Satisfaction:\n  NPS Score:                +42                   \u2191 8 points\n  Most Loved Feature:       GitOps auto-deploy   (80% positive mentions)\n  Most Frustrating:         Vault secret rotation (30% negative mentions)\n\nPlatform Adoption:\n  Backstage Users:          220 / 250 devs (88%)\n  GitOps Enabled:           45 / 60 teams (75%)\n  Buildpacks Adoption:      50 / 60 teams (83%)\n\nSupport:\n  Tickets/Week:             12                    \u2193 40% vs. 3 months ago\n  Avg Resolution Time:      4.2 hours             \u2193 20%\n</code></pre> <p>What to Do With Data:</p> <p>If metrics improving: Double down, expand adoption If metrics flat: Investigate (wrong solution? Adoption barriers?) If metrics declining: Pivot or sunset the feature</p> <p>Example Decision Tree:</p> <pre><code>Feature: Buildpacks\nAdoption: 83% \u2705\nDORA Improvement: Lead time \u219325% \u2705\nSatisfaction: 72% positive \u2705\n\u2192 Decision: Make default for all new services\n\nFeature: Custom Helm Charts\nAdoption: 12% \u26a0\ufe0f\nDORA Improvement: Unclear (data insufficient) \u26a0\ufe0f\nSatisfaction: 40% say \"too complex\" \u274c\n\u2192 Decision: Deprecate in favor of Buildpacks\n</code></pre>"},{"location":"explanation/idp/product-discovery-delivery-flow/#the-platform-roadmap-continuous-discovery-and-delivery","title":"The Platform Roadmap: Continuous Discovery and Delivery","text":"<pre><code>gantt\n    title Fawkes Platform Roadmap (Example Quarter)\n    dateFormat  YYYY-MM-DD\n    section Discovery\n    Developer Interviews       :done,    disc1, 2024-10-01, 2w\n    Survey Deployment          :done,    disc2, 2024-10-15, 1w\n    Data Analysis              :active,  disc3, 2024-10-22, 1w\n\n    section Delivery\n    GitOps Auto-Deploy Alpha   :active,  del1, 2024-11-01, 3w\n    Vault Auto-Rotation Beta   :         del2, 2024-11-22, 4w\n    Backstage Templates GA     :         del3, 2024-12-20, 2w\n\n    section Measurement\n    DORA Metrics Dashboard     :done,    meas1, 2024-10-01, 12w\n    NPS Survey Monthly         :         meas2, 2024-11-01, 4w</code></pre> <p>Key Principles:</p> <ol> <li>Always in Discovery: Continuous conversations with developers</li> <li>Validate Before Building: Prototype first, scale later</li> <li>Measure Outcomes: Developer productivity, not feature count</li> <li>Iterate Ruthlessly: Kill features that don't work</li> </ol>"},{"location":"explanation/idp/product-discovery-delivery-flow/#trade-offs-product-discipline-vs-execution-speed","title":"Trade-Offs: Product Discipline vs. Execution Speed","text":""},{"location":"explanation/idp/product-discovery-delivery-flow/#what-ip3dp-gives-you","title":"What IP3dP Gives You","text":"Benefit Impact Build the Right Thing Solve actual problems, not imagined ones Higher Adoption Developers use features you validate with them Better Prioritization Focus on high-impact work, not loudest request Measurable Value Quantify platform impact on business outcomes Developer Trust Teams see you listen and respond to feedback"},{"location":"explanation/idp/product-discovery-delivery-flow/#what-ip3dp-costs-you","title":"What IP3dP Costs You","text":"Challenge Mitigation Slower Initial Delivery Discovery takes time before building. Mitigation: Better to ship right feature slowly than wrong feature fast Complexity User research, surveys, data analysis. Mitigation: Start small (10 interviews vs. 100), scale as you learn Saying \"No\" Can't build every request. Mitigation: Transparent prioritization (RICE scores public) Measurement Overhead Setting up metrics, analyzing results. Mitigation: DORA metrics automated, NPS surveys quarterly <p>The Bet: Spending 20% time on discovery prevents 80% waste on wrong features.</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#practical-examples-ip3dp-in-action","title":"Practical Examples: IP3dP in Action","text":""},{"location":"explanation/idp/product-discovery-delivery-flow/#case-study-1-the-kubernetes-dashboard-request","title":"Case Study 1: The \"Kubernetes Dashboard\" Request","text":"<p>Request: \"We need a Kubernetes dashboard so developers can see pods\"</p> <p>Traditional Approach: Install K8s Dashboard, grant access, done.</p> <p>IP3dP Approach:</p> <ol> <li>Discovery: Why do they need to see pods?</li> <li>Interview reveals: \"Want to know if my app is healthy\"</li> <li> <p>Real job-to-be-done: Monitor application health</p> </li> <li> <p>Prioritization: </p> </li> <li>Reach: All teams (200 devs)</li> <li>Impact: High (currently checking Slack or kubectl)</li> <li>Confidence: Medium (is Grafana better than K8s Dashboard?)</li> <li>Effort: 2 weeks</li> <li> <p>RICE: High priority</p> </li> <li> <p>Delivery:</p> </li> <li>Prototype: Grafana dashboard showing service SLIs (latency, error rate, throughput)</li> <li>Alpha: 5 teams test, feedback: \"This is what we actually need!\"</li> <li>Beta: Template for all services</li> <li> <p>GA: Auto-generated Grafana dashboard for every service</p> </li> <li> <p>Measurement:</p> </li> <li>Before: 30 <code>kubectl get pods</code> per developer per week</li> <li>After: 5 <code>kubectl get pods</code> per developer per week (\u219383%)</li> <li>NPS: +15 points for \"platform helps me understand app health\"</li> </ol> <p>Outcome: Built Grafana dashboards (right solution) instead of K8s Dashboard (requested solution).</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#case-study-2-the-faster-builds-problem","title":"Case Study 2: The \"Faster Builds\" Problem","text":"<p>Request: \"Our builds are too slow, need faster build servers\"</p> <p>Traditional Approach: Provision larger Jenkins agents, increase CPU/RAM.</p> <p>IP3dP Approach:</p> <ol> <li>Discovery: What makes builds slow?</li> <li>Data analysis: 70% of build time is <code>npm install</code> (Node.js dependency download)</li> <li> <p>50% of builds fetch identical dependencies (no caching)</p> </li> <li> <p>Prioritization:</p> </li> <li>Reach: 30 teams (Node.js services)</li> <li>Impact: Very high (40 min \u2192 8 min builds)</li> <li>Confidence: High (buildpack caching proven)</li> <li>Effort: 2 weeks</li> <li> <p>RICE: Highest priority</p> </li> <li> <p>Delivery:</p> </li> <li>Implement buildpack layer caching</li> <li>Alpha: 5 teams, validate caching works</li> <li> <p>Beta: Gradual rollout to all Node.js services</p> </li> <li> <p>Measurement:</p> </li> <li>Before: 40 min average build time</li> <li>After: 8 min average build time (\u219380%)</li> <li>DORA: Deployment frequency \u21913x (faster builds = more deploys)</li> </ol> <p>Outcome: Solved with caching, not more powerful servers (saved $50K/year in infrastructure).</p>"},{"location":"explanation/idp/product-discovery-delivery-flow/#related-reading","title":"Related Reading","text":"<ul> <li>ADR: ADR-020: Platform-as-Product Operating Model</li> <li>ADR: ADR-018: Developer Experience Measurement Framework (SPACE)</li> <li>ADR: ADR-019: User Research &amp; Feedback Collection System</li> <li>Tutorial: Module 17: Platform as Product</li> <li>Reference: SPACE Framework</li> <li>Reference: Team Topologies (Platform as Product)</li> </ul>"},{"location":"explanation/idp/product-discovery-delivery-flow/#conclusion","title":"Conclusion","text":"<p>Internal Platform \u2260 Just Infrastructure\u2014it's a product with developers as customers.</p> <p>The IP3dP framework (Product Discovery and Delivery Process) ensures you: 1. Discover real developer problems (not imagined ones) 2. Prioritize high-impact solutions (not every request) 3. Deliver iteratively (prototype \u2192 alpha \u2192 beta \u2192 GA) 4. Measure outcomes (productivity, satisfaction, DORA metrics)</p> <p>The Core Insight: Developers won't use a platform just because you built it. They'll use it if it solves their problems better than alternatives (including <code>kubectl</code>, manual processes, or shadow IT).</p> <p>The Commitment: Treat developers like customers. Listen, validate, measure, iterate.</p> <p>This is Platform as Product. This is IP3dP.</p>"},{"location":"explanation/observability/unified-telemetry/","title":"Unified Telemetry: The OpenTelemetry Standard","text":""},{"location":"explanation/observability/unified-telemetry/#context","title":"Context","text":"<p>Modern applications emit three types of telemetry data: - Metrics - Numeric measurements (CPU usage, request count, error rate) - Logs - Event records (application logs, audit logs) - Traces - Request flow across services (distributed tracing)</p> <p>Historically, each observability vendor provided its own agent to collect this data: - Datadog Agent (proprietary) - New Relic Agent (proprietary) - Dynatrace OneAgent (proprietary) - APM Insight (proprietary)</p> <p>The Problem: Vendor lock-in, duplication, and complexity.</p> <p>Fawkes adopted OpenTelemetry (OTel) as the single standard for telemetry collection, replacing vendor-specific agents. This document explains why OpenTelemetry is a strategic architectural decision, not just a tool choice.</p>"},{"location":"explanation/observability/unified-telemetry/#the-problem-vendor-agent-chaos","title":"The Problem: Vendor Agent Chaos","text":""},{"location":"explanation/observability/unified-telemetry/#the-old-world-one-agent-per-vendor","title":"The Old World: One Agent Per Vendor","text":"<pre><code>graph TB\n    A[Application Pod] --&gt; B[Datadog Agent]\n    A --&gt; C[New Relic Agent]\n    A --&gt; D[Prometheus Exporter]\n    A --&gt; E[Fluentd Sidecar]\n\n    B --&gt; F[Datadog Backend]\n    C --&gt; G[New Relic Backend]\n    D --&gt; H[Prometheus]\n    E --&gt; I[Elasticsearch]\n\n    style A fill:#ff6b6b</code></pre> <p>What's Wrong Here?</p> <ol> <li>Resource Duplication</li> <li>4 agents per pod = 4x memory/CPU overhead</li> <li>Each agent has its own buffer, config, credentials</li> <li> <p>Cost: 200-400MB RAM per pod just for agents</p> </li> <li> <p>Vendor Lock-In</p> </li> <li>Proprietary instrumentation libraries</li> <li>Can't switch backends without re-instrumenting code</li> <li> <p>Risk: Vendor pricing changes, service degradation, or shutdown</p> </li> <li> <p>Inconsistent Data</p> </li> <li>Each vendor collects slightly differently</li> <li>Metric names don't match across tools</li> <li> <p>Problem: \"Datadog shows 500 req/sec, but New Relic shows 520. Which is right?\"</p> </li> <li> <p>Configuration Sprawl</p> </li> <li>4 agents = 4 config files per service</li> <li>Updating sampling rate? Touch all 4 configs</li> <li> <p>Toil: Platform team maintains multiple agent configs</p> </li> <li> <p>Security Surface</p> </li> <li>Each agent needs credentials to its backend</li> <li>4 agents = 4 secret rotation processes</li> <li>Attack Surface: More agents = more potential vulnerabilities</li> </ol>"},{"location":"explanation/observability/unified-telemetry/#real-world-vendor-lock-in-example","title":"Real-World Vendor Lock-In Example","text":"<p>2019: Company X uses Datadog, instruments all apps with Datadog APM libraries</p> <p>2022: Datadog raises prices 40%. Company X evaluates alternatives.</p> <p>Discovery:  - 200 microservices instrumented with <code>dd-trace</code> library - Custom dashboards use Datadog-specific query language - Alerts depend on Datadog metric names - Estimated Migration Cost: 6 months, $500K+ engineering time</p> <p>Outcome: Stuck with Datadog despite cost increase (lock-in worked as designed)</p>"},{"location":"explanation/observability/unified-telemetry/#the-solution-opentelemetry-as-the-standard","title":"The Solution: OpenTelemetry as the Standard","text":""},{"location":"explanation/observability/unified-telemetry/#what-is-opentelemetry","title":"What is OpenTelemetry?","text":"<p>OpenTelemetry (OTel) is a vendor-neutral, open-source observability framework that provides: - Standardized APIs - Uniform way to instrument code - SDKs for all languages - Java, Python, Go, Node.js, .NET, Ruby, PHP, etc. - Automatic instrumentation - Zero-code instrumentation for frameworks - Collector - Vendor-agnostic telemetry pipeline - Export to any backend - Prometheus, Grafana, Datadog, Jaeger, etc.</p> <p>Created by: CNCF (merger of OpenTracing and OpenCensus) Status: CNCF Graduated (highest maturity) Backed by: Google, Microsoft, AWS, Splunk, Datadog, New Relic, etc.</p> <p>The Key Insight: Get vendors to agree on a standard, then compete on backends, not agents.</p>"},{"location":"explanation/observability/unified-telemetry/#the-opentelemetry-architecture","title":"The OpenTelemetry Architecture","text":"<pre><code>graph TB\n    A[Application Code] --&gt;|OTel SDK| B[OTel Collector]\n    B --&gt; C[Prometheus]\n    B --&gt; D[Grafana Tempo]\n    B --&gt; E[Loki]\n    B --&gt; F[Optional: Datadog]\n    B --&gt; G[Optional: New Relic]\n\n    style B fill:#4CAF50\n    style C fill:#2196F3\n    style D fill:#2196F3\n    style E fill:#2196F3</code></pre> <p>How It Works:</p> <ol> <li>Instrument Once</li> <li>App uses OTel SDK (vendor-neutral)</li> <li> <p>Emits metrics, logs, traces in OTLP format (OpenTelemetry Protocol)</p> </li> <li> <p>Centralized Collection</p> </li> <li>OTel Collector receives all telemetry</li> <li> <p>Runs as DaemonSet (one per node) or sidecar</p> </li> <li> <p>Flexible Export</p> </li> <li>Collector transforms and forwards to backends</li> <li>Want to switch from Datadog to Prometheus? Change collector config, not app code</li> <li>Want to send to multiple backends? Configure multiple exporters</li> </ol> <p>Benefits: - \u2705 Single agent - OTel Collector replaces all vendor agents - \u2705 No vendor lock-in - Switch backends without code changes - \u2705 Consistent data - Same telemetry regardless of backend - \u2705 Future-proof - Industry standard, not vendor-specific</p>"},{"location":"explanation/observability/unified-telemetry/#fawkes-telemetry-stack","title":"Fawkes Telemetry Stack","text":"<p>Metrics: Prometheus (via OTel Collector) Logs: Loki (via OTel Collector) Traces: Grafana Tempo (via OTel Collector) Visualization: Grafana (unified dashboard)</p> <p>All data flows through OTel Collector: <pre><code># OTel Collector config\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:4317\n      http:\n        endpoint: 0.0.0.0:4318\n\nprocessors:\n  batch:\n    timeout: 10s\n    send_batch_size: 1024\n\n  # Remove sensitive data\n  attributes:\n    actions:\n      - key: password\n        action: delete\n      - key: token\n        action: delete\n\nexporters:\n  prometheus:\n    endpoint: \"prometheus:9090\"\n\n  otlp/tempo:\n    endpoint: \"tempo:4317\"\n    tls:\n      insecure: false\n\n  loki:\n    endpoint: \"http://loki:3100/loki/api/v1/push\"\n\nservice:\n  pipelines:\n    metrics:\n      receivers: [otlp]\n      processors: [batch, attributes]\n      exporters: [prometheus]\n\n    traces:\n      receivers: [otlp]\n      processors: [batch, attributes]\n      exporters: [otlp/tempo]\n\n    logs:\n      receivers: [otlp]\n      processors: [batch, attributes]\n      exporters: [loki]\n</code></pre></p> <p>Effect: Single configuration controls all telemetry routing.</p>"},{"location":"explanation/observability/unified-telemetry/#trade-offs-standardization-vs-vendor-features","title":"Trade-Offs: Standardization vs. Vendor Features","text":""},{"location":"explanation/observability/unified-telemetry/#what-opentelemetry-gives-you","title":"What OpenTelemetry Gives You","text":"Benefit Impact Vendor Neutrality Switch backends without re-instrumenting code Cost Control Evaluate vendors on backend merit, not ecosystem lock-in Single Agent Reduce resource overhead by 50-75% (1 collector vs. 4 agents) Consistent Data Model Metrics/logs/traces use same attributes, same naming Community Support CNCF backing means long-term sustainability Auto-Instrumentation Zero-code instrumentation for popular frameworks Cross-Cloud Works on AWS, Azure, GCP, on-prem identically"},{"location":"explanation/observability/unified-telemetry/#what-opentelemetry-costs-you","title":"What OpenTelemetry Costs You","text":"Challenge Mitigation Missing Vendor Features Vendor agents have proprietary features (e.g., Datadog Live Profiling). Mitigation: Use OTel for core observability, add vendor agent only for specific features if justified Configuration Complexity OTel Collector config can be verbose. Mitigation: Fawkes provides templates and Helm charts for common patterns Learning Curve New standard to learn vs. familiar vendor tools. Mitigation: Dojo Module 13: Observability covers OTel Maturity Gaps Some language SDKs less mature than vendor equivalents. Mitigation: Java, Go, Python, Node.js are production-ready (Fawkes primary languages) Backend Performance Prometheus/Tempo/Loki may not match Datadog polish initially. Mitigation: Acceptable trade-off for avoiding lock-in; Grafana ecosystem rapidly improving"},{"location":"explanation/observability/unified-telemetry/#when-to-use-vendor-agents-anyway","title":"When to Use Vendor Agents Anyway","text":"<p>OpenTelemetry is the default, but vendor agents allowed for specific use cases:</p> <p>Use OTel When (90% of cases): - \u2705 Standard metrics, logs, traces - \u2705 Application performance monitoring - \u2705 Distributed tracing - \u2705 Custom instrumentation</p> <p>Use Vendor Agent When: - \u26a0\ufe0f Need proprietary features (e.g., Datadog Real User Monitoring, synthetic tests) - \u26a0\ufe0f Backend vendor requires their agent for full functionality - \u26a0\ufe0f Compliance/legal requirement mandates specific vendor</p> <p>Hybrid Approach: Run OTel Collector for core telemetry, add vendor sidecar only where needed.</p>"},{"location":"explanation/observability/unified-telemetry/#practical-implications","title":"Practical Implications","text":""},{"location":"explanation/observability/unified-telemetry/#for-developers","title":"For Developers","text":"<p>Q: How do I instrument my application?</p> <p>A: Auto-Instrumentation (Preferred)</p> <p>Most frameworks supported automatically:</p> <p>Java (Spring Boot, Quarkus, Micronaut): <pre><code># Download OTel Java agent\ncurl -L https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar -o agent.jar\n\n# Run app with agent\njava -javaagent:agent.jar \\\n  -Dotel.service.name=my-service \\\n  -Dotel.exporter.otlp.endpoint=http://otel-collector:4317 \\\n  -jar app.jar\n</code></pre></p> <p>Node.js (Express, Fastify, NestJS): <pre><code>// tracing.js\nconst { NodeSDK } = require('@opentelemetry/sdk-node');\nconst { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');\nconst { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-grpc');\n\nconst sdk = new NodeSDK({\n  serviceName: 'my-service',\n  traceExporter: new OTLPTraceExporter({\n    url: 'http://otel-collector:4317'\n  }),\n  instrumentations: [getNodeAutoInstrumentations()]\n});\n\nsdk.start();\n</code></pre></p> <p>Python (Flask, Django, FastAPI): <pre><code># Install OTel packages\npip install opentelemetry-distro opentelemetry-exporter-otlp\n\n# Auto-instrument\nopentelemetry-bootstrap -a install\n\n# Run with instrumentation\nopentelemetry-instrument \\\n  --service_name=my-service \\\n  --exporter_otlp_endpoint=http://otel-collector:4317 \\\n  python app.py\n</code></pre></p> <p>No code changes required! Framework calls automatically traced.</p> <p>Q: What if I need custom spans?</p> <p>A: Manual Instrumentation</p> <pre><code>from opentelemetry import trace\n\ntracer = trace.get_tracer(__name__)\n\ndef process_order(order_id):\n    with tracer.start_as_current_span(\"process_order\") as span:\n        span.set_attribute(\"order.id\", order_id)\n        span.set_attribute(\"order.amount\", order.total)\n\n        # Business logic\n        validate_order(order_id)\n        charge_payment(order_id)\n        ship_order(order_id)\n\n        span.set_attribute(\"order.status\", \"completed\")\n</code></pre> <p>Result: Custom span appears in Grafana Tempo with attributes.</p>"},{"location":"explanation/observability/unified-telemetry/#for-platform-engineers","title":"For Platform Engineers","text":"<p>Q: How do I deploy the OTel Collector?</p> <p>A: DaemonSet (Recommended)</p> <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: otel-collector\n  namespace: observability\nspec:\n  selector:\n    matchLabels:\n      app: otel-collector\n  template:\n    metadata:\n      labels:\n        app: otel-collector\n    spec:\n      containers:\n        - name: otel-collector\n          image: otel/opentelemetry-collector-contrib:0.88.0\n          ports:\n            - containerPort: 4317  # OTLP gRPC\n            - containerPort: 4318  # OTLP HTTP\n          volumeMounts:\n            - name: config\n              mountPath: /etc/otel\n          resources:\n            requests:\n              cpu: 100m\n              memory: 128Mi\n            limits:\n              cpu: 500m\n              memory: 512Mi\n      volumes:\n        - name: config\n          configMap:\n            name: otel-collector-config\n</code></pre> <p>Q: How do I handle high cardinality?</p> <p>A: Sampling and Aggregation</p> <pre><code># Tail-based sampling (keep interesting traces)\nprocessors:\n  tail_sampling:\n    policies:\n      - name: errors\n        type: status_code\n        status_code:\n          status_codes: [ERROR]\n\n      - name: slow-requests\n        type: latency\n        latency:\n          threshold_ms: 1000\n\n      - name: probabilistic\n        type: probabilistic\n        probabilistic:\n          sampling_percentage: 10\n</code></pre> <p>Effect: Keep 100% of errors/slow requests, sample 10% of fast successful requests.</p>"},{"location":"explanation/observability/unified-telemetry/#for-consultants","title":"For Consultants","text":"<p>Client Question: \"Why not just use Datadog/New Relic? It's easier.\"</p> <p>Response:</p> <ol> <li>Short-Term vs. Long-Term</li> <li>Short-Term: Vendor agent easier (pre-built dashboards, support)</li> <li> <p>Long-Term: Vendor lock-in, pricing pressure, limited flexibility</p> </li> <li> <p>Cost Control</p> </li> <li>Datadog pricing: $15-31/host/month + $1.27/million spans</li> <li>100 hosts, 10M spans/day = $50K+/year</li> <li> <p>OTel + Grafana Cloud: $0-8K/year (or self-hosted = $0)</p> </li> <li> <p>Strategic Flexibility</p> </li> <li>Want to switch vendors? OTel makes it a config change</li> <li>Vendor raises prices? No re-instrumentation needed</li> <li> <p>Multi-cloud? Same telemetry stack everywhere</p> </li> <li> <p>Industry Momentum</p> </li> <li>CNCF Graduated, backed by all major vendors</li> <li>Even Datadog supports OTel (they know it's the future)</li> </ol> <p>Analogy: \"Would you write SQL queries in Oracle PL/SQL or ANSI SQL? ANSI SQL works across databases. OTel is the ANSI SQL of observability.\"</p> <p>Objection Handling: - \"OTel is immature\" \u2192 Graduated project, 100+ companies contributing - \"We lose vendor features\" \u2192 Hybrid approach: OTel + vendor agent only where needed - \"Our team knows Datadog\" \u2192 Training investment pays off via flexibility</p>"},{"location":"explanation/observability/unified-telemetry/#historical-context-from-vendor-agents-to-otel","title":"Historical Context: From Vendor Agents to OTel","text":""},{"location":"explanation/observability/unified-telemetry/#fawkes-10-2022-prometheus-vendor-sprawl","title":"Fawkes 1.0 (2022): Prometheus + Vendor Sprawl","text":"<p>Metrics: Prometheus exporters (custom per service) Logs: Fluentd + Elasticsearch Traces: Jaeger (limited adoption)</p> <p>Problems: - Developers didn't instrument traces (too complex) - Logs disconnected from metrics/traces - No unified view of system state - MTTR: High (couldn't correlate data across tools)</p>"},{"location":"explanation/observability/unified-telemetry/#fawkes-20-2023-opentelemetry-adoption","title":"Fawkes 2.0 (2023): OpenTelemetry Adoption","text":"<p>Decision: Bet on OpenTelemetry as standard</p> <p>Migration: 1. Deploy OTel Collector (DaemonSet) 2. Auto-instrument new services with OTel SDKs 3. Migrate existing services incrementally 4. Sunset Jaeger, direct Prometheus exporters</p> <p>Results: - Unified data model: Metrics, logs, traces use same attributes - Correlation: Trace ID in logs, link from Grafana to Tempo - Developer adoption: Auto-instrumentation = zero friction - MTTR: \u2b07\ufe0f 40% (faster root cause analysis) - Cost: \u2b07\ufe0f $30K/year (avoided Datadog expansion)</p>"},{"location":"explanation/observability/unified-telemetry/#fawkes-30-2024-present-grafana-lgtm-stack","title":"Fawkes 3.0 (2024-Present): Grafana LGTM Stack","text":"<p>Full Observability Stack: - Loki (Logs) - Grafana (Visualization) - Tempo (Traces) - Mimir/Prometheus (Metrics)</p> <p>All powered by OTel Collector as the telemetry ingestion layer.</p>"},{"location":"explanation/observability/unified-telemetry/#the-mental-model-otel-as-the-telemetry-layer","title":"The Mental Model: OTel as the Telemetry Layer","text":"<p>Think of OpenTelemetry like the OSI Network Model:</p> Layer Network Model Telemetry Model Application HTTP, gRPC Business Logic Presentation TLS, Compression OTel SDK (instrumentation) Session Authentication Trace Context Propagation Transport TCP, UDP OTel Collector (routing, batching) Network IP OTLP Protocol Data Link Ethernet Backend Protocol (Prometheus, Tempo) Physical Cables Storage (Prometheus TSDB, Tempo blocks) <p>Key Insight: You don't write TCP socket code to make HTTP requests\u2014you use a library. Similarly, you don't use vendor-specific agents\u2014you use OTel SDK and let the collector handle backend details.</p> <p>This is abstraction working as intended.</p>"},{"location":"explanation/observability/unified-telemetry/#related-reading","title":"Related Reading","text":"<ul> <li>How-To: Trace Requests with Tempo</li> <li>How-To: View DORA Metrics</li> <li>ADR: ADR-013: Distributed Tracing</li> <li>ADR: ADR-011: Centralized Log Management</li> <li>ADR: ADR-012: Metrics Monitoring</li> <li>Tutorial: Module 13: Observability</li> <li>Reference: OpenTelemetry Documentation</li> </ul>"},{"location":"explanation/observability/unified-telemetry/#conclusion","title":"Conclusion","text":"<p>OpenTelemetry is not just a tool\u2014it's a strategic architectural decision that prevents vendor lock-in while enabling world-class observability.</p> <p>The Core Principle: Instrument once with a vendor-neutral standard, then send telemetry to any backend. This gives you: - Flexibility: Switch backends without code changes - Cost Control: Vendors compete on backend quality, not ecosystem lock-in - Future-Proofing: Industry standard, backed by CNCF and all major vendors - Simplicity: One agent (OTel Collector) instead of many vendor agents</p> <p>The Trade-Off: You may lose some proprietary vendor features, but you gain strategic independence. For Fawkes, that's the right trade.</p> <p>The Future: As Datadog, New Relic, and others adopt OTel (they already are), the ecosystem converges on the standard. Choosing OTel today means you're ahead of the curve, not behind it.</p> <p>Unified Telemetry = OpenTelemetry. This is the way.</p>"},{"location":"explanation/security/zero-trust-model/","title":"Zero Trust Security Model: Never Trust, Always Verify","text":""},{"location":"explanation/security/zero-trust-model/#context","title":"Context","text":"<p>Traditional security models operate on the perimeter defense principle: hard outer shell (firewall), soft interior (trusted network). Once you're inside the network, you're trusted. This worked when datacenters had literal walls and employees sat in offices.</p> <p>But modern cloud-native applications break these assumptions: - No perimeter - Services span multiple clouds, regions, networks - Ephemeral workloads - Containers are created and destroyed constantly - Lateral movement - A compromised pod can talk to others on the same network - Supply chain attacks - Third-party dependencies could be malicious</p> <p>The solution is Zero Trust Architecture: assume breach, verify everything, and grant least-privilege access at every layer.</p> <p>Fawkes implements Zero Trust through the integration of three key components: - HashiCorp Vault - Secrets management and identity - Kyverno - Policy-as-Code enforcement - Istio/Ingress - Network policy and mTLS</p> <p>This document explains how these pieces work together to create defense in depth.</p>"},{"location":"explanation/security/zero-trust-model/#the-problem-trust-based-security-fails-in-kubernetes","title":"The Problem: Trust-Based Security Fails in Kubernetes","text":""},{"location":"explanation/security/zero-trust-model/#the-traditional-trust-the-network-approach","title":"The Traditional \"Trust the Network\" Approach","text":"<p>In legacy architectures: <pre><code>Internet \u2192 Firewall \u2192 Internal Network (Trusted Zone)\n</code></pre></p> <p>Inside the firewall: - Services communicate over HTTP (no encryption) - Authentication is often \"source IP\" or \"same VLAN\" - Secrets stored in environment variables or config files - Policies enforced at deploy time (if at all)</p> <p>What Could Go Wrong?</p> <pre><code>graph TB\n    A[Compromised App Pod] --&gt;|No network policy| B[Database Pod]\n    A --&gt;|No network policy| C[Secret Store]\n    A --&gt;|No network policy| D[Other App Pods]\n\n    style A fill:#ff6b6b</code></pre> <ol> <li>Lateral Movement: Compromised pod accesses database directly</li> <li>Secret Sprawl: Environment variables visible in <code>kubectl describe pod</code></li> <li>No Audit Trail: Who accessed what secret? Unknown.</li> <li>Static Credentials: Secrets rotate manually (if ever)</li> <li>Policy Drift: Deployed configuration diverges from security requirements</li> </ol>"},{"location":"explanation/security/zero-trust-model/#real-world-attack-scenario","title":"Real-World Attack Scenario","text":"<p>Day 1: Developer deploys app with a vulnerable dependency (Log4Shell, typo-squatting, etc.)</p> <p>Day 2: Attacker exploits vulnerability, gains remote code execution in pod</p> <p>Day 3: Attacker pivots: <pre><code># From inside compromised pod\ncurl http://database:5432  # No network policy blocks this\nenv | grep DB_PASSWORD     # Secrets in environment variables\nkubectl get secrets -n prod  # Service account has excessive permissions\n</code></pre></p> <p>Day 4: Attacker exfiltrates customer data, deploys cryptominer, pivots to other clusters</p> <p>Time to Detect: Days to weeks Blast Radius: Entire cluster potentially compromised</p>"},{"location":"explanation/security/zero-trust-model/#the-solution-layered-zero-trust-defense","title":"The Solution: Layered Zero Trust Defense","text":"<p>Fawkes implements defense in depth with multiple verification layers:</p> <pre><code>graph TB\n    A[Incoming Request] --&gt;|1. TLS Termination| B[Ingress/Istio]\n    B --&gt;|2. Identity Verification| C[mTLS Between Services]\n    C --&gt;|3. Policy Check| D[Kyverno Admission]\n    D --&gt;|4. Secret Injection| E[Vault Agent]\n    E --&gt;|5. Application| F[Pod]\n\n    style B fill:#2196F3\n    style D fill:#FF9800\n    style E fill:#4CAF50</code></pre>"},{"location":"explanation/security/zero-trust-model/#layer-1-network-security-with-istioingress","title":"Layer 1: Network Security with Istio/Ingress","text":"<p>Principle: Encrypted transport, verified identity</p>"},{"location":"explanation/security/zero-trust-model/#ingress-controller-external-traffic","title":"Ingress Controller (External Traffic)","text":"<p>Purpose: TLS termination for traffic entering the cluster</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: api-ingress\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nspec:\n  tls:\n    - hosts:\n        - api.fawkes.io\n      secretName: api-tls\n  rules:\n    - host: api.fawkes.io\n      http:\n        paths:\n          - path: /\n            backend:\n              service:\n                name: api-service\n                port:\n                  number: 8080\n</code></pre> <p>What This Provides: - \u2705 Encryption in transit - HTTPS for all external traffic - \u2705 Certificate management - Cert-manager automates TLS renewal - \u2705 SNI routing - Multiple services, one load balancer - \u2705 DDoS mitigation - Rate limiting, WAF integration (if enabled)</p>"},{"location":"explanation/security/zero-trust-model/#istio-service-mesh-internal-traffic","title":"Istio Service Mesh (Internal Traffic)","text":"<p>Purpose: Mutual TLS (mTLS) for pod-to-pod communication</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: production\nspec:\n  mtls:\n    mode: STRICT  # Require mTLS for all traffic\n</code></pre> <p>What This Provides: - \u2705 Zero trust networking - Pods authenticate to each other via certificates - \u2705 Encrypted service mesh - Even inside the cluster, traffic is encrypted - \u2705 Identity-based access - Authorization based on service identity, not IP - \u2705 Observability - Istio traces every request (distributed tracing)</p> <p>Example AuthorizationPolicy: <pre><code>apiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: api-to-database\n  namespace: production\nspec:\n  selector:\n    matchLabels:\n      app: postgres\n  action: ALLOW\n  rules:\n    - from:\n        - source:\n            principals: [\"cluster.local/ns/production/sa/api-service\"]\n      to:\n        - operation:\n            ports: [\"5432\"]\n</code></pre></p> <p>Translation: Only the <code>api-service</code> service account can connect to Postgres port 5432. Everything else denied.</p>"},{"location":"explanation/security/zero-trust-model/#layer-2-policy-enforcement-with-kyverno","title":"Layer 2: Policy Enforcement with Kyverno","text":"<p>Principle: Prevent bad configurations from ever being deployed</p> <p>Kyverno is a Kubernetes-native policy engine that validates, mutates, and generates resources based on policy rules.</p>"},{"location":"explanation/security/zero-trust-model/#policy-types","title":"Policy Types","text":"<p>1. Validation Policies (Block Bad Configs)</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-non-root\nspec:\n  validationFailureAction: Enforce  # Block deployment if violated\n  rules:\n    - name: check-containers-non-root\n      match:\n        any:\n          - resources:\n              kinds:\n                - Pod\n      validate:\n        message: \"Containers must not run as root\"\n        pattern:\n          spec:\n            containers:\n              - securityContext:\n                  runAsNonRoot: true\n</code></pre> <p>Effect: Pods running as root are rejected at admission time.</p> <p>2. Mutation Policies (Auto-Fix Configs)</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: add-security-context\nspec:\n  rules:\n    - name: add-safe-security-context\n      match:\n        any:\n          - resources:\n              kinds:\n                - Pod\n      mutate:\n        patchStrategicMerge:\n          spec:\n            securityContext:\n              runAsNonRoot: true\n              runAsUser: 1000\n              fsGroup: 2000\n              seccompProfile:\n                type: RuntimeDefault\n</code></pre> <p>Effect: Even if developer forgets, security context is automatically added.</p> <p>3. Generation Policies (Auto-Create Resources)</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: generate-network-policy\nspec:\n  rules:\n    - name: default-deny-ingress\n      match:\n        any:\n          - resources:\n              kinds:\n                - Namespace\n      generate:\n        kind: NetworkPolicy\n        name: default-deny-ingress\n        namespace: \"{{request.object.metadata.name}}\"\n        data:\n          spec:\n            podSelector: {}\n            policyTypes:\n              - Ingress\n</code></pre> <p>Effect: Every new namespace automatically gets a default-deny network policy.</p>"},{"location":"explanation/security/zero-trust-model/#audit-vs-enforce-modes","title":"Audit vs. Enforce Modes","text":"<p>Kyverno supports two enforcement modes:</p> Mode Behavior Use Case Enforce Block non-compliant resources Production environments, critical policies Audit Allow but log violations Testing new policies, gradual rollout <p>Fawkes Approach: 1. Phase 1 (Audit): Deploy policy in audit mode, observe violations 2. Phase 2 (Remediation): Work with teams to fix violations 3. Phase 3 (Enforce): Switch to enforce mode, block new violations</p> <p>Example Policy Report: <pre><code>apiVersion: wgpolicyk8s.io/v1alpha2\nkind: PolicyReport\nmetadata:\n  name: polr-ns-production\n  namespace: production\nresults:\n  - policy: require-non-root\n    rule: check-containers-non-root\n    result: fail\n    resources:\n      - apiVersion: v1\n        kind: Pod\n        name: legacy-app-pod-123\n        namespace: production\n    message: \"Container 'app' runs as root user\"\n</code></pre></p> <p>Visibility: Platform team sees violations, can track compliance over time.</p>"},{"location":"explanation/security/zero-trust-model/#layer-3-secrets-management-with-vault","title":"Layer 3: Secrets Management with Vault","text":"<p>Principle: Secrets are ephemeral, dynamically generated, and audited</p>"},{"location":"explanation/security/zero-trust-model/#the-problem-with-kubernetes-secrets","title":"The Problem with Kubernetes Secrets","text":"<p>Native Kubernetes Secrets are not secret: - Stored base64-encoded (not encrypted) in etcd - Visible to anyone with <code>get secrets</code> permission - Static (no automatic rotation) - No audit trail (who read the secret?)</p>"},{"location":"explanation/security/zero-trust-model/#vaults-solution","title":"Vault's Solution","text":"<p>HashiCorp Vault is a secrets management platform that provides: - Encryption at rest - Secrets encrypted in storage backend - Dynamic secrets - Generated on-demand, short-lived - Audit logging - Every secret access logged - Access policies - Fine-grained RBAC - Automatic rotation - Secrets rotated automatically</p>"},{"location":"explanation/security/zero-trust-model/#integration-pattern-vault-agent-sidecar","title":"Integration Pattern: Vault Agent Sidecar","text":"<p>Option 1: Vault Agent Injector (Recommended)</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: api-pod\n  annotations:\n    vault.hashicorp.com/agent-inject: \"true\"\n    vault.hashicorp.com/role: \"api-service\"\n    vault.hashicorp.com/agent-inject-secret-database: \"secret/data/database\"\n    vault.hashicorp.com/agent-inject-template-database: |\n      {{- with secret \"secret/data/database\" -}}\n      DB_HOST={{ .Data.data.host }}\n      DB_USER={{ .Data.data.username }}\n      DB_PASS={{ .Data.data.password }}\n      {{- end }}\nspec:\n  serviceAccountName: api-service\n  containers:\n    - name: api\n      image: fawkes/api:v1.2.3\n      # Secrets injected at /vault/secrets/database\n</code></pre> <p>What Happens: 1. Vault Agent sidecar injected - Runs alongside app container 2. Kubernetes auth - Vault verifies pod's service account 3. Secret retrieval - Agent fetches secrets from Vault 4. File injection - Secrets written to shared volume at <code>/vault/secrets/</code> 5. Automatic renewal - Agent refreshes secrets before expiration</p> <p>Benefits: - \u2705 No secrets in environment variables - Hidden from <code>kubectl describe</code> - \u2705 No code changes - App reads from file like config - \u2705 Automatic rotation - Agent handles renewal - \u2705 Audit trail - Vault logs every access</p> <p>Option 2: External Secrets Operator</p> <p>For teams preferring Kubernetes-native pattern:</p> <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: database-secret\n  namespace: production\nspec:\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: database-secret\n  data:\n    - secretKey: username\n      remoteRef:\n        key: secret/data/database\n        property: username\n    - secretKey: password\n      remoteRef:\n        key: secret/data/database\n        property: password\n</code></pre> <p>Effect: Kubernetes Secret created/updated automatically from Vault.</p>"},{"location":"explanation/security/zero-trust-model/#dynamic-database-credentials","title":"Dynamic Database Credentials","text":"<p>The Ultimate Secret Management:</p> <pre><code># Vault configuration\nvault write database/config/postgres \\\n  plugin_name=postgresql-database-plugin \\\n  allowed_roles=\"api-role\" \\\n  connection_url=\"postgresql://{{username}}:{{password}}@postgres:5432/production\"\n\nvault write database/roles/api-role \\\n  db_name=postgres \\\n  creation_statements=\"CREATE ROLE \\\"{{name}}\\\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}'; GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO \\\"{{name}}\\\";\" \\\n  default_ttl=\"1h\" \\\n  max_ttl=\"24h\"\n</code></pre> <p>What This Enables: - Vault generates unique database credentials per application - Credentials expire after 1 hour (auto-rotated by Vault Agent) - If pod compromised, credentials useless after 1 hour - No shared passwords - Each pod gets unique creds - Audit trail - Know which pod accessed database at what time</p> <p>Time-Limited Blast Radius: Compromised credentials valid for max 1 hour, not indefinitely.</p>"},{"location":"explanation/security/zero-trust-model/#how-the-layers-work-together","title":"How the Layers Work Together","text":""},{"location":"explanation/security/zero-trust-model/#scenario-deploying-a-new-api-service","title":"Scenario: Deploying a New API Service","text":"<p>Step 1: Developer creates manifest</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api\n  namespace: production\nspec:\n  template:\n    metadata:\n      annotations:\n        vault.hashicorp.com/agent-inject: \"true\"\n        vault.hashicorp.com/role: \"api\"\n    spec:\n      serviceAccountName: api\n      containers:\n        - name: api\n          image: fawkes/api:v2.0.0\n          ports:\n            - containerPort: 8080\n</code></pre> <p>Step 2: Kyverno validates</p> <ul> <li>\u2705 Non-root user - <code>runAsNonRoot: true</code> (mutated if missing)</li> <li>\u2705 Resource limits - Memory/CPU limits set (mutated if missing)</li> <li>\u2705 No privileged escalation - <code>allowPrivilegeEscalation: false</code> enforced</li> <li>\u2705 Image from approved registry - Not from Docker Hub public repos</li> <li>\u2705 Service account exists - <code>api</code> service account present</li> <li>\u26d4 Violations rejected - If any policy fails, deployment blocked</li> </ul> <p>Step 3: Pod created with Vault injection</p> <ul> <li>Vault Agent sidecar automatically injected</li> <li>Agent authenticates to Vault using service account token</li> <li>Secrets fetched from Vault and written to <code>/vault/secrets/</code></li> </ul> <p>Step 4: Network policy enforced</p> <ul> <li>Istio injects Envoy sidecar</li> <li>mTLS established between api pod and dependencies</li> <li>AuthorizationPolicy enforces \"api can only talk to postgres and redis\"</li> </ul> <p>Step 5: Ingress exposes service</p> <ul> <li>TLS certificate issued by cert-manager (Let's Encrypt)</li> <li>External traffic encrypted via HTTPS</li> <li>Internal traffic encrypted via mTLS</li> </ul> <p>Security Layers Active: 1. \u2705 Ingress - TLS encryption for external traffic 2. \u2705 Istio - mTLS for internal service-to-service 3. \u2705 Kyverno - Policy validation (non-root, resource limits, etc.) 4. \u2705 Vault - Dynamic secrets with audit trail 5. \u2705 Network Policy - Least privilege network access</p>"},{"location":"explanation/security/zero-trust-model/#scenario-compromised-pod-defense-in-depth","title":"Scenario: Compromised Pod (Defense in Depth)","text":"<p>Attacker gains code execution in <code>api</code> pod:</p> <p>Attack 1: Lateral movement to database <pre><code>curl http://postgres:5432\n</code></pre> \u274c Blocked: Istio AuthorizationPolicy requires mTLS with <code>api</code> service identity. Attacker can't forge certificate.</p> <p>Attack 2: Steal secrets from environment <pre><code>env | grep PASSWORD\n</code></pre> \u274c Mitigated: No secrets in environment variables. Secrets in <code>/vault/secrets/</code> (but still accessible if pod compromised).</p> <p>Attack 3: Read secrets from Vault directly <pre><code>export VAULT_ADDR=http://vault:8200\nvault read secret/data/database\n</code></pre> \u274c Blocked: Vault requires service account token. Attacker's manual <code>vault</code> CLI doesn't have token (Vault Agent does, but Agent is separate container).</p> <p>Attack 4: Pivot to other namespaces <pre><code>kubectl get pods -n other-namespace\n</code></pre> \u274c Blocked: Service account has RBAC limited to own namespace. No cross-namespace access.</p> <p>Attack 5: Deploy malicious pod <pre><code>kubectl run evil-pod --image=attacker/cryptominer\n</code></pre> \u274c Blocked: Kyverno policy rejects images from unapproved registries. Admission denied.</p> <p>Attack 6: Exfiltrate data from accessible database <pre><code># Assume attacker accesses DB using app's connection\nSELECT * FROM customers;\n</code></pre> \u2705 Possible: If app has database access, attacker can read data the app can read.</p> <p>Mitigation: - Least privilege DB credentials (Vault dynamic secrets give minimal permissions) - Audit logging (Vault logs all secret access; know which pod at what time) - Incident response (Revoke Vault credentials for compromised pod, rotate dynamic secrets)</p> <p>Blast Radius: Limited to what the <code>api</code> service legitimately needs. Can't pivot to other services or namespaces.</p>"},{"location":"explanation/security/zero-trust-model/#trade-offs-security-vs-complexity","title":"Trade-Offs: Security vs. Complexity","text":""},{"location":"explanation/security/zero-trust-model/#what-zero-trust-gives-you","title":"What Zero Trust Gives You","text":"Benefit Explanation Minimized Blast Radius Compromised pod can't pivot to other services Audit Trail Vault logs every secret access; Istio logs every request Defense in Depth Multiple layers must fail for breach to succeed Compliance Encryption, RBAC, audit logs satisfy SOC2, PCI-DSS, HIPAA Time-Limited Exposure Dynamic secrets expire; compromised creds short-lived Policy Enforcement Security policies enforced automatically, not via docs/training"},{"location":"explanation/security/zero-trust-model/#what-zero-trust-costs-you","title":"What Zero Trust Costs You","text":"Challenge Mitigation Complexity More components (Vault, Kyverno, Istio) to learn and maintain. Mitigation: Fawkes Dojo has Zero Trust module Operational Overhead Vault HA, secret rotation, policy management. Mitigation: Automated via GitOps; platform team handles Debugging Difficulty mTLS/network policies can block legitimate traffic during troubleshooting. Mitigation: Troubleshooting guides and <code>istioctl</code> debugging tools Performance Impact mTLS encryption adds latency (~1-5ms per hop). Mitigation: Acceptable for security gain; not noticeable in most apps Policy Authoring Writing Kyverno policies requires Kubernetes knowledge. Mitigation: Fawkes provides library of common policies"},{"location":"explanation/security/zero-trust-model/#when-to-relax-zero-trust","title":"When to Relax Zero Trust","text":"<p>Not every environment needs fortress-level security:</p> Environment Security Posture Rationale Production \u2705 Full Zero Trust Customer data, compliance requirements Staging \u26a0\ufe0f Relaxed (audit mode) Test policies before enforcing Development \u26a0\ufe0f Minimal Developer velocity &gt; security (no real data) Local (Kind/Minikube) \u274c Disabled Avoid complexity on laptop <p>Fawkes Approach: Security policies applied per environment via Kustomize overlays.</p>"},{"location":"explanation/security/zero-trust-model/#governance-audit-vs-enforce-tiers","title":"Governance: Audit vs. Enforce Tiers","text":"<p>Kyverno's audit mode enables gradual security adoption:</p>"},{"location":"explanation/security/zero-trust-model/#tier-1-critical-enforce","title":"Tier 1: Critical (Enforce)","text":"<p>Policies that prevent immediate security incidents:</p> <ul> <li>\u274c No privileged containers - Block root access, privilege escalation</li> <li>\u274c No host network/PID namespaces - Prevent container breakout</li> <li>\u274c Images from approved registries - Block public Docker Hub</li> <li>\u274c Required security contexts - Non-root user, read-only filesystem</li> </ul> <p>Effect: Deployment blocked if violated.</p>"},{"location":"explanation/security/zero-trust-model/#tier-2-important-audit-enforce","title":"Tier 2: Important (Audit \u2192 Enforce)","text":"<p>Policies that improve security posture but allow migration time:</p> <ul> <li>\u26a0\ufe0f Resource limits required - Prevent resource exhaustion</li> <li>\u26a0\ufe0f Liveness/readiness probes - Improve reliability</li> <li>\u26a0\ufe0f No latest tag - Require specific version tags</li> <li>\u26a0\ufe0f Secrets via Vault - Not Kubernetes Secrets</li> </ul> <p>Rollout: 1. Month 1: Audit mode (log violations, don't block) 2. Month 2: Notify teams of violations, provide guidance 3. Month 3: Enforce mode (block non-compliant deployments)</p>"},{"location":"explanation/security/zero-trust-model/#tier-3-best-practice-audit-only","title":"Tier 3: Best Practice (Audit Only)","text":"<p>Policies that encourage good practices but don't block:</p> <ul> <li>\u2139\ufe0f Recommended labels - team, component, version labels</li> <li>\u2139\ufe0f Cost allocation tags - For chargeback</li> <li>\u2139\ufe0f Deployment strategy - RollingUpdate preferred</li> </ul> <p>Effect: Logged for visibility, never enforced.</p> <p>Policy Report Dashboard: Grafana shows compliance trends over time.</p>"},{"location":"explanation/security/zero-trust-model/#related-reading","title":"Related Reading","text":"<ul> <li>ADR: ADR-015: Vault Deployment</li> <li>ADR: ADR-017: Kyverno Policy Engine</li> <li>ADR: ADR-010: Ingress Controller</li> <li>How-To: Rotate Vault Secrets</li> <li>How-To: Troubleshoot Kyverno Violations</li> <li>Tutorial: Module 19: Zero Trust Security</li> </ul>"},{"location":"explanation/security/zero-trust-model/#conclusion","title":"Conclusion","text":"<p>Zero Trust is not a product\u2014it's an architectural philosophy. No single tool provides Zero Trust; it emerges from the integration of complementary security layers.</p> <p>Fawkes implements Zero Trust through: - Vault - Identity-based secrets with audit trail - Kyverno - Policy enforcement at admission time - Istio/Ingress - Encrypted transport and identity verification</p> <p>Together, these create defense in depth: multiple security layers that must all fail for a breach to succeed.</p> <p>The Goal: Make attacks expensive. Even if an attacker compromises one pod, they can't pivot laterally, can't exfiltrate secrets, can't deploy malicious workloads. The blast radius is minimized, and the audit trail is complete.</p> <p>This is Zero Trust: Never trust, always verify, and limit the damage when (not if) something goes wrong.</p>"},{"location":"how-to/","title":"How-To Guides","text":"<p>How-to guides are task-oriented and take you through the steps required to solve a specific problem or accomplish a particular goal.</p>"},{"location":"how-to/#what-youll-find-here","title":"What You'll Find Here","text":"<p>How-to guides in Fawkes are designed to:</p> <ul> <li>Provide step-by-step instructions for specific tasks</li> <li>Assume you have basic familiarity with the platform</li> <li>Focus on practical outcomes</li> <li>Address real-world use cases and scenarios</li> </ul>"},{"location":"how-to/#platform-operations","title":"Platform Operations","text":"<p>The following how-to guides help you accomplish specific tasks with Fawkes.</p>"},{"location":"how-to/#deployment-delivery","title":"Deployment &amp; Delivery","text":"Guide Description Status Onboard Service to ArgoCD Deploy a new microservice using GitOps \u2705 Available Sync ArgoCD Application Manual and automated synchronization \u2705 Available Configure Blue-Green Deployments Set up zero-downtime deployments \ud83d\udea7 Coming soon Implement Canary Releases Gradually roll out changes \ud83d\udea7 Coming soon Rollback a Deployment Quickly revert problematic releases \ud83d\udea7 Coming soon"},{"location":"how-to/#infrastructure","title":"Infrastructure","text":"Guide Description Status Provision Infrastructure with Terraform Create cloud resources declaratively See Infrastructure as Code Pattern Rotate Vault Secrets Securely rotate secrets and update applications \u2705 Available Configure Ingress with TLS Set up HTTPS access with automatic certificates \u2705 Available"},{"location":"how-to/#observability","title":"Observability","text":"Guide Description Status Trace Requests with Grafana Tempo Debug latency and errors using distributed tracing \u2705 Available View DORA Metrics in DevLake Access and analyze deployment performance metrics \u2705 Available Configure Alerts Set up proactive notifications \ud83d\udea7 Coming soon Aggregate Logs Centralize logging with OpenSearch See Centralized Logging"},{"location":"how-to/#security-policy","title":"Security &amp; Policy","text":"Guide Description Status Troubleshoot Kyverno Policy Violations Resolve policy blocks and enforcement issues \u2705 Available Implement Security Scanning Add SAST and container scanning See Security Set Up RBAC Configure role-based access control \ud83d\udea7 Coming soon"},{"location":"how-to/#development","title":"Development","text":"Guide Description Status Debug Buildpack Failures Troubleshoot Cloud Native Buildpack build errors \u2705 Available Set Up Local Development Configure local Fawkes environment \ud83d\udea7 Coming soon Create Custom Pipeline Build Jenkins pipeline for your project \ud83d\udea7 Coming soon"},{"location":"how-to/#how-to-use-these-guides","title":"How to Use These Guides","text":"<ol> <li>Identify your goal - What specific task do you need to accomplish?</li> <li>Check prerequisites - Each guide lists what you need before starting</li> <li>Follow the steps - Work through the guide sequentially</li> <li>Verify success - Each guide includes validation steps</li> </ol>"},{"location":"how-to/#need-more-context","title":"Need More Context?","text":"<p>If you need to understand the concepts behind these guides:</p> <ul> <li>Visit Explanation for conceptual background</li> <li>Check Reference for detailed technical specifications</li> <li>Try Tutorials if you're new to a topic</li> </ul> <p>View Playbooks  Explore Reference </p>"},{"location":"how-to/development/debug-buildpack-failure/","title":"Debug Buildpack Failure","text":""},{"location":"how-to/development/debug-buildpack-failure/#goal","title":"Goal","text":"<p>Identify and resolve failures when building container images using Cloud Native Buildpacks, enabling successful application deployment.</p>"},{"location":"how-to/development/debug-buildpack-failure/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Access to the CI/CD system (Jenkins) where the build failed</li> <li>[ ] Build logs from the failed buildpack execution</li> <li>[ ] Source code repository access</li> <li>[ ] <code>pack</code> CLI installed locally (optional, for local testing)</li> <li>[ ] Docker installed locally (for local debugging)</li> </ul>"},{"location":"how-to/development/debug-buildpack-failure/#steps","title":"Steps","text":""},{"location":"how-to/development/debug-buildpack-failure/#1-locate-the-build-failure","title":"1. Locate the Build Failure","text":""},{"location":"how-to/development/debug-buildpack-failure/#access-jenkins-build-logs","title":"Access Jenkins Build Logs","text":"<pre><code># Get Jenkins URL\necho \"https://jenkins.127.0.0.1.nip.io\"\n\n# Navigate to the failed build\n# Jobs \u2192 Your Pipeline \u2192 Build #XX \u2192 Console Output\n</code></pre> <p>Or using Jenkins CLI:</p> <pre><code># Download Jenkins CLI\nwget http://jenkins.127.0.0.1.nip.io/jnlpJars/jenkins-cli.jar\n\n# Get build log\njava -jar jenkins-cli.jar -s http://jenkins.127.0.0.1.nip.io \\\n  -auth admin:password \\\n  console my-pipeline 123  # build number\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#identify-the-failure-point","title":"Identify the Failure Point","text":"<p>Look for error indicators in logs:</p> <pre><code>[detector] ======== Results ========\n[detector] fail: paketo-buildpacks/node-engine@1.0.0\n[detector] ERROR: No buildpack groups passed detection.\n[detector] ERROR: Please check that you are running against the correct path.\nERROR: failed to build: exit status 1\n</code></pre> <p>Common failure patterns:</p> <ul> <li><code>No buildpack groups passed detection</code> - Buildpack couldn't detect project type</li> <li><code>Unable to satisfy X dependency</code> - Missing dependency or version conflict</li> <li><code>Error during build</code> - Build command failed</li> <li><code>COPY failed</code> - File not found during build</li> </ul>"},{"location":"how-to/development/debug-buildpack-failure/#2-analyze-the-error-message","title":"2. Analyze the Error Message","text":""},{"location":"how-to/development/debug-buildpack-failure/#understand-the-failure-type","title":"Understand the Failure Type","text":"Error Pattern Cause Section to Check <code>No buildpack groups passed detection</code> Wrong project structure or missing files 3. Detection Failures <code>Unable to satisfy dependency</code> Version constraints or unavailable dependency 4. Dependency Issues <code>Error: npm install failed</code> Node.js build error 5. Build Command Failures <code>Permission denied</code> File permission issues 6. Permission Issues <code>Layer restoration failed</code> Cache corruption 7. Cache Issues"},{"location":"how-to/development/debug-buildpack-failure/#3-detection-failures","title":"3. Detection Failures","text":"<p>If buildpack can't detect your project type:</p>"},{"location":"how-to/development/debug-buildpack-failure/#verify-required-files-exist","title":"Verify Required Files Exist","text":"<p>Different buildpacks require different files:</p> <p>Node.js (Paketo):</p> <pre><code># Required: package.json in repository root\nls -la package.json\n\n# Verify package.json is valid JSON\ncat package.json | jq .\n</code></pre> <p>Java (Paketo):</p> <pre><code># Required: pom.xml (Maven) or build.gradle (Gradle)\nls -la pom.xml build.gradle\n\n# For multi-module projects, ensure parent POM exists\n</code></pre> <p>Python (Paketo):</p> <pre><code># Required: requirements.txt, Pipfile, or setup.py\nls -la requirements.txt Pipfile setup.py\n</code></pre> <p>Go (Paketo):</p> <pre><code># Required: go.mod\nls -la go.mod\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#fix-add-missing-files","title":"Fix: Add Missing Files","text":"<p>Create the required file for your project:</p> <pre><code># Node.js example\ncat &gt; package.json &lt;&lt;EOF\n{\n  \"name\": \"my-app\",\n  \"version\": \"1.0.0\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"start\": \"node index.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.0\"\n  }\n}\nEOF\n\n# Python example\ncat &gt; requirements.txt &lt;&lt;EOF\nflask==2.3.0\ngunicorn==21.2.0\nEOF\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#4-dependency-issues","title":"4. Dependency Issues","text":"<p>If dependencies can't be resolved:</p>"},{"location":"how-to/development/debug-buildpack-failure/#check-version-constraints","title":"Check Version Constraints","text":"<pre><code># Node.js: View dependency versions\ncat package.json | jq '.dependencies, .devDependencies'\n\n# Python: Check requirements\ncat requirements.txt\n\n# Java: Check Maven dependencies\ncat pom.xml | grep -A 5 \"&lt;dependencies&gt;\"\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#fix-update-dependency-versions","title":"Fix: Update Dependency Versions","text":"<pre><code># Node.js: Use compatible versions\nnpm install express@4.18.0\n\n# Python: Pin versions\necho \"flask==2.3.0\" &gt;&gt; requirements.txt\n\n# Java: Update in pom.xml\n&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n  &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\n  &lt;version&gt;3.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#verify-dependency-availability","title":"Verify Dependency Availability","text":"<pre><code># Node.js: Check if package exists in npm registry\nnpm view express versions --json\n\n# Python: Check PyPI\npip index versions flask\n\n# Java: Check Maven Central\ncurl https://search.maven.org/solrsearch/select?q=g:org.springframework.boot+AND+a:spring-boot-starter-web\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#5-build-command-failures","title":"5. Build Command Failures","text":"<p>If the build command itself fails:</p>"},{"location":"how-to/development/debug-buildpack-failure/#reproduce-locally","title":"Reproduce Locally","text":"<pre><code># Test build locally with pack CLI\npack build my-app:local \\\n  --builder paketobuildpacks/builder:base \\\n  --path .\n\n# Or use docker\ndocker build -t my-app:local .\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#check-build-logs-for-specific-errors","title":"Check Build Logs for Specific Errors","text":"<p>Common build errors:</p> <p>Node.js:</p> <pre><code>ERROR: npm install failed\nENOENT: no such file or directory\n</code></pre> <p>Fix:</p> <pre><code># Ensure all files are committed\ngit status\n\n# Check .gitignore doesn't exclude required files\ncat .gitignore\n\n# Add missing files\ngit add src/config.js\ngit commit -m \"fix: add missing config file\"\n</code></pre> <p>Python:</p> <pre><code>ERROR: Could not find a version that satisfies the requirement\n</code></pre> <p>Fix:</p> <pre><code># Use compatible Python version\necho \"python_version = \\\"3.11\\\"\" &gt; runtime.txt\n\n# Or specify in buildpack config\ncat &gt; project.toml &lt;&lt;EOF\n[[build.env]]\nname = \"BP_PYTHON_VERSION\"\nvalue = \"3.11.*\"\nEOF\n</code></pre> <p>Java:</p> <pre><code>ERROR: Compilation error\n[ERROR] cannot find symbol\n</code></pre> <p>Fix:</p> <pre><code># Build locally to identify error\nmvn clean install\n\n# Fix compilation errors in code\n# Then commit and rebuild\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#6-permission-issues","title":"6. Permission Issues","text":"<p>If build fails due to permissions:</p> <pre><code>ERROR: Permission denied\nCOPY failed: stat /tmp/src/app: permission denied\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#fix-correct-file-permissions","title":"Fix: Correct File Permissions","text":"<pre><code># Make files readable\nchmod -R 644 .\n\n# Make directories executable\nfind . -type d -exec chmod 755 {} \\;\n\n# Make scripts executable\nchmod +x scripts/*.sh\n\n# Commit permission changes\ngit add --chmod=+x scripts/entrypoint.sh\ngit commit -m \"fix: make entrypoint executable\"\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#7-cache-issues","title":"7. Cache Issues","text":"<p>If layer restoration fails:</p> <pre><code>ERROR: failed to restore cached layer\nERROR: layer restoration failed\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#fix-clear-build-cache","title":"Fix: Clear Build Cache","text":"<p>In Jenkins pipeline:</p> <pre><code>stage('Build with Buildpack') {\n    steps {\n        sh '''\n            # Clear buildpack cache\n            pack build my-app:latest \\\n              --builder paketobuildpacks/builder:base \\\n              --clear-cache \\\n              --path .\n        '''\n    }\n}\n</code></pre> <p>Or delete cache manually:</p> <pre><code># In CI/CD environment\nrm -rf /var/cache/buildpacks/*\n\n# Rebuild without cache\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#8-configure-buildpack-behavior","title":"8. Configure Buildpack Behavior","text":""},{"location":"how-to/development/debug-buildpack-failure/#create-projecttoml","title":"Create <code>project.toml</code>","text":"<p>Customize buildpack behavior with a configuration file:</p> <pre><code># project.toml - place in repository root\n[_]\nschema-version = \"0.2\"\n\n[[build.env]]\nname = \"BP_NODE_VERSION\"\nvalue = \"20.*\"\n\n[[build.env]]\nname = \"BP_NPM_INSTALL_ARGS\"\nvalue = \"--production\"\n\n[[build.buildpacks]]\nuri = \"docker://gcr.io/paketo-buildpacks/nodejs:latest\"\n\n[[build.buildpacks]]\nuri = \"docker://gcr.io/paketo-buildpacks/npm-install:latest\"\n</code></pre> <p>Common configuration options:</p> <p>Node.js:</p> <pre><code>[[build.env]]\nname = \"BP_NODE_VERSION\"\nvalue = \"20.*\"\n\n[[build.env]]\nname = \"BP_NPM_INSTALL_ARGS\"\nvalue = \"--production\"\n</code></pre> <p>Python:</p> <pre><code>[[build.env]]\nname = \"BP_PYTHON_VERSION\"\nvalue = \"3.11.*\"\n\n[[build.env]]\nname = \"BP_PIP_ARGS\"\nvalue = \"--no-cache-dir\"\n</code></pre> <p>Java:</p> <pre><code>[[build.env]]\nname = \"BP_JVM_VERSION\"\nvalue = \"17.*\"\n\n[[build.env]]\nname = \"BP_MAVEN_BUILD_ARGUMENTS\"\nvalue = \"clean install -DskipTests\"\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#9-test-locally-before-pushing","title":"9. Test Locally Before Pushing","text":"<p>Always test buildpack builds locally:</p> <pre><code># Install pack CLI\nbrew install buildpacks/tap/pack  # macOS\n# or download from https://buildpacks.io/docs/tools/pack/\n\n# Build locally\npack build my-app:test \\\n  --builder paketobuildpacks/builder:base \\\n  --path .\n\n# Run container to verify\ndocker run -p 8080:8080 my-app:test\n\n# Test endpoint\ncurl http://localhost:8080/health\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#verification","title":"Verification","text":""},{"location":"how-to/development/debug-buildpack-failure/#1-verify-build-succeeds","title":"1. Verify Build Succeeds","text":"<pre><code># Re-run Jenkins build\n# Or build locally\npack build my-app:verified \\\n  --builder paketobuildpacks/builder:base \\\n  --path .\n\n# Should complete without errors\n# Look for: Successfully built image my-app:verified\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#2-verify-image-runs","title":"2. Verify Image Runs","text":"<pre><code># Run the built image\ndocker run -d -p 8080:8080 --name test-app my-app:verified\n\n# Check container is running\ndocker ps | grep test-app\n\n# Check logs for errors\ndocker logs test-app\n\n# Test application endpoints\ncurl http://localhost:8080\ncurl http://localhost:8080/health\n\n# Clean up\ndocker rm -f test-app\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#3-verify-buildpack-metadata","title":"3. Verify Buildpack Metadata","text":"<pre><code># Inspect image for buildpack metadata\npack inspect my-app:verified\n\n# Should show:\n# - Buildpacks used\n# - Runtime version\n# - Build processes\n# - Launch processes\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#4-verify-in-cicd-pipeline","title":"4. Verify in CI/CD Pipeline","text":"<pre><code># Trigger Jenkins build\n# Navigate to Console Output\n\n# Verify all stages pass:\n# [detector] \u2713 paketo-buildpacks/node-engine\n# [analyzer] \u2713 Layer restoration successful\n# [builder] \u2713 Build completed successfully\n# [exporter] \u2713 Image exported\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#common-buildpack-issues-and-solutions","title":"Common Buildpack Issues and Solutions","text":""},{"location":"how-to/development/debug-buildpack-failure/#issue-no-buildpack-groups-passed-detection","title":"Issue: \"No buildpack groups passed detection\"","text":"<p>Solution:</p> <pre><code># Ensure correct file structure\nls -la package.json  # Node.js\nls -la pom.xml       # Java\nls -la requirements.txt  # Python\n\n# Specify builder explicitly\npack build my-app --builder paketobuildpacks/builder:full\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#issue-unable-to-satisfy-node-version","title":"Issue: \"Unable to satisfy node version\"","text":"<p>Solution:</p> <pre><code># Add to project.toml\n[[build.env]]\nname = \"BP_NODE_VERSION\"\nvalue = \"20.*\"  # Use wildcard for flexibility\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#issue-npm-install-fails-with-network-error","title":"Issue: \"npm install fails with network error\"","text":"<p>Solution:</p> <pre><code># Configure npm registry\n[[build.env]]\nname = \"NPM_CONFIG_REGISTRY\"\nvalue = \"https://registry.npmjs.org\"\n\n# Or use .npmrc\necho \"registry=https://registry.npmjs.org\" &gt; .npmrc\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#issue-out-of-memory-during-build","title":"Issue: \"Out of memory during build\"","text":"<p>Solution:</p> <pre><code>// Increase memory in Jenkins pipeline\nstage('Build') {\n    environment {\n        PACK_MEMORY_LIMIT = '4G'\n    }\n    steps {\n        sh 'pack build my-app --memory 4G'\n    }\n}\n</code></pre>"},{"location":"how-to/development/debug-buildpack-failure/#troubleshooting-checklist","title":"Troubleshooting Checklist","text":"<ul> <li>[ ] Required manifest file exists (package.json, pom.xml, etc.)</li> <li>[ ] Manifest file is valid (JSON/XML syntax)</li> <li>[ ] Dependencies are available and versions are compatible</li> <li>[ ] Build commands succeed locally</li> <li>[ ] File permissions are correct</li> <li>[ ] No sensitive files in repository (check .gitignore)</li> <li>[ ] Buildpack version is up to date</li> <li>[ ] Correct builder is specified</li> <li>[ ] Cache is not corrupted</li> </ul>"},{"location":"how-to/development/debug-buildpack-failure/#next-steps","title":"Next Steps","text":"<p>After resolving buildpack issues:</p> <ul> <li>Onboard Service to ArgoCD - Deploy your application</li> <li>Configure Ingress TLS - Expose your service</li> <li>View DORA Metrics - Track deployment performance</li> <li>Troubleshooting Guide - Additional debugging help</li> </ul>"},{"location":"how-to/development/debug-buildpack-failure/#related-documentation","title":"Related Documentation","text":"<ul> <li>Continuous Delivery Pattern - Build and deployment best practices</li> <li>Jenkins Configuration - CI/CD setup</li> <li>Paketo Buildpacks Documentation - Official buildpack docs</li> <li>Cloud Native Buildpacks - CNB specification</li> </ul>"},{"location":"how-to/gitops/onboard-service-argocd/","title":"Onboard a Service to ArgoCD","text":""},{"location":"how-to/gitops/onboard-service-argocd/#goal","title":"Goal","text":"<p>Deploy a new microservice to the Fawkes platform using ArgoCD's GitOps workflow, ensuring the service is automatically synchronized from your Git repository.</p>"},{"location":"how-to/gitops/onboard-service-argocd/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Git repository containing your service's Kubernetes manifests or Helm chart</li> <li>[ ] Access to the <code>platform-root</code> repository with write permissions</li> <li>[ ] <code>kubectl</code> configured with access to the target Kubernetes cluster</li> <li>[ ] ArgoCD CLI installed (optional, for CLI-based workflow)</li> <li>[ ] Basic understanding of Kubernetes resources (Deployments, Services, ConfigMaps)</li> </ul>"},{"location":"how-to/gitops/onboard-service-argocd/#steps","title":"Steps","text":""},{"location":"how-to/gitops/onboard-service-argocd/#1-prepare-your-service-manifests","title":"1. Prepare Your Service Manifests","text":"<p>Organize your Kubernetes manifests in your Git repository:</p> <pre><code>my-service/\n\u251c\u2500\u2500 base/\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u251c\u2500\u2500 configmap.yaml\n\u2502   \u2514\u2500\u2500 kustomization.yaml\n\u2514\u2500\u2500 overlays/\n    \u251c\u2500\u2500 dev/\n    \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u251c\u2500\u2500 staging/\n    \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u2514\u2500\u2500 production/\n        \u2514\u2500\u2500 kustomization.yaml\n</code></pre> <p>Example <code>base/kustomization.yaml</code>:</p> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nresources:\n  - deployment.yaml\n  - service.yaml\n  - configmap.yaml\n\ncommonLabels:\n  app: my-service\n  component: backend\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#2-create-argocd-application-manifest","title":"2. Create ArgoCD Application Manifest","text":"<p>Create a new ArgoCD Application manifest in the <code>platform-root</code> repository:</p> <p>File: <code>platform-root/manifests/argocd/apps/my-service-dev.yaml</code></p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-service-dev\n  namespace: argocd\n  # Add finalizer to ensure proper cleanup\n  finalizers:\n    - resources-finalizer.argocd.argoproj.io\nspec:\n  project: default\n\n  # Source: Your service Git repository\n  source:\n    repoURL: https://github.com/your-org/my-service.git\n    targetRevision: main\n    path: overlays/dev\n\n  # Destination: Target cluster and namespace\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-service-dev\n\n  # Sync policy: Automatic synchronization\n  syncPolicy:\n    automated:\n      prune: true        # Delete resources that are no longer in Git\n      selfHeal: true     # Force sync when cluster state deviates\n      allowEmpty: false\n    syncOptions:\n      - CreateNamespace=true  # Auto-create namespace if it doesn't exist\n    retry:\n      limit: 5\n      backoff:\n        duration: 5s\n        factor: 2\n        maxDuration: 3m\n\n  # Health assessment\n  ignoreDifferences:\n    - group: apps\n      kind: Deployment\n      jsonPointers:\n        - /spec/replicas  # Ignore replica count changes (for HPA)\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#3-add-application-to-kustomization","title":"3. Add Application to Kustomization","text":"<p>Add your new Application to the ArgoCD apps kustomization:</p> <p>File: <code>platform-root/manifests/argocd/apps/kustomization.yaml</code></p> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nresources:\n  - existing-app-1.yaml\n  - existing-app-2.yaml\n  - my-service-dev.yaml  # Add this line\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#4-commit-and-push-to-git","title":"4. Commit and Push to Git","text":"<pre><code># Navigate to platform-root repository\ncd platform-root\n\n# Add the new Application manifest\ngit add manifests/argocd/apps/my-service-dev.yaml\ngit add manifests/argocd/apps/kustomization.yaml\n\n# Commit with descriptive message\ngit commit -m \"feat: onboard my-service to ArgoCD (dev environment)\"\n\n# Push to remote\ngit push origin main\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#5-wait-for-argocd-sync","title":"5. Wait for ArgoCD Sync","text":"<p>ArgoCD automatically detects changes in the <code>platform-root</code> repository. Wait 1-3 minutes for the sync.</p> <p>Alternatively, trigger manual sync:</p> <pre><code># Using ArgoCD CLI\nargocd app sync argocd/my-service-dev\n\n# Or using kubectl\nkubectl patch app my-service-dev -n argocd \\\n  --type merge \\\n  -p '{\"operation\":{\"initiatedBy\":{\"username\":\"admin\"},\"sync\":{}}}'\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#6-monitor-deployment-progress","title":"6. Monitor Deployment Progress","text":"<p>Watch the deployment status:</p> <pre><code># View ArgoCD Application status\nargocd app get my-service-dev\n\n# Watch pod creation\nkubectl get pods -n my-service-dev --watch\n\n# Check ArgoCD sync status\nkubectl get application my-service-dev -n argocd -o jsonpath='{.status.sync.status}'\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#verification","title":"Verification","text":"<p>Verify your service is successfully onboarded and healthy:</p>"},{"location":"how-to/gitops/onboard-service-argocd/#1-check-argocd-application-status","title":"1. Check ArgoCD Application Status","text":"<pre><code>argocd app get my-service-dev\n</code></pre> <p>Expected output:</p> <pre><code>Name:               my-service-dev\nProject:            default\nServer:             https://kubernetes.default.svc\nNamespace:          my-service-dev\nURL:                https://argocd.127.0.0.1.nip.io/applications/my-service-dev\nRepo:               https://github.com/your-org/my-service.git\nTarget:             main\nPath:               overlays/dev\nSyncWindow:         Sync Allowed\nSync Policy:        Automated (Prune)\nSync Status:        Synced to main (abc123)\nHealth Status:      Healthy\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#2-verify-application-health-in-argocd-ui","title":"2. Verify Application Health in ArgoCD UI","text":"<ol> <li>Navigate to ArgoCD UI: <code>https://argocd.127.0.0.1.nip.io</code></li> <li>Log in with your credentials</li> <li>Find your application <code>my-service-dev</code></li> <li>Verify:</li> <li>Sync Status: <code>Synced</code> (green checkmark)</li> <li>Health Status: <code>Healthy</code> (green heart icon)</li> <li>All resources show green status</li> </ol>"},{"location":"how-to/gitops/onboard-service-argocd/#3-test-service-endpoints","title":"3. Test Service Endpoints","text":"<pre><code># Port-forward to test the service locally\nkubectl port-forward -n my-service-dev svc/my-service 8080:80\n\n# Test the endpoint\ncurl http://localhost:8080/health\n\n# Expected: HTTP 200 OK with health check response\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#4-verify-gitops-workflow","title":"4. Verify GitOps Workflow","text":"<p>Test the GitOps workflow by making a change:</p> <pre><code># In your service repository, update an environment variable\n# Edit overlays/dev/kustomization.yaml\n\ngit add .\ngit commit -m \"test: update environment variable\"\ngit push origin main\n\n# Wait 1-3 minutes and verify ArgoCD auto-synced\nargocd app get my-service-dev\n# Check \"Sync Status\" shows new commit SHA\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/gitops/onboard-service-argocd/#application-shows-outofsync-status","title":"Application Shows \"OutOfSync\" Status","text":"<p>Cause: ArgoCD detected differences between Git and cluster state.</p> <p>Solution:</p> <pre><code># View differences\nargocd app diff my-service-dev\n\n# Force sync\nargocd app sync my-service-dev --force\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#application-shows-degraded-health","title":"Application Shows \"Degraded\" Health","text":"<p>Cause: Kubernetes resources are not healthy (e.g., CrashLoopBackOff).</p> <p>Solution:</p> <pre><code># Check pod logs\nkubectl logs -n my-service-dev -l app=my-service --tail=100\n\n# Describe pods for events\nkubectl describe pods -n my-service-dev -l app=my-service\n\n# Check deployment status\nkubectl get deployment -n my-service-dev\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#application-not-appearing-in-argocd","title":"Application Not Appearing in ArgoCD","text":"<p>Cause: ArgoCD hasn't synced the <code>platform-root</code> repository yet.</p> <p>Solution:</p> <pre><code># Check if Application resource exists\nkubectl get application -n argocd | grep my-service\n\n# If missing, verify the manifest is in Git\n# Then manually sync the platform-root app\nargocd app sync platform-root\n</code></pre>"},{"location":"how-to/gitops/onboard-service-argocd/#next-steps","title":"Next Steps","text":"<p>After successfully onboarding your service:</p> <ul> <li>Configure Ingress for External Access</li> <li>Set Up Monitoring Dashboards</li> <li>Implement Security Scanning</li> <li>Configure Policy Enforcement</li> </ul>"},{"location":"how-to/gitops/onboard-service-argocd/#related-documentation","title":"Related Documentation","text":"<ul> <li>Continuous Delivery Pattern - Understand the CD workflow</li> <li>ArgoCD Architecture - Learn how ArgoCD works</li> <li>GitOps Explanation - Conceptual background</li> <li>Green Belt Module: GitOps with ArgoCD</li> </ul>"},{"location":"how-to/gitops/sync-argocd-app/","title":"Sync an ArgoCD Application","text":""},{"location":"how-to/gitops/sync-argocd-app/#goal","title":"Goal","text":"<p>Synchronize an ArgoCD Application to apply changes from Git to your Kubernetes cluster, either manually on-demand or by configuring automated sync policies.</p>"},{"location":"how-to/gitops/sync-argocd-app/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] An existing ArgoCD Application deployed</li> <li>[ ] ArgoCD CLI installed or access to the ArgoCD UI</li> <li>[ ] <code>kubectl</code> configured with access to the cluster</li> <li>[ ] Changes committed to your Git repository</li> </ul>"},{"location":"how-to/gitops/sync-argocd-app/#steps","title":"Steps","text":""},{"location":"how-to/gitops/sync-argocd-app/#method-1-manual-sync-via-argocd-ui","title":"Method 1: Manual Sync via ArgoCD UI","text":""},{"location":"how-to/gitops/sync-argocd-app/#1-access-argocd-ui","title":"1. Access ArgoCD UI","text":"<p>Navigate to the ArgoCD web interface:</p> <pre><code># Get ArgoCD URL\necho \"https://argocd.127.0.0.1.nip.io\"\n\n# Get admin password (if needed)\nkubectl -n argocd get secret argocd-initial-admin-secret \\\n  -o jsonpath=\"{.data.password}\" | base64 -d\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#2-locate-your-application","title":"2. Locate Your Application","text":"<ol> <li>Log in to the ArgoCD UI</li> <li>Find your application in the Applications list</li> <li>Click on the application name to view details</li> </ol>"},{"location":"how-to/gitops/sync-argocd-app/#3-trigger-synchronization","title":"3. Trigger Synchronization","text":"<ol> <li>Click the \"SYNC\" button in the top toolbar</li> <li>Review the sync options:</li> <li>Prune: Delete resources not in Git</li> <li>Dry Run: Preview changes without applying</li> <li>Apply Only: Skip pre-sync hooks</li> <li>Select resources to sync (or select all)</li> <li>Click \"SYNCHRONIZE\"</li> </ol>"},{"location":"how-to/gitops/sync-argocd-app/#4-monitor-sync-progress","title":"4. Monitor Sync Progress","text":"<p>Watch the application tile as resources are synchronized:</p> <ul> <li>Blue (pulsing): Sync in progress</li> <li>Green: Healthy and synced</li> <li>Yellow/Orange: Progressing</li> <li>Red: Failed or degraded</li> </ul>"},{"location":"how-to/gitops/sync-argocd-app/#method-2-manual-sync-via-argocd-cli","title":"Method 2: Manual Sync via ArgoCD CLI","text":""},{"location":"how-to/gitops/sync-argocd-app/#1-sync-application","title":"1. Sync Application","text":"<pre><code># Basic sync\nargocd app sync my-service-dev\n\n# Sync with prune (delete extra resources)\nargocd app sync my-service-dev --prune\n\n# Dry run to preview changes\nargocd app sync my-service-dev --dry-run\n\n# Sync specific resources only\nargocd app sync my-service-dev --resource apps:Deployment:my-service\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#2-monitor-sync-progress","title":"2. Monitor Sync Progress","text":"<pre><code># Watch sync status in real-time\nargocd app wait my-service-dev --timeout 300\n\n# View sync operation details\nargocd app get my-service-dev\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#method-3-manual-sync-via-kubectl","title":"Method 3: Manual Sync via kubectl","text":"<pre><code># Trigger sync using kubectl patch\nkubectl patch application my-service-dev -n argocd \\\n  --type merge \\\n  -p '{\"operation\":{\"initiatedBy\":{\"username\":\"admin\"},\"sync\":{}}}'\n\n# Check sync status\nkubectl get application my-service-dev -n argocd \\\n  -o jsonpath='{.status.sync.status}'\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#method-4-enable-automated-sync","title":"Method 4: Enable Automated Sync","text":"<p>Configure your Application to automatically sync on Git changes:</p>"},{"location":"how-to/gitops/sync-argocd-app/#1-update-application-manifest","title":"1. Update Application Manifest","text":"<p>Edit your ArgoCD Application manifest:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-service-dev\n  namespace: argocd\nspec:\n  # ... other fields ...\n\n  syncPolicy:\n    automated:\n      prune: true        # Automatically delete resources removed from Git\n      selfHeal: true     # Automatically sync when cluster state drifts\n      allowEmpty: false  # Prevent sync if Git directory is empty\n\n    syncOptions:\n      - CreateNamespace=true\n      - PrunePropagationPolicy=foreground\n      - PruneLast=true   # Prune after all resources are synced\n\n    retry:\n      limit: 5           # Retry failed syncs up to 5 times\n      backoff:\n        duration: 5s     # Initial retry delay\n        factor: 2        # Exponential backoff multiplier\n        maxDuration: 3m  # Maximum retry delay\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#2-apply-the-updated-configuration","title":"2. Apply the Updated Configuration","text":"<pre><code>kubectl apply -f my-service-dev.yaml\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#3-verify-automated-sync-is-enabled","title":"3. Verify Automated Sync is Enabled","text":"<pre><code>argocd app get my-service-dev | grep \"Sync Policy\"\n# Expected: \"Sync Policy:        Automated (Prune)\"\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#method-5-sync-with-hooks-and-waves","title":"Method 5: Sync with Hooks and Waves","text":"<p>For complex deployments, use sync phases and waves:</p>"},{"location":"how-to/gitops/sync-argocd-app/#1-add-sync-wave-annotations","title":"1. Add Sync Wave Annotations","text":"<p>In your Kubernetes manifests, control sync order:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: database-config\n  annotations:\n    argocd.argoproj.io/sync-wave: \"0\"  # Sync first\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-service\n  annotations:\n    argocd.argoproj.io/sync-wave: \"1\"  # Sync after ConfigMap\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#2-add-sync-hooks","title":"2. Add Sync Hooks","text":"<p>For tasks that run before or after sync:</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: database-migration\n  annotations:\n    argocd.argoproj.io/hook: PreSync     # Run before sync\n    argocd.argoproj.io/hook-delete-policy: HookSucceeded\nspec:\n  template:\n    spec:\n      containers:\n      - name: migrate\n        image: my-app:latest\n        command: [\"./migrate-db.sh\"]\n      restartPolicy: Never\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#3-sync-with-hooks","title":"3. Sync with Hooks","text":"<pre><code># Sync will automatically respect waves and hooks\nargocd app sync my-service-dev\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#verification","title":"Verification","text":""},{"location":"how-to/gitops/sync-argocd-app/#1-verify-sync-completed-successfully","title":"1. Verify Sync Completed Successfully","text":"<pre><code># Check sync status\nargocd app get my-service-dev\n\n# Expected output includes:\n# Sync Status:        Synced to main (abc123)\n# Health Status:      Healthy\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#2-verify-resource-changes-applied","title":"2. Verify Resource Changes Applied","text":"<pre><code># Compare Git commit with deployed version\nargocd app manifests my-service-dev | kubectl diff -f -\n\n# No output means cluster matches Git\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#3-check-application-health","title":"3. Check Application Health","text":"<pre><code># View application health\nkubectl get application my-service-dev -n argocd \\\n  -o jsonpath='{.status.health.status}'\n\n# Expected: \"Healthy\"\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#4-verify-pods-are-running","title":"4. Verify Pods are Running","text":"<pre><code># List pods in the namespace\nkubectl get pods -n my-service-dev\n\n# All pods should be Running/Completed\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#5-test-automated-sync-if-enabled","title":"5. Test Automated Sync (if enabled)","text":"<pre><code># Make a change in Git (e.g., update image tag)\n# Edit your deployment.yaml and commit\n\n# Wait 1-3 minutes (default polling interval)\n# Then verify ArgoCD detected and synced the change\nargocd app get my-service-dev\n\n# Check the \"Synced to\" commit SHA matches your latest commit\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#sync-policies-explained","title":"Sync Policies Explained","text":""},{"location":"how-to/gitops/sync-argocd-app/#automated-sync-options","title":"Automated Sync Options","text":"Option Description Use Case <code>prune: true</code> Delete resources removed from Git Keep cluster clean, enforce Git as source of truth <code>prune: false</code> Keep resources not in Git Safer for testing, prevents accidental deletion <code>selfHeal: true</code> Revert manual kubectl changes Enforce GitOps, prevent configuration drift <code>selfHeal: false</code> Allow manual changes Useful for debugging, manual hotfixes <code>allowEmpty: false</code> Prevent sync if Git path is empty Safety check against accidental deletion"},{"location":"how-to/gitops/sync-argocd-app/#sync-windows","title":"Sync Windows","text":"<p>Restrict when applications can sync (e.g., only during business hours):</p> <pre><code>spec:\n  syncPolicy:\n    syncWindows:\n    - kind: allow\n      schedule: '0 9 * * 1-5'  # Mon-Fri, 9 AM\n      duration: 8h             # 8-hour window\n      applications:\n      - my-service-dev\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/gitops/sync-argocd-app/#sync-fails-with-comparisonerror","title":"Sync Fails with \"ComparisonError\"","text":"<p>Cause: ArgoCD cannot generate manifests from your Git repository.</p> <p>Solution:</p> <pre><code># View detailed error\nargocd app get my-service-dev\n\n# Common causes:\n# 1. Invalid Kustomize/Helm syntax\n# 2. Missing files in Git\n# 3. Incorrect path in Application spec\n\n# Test manifest generation locally\nkubectl kustomize overlays/dev\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#sync-stuck-in-progressing-state","title":"Sync Stuck in \"Progressing\" State","text":"<p>Cause: Resources are deploying but not reaching healthy state.</p> <p>Solution:</p> <pre><code># Check resource status\nargocd app resources my-service-dev\n\n# View pod events\nkubectl describe pods -n my-service-dev\n\n# Check for image pull errors, CrashLoopBackOff\nkubectl get events -n my-service-dev --sort-by='.lastTimestamp'\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#automated-sync-not-triggering","title":"Automated Sync Not Triggering","text":"<p>Cause: ArgoCD hasn't detected Git changes yet.</p> <p>Solution:</p> <pre><code># Force refresh application from Git\nargocd app get my-service-dev --refresh\n\n# Check last sync attempt time\nargocd app get my-service-dev | grep \"Last Sync\"\n\n# Verify webhook is configured (optional)\n# For faster sync, configure Git webhook to ArgoCD\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#sync-fails-due-to-resource-conflicts","title":"Sync Fails Due to Resource Conflicts","text":"<p>Cause: Resource already exists (not managed by ArgoCD).</p> <p>Solution:</p> <pre><code># Option 1: Add ArgoCD annotation to existing resource\nkubectl annotate &lt;resource-type&gt; &lt;resource-name&gt; -n &lt;namespace&gt; \\\n  argocd.argoproj.io/tracking-id=my-service-dev:/&lt;resource-type&gt;/&lt;namespace&gt;/&lt;resource-name&gt;\n\n# Option 2: Delete existing resource and let ArgoCD recreate\nkubectl delete &lt;resource-type&gt; &lt;resource-name&gt; -n &lt;namespace&gt;\nargocd app sync my-service-dev\n</code></pre>"},{"location":"how-to/gitops/sync-argocd-app/#next-steps","title":"Next Steps","text":"<p>After mastering ArgoCD sync:</p> <ul> <li>Configure Ingress for External Access</li> <li>View DORA Metrics in DevLake</li> <li>Troubleshoot Kyverno Policy Violations</li> <li>Debug Deployment Failures</li> </ul>"},{"location":"how-to/gitops/sync-argocd-app/#related-documentation","title":"Related Documentation","text":"<ul> <li>Onboard a Service to ArgoCD - Create a new ArgoCD Application</li> <li>ArgoCD Sync Phases Documentation</li> <li>GitOps Pattern Explanation</li> <li>Green Belt Module: GitOps with ArgoCD</li> </ul>"},{"location":"how-to/networking/configure-ingress-tls/","title":"Configure Ingress with TLS","text":""},{"location":"how-to/networking/configure-ingress-tls/#goal","title":"Goal","text":"<p>Expose a Kubernetes service to external HTTPS traffic using NGINX Ingress Controller with automatic TLS certificate management via cert-manager.</p>"},{"location":"how-to/networking/configure-ingress-tls/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] NGINX Ingress Controller deployed in the cluster</li> <li>[ ] cert-manager deployed and configured</li> <li>[ ] A Kubernetes Service to expose (ClusterIP or LoadBalancer)</li> <li>[ ] DNS record pointing to the Ingress Controller's external IP</li> <li>[ ] <code>kubectl</code> configured with cluster access</li> </ul>"},{"location":"how-to/networking/configure-ingress-tls/#steps","title":"Steps","text":""},{"location":"how-to/networking/configure-ingress-tls/#1-verify-prerequisites","title":"1. Verify Prerequisites","text":""},{"location":"how-to/networking/configure-ingress-tls/#check-nginx-ingress-controller","title":"Check NGINX Ingress Controller","text":"<pre><code># Verify Ingress Controller is running\nkubectl get pods -n ingress-nginx -l app.kubernetes.io/component=controller\n\n# Get Ingress Controller external IP\nkubectl get svc -n ingress-nginx ingress-nginx-controller\n\n# Should show EXTERNAL-IP (not &lt;pending&gt;)\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#check-cert-manager","title":"Check cert-manager","text":"<pre><code># Verify cert-manager is running\nkubectl get pods -n cert-manager\n\n# Should show 3 pods: cert-manager, cert-manager-cainjector, cert-manager-webhook\n# All should be Running\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#verify-your-service-exists","title":"Verify Your Service Exists","text":"<pre><code># List services in your namespace\nkubectl get svc -n my-namespace\n\n# Your service should exist with type ClusterIP or LoadBalancer\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#2-create-a-clusterissuer-for-lets-encrypt","title":"2. Create a ClusterIssuer for Let's Encrypt","text":""},{"location":"how-to/networking/configure-ingress-tls/#create-clusterissuer-manifest","title":"Create ClusterIssuer Manifest","text":"<p>A ClusterIssuer configures cert-manager to obtain certificates from Let's Encrypt:</p> <p>File: <code>cluster-issuer-letsencrypt.yaml</code></p> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    # Let's Encrypt production server\n    server: https://acme-v02.api.letsencrypt.org/directory\n\n    # Email for certificate expiration notifications\n    email: platform-team@example.com\n\n    # Secret to store ACME account private key\n    privateKeySecretRef:\n      name: letsencrypt-prod-account-key\n\n    # HTTP-01 challenge solver using NGINX Ingress\n    solvers:\n    - http01:\n        ingress:\n          class: nginx\n</code></pre> <p>For staging/testing, use Let's Encrypt staging:</p> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-staging\nspec:\n  acme:\n    # Let's Encrypt staging server (higher rate limits, use for testing)\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    email: platform-team@example.com\n    privateKeySecretRef:\n      name: letsencrypt-staging-account-key\n    solvers:\n    - http01:\n        ingress:\n          class: nginx\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#apply-clusterissuer","title":"Apply ClusterIssuer","text":"<pre><code># Create production issuer\nkubectl apply -f cluster-issuer-letsencrypt.yaml\n\n# Verify ClusterIssuer is ready\nkubectl get clusterissuer letsencrypt-prod\n\n# Should show: READY=True\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#3-create-dns-record","title":"3. Create DNS Record","text":""},{"location":"how-to/networking/configure-ingress-tls/#point-your-domain-to-ingress","title":"Point Your Domain to Ingress","text":"<p>Get the Ingress Controller external IP:</p> <pre><code># Get external IP\nINGRESS_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller \\\n  -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n\necho \"Ingress IP: $INGRESS_IP\"\n</code></pre> <p>Create a DNS A record:</p> <pre><code>Type: A\nName: my-app.example.com\nValue: &lt;INGRESS_IP&gt;\nTTL: 300\n</code></pre> <p>For development (using nip.io):</p> <p>You can use <code>nip.io</code> for automatic DNS resolution without creating records:</p> <pre><code>my-app.127.0.0.1.nip.io \u2192 resolves to 127.0.0.1\nmy-app.10.0.0.5.nip.io \u2192 resolves to 10.0.0.5\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#verify-dns-resolution","title":"Verify DNS Resolution","text":"<pre><code># Check DNS resolution\nnslookup my-app.example.com\n\n# Should return the Ingress IP\n# May take 5-10 minutes to propagate\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#4-create-ingress-resource","title":"4. Create Ingress Resource","text":""},{"location":"how-to/networking/configure-ingress-tls/#create-ingress-manifest","title":"Create Ingress Manifest","text":"<p>File: <code>my-app-ingress.yaml</code></p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-app-ingress\n  namespace: my-namespace\n  annotations:\n    # Use NGINX Ingress Controller\n    kubernetes.io/ingress.class: nginx\n\n    # Enable cert-manager for automatic TLS\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n\n    # NGINX-specific annotations\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"  # Force HTTPS\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n\n    # Optional: Client body size limit (for file uploads)\n    nginx.ingress.kubernetes.io/proxy-body-size: \"10m\"\n\n    # Optional: Request timeout\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"600\"\n\n    # Optional: CORS headers\n    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n    nginx.ingress.kubernetes.io/cors-allow-origin: \"https://example.com\"\n\nspec:\n  # TLS configuration\n  tls:\n  - hosts:\n    - my-app.example.com\n    secretName: my-app-tls-cert  # cert-manager creates this secret\n\n  # Routing rules\n  rules:\n  - host: my-app.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-app-service\n            port:\n              number: 80\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#apply-ingress","title":"Apply Ingress","text":"<pre><code># Create Ingress\nkubectl apply -f my-app-ingress.yaml\n\n# Verify Ingress created\nkubectl get ingress -n my-namespace\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#5-monitor-certificate-issuance","title":"5. Monitor Certificate Issuance","text":""},{"location":"how-to/networking/configure-ingress-tls/#watch-certificate-creation","title":"Watch Certificate Creation","text":"<pre><code># Watch Certificate resource\nkubectl get certificate -n my-namespace -w\n\n# Should transition from False \u2192 True in 1-3 minutes\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#check-certificate-status","title":"Check Certificate Status","text":"<pre><code># Describe Certificate\nkubectl describe certificate my-app-tls-cert -n my-namespace\n\n# Look for events like:\n# - Requesting new certificate\n# - Waiting for http-01 challenge propagation\n# - Certificate issued successfully\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#verify-certificate-secret","title":"Verify Certificate Secret","text":"<pre><code># Check if secret was created by cert-manager\nkubectl get secret my-app-tls-cert -n my-namespace\n\n# View certificate details\nkubectl get secret my-app-tls-cert -n my-namespace \\\n  -o jsonpath='{.data.tls\\.crt}' | base64 -d | openssl x509 -text -noout\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#6-test-https-access","title":"6. Test HTTPS Access","text":""},{"location":"how-to/networking/configure-ingress-tls/#access-via-browser","title":"Access via Browser","text":"<p>Open browser and navigate to:</p> <pre><code>https://my-app.example.com\n</code></pre> <p>Verify:</p> <ul> <li>\u2705 HTTPS padlock icon appears (not \"Not Secure\")</li> <li>\u2705 Certificate issued by \"Let's Encrypt\"</li> <li>\u2705 Certificate valid for your domain</li> <li>\u2705 No certificate warnings</li> </ul>"},{"location":"how-to/networking/configure-ingress-tls/#test-with-curl","title":"Test with curl","text":"<pre><code># Test HTTPS endpoint\ncurl -v https://my-app.example.com\n\n# Should return:\n# * SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n# * Server certificate:\n# *  subject: CN=my-app.example.com\n# *  issuer: C=US; O=Let's Encrypt; CN=R3\n# HTTP/2 200\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#test-http-redirect","title":"Test HTTP Redirect","text":"<pre><code># HTTP should redirect to HTTPS\ncurl -I http://my-app.example.com\n\n# Should return:\n# HTTP/1.1 308 Permanent Redirect\n# Location: https://my-app.example.com/\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#verification","title":"Verification","text":""},{"location":"how-to/networking/configure-ingress-tls/#1-verify-ingress-configuration","title":"1. Verify Ingress Configuration","text":"<pre><code># Get Ingress details\nkubectl get ingress my-app-ingress -n my-namespace -o yaml\n\n# Check for:\n# - rules[].host matches your domain\n# - tls[].hosts matches your domain\n# - tls[].secretName exists\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#2-verify-certificate-is-valid","title":"2. Verify Certificate is Valid","text":"<pre><code># Check certificate expiration\nkubectl get certificate my-app-tls-cert -n my-namespace \\\n  -o jsonpath='{.status.notAfter}'\n\n# Should show expiration ~90 days in the future\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#3-verify-nginx-configuration","title":"3. Verify NGINX Configuration","text":"<pre><code># Get NGINX Ingress Controller pod\nNGINX_POD=$(kubectl get pod -n ingress-nginx \\\n  -l app.kubernetes.io/component=controller \\\n  -o jsonpath='{.items[0].metadata.name}')\n\n# Check NGINX configuration for your ingress\nkubectl exec -n ingress-nginx $NGINX_POD -- cat /etc/nginx/nginx.conf | grep my-app\n\n# Should show SSL configuration and upstream backend\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#4-test-tls-certificate-chain","title":"4. Test TLS Certificate Chain","text":"<pre><code># Test certificate chain\nopenssl s_client -connect my-app.example.com:443 -servername my-app.example.com &lt;/dev/null\n\n# Verify:\n# - Certificate chain OK\n# - No errors\n# - Issuer: Let's Encrypt\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#5-verify-auto-renewal","title":"5. Verify Auto-Renewal","text":"<p>cert-manager automatically renews certificates 30 days before expiration.</p> <pre><code># Check cert-manager logs for renewal\nkubectl logs -n cert-manager deployment/cert-manager | grep renewal\n\n# Force renewal test (optional)\nkubectl delete secret my-app-tls-cert -n my-namespace\n# Certificate should be automatically re-issued\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#advanced-configurations","title":"Advanced Configurations","text":""},{"location":"how-to/networking/configure-ingress-tls/#multiple-hosts-one-ingress","title":"Multiple Hosts (One Ingress)","text":"<pre><code>spec:\n  tls:\n  - hosts:\n    - app.example.com\n    - www.app.example.com\n    secretName: app-tls-cert\n\n  rules:\n  - host: app.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-app\n            port:\n              number: 80\n\n  - host: www.app.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-app\n            port:\n              number: 80\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#path-based-routing","title":"Path-Based Routing","text":"<pre><code>spec:\n  rules:\n  - host: my-app.example.com\n    http:\n      paths:\n      - path: /api\n        pathType: Prefix\n        backend:\n          service:\n            name: api-service\n            port:\n              number: 8080\n\n      - path: /web\n        pathType: Prefix\n        backend:\n          service:\n            name: web-service\n            port:\n              number: 80\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#custom-tls-certificate-not-lets-encrypt","title":"Custom TLS Certificate (Not Let's Encrypt)","text":"<pre><code># Create secret from existing certificate\nkubectl create secret tls my-custom-cert \\\n  --cert=path/to/tls.crt \\\n  --key=path/to/tls.key \\\n  -n my-namespace\n\n# Reference in Ingress (remove cert-manager annotation)\n</code></pre> <pre><code>spec:\n  tls:\n  - hosts:\n    - my-app.example.com\n    secretName: my-custom-cert  # Use custom cert\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#rate-limiting","title":"Rate Limiting","text":"<pre><code>metadata:\n  annotations:\n    nginx.ingress.kubernetes.io/limit-rps: \"10\"  # 10 requests per second\n    nginx.ingress.kubernetes.io/limit-connections: \"5\"  # 5 concurrent connections\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#basic-authentication","title":"Basic Authentication","text":"<pre><code># Create htpasswd file\nhtpasswd -c auth username\n\n# Create secret\nkubectl create secret generic basic-auth \\\n  --from-file=auth \\\n  -n my-namespace\n</code></pre> <pre><code>metadata:\n  annotations:\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required\"\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/networking/configure-ingress-tls/#certificate-stuck-in-false-status","title":"Certificate Stuck in \"False\" Status","text":"<p>Cause: HTTP-01 challenge failing.</p> <p>Solution:</p> <pre><code># Check CertificateRequest\nkubectl get certificaterequest -n my-namespace\n\n# Describe for errors\nkubectl describe certificaterequest &lt;name&gt; -n my-namespace\n\n# Common issues:\n# 1. DNS not pointing to Ingress IP\n# 2. Firewall blocking port 80\n# 3. Ingress class mismatch\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#404-not-found-on-https","title":"\"404 Not Found\" on HTTPS","text":"<p>Cause: Service not reachable or incorrect backend.</p> <p>Solution:</p> <pre><code># Verify service exists and has endpoints\nkubectl get svc my-app-service -n my-namespace\nkubectl get endpoints my-app-service -n my-namespace\n\n# Test service directly\nkubectl port-forward -n my-namespace svc/my-app-service 8080:80\ncurl http://localhost:8080\n\n# Check Ingress backend\nkubectl describe ingress my-app-ingress -n my-namespace\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#too-many-redirects","title":"\"Too Many Redirects\"","text":"<p>Cause: Application also redirecting to HTTPS.</p> <p>Solution:</p> <pre><code>metadata:\n  annotations:\n    # Tell app it's already behind HTTPS\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTP\"\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#lets-encrypt-rate-limit-exceeded","title":"Let's Encrypt Rate Limit Exceeded","text":"<p>Cause: Too many certificate requests (5 per week for same domain).</p> <p>Solution:</p> <pre><code># Use staging issuer for testing\n# Update Ingress annotation\ncert-manager.io/cluster-issuer: letsencrypt-staging\n\n# After testing, switch back to prod\n</code></pre>"},{"location":"how-to/networking/configure-ingress-tls/#next-steps","title":"Next Steps","text":"<p>After configuring Ingress with TLS:</p> <ul> <li>Onboard Service to ArgoCD - Automate Ingress deployment</li> <li>Rotate Vault Secrets - Manage TLS certificate secrets</li> <li>Trace Requests with Tempo - Monitor HTTPS traffic</li> <li>Ingress Access Guide - Advanced routing patterns</li> </ul>"},{"location":"how-to/networking/configure-ingress-tls/#related-documentation","title":"Related Documentation","text":"<ul> <li>Networking Configuration - NGINX Ingress setup</li> <li>Security Best Practices - TLS configuration</li> <li>cert-manager Documentation - Certificate management</li> <li>NGINX Ingress Annotations - Full annotation reference</li> </ul>"},{"location":"how-to/observability/trace-request-tempo/","title":"Trace a Request with Grafana Tempo","text":""},{"location":"how-to/observability/trace-request-tempo/#goal","title":"Goal","text":"<p>Find and analyze a specific request trace using Grafana Tempo to debug latency issues, identify bottlenecks, or investigate errors across microservices.</p>"},{"location":"how-to/observability/trace-request-tempo/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Application instrumented with OpenTelemetry (see Distributed Tracing)</li> <li>[ ] Access to Grafana UI (<code>https://grafana.127.0.0.1.nip.io</code>)</li> <li>[ ] Tempo data source configured in Grafana</li> <li>[ ] Trace ID from application logs (for direct lookup) OR time window of the issue</li> </ul>"},{"location":"how-to/observability/trace-request-tempo/#steps","title":"Steps","text":""},{"location":"how-to/observability/trace-request-tempo/#method-1-find-trace-by-trace-id-direct-lookup","title":"Method 1: Find Trace by Trace ID (Direct Lookup)","text":"<p>Use this method when you have a specific trace ID from application logs.</p>"},{"location":"how-to/observability/trace-request-tempo/#1-locate-trace-id-in-application-logs","title":"1. Locate Trace ID in Application Logs","text":"<p>Application logs should include trace IDs. Example log entry:</p> <pre><code>{\n  \"timestamp\": \"2024-12-06T10:30:45Z\",\n  \"level\": \"ERROR\",\n  \"message\": \"Payment processing failed\",\n  \"trace_id\": \"4bf92f3577b34da6a3ce929d0e0e4736\",\n  \"span_id\": \"00f067aa0ba902b7\",\n  \"service\": \"payment-service\",\n  \"error\": \"Database connection timeout\"\n}\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#2-open-grafana-explore","title":"2. Open Grafana Explore","text":"<ol> <li>Navigate to Grafana: <code>https://grafana.127.0.0.1.nip.io</code></li> <li>Click Explore (compass icon) in the left sidebar</li> <li>Select Tempo from the data source dropdown</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#3-search-by-trace-id","title":"3. Search by Trace ID","text":"<ol> <li>In the query builder, select Search tab</li> <li>Enter the trace ID in the Trace ID field:    <pre><code>4bf92f3577b34da6a3ce929d0e0e4736\n</code></pre></li> <li>Click Run query (or press Shift+Enter)</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#4-analyze-the-trace","title":"4. Analyze the Trace","text":"<p>The trace view displays:</p> <ul> <li>Service Map: Visual representation of service calls</li> <li>Timeline: Waterfall view showing span duration</li> <li>Span Details: Click any span to see:</li> <li>Span name and duration</li> <li>HTTP method, status code, route</li> <li>Database queries</li> <li>Error messages</li> <li>Custom attributes</li> </ul>"},{"location":"how-to/observability/trace-request-tempo/#method-2-search-traces-using-traceql","title":"Method 2: Search Traces Using TraceQL","text":"<p>Use this method to find traces matching specific criteria (errors, slow requests, specific service).</p>"},{"location":"how-to/observability/trace-request-tempo/#1-open-tempo-in-grafana-explore","title":"1. Open Tempo in Grafana Explore","text":"<ol> <li>Navigate to Explore in Grafana</li> <li>Select Tempo data source</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#2-write-traceql-query","title":"2. Write TraceQL Query","text":"<p>Use TraceQL to search for traces. Common queries:</p> <p>Find all error traces in the last hour:</p> <pre><code>{status = error}\n</code></pre> <p>Find slow requests (&gt; 1 second):</p> <pre><code>{duration &gt; 1s}\n</code></pre> <p>Find traces for a specific service:</p> <pre><code>{resource.service.name = \"payment-service\"}\n</code></pre> <p>Find traces with database errors:</p> <pre><code>{span.db.system = \"postgresql\" &amp;&amp; status = error}\n</code></pre> <p>Find traces for a specific HTTP route:</p> <pre><code>{span.http.route = \"/api/orders/*\" &amp;&amp; span.http.method = \"POST\"}\n</code></pre> <p>Combine multiple conditions:</p> <pre><code>{\n  resource.service.name = \"payment-service\" &amp;&amp;\n  duration &gt; 500ms &amp;&amp;\n  span.http.status_code = 500\n}\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#3-execute-query","title":"3. Execute Query","text":"<ol> <li>Enter your TraceQL query in the query editor</li> <li>Set the time range (e.g., \"Last 1 hour\")</li> <li>Click Run query</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#4-review-search-results","title":"4. Review Search Results","text":"<p>Results show:</p> <ul> <li>Trace ID</li> <li>Root service name</li> <li>Trace duration</li> <li>Start time</li> <li>Number of spans</li> <li>Number of errors</li> </ul> <p>Click on a trace to view details.</p>"},{"location":"how-to/observability/trace-request-tempo/#method-3-trace-to-logs-correlation","title":"Method 3: Trace-to-Logs Correlation","text":"<p>Use this method to jump from logs to traces.</p>"},{"location":"how-to/observability/trace-request-tempo/#1-open-logs-in-grafana","title":"1. Open Logs in Grafana","text":"<ol> <li>Navigate to Explore in Grafana</li> <li>Select OpenSearch (or Loki) data source</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#2-query-application-logs","title":"2. Query Application Logs","text":"<p>Example query for recent errors:</p> <pre><code>{namespace=\"my-service-dev\"} |~ \"ERROR\"\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#3-click-trace-id-link","title":"3. Click Trace ID Link","text":"<p>In the log results:</p> <ol> <li>Find a log entry with a <code>trace_id</code> field</li> <li>Click on the trace ID link (appears as a blue hyperlink)</li> <li>Grafana automatically switches to Tempo and loads the trace</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#method-4-trace-from-service-map","title":"Method 4: Trace from Service Map","text":"<p>Use this method to explore service dependencies and find problematic traces.</p>"},{"location":"how-to/observability/trace-request-tempo/#1-open-service-map","title":"1. Open Service Map","text":"<ol> <li>In Grafana, navigate to Explore</li> <li>Select Tempo data source</li> <li>Click on Service Graph tab</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#2-identify-problematic-service","title":"2. Identify Problematic Service","text":"<p>The service map shows:</p> <ul> <li>Nodes: Each service in your architecture</li> <li>Edges: Request flow between services</li> <li>Colors: Green (healthy), Yellow (warnings), Red (errors)</li> <li>Size: Proportional to request volume</li> </ul>"},{"location":"how-to/observability/trace-request-tempo/#3-search-traces-for-that-service","title":"3. Search Traces for That Service","text":"<ol> <li>Click on a service node showing high latency or errors</li> <li>The query builder auto-populates with the service name</li> <li>Add additional filters (e.g., errors only)</li> <li>Click Run query</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#method-5-search-by-custom-attributes","title":"Method 5: Search by Custom Attributes","text":"<p>Use custom span attributes to find specific user journeys or business flows.</p>"},{"location":"how-to/observability/trace-request-tempo/#1-build-query-with-custom-attributes","title":"1. Build Query with Custom Attributes","text":"<p>Example queries using custom attributes:</p> <p>Find traces for a specific user:</p> <pre><code>{span.user.id = \"alice@example.com\"}\n</code></pre> <p>Find traces for a specific order:</p> <pre><code>{span.order.id = \"ORD-12345\"}\n</code></pre> <p>Find traces with feature flag enabled:</p> <pre><code>{span.feature.flag.new_checkout = \"true\"}\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#2-combine-with-other-filters","title":"2. Combine with Other Filters","text":"<pre><code>{\n  span.user.id = \"alice@example.com\" &amp;&amp;\n  resource.service.name = \"checkout-service\" &amp;&amp;\n  duration &gt; 2s\n}\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#verification","title":"Verification","text":""},{"location":"how-to/observability/trace-request-tempo/#1-verify-trace-completeness","title":"1. Verify Trace Completeness","text":"<p>A complete trace should show:</p> <ul> <li>\u2705 All services involved in the request path</li> <li>\u2705 Parent-child relationships between spans</li> <li>\u2705 No missing spans (gaps in the timeline)</li> <li>\u2705 Consistent trace context propagation</li> </ul> <p>Check for missing spans:</p> <ul> <li>Look for gaps in the waterfall view</li> <li>Verify each service call has a corresponding child span</li> <li>Check for orphaned spans (no parent)</li> </ul>"},{"location":"how-to/observability/trace-request-tempo/#2-identify-bottlenecks","title":"2. Identify Bottlenecks","text":"<p>Find the slowest operation in the trace:</p> <ol> <li>Sort spans by duration (longest first)</li> <li>Look for spans consuming &gt;50% of total trace time</li> <li>Common bottlenecks:</li> <li>Slow database queries</li> <li>External API calls</li> <li>Expensive computation</li> <li>Network latency between services</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#3-analyze-error-attribution","title":"3. Analyze Error Attribution","text":"<p>For traces with errors:</p> <ol> <li>Find the first span with <code>status = error</code></li> <li>Check span attributes for error details:</li> <li><code>error.type</code>: Exception class name</li> <li><code>error.message</code>: Error description</li> <li><code>error.stack</code>: Stack trace</li> <li>Trace backwards to find the root cause</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#4-verify-span-attributes","title":"4. Verify Span Attributes","text":"<p>Inspect key span attributes:</p> <pre><code>Service: payment-service\nOperation: POST /api/payments\nDuration: 1.2s\n\nAttributes:\n  http.method: POST\n  http.route: /api/payments\n  http.status_code: 500\n  http.url: https://api.example.com/api/payments\n  db.system: postgresql\n  db.statement: SELECT * FROM payments WHERE id = $1\n  db.statement.duration: 850ms\n  error.type: ConnectionTimeoutError\n  error.message: Database connection timeout after 1000ms\n  user.id: alice@example.com\n  payment.amount: 99.99\n  payment.currency: USD\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#understanding-trace-visualization","title":"Understanding Trace Visualization","text":""},{"location":"how-to/observability/trace-request-tempo/#waterfall-view","title":"Waterfall View","text":"<p>The waterfall view shows spans in chronological order:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 payment-service: POST /api/payments         [1.2s] \u2593\u2593\u2593\u2593\u2593\u2593\u2593 \u2502\n\u2502  \u251c\u2500 validate-payment                       [50ms]  \u2593        \u2502\n\u2502  \u251c\u2500 check-fraud                            [200ms] \u2593\u2593       \u2502\n\u2502  \u251c\u2500 database: SELECT                       [850ms] \u2593\u2593\u2593\u2593\u2593\u2593   \u2502\n\u2502  \u2514\u2500 send-confirmation                      [100ms] \u2593        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          Time \u2192\n</code></pre> <p>Key indicators:</p> <ul> <li>Width: Span duration (wider = slower)</li> <li>Color: Status (green = success, red = error)</li> <li>Nesting: Parent-child relationships</li> <li>Gaps: Network latency or waiting time</li> </ul>"},{"location":"how-to/observability/trace-request-tempo/#service-dependency-graph","title":"Service Dependency Graph","text":"<p>Shows the flow of requests across services:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Frontend   \u2502 \u2500\u2500\u2500\u2500\u2500\u25b6  \u2502   API GW     \u2502 \u2500\u2500\u2500\u2500\u2500\u25b6  \u2502   Payment    \u2502\n\u2502              \u2502         \u2502              \u2502         \u2502   Service    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                          \u2502\n                                                          \u25bc\n                                                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                   \u2502  PostgreSQL  \u2502\n                                                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#span-timeline","title":"Span Timeline","text":"<p>Detailed view of a single span:</p> <pre><code>Span: database-query\nDuration: 850ms\nStart: 2024-12-06 10:30:45.123\nEnd: 2024-12-06 10:30:45.973\n\nTimeline:\n  0ms \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 Connection acquired\n  50ms \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 Query sent to database\n  800ms \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 Results received\n  850ms \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 Span complete\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/observability/trace-request-tempo/#no-traces-found-for-trace-id","title":"No Traces Found for Trace ID","text":"<p>Cause: Trace ID not in Tempo, or retention period expired.</p> <p>Solution:</p> <pre><code># Check Tempo health\nkubectl get pods -n monitoring -l app.kubernetes.io/name=tempo\n\n# Verify trace retention period\nkubectl get configmap tempo-config -n monitoring -o yaml | grep retention\n\n# Check OpenTelemetry Collector is sending traces\nkubectl logs -n monitoring -l app.kubernetes.io/name=opentelemetry-collector | grep -i tempo\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#trace-shows-incomplete-spans","title":"Trace Shows Incomplete Spans","text":"<p>Cause: Missing OpenTelemetry instrumentation or broken trace context propagation.</p> <p>Solution:</p> <ol> <li>Verify all services are instrumented with OpenTelemetry</li> <li>Check for proper trace context propagation:    <pre><code># Logs should include trace_id in each service\nkubectl logs -n my-service-dev deployment/my-service | grep trace_id\n</code></pre></li> <li>Verify HTTP headers are propagated (<code>traceparent</code>, <code>tracestate</code>)</li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#traceql-query-returns-no-results","title":"TraceQL Query Returns No Results","text":"<p>Cause: Incorrect query syntax or no matching traces.</p> <p>Solution:</p> <pre><code># Start with broad query\n{ }  # Returns all traces in time range\n\n# Gradually narrow down\n{resource.service.name = \"payment-service\"}\n\n# Check attribute spelling and case sensitivity\n{span.http.method = \"POST\"}  # Correct\n{span.HTTP.Method = \"POST\"}  # Incorrect (case-sensitive)\n</code></pre>"},{"location":"how-to/observability/trace-request-tempo/#trace-shows-high-latency-but-no-bottleneck","title":"Trace Shows High Latency but No Bottleneck","text":"<p>Cause: Network latency or waiting between spans.</p> <p>Solution:</p> <ol> <li>Look for gaps in the waterfall view (time between spans)</li> <li>Check for asynchronous operations or queued tasks</li> <li>Verify inter-service network latency:    <pre><code># Test network latency between pods\nkubectl exec -n namespace1 pod1 -- curl -w \"@curl-format.txt\" -o /dev/null -s http://service2.namespace2.svc.cluster.local\n</code></pre></li> </ol>"},{"location":"how-to/observability/trace-request-tempo/#next-steps","title":"Next Steps","text":"<p>After mastering request tracing:</p> <ul> <li>View DORA Metrics in DevLake - Analyze deployment performance</li> <li>Configure Alerts - Set up proactive monitoring</li> <li>Optimize Performance - Use trace data to improve latency</li> <li>Instrument Custom Spans - Add custom tracing</li> </ul>"},{"location":"how-to/observability/trace-request-tempo/#related-documentation","title":"Related Documentation","text":"<ul> <li>Distributed Tracing with OpenTelemetry and Tempo - Architecture and setup</li> <li>ADR-013: Distributed Tracing - Technical decisions</li> <li>Centralized Logging - Trace-to-logs correlation</li> <li>Brown Belt Module: Observability - Hands-on training</li> </ul>"},{"location":"how-to/observability/view-dora-metrics-devlake/","title":"View DORA Metrics in DevLake","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#goal","title":"Goal","text":"<p>Access and analyze DORA (DevOps Research and Assessment) metrics for your team to measure deployment frequency, lead time for changes, change failure rate, and mean time to recovery.</p>"},{"location":"how-to/observability/view-dora-metrics-devlake/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] DevLake deployed and configured (see DORA Metrics Implementation)</li> <li>[ ] Your project connected to DevLake data sources (Git, Jenkins, ArgoCD)</li> <li>[ ] Access to Grafana UI (<code>https://grafana.127.0.0.1.nip.io</code>)</li> <li>[ ] At least 7 days of deployment data for meaningful metrics</li> </ul>"},{"location":"how-to/observability/view-dora-metrics-devlake/#steps","title":"Steps","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#1-access-grafana-dashboards","title":"1. Access Grafana Dashboards","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#open-grafana","title":"Open Grafana","text":"<p>Navigate to Grafana:</p> <pre><code># Get Grafana URL\necho \"https://grafana.127.0.0.1.nip.io\"\n\n# Get admin password (if needed)\nkubectl -n monitoring get secret grafana-admin \\\n  -o jsonpath=\"{.data.admin-password}\" | base64 -d\n</code></pre> <p>Log in with your credentials.</p>"},{"location":"how-to/observability/view-dora-metrics-devlake/#2-locate-dora-metrics-dashboard","title":"2. Locate DORA Metrics Dashboard","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#navigate-to-dora-dashboard","title":"Navigate to DORA Dashboard","text":"<ol> <li>In Grafana, click Dashboards (four squares icon) in the left sidebar</li> <li>Search for \"DORA Metrics\" or \"DevLake\"</li> <li>Click on the \"DORA Metrics Overview\" dashboard</li> </ol> <p>Common DORA dashboards:</p> <ul> <li>DORA Metrics Overview: All four metrics in one view</li> <li>Deployment Frequency: Detailed deployment trends</li> <li>Lead Time Analysis: Commit to deployment timeline</li> <li>Change Failure Rate: Failed vs. successful deployments</li> <li>MTTR Dashboard: Incident response times</li> </ul>"},{"location":"how-to/observability/view-dora-metrics-devlake/#3-select-your-teamproject","title":"3. Select Your Team/Project","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#filter-by-team","title":"Filter by Team","text":"<p>Most DORA dashboards include filters at the top:</p> <ol> <li>Team/Project Dropdown: Select your team or project</li> <li>Time Range: Choose the period to analyze (default: Last 90 days)</li> <li>Environment: Filter by dev/staging/production</li> </ol> <p>Example filters:</p> <pre><code>Team: Payment Squad\nProject: payment-service\nEnvironment: production\nTime Range: Last 90 days\n</code></pre>"},{"location":"how-to/observability/view-dora-metrics-devlake/#4-analyze-the-four-dora-metrics","title":"4. Analyze the Four DORA Metrics","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#metric-1-deployment-frequency","title":"Metric 1: Deployment Frequency","text":"<p>What it measures: How often your team deploys code to production.</p> <p>Dashboard panels:</p> <ul> <li>Deployments per Day/Week: Bar chart showing deployment count over time</li> <li>Deployment Trend: Line graph showing frequency trend</li> <li>Team Comparison: Compare your team's frequency to organization average</li> </ul> <p>Interpretation:</p> Performance Level Deployment Frequency Elite Multiple deploys per day High Between once per day and once per week Medium Between once per week and once per month Low Fewer than once per month <p>Example view:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Deployment Frequency                                \u2502\n\u2502                                                     \u2502\n\u2502 This Week: 23 deployments (3.3 per day)           \u2502\n\u2502 Last Week: 19 deployments (2.7 per day)           \u2502\n\u2502                                                     \u2502\n\u2502 Performance Level: Elite \u2b50                        \u2502\n\u2502                                                     \u2502\n\u2502 [Bar Chart: Deployments by Day]                   \u2502\n\u2502  Mon  Tue  Wed  Thu  Fri  Sat  Sun                \u2502\n\u2502   \u2593\u2593   \u2593\u2593\u2593  \u2593\u2593\u2593  \u2593\u2593   \u2593\u2593   \u2593    \u2593                \u2502\n\u2502    4    5    5    4    4    1    0                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"how-to/observability/view-dora-metrics-devlake/#metric-2-lead-time-for-changes","title":"Metric 2: Lead Time for Changes","text":"<p>What it measures: Time from code commit to production deployment.</p> <p>Dashboard panels:</p> <ul> <li>Average Lead Time: Single stat showing mean lead time</li> <li>Lead Time Distribution: Histogram showing lead time spread</li> <li>Lead Time Trend: Line graph showing trend over time</li> <li>Lead Time by Stage: Breakdown by commit\u2192build\u2192test\u2192deploy</li> </ul> <p>Interpretation:</p> Performance Level Lead Time for Changes Elite Less than one hour High Between one day and one week Medium Between one week and one month Low More than one month <p>Example view:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Lead Time for Changes                               \u2502\n\u2502                                                     \u2502\n\u2502 Average: 45 minutes                                \u2502\n\u2502 P50 (Median): 32 minutes                           \u2502\n\u2502 P95: 2 hours 15 minutes                            \u2502\n\u2502                                                     \u2502\n\u2502 Performance Level: Elite \u2b50                        \u2502\n\u2502                                                     \u2502\n\u2502 Breakdown by Stage:                                \u2502\n\u2502  Commit \u2192 Build:    8 min  \u2593\u2593                     \u2502\n\u2502  Build \u2192 Test:     12 min  \u2593\u2593\u2593                    \u2502\n\u2502  Test \u2192 Deploy:    15 min  \u2593\u2593\u2593\u2593                   \u2502\n\u2502  Deploy \u2192 Verify:  10 min  \u2593\u2593\u2593                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"how-to/observability/view-dora-metrics-devlake/#metric-3-change-failure-rate","title":"Metric 3: Change Failure Rate","text":"<p>What it measures: Percentage of deployments that result in failure requiring remediation.</p> <p>Dashboard panels:</p> <ul> <li>Change Failure Rate %: Single stat showing failure percentage</li> <li>Failed vs. Successful Deployments: Pie chart</li> <li>Failure Trend: Line graph showing failure rate over time</li> <li>Top Failure Causes: Table of most common failure reasons</li> </ul> <p>Interpretation:</p> Performance Level Change Failure Rate Elite 0-15% High 16-30% Medium 31-45% Low More than 45% <p>Example view:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Change Failure Rate                                 \u2502\n\u2502                                                     \u2502\n\u2502 Last 30 days: 8.5%                                 \u2502\n\u2502                                                     \u2502\n\u2502 Performance Level: Elite \u2b50                        \u2502\n\u2502                                                     \u2502\n\u2502 Failed:     7 deployments  \u2593                       \u2502\n\u2502 Successful: 75 deployments \u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593            \u2502\n\u2502                                                     \u2502\n\u2502 Top Failure Causes:                                \u2502\n\u2502  1. Database migration error     (3)              \u2502\n\u2502  2. Configuration missing        (2)              \u2502\n\u2502  3. Image pull error             (2)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"how-to/observability/view-dora-metrics-devlake/#metric-4-mean-time-to-recovery-mttr","title":"Metric 4: Mean Time to Recovery (MTTR)","text":"<p>What it measures: Time to restore service after a production incident.</p> <p>Dashboard panels:</p> <ul> <li>Average MTTR: Single stat showing mean recovery time</li> <li>MTTR Distribution: Histogram showing recovery time spread</li> <li>MTTR Trend: Line graph showing trend over time</li> <li>Recent Incidents: Table of recent incidents with recovery times</li> </ul> <p>Interpretation:</p> Performance Level Mean Time to Recovery Elite Less than one hour High Less than one day Medium Between one day and one week Low More than one week <p>Example view:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Mean Time to Recovery (MTTR)                        \u2502\n\u2502                                                     \u2502\n\u2502 Average: 28 minutes                                \u2502\n\u2502 P50 (Median): 18 minutes                           \u2502\n\u2502 P95: 1 hour 45 minutes                             \u2502\n\u2502                                                     \u2502\n\u2502 Performance Level: Elite \u2b50                        \u2502\n\u2502                                                     \u2502\n\u2502 Recent Incidents:                                  \u2502\n\u2502  Dec 5: API timeout         MTTR: 15 min          \u2502\n\u2502  Dec 3: Database connection MTTR: 42 min          \u2502\n\u2502  Dec 1: Memory leak         MTTR: 1h 30min        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"how-to/observability/view-dora-metrics-devlake/#5-drill-down-into-specific-metrics","title":"5. Drill Down into Specific Metrics","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#view-deployment-details","title":"View Deployment Details","text":"<p>Click on any data point in the charts to drill down:</p> <ol> <li>Click on a deployment bar in the Deployment Frequency chart</li> <li>View deployment details:</li> <li>Commit SHA and message</li> <li>Author and timestamp</li> <li>Build duration</li> <li>Deploy duration</li> <li>Success/failure status</li> </ol>"},{"location":"how-to/observability/view-dora-metrics-devlake/#trace-lead-time-breakdown","title":"Trace Lead Time Breakdown","text":"<p>Click on a lead time data point to see:</p> <ul> <li>Commit timestamp</li> <li>Build start/end time</li> <li>Test execution time</li> <li>Deployment start/end time</li> <li>Link to ArgoCD application</li> <li>Link to Jenkins pipeline</li> </ul>"},{"location":"how-to/observability/view-dora-metrics-devlake/#investigate-failed-deployments","title":"Investigate Failed Deployments","text":"<p>Click on a failed deployment to view:</p> <ul> <li>Error message and logs</li> <li>Failed stage (build/test/deploy)</li> <li>Rollback timestamp</li> <li>Time to detection</li> <li>Time to resolution</li> <li>Link to incident ticket</li> </ul>"},{"location":"how-to/observability/view-dora-metrics-devlake/#6-compare-team-performance","title":"6. Compare Team Performance","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#view-team-comparison-dashboard","title":"View Team Comparison Dashboard","text":"<p>Navigate to the Team Comparison dashboard:</p> <ol> <li>Click Dashboards \u2192 DORA Team Comparison</li> <li>View metrics across all teams:</li> <li>Deployment frequency by team</li> <li>Lead time comparison</li> <li>Failure rate comparison</li> <li>MTTR comparison</li> </ol>"},{"location":"how-to/observability/view-dora-metrics-devlake/#identify-best-practices","title":"Identify Best Practices","text":"<p>Look for high-performing teams and investigate:</p> <ul> <li>What tools do they use?</li> <li>What practices enable fast deployment?</li> <li>How do they maintain low failure rates?</li> <li>What's their secret to fast recovery?</li> </ul>"},{"location":"how-to/observability/view-dora-metrics-devlake/#7-export-and-share-metrics","title":"7. Export and Share Metrics","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#share-dashboard","title":"Share Dashboard","text":"<ol> <li>Click the Share icon (arrow) at the top of the dashboard</li> <li>Choose sharing option:</li> <li>Link: Copy URL to share with team</li> <li>Snapshot: Create a public snapshot</li> <li>Export: Download as JSON</li> <li>Email: Schedule email report</li> </ol>"},{"location":"how-to/observability/view-dora-metrics-devlake/#generate-report","title":"Generate Report","text":"<p>Create a PDF report:</p> <ol> <li>Set the desired time range and filters</li> <li>Click Share \u2192 Render PDF</li> <li>Download and share with stakeholders</li> </ol>"},{"location":"how-to/observability/view-dora-metrics-devlake/#schedule-weekly-report","title":"Schedule Weekly Report","text":"<p>Configure automated reports:</p> <ol> <li>Click Dashboards \u2192 Dashboard Settings</li> <li>Select Reporting tab</li> <li>Click Schedule Report</li> <li>Configure:</li> <li>Frequency: Weekly (Monday 9 AM)</li> <li>Recipients: team@example.com</li> <li>Format: PDF</li> <li>Time range: Last 7 days</li> </ol>"},{"location":"how-to/observability/view-dora-metrics-devlake/#verification","title":"Verification","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#1-verify-data-accuracy","title":"1. Verify Data Accuracy","text":"<p>Check that metrics reflect recent deployments:</p> <pre><code># List recent deployments from ArgoCD\nkubectl get applications -n argocd \\\n  -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.status.sync.revision}{\"\\t\"}{.status.operationState.finishedAt}{\"\\n\"}{end}'\n\n# Compare with dashboard deployment count\n# Numbers should match\n</code></pre>"},{"location":"how-to/observability/view-dora-metrics-devlake/#2-verify-lead-time-calculation","title":"2. Verify Lead Time Calculation","text":"<p>Manually verify a recent deployment:</p> <pre><code># Get commit timestamp\ngit log -1 --format=\"%ai\" &lt;commit-sha&gt;\n\n# Get deployment timestamp from ArgoCD\nargocd app get my-service-prod | grep \"Sync Status\"\n\n# Calculate lead time manually\n# Should match DevLake dashboard\n</code></pre>"},{"location":"how-to/observability/view-dora-metrics-devlake/#3-check-data-freshness","title":"3. Check Data Freshness","text":"<p>Ensure metrics are up to date:</p> <ol> <li>Check Last Update timestamp in dashboard header</li> <li>Should be within the last 5-15 minutes</li> <li>If stale, check DevLake data collection:</li> </ol> <pre><code># Check DevLake pods\nkubectl get pods -n devlake\n\n# Check data collection logs\nkubectl logs -n devlake -l app=devlake-collector --tail=50\n</code></pre>"},{"location":"how-to/observability/view-dora-metrics-devlake/#understanding-performance-levels","title":"Understanding Performance Levels","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#dora-performance-tiers","title":"DORA Performance Tiers","text":"<p>Based on the State of DevOps Report, teams are categorized as:</p> Tier Deployment Frequency Lead Time Change Failure Rate MTTR Elite Multiple/day &lt; 1 hour 0-15% &lt; 1 hour High 1/day - 1/week 1 day - 1 week 16-30% &lt; 1 day Medium 1/week - 1/month 1 week - 1 month 31-45% 1 day - 1 week Low &lt; 1/month &gt; 1 month &gt; 45% &gt; 1 week"},{"location":"how-to/observability/view-dora-metrics-devlake/#improvement-recommendations","title":"Improvement Recommendations","text":"<p>If your team is not at Elite level, focus on:</p> <p>To improve Deployment Frequency:</p> <ul> <li>Reduce batch size (smaller, more frequent deploys)</li> <li>Automate deployment pipeline</li> <li>Enable feature flags for gradual rollout</li> <li>Remove manual approval gates</li> </ul> <p>To reduce Lead Time:</p> <ul> <li>Parallelize build and test stages</li> <li>Optimize test suite (remove slow/flaky tests)</li> <li>Use trunk-based development</li> <li>Automate code review checks</li> </ul> <p>To reduce Change Failure Rate:</p> <ul> <li>Increase test coverage (unit, integration, E2E)</li> <li>Implement canary deployments</li> <li>Add smoke tests after deployment</li> <li>Improve monitoring and alerting</li> </ul> <p>To reduce MTTR:</p> <ul> <li>Improve observability (logs, metrics, traces)</li> <li>Automate rollback procedures</li> <li>Practice incident response drills</li> <li>Maintain runbooks for common issues</li> </ul>"},{"location":"how-to/observability/view-dora-metrics-devlake/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/observability/view-dora-metrics-devlake/#dashboard-shows-no-data","title":"Dashboard Shows No Data","text":"<p>Cause: DevLake not connected to data sources or no deployments in time range.</p> <p>Solution:</p> <pre><code># Check DevLake data source connections\nkubectl get configmap -n devlake devlake-config -o yaml\n\n# Verify Jenkins connection\ncurl -u admin:password http://jenkins.127.0.0.1.nip.io/api/json\n\n# Verify ArgoCD connection\nargocd app list\n\n# Check time range in dashboard (expand to 30 or 90 days)\n</code></pre>"},{"location":"how-to/observability/view-dora-metrics-devlake/#metrics-seem-inaccurate","title":"Metrics Seem Inaccurate","text":"<p>Cause: Incorrect deployment detection or missing metadata.</p> <p>Solution:</p> <ol> <li>Verify ArgoCD Applications have proper labels:    <pre><code>kubectl get application -n argocd -o yaml | grep -A 5 labels\n</code></pre></li> <li>Ensure Jenkins pipelines emit DORA events</li> <li>Check DevLake collection logs for errors:    <pre><code>kubectl logs -n devlake -l app=devlake-collector | grep ERROR\n</code></pre></li> </ol>"},{"location":"how-to/observability/view-dora-metrics-devlake/#lead-time-shows-extremely-high-values","title":"Lead Time Shows Extremely High Values","text":"<p>Cause: Old commits being deployed or incorrect timestamp parsing.</p> <p>Solution:</p> <ul> <li>Filter out outliers in dashboard (use percentiles instead of mean)</li> <li>Verify commit timestamps match deployment timestamps</li> <li>Check for long-lived branches (use trunk-based development)</li> </ul>"},{"location":"how-to/observability/view-dora-metrics-devlake/#next-steps","title":"Next Steps","text":"<p>After viewing DORA metrics:</p> <ul> <li>Trace Requests with Tempo - Debug slow deployments</li> <li>Onboard Service to ArgoCD - Improve deployment frequency</li> <li>Configure Ingress TLS - Secure production deployments</li> <li>DORA Metrics Playbook - Deep dive into implementation</li> </ul>"},{"location":"how-to/observability/view-dora-metrics-devlake/#related-documentation","title":"Related Documentation","text":"<ul> <li>DORA Metrics Implementation Playbook - Setup guide</li> <li>Continuous Delivery Pattern - Best practices</li> <li>Architecture Overview - Platform architecture</li> <li>2023 State of DevOps Report - Research foundation</li> </ul>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/","title":"Troubleshoot Kyverno Policy Violations","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#goal","title":"Goal","text":"<p>Identify, understand, and resolve Kyverno policy violations that are blocking resource creation or modification in Kubernetes.</p>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Kyverno installed in the cluster</li> <li>[ ] <code>kubectl</code> configured with cluster access</li> <li>[ ] Knowledge of which resource is being blocked</li> <li>[ ] Access to view PolicyReports (RBAC permissions)</li> </ul>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#steps","title":"Steps","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#1-identify-the-policy-violation","title":"1. Identify the Policy Violation","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#check-resource-status","title":"Check Resource Status","text":"<p>When a resource fails to deploy due to policy:</p> <pre><code># Try to create/update resource\nkubectl apply -f my-deployment.yaml\n\n# Error message will reference the policy:\n# Error from server: admission webhook \"validate.kyverno.svc\" denied the request:\n# \n# policy Deployment/my-app-deployment for resource violation:\n# \n# require-non-root:\n#   runAsNonRoot: 'must set runAsNonRoot to true'\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#view-policyreports","title":"View PolicyReports","text":"<pre><code># List all PolicyReports in namespace\nkubectl get policyreport -n my-namespace\n\n# Get detailed report\nkubectl get policyreport -n my-namespace polr-ns-my-namespace -o yaml\n\n# Filter for failures only\nkubectl get policyreport -n my-namespace -o json | \\\n  jq '.items[].results[] | select(.result == \"fail\")'\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#check-clusterpolicyreports","title":"Check ClusterPolicyReports","text":"<p>For cluster-wide resources:</p> <pre><code># List ClusterPolicyReports\nkubectl get clusterpolicyreport\n\n# View specific report\nkubectl describe clusterpolicyreport clusterpolicyreport\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#2-understand-the-policy","title":"2. Understand the Policy","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#view-policy-definition","title":"View Policy Definition","text":"<pre><code># List all policies\nkubectl get clusterpolicy\n\n# Get specific policy\nkubectl get clusterpolicy require-non-root -o yaml\n\n# View policy in readable format\nkubectl get clusterpolicy require-non-root -o jsonpath='{.spec.rules[*].validate.message}'\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#understand-policy-rules","title":"Understand Policy Rules","text":"<p>Common Kyverno policies in Fawkes:</p> Policy Purpose Validation Rule <code>require-non-root</code> Security: Prevent root containers <code>securityContext.runAsNonRoot == true</code> <code>require-resource-limits</code> Resource management <code>resources.limits</code> must be set <code>require-labels</code> Organization Required labels: <code>app</code>, <code>team</code>, <code>env</code> <code>disallow-latest-tag</code> Stability Image tag cannot be <code>latest</code> <code>require-probes</code> Reliability <code>livenessProbe</code> and <code>readinessProbe</code> required <code>restrict-ingress-classes</code> Security Only approved Ingress classes allowed"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#3-fix-common-policy-violations","title":"3. Fix Common Policy Violations","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#violation-runasnonroot-must-be-true","title":"Violation: \"runAsNonRoot must be true\"","text":"<p>Policy: <code>require-non-root</code></p> <p>Problem: Container running as root user (UID 0).</p> <p>Fix:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  template:\n    spec:\n      # Add security context\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 1000      # Non-root user ID\n        fsGroup: 1000        # File system group\n\n      containers:\n      - name: my-app\n        image: my-app:v1.0.0\n        # Container-level security context (optional)\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 1000\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n              - ALL\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#violation-resource-limits-must-be-set","title":"Violation: \"resource limits must be set\"","text":"<p>Policy: <code>require-resource-limits</code></p> <p>Problem: Missing resource requests and limits.</p> <p>Fix:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  template:\n    spec:\n      containers:\n      - name: my-app\n        image: my-app:v1.0.0\n        # Add resource limits\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"512Mi\"\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#violation-required-labels-missing","title":"Violation: \"required labels missing\"","text":"<p>Policy: <code>require-labels</code></p> <p>Problem: Missing mandatory labels.</p> <p>Fix:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  # Add required labels\n  labels:\n    app: my-app\n    team: platform-squad\n    env: production\n    version: v1.0.0\n    component: backend\nspec:\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      # Also add to pod template\n      labels:\n        app: my-app\n        team: platform-squad\n        env: production\n        version: v1.0.0\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#violation-image-tag-latest-not-allowed","title":"Violation: \"image tag 'latest' not allowed\"","text":"<p>Policy: <code>disallow-latest-tag</code></p> <p>Problem: Using <code>latest</code> tag (not deterministic).</p> <p>Fix:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  template:\n    spec:\n      containers:\n      - name: my-app\n        # Use specific version tag, SHA, or semantic version\n        image: my-app:v1.2.3\n        # Or use SHA\n        # image: my-app@sha256:abc123...\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#violation-probes-required","title":"Violation: \"probes required\"","text":"<p>Policy: <code>require-probes</code></p> <p>Problem: Missing liveness or readiness probes.</p> <p>Fix:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  template:\n    spec:\n      containers:\n      - name: my-app\n        image: my-app:v1.0.0\n\n        # Add liveness probe\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          failureThreshold: 3\n\n        # Add readiness probe\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n          timeoutSeconds: 3\n          failureThreshold: 3\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#4-request-policy-exception","title":"4. Request Policy Exception","text":"<p>If a policy violation is legitimate but unavoidable:</p>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#create-policyexception","title":"Create PolicyException","text":"<pre><code>apiVersion: kyverno.io/v2beta1\nkind: PolicyException\nmetadata:\n  name: allow-root-for-legacy-app\n  namespace: my-namespace\nspec:\n  # Which resources to exclude\n  match:\n    any:\n    - resources:\n        kinds:\n          - Deployment\n        namespaces:\n          - my-namespace\n        names:\n          - legacy-app*  # Wildcard supported\n\n  # Which policies to exclude from\n  exceptions:\n  - policyName: require-non-root\n    ruleNames:\n    - validate-runAsNonRoot\n\n  # Justification (good practice)\n  background: \"Legacy database container requires root for initialization scripts\"\n</code></pre> <p>Apply the exception:</p> <pre><code># Create exception\nkubectl apply -f policy-exception.yaml\n\n# Verify exception created\nkubectl get policyexception -n my-namespace\n\n# Now resource can be created despite policy\nkubectl apply -f legacy-app-deployment.yaml\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#5-test-policy-compliance","title":"5. Test Policy Compliance","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#dry-run-validation","title":"Dry-Run Validation","text":"<pre><code># Test resource against policies without creating it\nkubectl apply -f my-deployment.yaml --dry-run=server\n\n# If policies pass, no error message\n# If policies fail, error shows which policy blocked it\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#use-kubectl-kyverno-plugin","title":"Use kubectl-kyverno Plugin","text":"<pre><code># Install kubectl-kyverno plugin\nkubectl krew install kyverno\n\n# Test resource against policies\nkubectl kyverno apply \\\n  --cluster \\\n  --resource my-deployment.yaml\n\n# Output shows which policies pass/fail\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#validate-locally-before-push","title":"Validate Locally Before Push","text":"<p>Create a test script:</p> <pre><code>#!/bin/bash\n# validate-manifests.sh\n\nfor manifest in manifests/*.yaml; do\n  echo \"Validating $manifest...\"\n  kubectl apply -f \"$manifest\" --dry-run=server || exit 1\ndone\n\necho \"All manifests passed policy validation!\"\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#6-monitor-policy-reports","title":"6. Monitor Policy Reports","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#create-alert-on-policy-violations","title":"Create Alert on Policy Violations","text":"<pre><code># View recent violations\nkubectl get policyreport -A -o json | \\\n  jq '.items[].results[] | select(.result == \"fail\") | {policy: .policy, resource: .resources[0].name, message: .message}'\n\n# Set up Prometheus alert (if metrics enabled)\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#export-policy-report","title":"Export Policy Report","text":"<pre><code># Export violations to file\nkubectl get policyreport -A -o json &gt; policy-violations.json\n\n# Generate HTML report (using kubectl-kyverno)\nkubectl kyverno report --output html &gt; policy-report.html\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#verification","title":"Verification","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#1-verify-resource-passes-policies","title":"1. Verify Resource Passes Policies","text":"<pre><code># Apply with dry-run\nkubectl apply -f my-deployment.yaml --dry-run=server\n\n# Expected: No error (policies pass)\n# Actually apply\nkubectl apply -f my-deployment.yaml\n\n# Verify resource created\nkubectl get deployment my-app -n my-namespace\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#2-verify-policyreport-shows-pass","title":"2. Verify PolicyReport Shows Pass","text":"<pre><code># Check PolicyReport for resource\nkubectl get policyreport -n my-namespace -o json | \\\n  jq '.items[].results[] | select(.resources[0].name == \"my-app\")'\n\n# Should show: \"result\": \"pass\"\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#3-verify-no-violations-in-audit-mode","title":"3. Verify No Violations in Audit Mode","text":"<pre><code># Check for any fail results\nkubectl get policyreport -A -o json | \\\n  jq '.items[].results[] | select(.result == \"fail\") | length'\n\n# Expected: 0 (no failures)\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#understanding-kyverno-policy-modes","title":"Understanding Kyverno Policy Modes","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#audit-mode","title":"Audit Mode","text":"<p>Policy violations are logged but not blocked:</p> <pre><code>spec:\n  validationFailureAction: Audit  # Log violations, don't block\n</code></pre> <p>Resources are created, but violations appear in PolicyReports.</p>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#enforce-mode","title":"Enforce Mode","text":"<p>Policy violations block resource creation:</p> <pre><code>spec:\n  validationFailureAction: Enforce  # Block non-compliant resources\n</code></pre> <p>Resources fail to create if they violate the policy.</p>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#check-policy-mode","title":"Check Policy Mode","text":"<pre><code># View policy mode\nkubectl get clusterpolicy require-non-root -o jsonpath='{.spec.validationFailureAction}'\n\n# Output: Audit or Enforce\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#common-policy-patterns","title":"Common Policy Patterns","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#allow-specific-namespaces","title":"Allow Specific Namespaces","text":"<pre><code>spec:\n  # Exclude certain namespaces from policy\n  exclude:\n    resources:\n      namespaces:\n        - kube-system\n        - monitoring\n        - cert-manager\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#require-specific-annotations","title":"Require Specific Annotations","text":"<pre><code>spec:\n  rules:\n  - name: require-deployment-annotations\n    match:\n      resources:\n        kinds:\n        - Deployment\n    validate:\n      message: \"Deployments must have 'owner' and 'cost-center' annotations\"\n      pattern:\n        metadata:\n          annotations:\n            owner: \"?*\"\n            cost-center: \"?*\"\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#mutate-resources-auto-fix","title":"Mutate Resources (Auto-Fix)","text":"<pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: add-default-resources\nspec:\n  rules:\n  - name: add-resource-limits\n    match:\n      resources:\n        kinds:\n        - Deployment\n    mutate:\n      patchStrategicMerge:\n        spec:\n          template:\n            spec:\n              containers:\n              - (name): \"*\"\n                resources:\n                  limits:\n                    +(memory): \"512Mi\"\n                    +(cpu): \"500m\"\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/policy/troubleshoot-kyverno-violation/#policy-not-being-enforced","title":"Policy Not Being Enforced","text":"<p>Cause: Policy mode is <code>Audit</code> or policy doesn't match resources.</p> <p>Solution:</p> <pre><code># Check policy mode\nkubectl get clusterpolicy &lt;policy-name&gt; -o jsonpath='{.spec.validationFailureAction}'\n\n# Check if policy matches resource\nkubectl describe clusterpolicy &lt;policy-name&gt;\n\n# Look at match/exclude rules\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#policyreport-not-showing-results","title":"PolicyReport Not Showing Results","text":"<p>Cause: Background scanning disabled or reports not generated yet.</p> <p>Solution:</p> <pre><code># Check if background scanning is enabled\nkubectl get clusterpolicy &lt;policy-name&gt; -o jsonpath='{.spec.background}'\n\n# Trigger manual scan\nkubectl annotate deployment my-app -n my-namespace \\\n  policies.kyverno.io/last-applied-patches=\"\"\n\n# Wait 1-2 minutes for report to update\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#cannot-create-exception","title":"Cannot Create Exception","text":"<p>Cause: PolicyException CRD not installed or insufficient permissions.</p> <p>Solution:</p> <pre><code># Check if PolicyException CRD exists\nkubectl get crd policyexceptions.kyverno.io\n\n# If missing, upgrade Kyverno\nhelm upgrade kyverno kyverno/kyverno -n kyverno --set features.policyExceptions.enabled=true\n\n# Check RBAC permissions\nkubectl auth can-i create policyexceptions --namespace my-namespace\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#resource-passes-dry-run-but-fails-on-apply","title":"Resource Passes Dry-Run but Fails on Apply","text":"<p>Cause: Webhook timeout or Kyverno unavailable.</p> <p>Solution:</p> <pre><code># Check Kyverno pods\nkubectl get pods -n kyverno\n\n# Check webhook configuration\nkubectl get validatingwebhookconfiguration kyverno-resource-validating-webhook-cfg\n\n# Check webhook logs\nkubectl logs -n kyverno -l app.kubernetes.io/component=admission-controller --tail=100\n</code></pre>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#next-steps","title":"Next Steps","text":"<p>After resolving policy violations:</p> <ul> <li>Onboard Service to ArgoCD - Deploy compliant resources</li> <li>Rotate Vault Secrets - Manage secrets per policy</li> <li>Configure Ingress TLS - Secure networking</li> <li>Security Documentation - Platform security best practices</li> </ul>"},{"location":"how-to/policy/troubleshoot-kyverno-violation/#related-documentation","title":"Related Documentation","text":"<ul> <li>Kyverno Configuration - Policy setup</li> <li>Security Best Practices - Platform security</li> <li>Kyverno Documentation - Official Kyverno docs</li> <li>Policy Catalog - Pre-built policies</li> </ul>"},{"location":"how-to/security/rotate-vault-secrets/","title":"Rotate Vault Secrets","text":""},{"location":"how-to/security/rotate-vault-secrets/#goal","title":"Goal","text":"<p>Rotate a secret stored in HashiCorp Vault (such as a database password or API key) and ensure all applications using that secret are updated without downtime.</p>"},{"location":"how-to/security/rotate-vault-secrets/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] HashiCorp Vault deployed and configured</li> <li>[ ] Vault CLI installed (<code>vault</code> command)</li> <li>[ ] Authentication credentials for Vault (token or role)</li> <li>[ ] Knowledge of which secret to rotate and which applications use it</li> <li>[ ] Applications configured with Vault Agent or External Secrets Operator</li> </ul>"},{"location":"how-to/security/rotate-vault-secrets/#steps","title":"Steps","text":""},{"location":"how-to/security/rotate-vault-secrets/#1-authenticate-to-vault","title":"1. Authenticate to Vault","text":""},{"location":"how-to/security/rotate-vault-secrets/#login-with-token","title":"Login with Token","text":"<pre><code># Set Vault address\nexport VAULT_ADDR=\"https://vault.127.0.0.1.nip.io\"\n\n# Login with token\nvault login &lt;your-vault-token&gt;\n\n# Verify authentication\nvault token lookup\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#login-with-kubernetes-service-account-recommended","title":"Login with Kubernetes Service Account (Recommended)","text":"<pre><code># Login using Kubernetes auth\nvault login -method=kubernetes role=my-app-role\n\n# Verify authentication\nvault token lookup\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#2-identify-the-secret-to-rotate","title":"2. Identify the Secret to Rotate","text":""},{"location":"how-to/security/rotate-vault-secrets/#list-existing-secrets","title":"List Existing Secrets","text":"<pre><code># List secret engines\nvault secrets list\n\n# List secrets in a KV path\nvault kv list secret/database\n\n# Read current secret value (to verify)\nvault kv get secret/database/postgres-credentials\n</code></pre> <p>Example output:</p> <pre><code>====== Data ======\nKey         Value\n---         -----\nusername    dbuser\npassword    oldPassword123\nhost        postgres.database.svc.cluster.local\nport        5432\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#3-identify-dependent-applications","title":"3. Identify Dependent Applications","text":""},{"location":"how-to/security/rotate-vault-secrets/#find-pods-using-the-secret","title":"Find Pods Using the Secret","text":"<pre><code># Search for pods with Vault annotations\nkubectl get pods --all-namespaces -o json | \\\n  jq '.items[] | select(.metadata.annotations[\"vault.hashicorp.com/agent-inject-secret-db\"] != null) | .metadata.name'\n\n# Or search by External Secrets\nkubectl get externalsecret --all-namespaces -o json | \\\n  jq '.items[] | select(.spec.data[].remoteRef.key == \"secret/database/postgres-credentials\")'\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#4-rotate-the-secret","title":"4. Rotate the Secret","text":""},{"location":"how-to/security/rotate-vault-secrets/#method-1-update-secret-in-vault-simple-rotation","title":"Method 1: Update Secret in Vault (Simple Rotation)","text":"<p>Update the secret value in Vault:</p> <pre><code># Read current secret\nvault kv get -format=json secret/database/postgres-credentials &gt; current-secret.json\n\n# Generate new password\nNEW_PASSWORD=$(openssl rand -base64 32)\n\n# Update secret with new password\nvault kv put secret/database/postgres-credentials \\\n  username=dbuser \\\n  password=\"${NEW_PASSWORD}\" \\\n  host=postgres.database.svc.cluster.local \\\n  port=5432\n\n# Verify new secret\nvault kv get secret/database/postgres-credentials\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#method-2-use-vault-database-secrets-engine-dynamic-rotation","title":"Method 2: Use Vault Database Secrets Engine (Dynamic Rotation)","text":"<p>For database credentials, use Vault's database secrets engine:</p> <pre><code># Configure database connection\nvault write database/config/postgres \\\n  plugin_name=postgresql-database-plugin \\\n  connection_url=\"postgresql://{{username}}:{{password}}@postgres.database.svc.cluster.local:5432/mydb\" \\\n  allowed_roles=\"my-app-role\" \\\n  username=\"vault-admin\" \\\n  password=\"admin-password\"\n\n# Create role for application\nvault write database/roles/my-app-role \\\n  db_name=postgres \\\n  creation_statements=\"CREATE ROLE \\\"{{name}}\\\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}'; \\\n    GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO \\\"{{name}}\\\";\" \\\n  default_ttl=\"1h\" \\\n  max_ttl=\"24h\"\n\n# Rotate root credentials\nvault write -force database/rotate-root/postgres\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#5-update-the-external-system","title":"5. Update the External System","text":""},{"location":"how-to/security/rotate-vault-secrets/#update-database-password","title":"Update Database Password","text":"<pre><code># Connect to database as admin\nkubectl exec -it -n database postgres-0 -- psql -U postgres\n\n# Change password for application user\nALTER USER dbuser WITH PASSWORD 'newPassword123';\n\n# Verify connection with new password\npsql -h postgres.database.svc.cluster.local -U dbuser -d mydb -c \"SELECT 1\"\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#update-third-party-api-key","title":"Update Third-Party API Key","text":"<p>For API keys, follow the provider's process:</p> <ol> <li>Log in to the third-party service (e.g., Stripe, SendGrid)</li> <li>Generate a new API key</li> <li>Update the key in Vault (see Step 4)</li> <li>Revoke the old API key (after verification in Step 7)</li> </ol>"},{"location":"how-to/security/rotate-vault-secrets/#6-trigger-application-secret-refresh","title":"6. Trigger Application Secret Refresh","text":""},{"location":"how-to/security/rotate-vault-secrets/#method-a-vault-agent-auto-refresh-recommended","title":"Method A: Vault Agent Auto-Refresh (Recommended)","text":"<p>If using Vault Agent injector, secrets auto-refresh:</p> <pre><code># Vault Agent annotation in Pod spec\nannotations:\n  vault.hashicorp.com/agent-inject: \"true\"\n  vault.hashicorp.com/role: \"my-app-role\"\n  vault.hashicorp.com/agent-inject-secret-db: \"secret/database/postgres-credentials\"\n  vault.hashicorp.com/agent-inject-template-db: |\n    {{- with secret \"secret/database/postgres-credentials\" -}}\n    export DB_PASSWORD=\"{{ .Data.data.password }}\"\n    {{- end }}\n</code></pre> <p>Wait for Vault Agent to refresh (default: 5 minutes) or force refresh:</p> <pre><code># Restart pods to trigger immediate refresh\nkubectl rollout restart deployment/my-app -n my-namespace\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#method-b-external-secrets-operator-refresh","title":"Method B: External Secrets Operator Refresh","text":"<p>If using External Secrets Operator:</p> <pre><code># Check External Secret refresh interval\nkubectl get externalsecret my-app-db-secret -n my-namespace -o yaml | grep refreshInterval\n\n# Force immediate refresh by annotating\nkubectl annotate externalsecret my-app-db-secret -n my-namespace \\\n  force-sync=\"$(date +%s)\" --overwrite\n\n# Wait for sync (usually 1-2 minutes)\nkubectl get externalsecret my-app-db-secret -n my-namespace -w\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#method-c-manual-pod-restart","title":"Method C: Manual Pod Restart","text":"<p>If secrets are mounted as environment variables (not recommended for rotation):</p> <pre><code># Restart deployment to pick up new secret\nkubectl rollout restart deployment/my-app -n my-namespace\n\n# Wait for rollout to complete\nkubectl rollout status deployment/my-app -n my-namespace\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#method-d-reloader-automated-restart","title":"Method D: Reloader (Automated Restart)","text":"<p>If using Reloader for automatic pod restarts on secret changes:</p> <pre><code># Deployment annotation to enable Reloader\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  annotations:\n    reloader.stakater.com/auto: \"true\"\n</code></pre> <p>Reloader automatically restarts pods when secrets change.</p>"},{"location":"how-to/security/rotate-vault-secrets/#7-verify-secret-rotation","title":"7. Verify Secret Rotation","text":""},{"location":"how-to/security/rotate-vault-secrets/#verify-vault-secret-updated","title":"Verify Vault Secret Updated","text":"<pre><code># Confirm new secret value in Vault\nvault kv get secret/database/postgres-credentials\n\n# Check version history\nvault kv metadata get secret/database/postgres-credentials\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#verify-applications-using-new-secret","title":"Verify Applications Using New Secret","text":"<pre><code># Check pod logs for successful connection\nkubectl logs -n my-namespace deployment/my-app --tail=50 | grep -i \"database\"\n\n# Verify no authentication errors\nkubectl logs -n my-namespace deployment/my-app --tail=100 | grep -i \"auth\"\n\n# Test application endpoint\ncurl https://my-app.127.0.0.1.nip.io/health\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#verify-database-connection","title":"Verify Database Connection","text":"<pre><code># Check active database connections\nkubectl exec -it -n database postgres-0 -- psql -U postgres -c \\\n  \"SELECT usename, application_name, client_addr FROM pg_stat_activity WHERE usename = 'dbuser';\"\n\n# Should show connections from your application pods\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#verification","title":"Verification","text":""},{"location":"how-to/security/rotate-vault-secrets/#1-verify-secret-rotation-completed","title":"1. Verify Secret Rotation Completed","text":"<pre><code># Get secret version\nvault kv metadata get secret/database/postgres-credentials\n\n# Confirm version incremented and updated timestamp matches rotation time\n</code></pre> <p>Expected output:</p> <pre><code>======= Metadata =======\nKey                Value\n---                -----\ncreated_time       2024-12-06T10:30:00Z\ncurrent_version    2\noldest_version     1\nupdated_time       2024-12-06T14:45:00Z  \u2190 Should match rotation time\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#2-verify-application-health","title":"2. Verify Application Health","text":"<pre><code># Check deployment status\nkubectl get deployment my-app -n my-namespace\n\n# All pods should be Running\nkubectl get pods -n my-namespace -l app=my-app\n\n# Check for CrashLoopBackOff or authentication errors\nkubectl describe pods -n my-namespace -l app=my-app | grep -A 10 Events\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#3-test-application-functionality","title":"3. Test Application Functionality","text":"<pre><code># Port-forward to application\nkubectl port-forward -n my-namespace svc/my-app 8080:80\n\n# Test endpoints requiring database access\ncurl http://localhost:8080/api/users\ncurl http://localhost:8080/api/orders\n\n# Should return data (not 401/500 errors)\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#4-verify-no-errors-in-logs","title":"4. Verify No Errors in Logs","text":"<pre><code># Check for authentication errors\nkubectl logs -n my-namespace -l app=my-app --since=10m | grep -i \"authentication\\|password\\|credential\"\n\n# No errors should appear after rotation time\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#5-revoke-old-secret-if-applicable","title":"5. Revoke Old Secret (if applicable)","text":"<p>After confirming the new secret works:</p> <pre><code># For database: Drop old user or revoke permissions\nkubectl exec -it -n database postgres-0 -- psql -U postgres -c \\\n  \"REVOKE ALL PRIVILEGES ON DATABASE mydb FROM old_user;\"\n\n# For API keys: Revoke old key in third-party service\n# (Do this manually via provider's dashboard)\n\n# For Vault dynamic secrets: Old leases auto-expire based on TTL\nvault list sys/leases/lookup/database/creds/my-app-role\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#secret-rotation-best-practices","title":"Secret Rotation Best Practices","text":""},{"location":"how-to/security/rotate-vault-secrets/#1-rotation-frequency","title":"1. Rotation Frequency","text":"Secret Type Recommended Frequency Database passwords Every 90 days API keys Every 90 days or on breach TLS certificates Every 90 days (automated with cert-manager) Service account tokens Every 30 days Root credentials Annually or on personnel change"},{"location":"how-to/security/rotate-vault-secrets/#2-zero-downtime-rotation","title":"2. Zero-Downtime Rotation","text":"<p>Use overlapping validity periods:</p> <ol> <li>Add new secret alongside old secret</li> <li>Deploy applications to accept both secrets</li> <li>Monitor for old secret usage</li> <li>Revoke old secret after no usage for 7 days</li> </ol>"},{"location":"how-to/security/rotate-vault-secrets/#3-automate-rotation","title":"3. Automate Rotation","text":"<p>Configure automatic rotation:</p> <pre><code># Vault database secrets engine handles automatic rotation\nvault write database/config/postgres \\\n  password_policy=\"complex-password-policy\" \\\n  rotation_period=\"2160h\"  # 90 days\n\n# Set up cron job for manual secrets\nkubectl create cronjob rotate-api-keys \\\n  --schedule=\"0 0 1 */3 *\" \\  # First day of every quarter\n  --image=vault:latest \\\n  -- vault kv put secret/api-keys/stripe api_key=&lt;new-key&gt;\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/security/rotate-vault-secrets/#applications-fail-after-rotation","title":"Applications Fail After Rotation","text":"<p>Cause: Applications haven't refreshed secret or new secret is invalid.</p> <p>Solution:</p> <pre><code># Verify new secret is valid\nvault kv get secret/database/postgres-credentials\n\n# Test database connection manually\nkubectl run -it --rm test-db-connection --image=postgres:15 --restart=Never -- \\\n  psql -h postgres.database.svc.cluster.local -U dbuser -d mydb -c \"SELECT 1\"\n\n# If connection fails, revert secret\nvault kv rollback -version=1 secret/database/postgres-credentials\n\n# Restart pods to pick up reverted secret\nkubectl rollout restart deployment/my-app -n my-namespace\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#vault-agent-not-refreshing","title":"Vault Agent Not Refreshing","text":"<p>Cause: Vault Agent lease renewal failing or annotation missing.</p> <p>Solution:</p> <pre><code># Check Vault Agent sidecar logs\nkubectl logs -n my-namespace my-app-pod vault-agent\n\n# Verify annotations\nkubectl get pod my-app-pod -n my-namespace -o yaml | grep vault.hashicorp.com\n\n# Restart pod to force re-injection\nkubectl delete pod my-app-pod -n my-namespace\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#external-secrets-not-syncing","title":"External Secrets Not Syncing","text":"<p>Cause: External Secrets Operator not polling or insufficient permissions.</p> <p>Solution:</p> <pre><code># Check External Secrets Operator logs\nkubectl logs -n external-secrets-operator deployment/external-secrets-operator\n\n# Verify ExternalSecret status\nkubectl get externalsecret my-app-db-secret -n my-namespace -o yaml\n\n# Check sync status\nkubectl describe externalsecret my-app-db-secret -n my-namespace | grep -A 5 Status\n\n# Force sync\nkubectl annotate externalsecret my-app-db-secret -n my-namespace \\\n  force-sync=\"$(date +%s)\" --overwrite\n</code></pre>"},{"location":"how-to/security/rotate-vault-secrets/#next-steps","title":"Next Steps","text":"<p>After rotating secrets:</p> <ul> <li>Configure Ingress TLS - Rotate TLS certificates</li> <li>Troubleshoot Kyverno Violations - Enforce secret policies</li> <li>Security Documentation - Review security best practices</li> <li>Vault Configuration Reference - Advanced Vault setup</li> </ul>"},{"location":"how-to/security/rotate-vault-secrets/#related-documentation","title":"Related Documentation","text":"<ul> <li>HashiCorp Vault - Vault setup guide</li> <li>Security - Platform security practices</li> <li>External Secrets Operator - External documentation</li> <li>Vault Database Secrets Engine - Vault docs</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/","title":"Fawkes Implementation Handoff Document","text":"<p>Version: 1.0 Date: December 2024 Status: Ready for Implementation  </p>"},{"location":"implementation-plan/fawkes-handoff-doc/#quick-reference","title":"\ud83d\udccb Quick Reference","text":"<p>Project: Fawkes Internal Delivery Platform GitHub: https://github.com/paruff/fawkes/ Duration: 12 weeks (3 months) Team: Solo developer + GitHub Copilot agents Infrastructure: Local 4-node K8s cluster  </p>"},{"location":"implementation-plan/fawkes-handoff-doc/#three-epic-overview","title":"\ud83c\udfaf Three Epic Overview","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#epic-1-dora-2023-foundation-month-1","title":"Epic 1: DORA 2023 Foundation (Month 1)","text":"<p>Goal: Deploy core IDP with automated DORA metrics</p> <p>Key Deliverables: - Local 4-node Kubernetes cluster - GitOps with ArgoCD - Developer portal (Backstage) - CI/CD pipelines (Jenkins) - Security scanning (SonarQube, Trivy) - Observability stack (Prometheus, Grafana) - DORA metrics automation - 3 golden path templates</p> <p>Acceptance Tests: AT-E1-001 through AT-E1-012 (12 tests) GitHub Issues: #1 through #38 (38 issues) Resource Target: &lt;70% CPU/Memory utilization</p>"},{"location":"implementation-plan/fawkes-handoff-doc/#epic-2-ai-data-platform-month-2","title":"Epic 2: AI &amp; Data Platform (Month 2)","text":"<p>Goal: Integrate AI capabilities and establish data platform</p> <p>Key Deliverables: - AI coding assistant (GitHub Copilot) - RAG architecture with vector database - Data catalog (DataHub) - Data quality framework (Great Expectations) - Value Stream Mapping (VSM) - Unified GraphQL data API - AI code review automation - Discovery capability foundation</p> <p>Acceptance Tests: AT-E2-001 through AT-E2-012 (12 tests) GitHub Issues: #39 through #72 (34 issues) Resource Target: &lt;75% CPU/Memory utilization</p>"},{"location":"implementation-plan/fawkes-handoff-doc/#epic-3-product-discovery-ux-month-3","title":"Epic 3: Product Discovery &amp; UX (Month 3)","text":"<p>Goal: Implement comprehensive product discovery capabilities</p> <p>Key Deliverables: - User research infrastructure - DevEx measurement (SPACE framework) - Multi-channel feedback system - Design system and component library - Journey maps (5 key workflows) - Product analytics platform - Feature flags and experimentation - Continuous discovery process</p> <p>Acceptance Tests: AT-E3-001 through AT-E3-012 (12 tests) GitHub Issues: #73 through #108 (36 issues) Resource Target: Optimized, &lt;75% CPU/Memory</p>"},{"location":"implementation-plan/fawkes-handoff-doc/#all-acceptance-tests-reference","title":"\ud83d\udcca All Acceptance Tests Reference","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#epic-1-dora-2023-foundation","title":"Epic 1: DORA 2023 Foundation","text":"Test ID Category Description Priority AT-E1-001 Infrastructure Local 4-node K8s cluster deployed P0 AT-E1-002 GitOps ArgoCD manages all platform components P0 AT-E1-003 Developer Portal Backstage with 3 templates functional P0 AT-E1-004 CI/CD Jenkins pipelines build/test/deploy P0 AT-E1-005 Security DevSecOps scanning integrated P0 AT-E1-006 Observability Prometheus/Grafana stack deployed P0 AT-E1-007 Metrics DORA metrics automated (4 key metrics) P0 AT-E1-008 Templates 3 golden paths work end-to-end P0 AT-E1-009 Registry Harbor with security scanning P0 AT-E1-010 Performance Resource usage &lt;70% on cluster P0 AT-E1-011 Documentation Complete docs and runbooks P0 AT-E1-012 Integration Full platform workflow validated P0"},{"location":"implementation-plan/fawkes-handoff-doc/#epic-2-ai-data-platform","title":"Epic 2: AI &amp; Data Platform","text":"Test ID Category Description Priority AT-E2-001 AI Integration AI coding assistant functional P0 AT-E2-002 AI Architecture RAG system with internal context P0 AT-E2-003 Data Platform DataHub catalog operational P0 AT-E2-004 Data Quality Great Expectations monitoring P0 AT-E2-005 VSM Value stream visibility end-to-end P0 AT-E2-006 AI Governance Clear AI policy and compliance P0 AT-E2-007 AI Automation AI code review working P1 AT-E2-008 Data API Unified GraphQL API deployed P1 AT-E2-009 AI Observability AI-powered anomaly detection P1 AT-E2-010 Discovery Foundation Basic feedback/NPS tools P1 AT-E2-011 Performance Resource usage &lt;75% on cluster P0 AT-E2-012 Documentation Complete Epic 2 docs P0"},{"location":"implementation-plan/fawkes-handoff-doc/#epic-3-product-discovery-ux","title":"Epic 3: Product Discovery &amp; UX","text":"Test ID Category Description Priority AT-E3-001 User Research Research tooling operational P0 AT-E3-002 DevEx SPACE framework implemented P0 AT-E3-003 Feedback Multi-channel feedback system P0 AT-E3-004 Design System Component library with Storybook P1 AT-E3-005 Journey Mapping 5 key user journeys documented P1 AT-E3-006 Experimentation Feature flags and A/B testing P1 AT-E3-007 Analytics Product usage analytics platform P1 AT-E3-008 Process Continuous discovery established P0 AT-E3-009 Accessibility WCAG 2.1 AA compliance &gt;90% P1 AT-E3-010 Usability Usability testing infrastructure P1 AT-E3-011 Advisory Board Customer advisory board setup P2 AT-E3-012 Documentation Complete Epic 3 docs P0"},{"location":"implementation-plan/fawkes-handoff-doc/#github-issues-structure","title":"\ud83d\uddc2\ufe0f GitHub Issues Structure","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#issue-numbering-convention","title":"Issue Numbering Convention","text":"<pre><code>Issues #1-38:   Epic 1 (DORA 2023 Foundation)\nIssues #39-72:  Epic 2 (AI &amp; Data Platform)\nIssues #73-108: Epic 3 (Product Discovery &amp; UX)\n</code></pre>"},{"location":"implementation-plan/fawkes-handoff-doc/#issue-template-structure","title":"Issue Template Structure","text":"<p>Every issue follows this format:</p> <p><pre><code># Issue #{number}: {Title}\n\n**Epic**: {Epic Name}  \n**Milestone**: {Milestone Name}  \n**Priority**: {P0/P1/P2}  \n**Estimated Effort**: {hours}  \n**Labels**: {epic-X, type-X, comp-X, priority}\n\n## Description\n{Clear description of what needs to be built}\n\n## Acceptance Criteria\n- [ ] {Criterion 1}\n- [ ] {Criterion 2}\n- [ ] {Criterion 3}\n- [ ] Acceptance test {AT-ID} passes\n\n## Tasks\n### Task {ID}: {Task Name}\n**Location**: `{file/directory}`  \n**Type**: {terraform/kubernetes/go/python/markdown}\n\n**Copilot Prompt**:\n</code></pre> {Detailed prompt optimized for AI agent} <pre><code>**Validation**:\n```bash\n{Commands to verify completion}\n</code></pre></p>"},{"location":"implementation-plan/fawkes-handoff-doc/#dependencies","title":"Dependencies","text":"<ul> <li>Depends on: #{issue numbers}</li> <li>Blocks: #{issue numbers}</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#definition-of-done","title":"Definition of Done","text":"<ul> <li>[ ] Code implemented and committed</li> <li>[ ] Tests written and passing</li> <li>[ ] Documentation updated</li> <li>[ ] Acceptance test passes</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#resources","title":"Resources","text":"<ul> <li>Architecture Doc</li> <li>ADR-00X <pre><code>---\n\n## \ud83d\udcc5 Weekly Breakdown\n\n### Month 1: Epic 1 - DORA 2023 Foundation\n\n**Week 1: Infrastructure &amp; GitOps**\n- Issue #1: Local K8s cluster (4 nodes)\n- Issue #2: Ingress controller\n- Issue #3: Persistent storage\n- Issue #4: AT-E1-001 validation\n- Issue #5: Deploy ArgoCD\n- Issue #6: Git repo structure\n- Issue #7: App-of-apps pattern\n- Issue #8: AT-E1-002 validation\n\n**Week 2: Developer Portal &amp; CI/CD**\n- Issue #9: Deploy Backstage + PostgreSQL\n- Issue #10: GitHub OAuth\n- Issue #11: 3 golden path templates\n- Issue #12: TechDocs plugin\n- Issue #13: AT-E1-003 validation\n- Issue #14: Deploy Jenkins\n- Issue #15: Jenkins JCasC\n- Issue #16: Shared library (3 Jenkinsfiles)\n- Issue #17: Deploy Harbor\n- Issue #18: AT-E1-004 + AT-E1-009 validation\n\n**Week 3: Security &amp; Observability**\n- Issue #19: Deploy SonarQube\n- Issue #20: Trivy integration\n- Issue #21: git-secrets\n- Issue #22: Security gates\n- Issue #23: AT-E1-005 validation\n- Issue #24: Deploy kube-prometheus-stack\n- Issue #25: OpenTelemetry Collector\n- Issue #26: Fluent Bit + OpenSearch\n- Issue #27: Grafana dashboards\n- Issue #28: AT-E1-006 validation\n\n**Week 4: DORA Metrics &amp; Integration**\n- Issue #29: DORA metrics service\n- Issue #30: Configure webhooks\n- Issue #31: DORA dashboard\n- Issue #32: AT-E1-007 validation\n- Issue #33: Deploy 3 sample apps\n- Issue #34: E2E integration test\n- Issue #35: Resource optimization\n- Issue #36: Complete documentation\n- Issue #37: Video walkthrough\n- Issue #38: AT-E1-012 final validation\n\n---\n\n### Month 2: Epic 2 - AI &amp; Data Platform\n\n**Week 1: AI Foundation**\n- Issue #39: Vector database (Weaviate)\n- Issue #40: RAG service\n- Issue #41: Index documentation\n- Issue #42: AI assistant config\n- Issue #43: AI policy docs\n- Issue #44: AT-E2-001 + AT-E2-002 validation\n\n**Week 2: Data Platform**\n- Issue #45: Deploy DataHub\n- Issue #46: Data source ingestion\n- Issue #47: Great Expectations\n- Issue #48: Expectation suites\n- Issue #49: Data quality dashboard\n- Issue #50: AT-E2-003 + AT-E2-004 validation\n\n**Week 3: VSM &amp; Enhanced Operations**\n- Issue #51: VSM tracking service\n- Issue #52: Define value stream stages\n- Issue #53: GraphQL unified API\n- Issue #54: Flow metrics dashboard\n- Issue #55: Focalboard integration\n- Issue #56: AT-E2-005 + AT-E2-008 validation\n- Issue #57: AI code review bot\n- Issue #58: AI anomaly detection\n- Issue #59: Smart alerting\n- Issue #60: AI observability dashboard\n- Issue #61: AT-E2-007 + AT-E2-009 validation\n\n**Week 4: Discovery Foundation &amp; Integration**\n- Issue #62: Feedback widget\n- Issue #63: NPS automation\n- Issue #64: Research templates\n- Issue #65: Feedback analytics\n- Issue #66: AT-E2-010 validation\n- Issue #67: AI training modules (3)\n- Issue #68: RAG architecture docs\n- Issue #69: Data platform runbooks\n- Issue #70: Video tutorials\n- Issue #71: Resource optimization\n- Issue #72: AT-E2-011 + AT-E2-012 validation\n\n---\n\n### Month 3: Epic 3 - Product Discovery &amp; UX\n\n**Week 1: Research Infrastructure &amp; DevEx**\n- Issue #73: Research repository\n- Issue #74: Persona templates\n- Issue #75: Interview guides\n- Issue #76: Insights database\n- Issue #77: Research dashboard\n- Issue #78: AT-E3-001 validation\n- Issue #79: SPACE metrics collection\n- Issue #80: DevEx dashboard\n- Issue #81: Survey automation\n- Issue #82: Friction logging\n- Issue #83: Cognitive load tool\n- Issue #84: AT-E3-002 validation\n\n**Week 2: Feedback &amp; Design Systems**\n- Issue #85: Enhanced feedback widget\n- Issue #86: CLI feedback tool\n- Issue #87: Mattermost bot\n- Issue #88: Feedback-to-issue automation\n- Issue #89: Feedback analytics\n- Issue #90: AT-E3-003 validation\n- Issue #91: Design system library\n- Issue #92: Figma/Penpot integration\n- Issue #93: Storybook deployment\n- Issue #94: Accessibility testing\n- Issue #95: Journey maps (5)\n- Issue #96: AT-E3-004 + AT-E3-005 + AT-E3-009 validation\n\n**Week 3: Analytics &amp; Experimentation**\n- Issue #97: Analytics platform\n- Issue #98: Event tracking\n- Issue #99: Feature flags (Unleash)\n- Issue #100: Experimentation framework\n- Issue #101: Analytics dashboards\n- Issue #102: AT-E3-006 + AT-E3-007 validation\n\n**Week 4: Process &amp; Final Integration**\n- Issue #103: Discovery workflow docs\n- Issue #104: Usability testing setup\n- Issue #105: Discovery metrics dashboard\n- Issue #106: Advisory board setup\n- Issue #107: Complete Epic 3 docs\n- Issue #108: AT-E3-008 + AT-E3-010 + AT-E3-011 + AT-E3-012 validation\n\n---\n\n## \ud83d\udd27 Technical Stack Reference\n\n### Core Platform (Epic 1)\n- **Orchestration**: Kubernetes (local, 4 nodes)\n- **GitOps**: ArgoCD\n- **Developer Portal**: Backstage\n- **CI/CD**: Jenkins with Kubernetes plugin\n- **Container Registry**: Harbor\n- **Security**: SonarQube, Trivy, git-secrets\n- **Observability**: Prometheus, Grafana, OpenTelemetry, OpenSearch, Fluent Bit\n- **Database**: PostgreSQL\n- **IaC**: Terraform\n\n### AI &amp; Data (Epic 2)\n- **AI Assistant**: GitHub Copilot (or Continue.dev)\n- **Vector Database**: Weaviate (or ChromaDB/Qdrant)\n- **RAG Service**: Custom (Python/Go)\n- **Data Catalog**: DataHub\n- **Data Quality**: Great Expectations\n- **Unified API**: GraphQL (Hasura or custom)\n- **Feature Flags**: Unleash\n\n### Discovery &amp; UX (Epic 3)\n- **Analytics**: Plausible or Matomo\n- **Design System**: Storybook\n- **Design Tool**: Figma or Penpot\n- **Feedback**: Custom widgets + integrations\n- **Accessibility**: axe-core, Lighthouse\n\n---\n\n## \ud83d\udcb0 Resource Requirements\n\n### Hardware (Local Development)\n```yaml\nminimum_requirements:\n  total_cpu: 16 cores\n  total_memory: 32 GB RAM\n  total_disk: 500 GB SSD\n  network: 1 Gbps\n\nrecommended_requirements:\n  total_cpu: 24+ cores\n  total_memory: 48+ GB RAM\n  total_disk: 1 TB SSD\n  network: 1+ Gbps\n\nper_node_allocation:\n  cpu: 4 cores\n  memory: 8 GB\n  disk: 100 GB\n</code></pre></li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#resource-utilization-targets","title":"Resource Utilization Targets","text":"<ul> <li>Epic 1 Complete: &lt;70% CPU/Memory</li> <li>Epic 2 Complete: &lt;75% CPU/Memory</li> <li>Epic 3 Complete: &lt;75% CPU/Memory (optimized)</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#cloud-alternative-if-local-insufficient","title":"Cloud Alternative (If Local Insufficient)","text":"<pre><code>aws_option:\n  service: EKS\n  instance_type: t3.xlarge\n  nodes: 4-6\n  monthly_cost: $400-600\n\nazure_option:\n  service: AKS\n  instance_type: Standard_D4s_v3\n  nodes: 4-6\n  monthly_cost: $350-550\n</code></pre>"},{"location":"implementation-plan/fawkes-handoff-doc/#success-criteria","title":"\u2705 Success Criteria","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#epic-1-gate-criteria","title":"Epic 1 Gate Criteria","text":"<ul> <li>\u2705 All 12 acceptance tests passing</li> <li>\u2705 3 sample apps deployed via platform</li> <li>\u2705 DORA metrics showing real data</li> <li>\u2705 Resource utilization &lt;70%</li> <li>\u2705 Documentation complete</li> <li>\u2705 Can scaffold new app and deploy in &lt;15 minutes</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#epic-2-gate-criteria","title":"Epic 2 Gate Criteria","text":"<ul> <li>\u2705 All 12 acceptance tests passing</li> <li>\u2705 AI assistant functional with internal context</li> <li>\u2705 Data catalog showing all data sources</li> <li>\u2705 VSM tracking end-to-end flow</li> <li>\u2705 Resource utilization &lt;75%</li> <li>\u2705 Documentation complete</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#epic-3-gate-criteria","title":"Epic 3 Gate Criteria","text":"<ul> <li>\u2705 All 12 acceptance tests passing</li> <li>\u2705 Complete discovery workflow operational</li> <li>\u2705 DevEx measurement showing trends</li> <li>\u2705 All 3 epics integrated seamlessly</li> <li>\u2705 Resource utilization optimized</li> <li>\u2705 Platform ready for external users</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#how-to-use-this-document","title":"\ud83d\ude80 How to Use This Document","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#starting-a-new-chat-session","title":"Starting a New Chat Session","text":"<p>Copy this template:</p> <pre><code>I'm implementing Fawkes Internal Delivery Platform.\n\nContext:\n- GitHub: https://github.com/paruff/fawkes/\n- Current Epic: {1/2/3}\n- Current Week: {1-4 of current epic}\n- Current Issue: #{issue number}\n\nI need help with: {specific task}\n\nFor full context, see the Implementation Handoff document in the repo.\n</code></pre>"},{"location":"implementation-plan/fawkes-handoff-doc/#generating-all-issues","title":"Generating All Issues","text":"<ol> <li>Run the <code>generate-issues.sh</code> script (see Artifact #2)</li> <li>Review generated issues in GitHub</li> <li>Adjust priorities if needed</li> </ol>"},{"location":"implementation-plan/fawkes-handoff-doc/#setting-up-project-board","title":"Setting Up Project Board","text":"<ol> <li>Run the <code>setup-project-board.sh</code> script (see Artifact #3)</li> <li>Verify automation rules</li> <li>Start moving issues through board</li> </ol>"},{"location":"implementation-plan/fawkes-handoff-doc/#working-with-copilot-agents","title":"Working with Copilot Agents","text":"<ol> <li>Reference Week 1 Detailed Tasks (see Artifact #4)</li> <li>Use Copilot prompts from issue descriptions</li> <li>Validate with provided commands</li> <li>Update issue status as you progress</li> </ol>"},{"location":"implementation-plan/fawkes-handoff-doc/#support-resources","title":"\ud83d\udcde Support &amp; Resources","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#documentation-locations","title":"Documentation Locations","text":"<ul> <li>Architecture: <code>docs/architecture.md</code></li> <li>ADRs: <code>docs/adr/ADR-001.md</code> through <code>ADR-008.md</code></li> <li>Runbooks: <code>docs/runbooks/*.md</code></li> <li>Dojo: <code>docs/dojo/DOJO_ARCHITECTURE.md</code></li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#key-files-to-reference","title":"Key Files to Reference","text":"<ul> <li><code>GOVERNANCE.md</code> - Project governance</li> <li><code>CODE_OF_CONDUCT.md</code> - Community standards</li> <li><code>PROJECT_CHARTER.md</code> - Vision and mission</li> <li><code>PROJECT_STATUS.md</code> - Current status tracking</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#getting-unstuck","title":"Getting Unstuck","text":"<ol> <li>Check acceptance test validation commands</li> <li>Review related ADRs for architectural decisions</li> <li>Search GitHub issues for similar problems</li> <li>Check runbooks for troubleshooting steps</li> <li>Start new chat with specific question and context</li> </ol>"},{"location":"implementation-plan/fawkes-handoff-doc/#progress-tracking","title":"\ud83d\udcc8 Progress Tracking","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#weekly-checklist-template","title":"Weekly Checklist Template","text":"<pre><code>## Week {N} Progress - Epic {X}\n\n**Target Issues**: #{start}-#{end}\n**Acceptance Tests**: AT-EX-00Y through AT-EX-00Z\n\n### Completed This Week\n- [ ] Issue #{N}: {Title}\n- [ ] Issue #{N+1}: {Title}\n- [ ] ...\n\n### In Progress\n- [ ] Issue #{N}: {Title} (Status: {%})\n\n### Blocked\n- [ ] Issue #{N}: {Title} (Blocker: {reason})\n\n### Acceptance Tests Status\n- [ ] AT-EX-00Y: {Status}\n- [ ] AT-EX-00Z: {Status}\n\n### Resource Utilization\n- CPU: {%}\n- Memory: {%}\n- Disk: {%}\n\n### Notes / Learnings\n{Any insights, challenges, or discoveries}\n\n### Next Week Plan\n- [ ] Issue #{N}: {Title}\n- [ ] ...\n</code></pre>"},{"location":"implementation-plan/fawkes-handoff-doc/#critical-paths","title":"\ud83c\udfaf Critical Paths","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#must-complete-sequential-no-parallelization","title":"Must Complete Sequential (No Parallelization)","text":"<ol> <li>Issue #1 (K8s cluster) \u2192 Everything else</li> <li>Issue #5 (ArgoCD) \u2192 All platform components</li> <li>Issue #9 (Backstage) \u2192 Templates and catalog</li> <li>Issue #29 (DORA service) \u2192 Metrics collection</li> </ol>"},{"location":"implementation-plan/fawkes-handoff-doc/#can-parallelize","title":"Can Parallelize","text":"<ul> <li>Security scanning (Issues #19-22) + Observability (Issues #24-28)</li> <li>AI foundation (Issues #39-43) + Data platform (Issues #45-50)</li> <li>Feedback systems (Issues #85-89) + Design system (Issues #91-95)</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#iteration-feedback","title":"\ud83d\udd04 Iteration &amp; Feedback","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#after-each-epic","title":"After Each Epic","text":"<ol> <li>Run full acceptance test suite</li> <li>Document lessons learned</li> <li>Update resource estimates</li> <li>Adjust next epic plan if needed</li> <li>Create epic retrospective issue</li> </ol>"},{"location":"implementation-plan/fawkes-handoff-doc/#monthly-review-questions","title":"Monthly Review Questions","text":"<ul> <li>Are we on track with timeline?</li> <li>Do resource limits need adjustment?</li> <li>Should any features be descoped?</li> <li>Are Copilot agents effective?</li> <li>Documentation keeping pace?</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#deliverable-artifacts","title":"\ud83d\udce6 Deliverable Artifacts","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#epic-1-final-deliverables","title":"Epic 1 Final Deliverables","text":"<pre><code>deliverables/epic-1/\n\u251c\u2500\u2500 architecture-diagrams/\n\u2502   \u251c\u2500\u2500 infrastructure.png\n\u2502   \u251c\u2500\u2500 gitops-flow.png\n\u2502   \u2514\u2500\u2500 dora-metrics.png\n\u251c\u2500\u2500 demo-videos/\n\u2502   \u2514\u2500\u2500 epic1-walkthrough.mp4\n\u251c\u2500\u2500 sample-apps/\n\u2502   \u251c\u2500\u2500 java-spring-boot/\n\u2502   \u251c\u2500\u2500 python-fastapi/\n\u2502   \u2514\u2500\u2500 nodejs-express/\n\u2514\u2500\u2500 test-reports/\n    \u2514\u2500\u2500 acceptance-tests-epic1.html\n</code></pre>"},{"location":"implementation-plan/fawkes-handoff-doc/#epic-2-final-deliverables","title":"Epic 2 Final Deliverables","text":"<pre><code>deliverables/epic-2/\n\u251c\u2500\u2500 ai-architecture/\n\u2502   \u251c\u2500\u2500 rag-design.png\n\u2502   \u2514\u2500\u2500 data-platform.png\n\u251c\u2500\u2500 demo-videos/\n\u2502   \u2514\u2500\u2500 ai-assisted-development.mp4\n\u251c\u2500\u2500 training-modules/\n\u2502   \u251c\u2500\u2500 ai-assisted-dev.md\n\u2502   \u251c\u2500\u2500 prompt-engineering.md\n\u2502   \u2514\u2500\u2500 ai-code-review.md\n\u2514\u2500\u2500 test-reports/\n    \u2514\u2500\u2500 acceptance-tests-epic2.html\n</code></pre>"},{"location":"implementation-plan/fawkes-handoff-doc/#epic-3-final-deliverables","title":"Epic 3 Final Deliverables","text":"<pre><code>deliverables/epic-3/\n\u251c\u2500\u2500 research-artifacts/\n\u2502   \u251c\u2500\u2500 personas.pdf\n\u2502   \u251c\u2500\u2500 journey-maps.pdf\n\u2502   \u2514\u2500\u2500 usability-findings.pdf\n\u251c\u2500\u2500 design-system/\n\u2502   \u2514\u2500\u2500 storybook-export/\n\u251c\u2500\u2500 demo-videos/\n\u2502   \u2514\u2500\u2500 continuous-discovery.mp4\n\u2514\u2500\u2500 test-reports/\n    \u2514\u2500\u2500 acceptance-tests-epic3.html\n</code></pre>"},{"location":"implementation-plan/fawkes-handoff-doc/#learning-resources","title":"\ud83c\udf93 Learning Resources","text":""},{"location":"implementation-plan/fawkes-handoff-doc/#recommended-reading-during-implementation","title":"Recommended Reading During Implementation","text":"<ul> <li>Week 1-2: Kubernetes documentation, ArgoCD guides</li> <li>Week 3-4: DORA State of DevOps reports</li> <li>Week 5-6: RAG architecture patterns</li> <li>Week 7-8: Value Stream Management resources</li> <li>Week 9-10: SPACE framework papers</li> <li>Week 11-12: Continuous Discovery research</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#communities-to-engage","title":"Communities to Engage","text":"<ul> <li>Platform Engineering community (platformengineering.org)</li> <li>CNCF Slack channels</li> <li>ArgoCD/Backstage GitHub discussions</li> <li>r/devops and r/kubernetes</li> </ul>"},{"location":"implementation-plan/fawkes-handoff-doc/#version-history","title":"\ud83d\udcdd Version History","text":"Version Date Changes Author 1.0 Dec 2024 Initial comprehensive plan AI Assistant <p>END OF HANDOFF DOCUMENT</p> <p>Save this to: <code>docs/implementation-plan/IMPLEMENTATION_HANDOFF.md</code></p>"},{"location":"implementation-plan/week1-detailed-tasks/","title":"Week 1 Detailed Tasks - Epic 1: Infrastructure &amp; GitOps","text":"<p>Epic: Epic 1 - DORA 2023 Foundation Week: 1 of 4 Milestone: 1.1 - Local Infrastructure &amp; 1.2 - GitOps Foundation Duration: 5 working days Goal: Deploy local K8s cluster with ArgoCD managing platform</p>"},{"location":"implementation-plan/week1-detailed-tasks/#day-by-day-breakdown","title":"\ud83d\udcc5 Day-by-Day Breakdown","text":""},{"location":"implementation-plan/week1-detailed-tasks/#day-1-local-kubernetes-cluster-setup","title":"Day 1: Local Kubernetes Cluster Setup","text":"<p>Issues: #1, #2, #3 Estimated Time: 6-8 hours Goal: Functional 4-node local K8s cluster with ingress and storage</p>"},{"location":"implementation-plan/week1-detailed-tasks/#morning-4-hours-issue-1-k8s-cluster","title":"Morning (4 hours): Issue #1 - K8s Cluster","text":"<p>Task 1.1: Create Terraform module (90 min) <pre><code># Location: infra/local/cluster/\n\n# Create directory structure\nmkdir -p infra/local/cluster/{terraform,inspec/controls,scripts}\n\n# File: infra/local/cluster/terraform/main.tf\n</code></pre></p> <p>Copilot Prompt for main.tf: <pre><code>Create a Terraform configuration for deploying a local Kubernetes cluster using kind:\n\nRequirements:\n1. Create a kind cluster named \"fawkes-local\"\n2. Configure 4 worker nodes\n3. Each node: 4 CPU, 8GB memory\n4. Enable ingress (extraPortMappings for ports 80, 443)\n5. Configure local-path-provisioner as default StorageClass\n6. Output the kubeconfig path\n\nInclude:\n- variables.tf (cluster_name, node_count, resources_per_node)\n- outputs.tf (kubeconfig_path, cluster_name, node_count)\n- versions.tf (terraform &gt;= 1.0, required providers)\n\nUse kind_cluster resource from tehcyx/kind provider.\nAdd comments explaining each configuration block.\n</code></pre></p> <p>Task 1.2: Create InSpec validation (45 min) <pre><code># Location: infra/local/cluster/inspec/controls/cluster.rb\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create an InSpec test suite for validating Kubernetes cluster deployment:\n\nTest cases:\n1. Exactly 4 nodes exist in the cluster\n2. All nodes have status \"Ready\"\n3. All system pods in kube-system namespace are \"Running\"\n4. A StorageClass named \"local-path\" exists and is marked as default\n5. Kubernetes version is &gt;= 1.28.0\n6. No nodes have MemoryPressure or DiskPressure conditions\n\nUse kubectl commands via command() InSpec resource.\nInclude descriptive test descriptions and impact levels.\n</code></pre></p> <p>Task 1.3: Create deployment script (90 min) <pre><code># Location: scripts/deploy-local-cluster.sh\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create a bash deployment script that:\n\n1. Checks prerequisites:\n   - Docker is installed and running\n   - kind CLI is installed (&gt;= 0.20.0)\n   - kubectl is installed (&gt;= 1.28.0)\n   - terraform is installed (&gt;= 1.0.0)\n   - inspec is installed (&gt;= 5.0.0)\n\n2. Deployment steps:\n   - cd to infra/local/cluster/terraform\n   - Run terraform init\n   - Run terraform plan\n   - Run terraform apply -auto-approve\n   - Export KUBECONFIG from terraform output\n   - Wait for all nodes to be Ready (timeout 5 minutes)\n   - Wait for all system pods Running (timeout 5 minutes)\n\n3. Validation:\n   - Run InSpec tests\n   - Print cluster info (nodes, pods, storageclasses)\n\n4. Error handling:\n   - Trap errors and provide clear messages\n   - Offer rollback option on failure\n   - Log all output to logs/cluster-deployment.log\n\nUse colors for output (green=success, red=error, yellow=warning).\nInclude functions for each major step.\n</code></pre></p> <p>Task 1.4: Create documentation (45 min) <pre><code># Location: docs/runbooks/local-cluster-setup.md\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create comprehensive documentation for local K8s cluster setup:\n\nSections:\n1. Overview (what, why, architecture diagram in mermaid)\n2. Prerequisites (system requirements, software versions)\n3. Quick Start (5-minute getting started)\n4. Detailed Setup (step-by-step with commands)\n5. Verification (how to validate deployment)\n6. Troubleshooting (common issues and solutions)\n7. Cluster Management (start, stop, destroy, reset)\n8. Advanced Configuration (resource tuning, multi-cluster)\n9. References (links to kind docs, k8s docs)\n\nUse clear language, code blocks with bash syntax highlighting.\nInclude expected output for verification commands.\nAdd troubleshooting for:\n- Docker not running\n- Insufficient resources\n- Port conflicts\n- StorageClass issues\n</code></pre></p> <p>Validation Commands: <pre><code># Test Terraform\ncd infra/local/cluster/terraform\nterraform init\nterraform validate\n\n# Test deployment script\nchmod +x scripts/deploy-local-cluster.sh\n./scripts/deploy-local-cluster.sh\n\n# Verify cluster\nkubectl get nodes\n# Expected: 4 nodes, all Ready\n\nkubectl get pods -A\n# Expected: All Running\n\nkubectl get storageclass\n# Expected: local-path (default)\n\n# Run InSpec tests\ninspec exec infra/local/cluster/inspec/ -t k8s://\n\n# Check resource usage\nkubectl top nodes\n# Expected: &lt;50% CPU, &lt;50% Memory\n</code></pre></p>"},{"location":"implementation-plan/week1-detailed-tasks/#afternoon-2-3-hours-issues-2-3-ingress-storage","title":"Afternoon (2-3 hours): Issues #2 &amp; #3 - Ingress &amp; Storage","text":"<p>Task 2.1: Deploy nginx-ingress (90 min) <pre><code># Location: platform/apps/ingress-nginx/\nmkdir -p platform/apps/ingress-nginx\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create ArgoCD Application and Helm values for nginx-ingress-controller:\n\nFiles needed:\n1. values.yaml - Helm values for ingress-nginx chart\n   - Enable metrics for Prometheus\n   - Configure for local development (NodePort)\n   - Set resource limits (500m CPU, 512Mi memory)\n   - Enable default SSL certificate\n\n2. application.yaml - ArgoCD Application manifest\n   - Name: ingress-nginx\n   - Namespace: ingress-nginx (create if not exists)\n   - Source: helm chart ingress-nginx/ingress-nginx\n   - Sync policy: automated, self-heal\n   - Sync options: CreateNamespace=true\n\n3. test-ingress.yaml - Test ingress resource\n   - Host: test.local\n   - Path: /\n   - Backend: test service (port 80)\n   - Include TLS with self-signed cert\n\n4. README.md - Setup and usage instructions\n</code></pre></p> <p>Task 3.1: Configure persistent storage (60 min) <pre><code># Location: platform/apps/local-path-storage/\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create configuration for local-path-provisioner:\n\nFiles:\n1. application.yaml - ArgoCD Application\n   - Deploy rancher/local-path-provisioner\n   - Set as default StorageClass\n   - Configure storage path: /opt/local-path-provisioner\n\n2. test-pvc.yaml - Test PersistentVolumeClaim\n   - Name: test-pvc\n   - Size: 1Gi\n   - AccessMode: ReadWriteOnce\n   - StorageClass: local-path\n\n3. test-pod.yaml - Pod that uses test-pvc\n   - Mount PVC at /data\n   - Run busybox\n   - Create test file in /data\n\nInclude cleanup script to delete test resources.\n</code></pre></p> <p>End of Day 1 Validation: <pre><code># Cluster healthy\nkubectl get nodes\nkubectl get pods -A\n\n# Ingress working\ncurl http://localhost:80\n# Or: curl http://test.local (if configured in /etc/hosts)\n\n# Storage working\nkubectl apply -f platform/apps/local-path-storage/test-pvc.yaml\nkubectl get pvc\n# Should show: Bound\n\n# Run acceptance test AT-E1-001\n./tests/acceptance/run-test.sh AT-E1-001\n</code></pre></p>"},{"location":"implementation-plan/week1-detailed-tasks/#day-2-argocd-deployment-git-structure","title":"Day 2: ArgoCD Deployment &amp; Git Structure","text":"<p>Issues: #5, #6, #7 Estimated Time: 6-8 hours Goal: ArgoCD managing all platform components via GitOps</p>"},{"location":"implementation-plan/week1-detailed-tasks/#morning-4-hours-issue-5-deploy-argocd","title":"Morning (4 hours): Issue #5 - Deploy ArgoCD","text":"<p>Task 5.1: Deploy ArgoCD (90 min) <pre><code># Location: platform/apps/argocd/\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create ArgoCD deployment configuration:\n\n1. install.yaml - ArgoCD installation manifest\n   - Use official ArgoCD install manifest (v2.9+)\n   - Namespace: argocd\n   - High availability disabled (for local)\n   - Ingress enabled\n\n2. ingress.yaml - Ingress for ArgoCD UI\n   - Host: argocd.local\n   - HTTPS with self-signed cert\n   - Backend: argocd-server:443\n\n3. initial-admin-secret.yaml (optional)\n   - Configure initial admin password\n   - Store securely or document retrieval method\n\n4. argocd-cm.yaml - ConfigMap for ArgoCD settings\n   - Enable anonymous read access (for local dev)\n   - Configure repository credentials\n   - Set default app project\n\n5. deploy.sh - Deployment script\n   - Apply install.yaml\n   - Wait for ArgoCD pods Ready\n   - Get initial admin password\n   - Configure argocd CLI\n   - Login and change password\n   - Print ArgoCD URL\n\nInclude README with:\n- How to access UI\n- How to login via CLI\n- Initial configuration steps\n</code></pre></p> <p>Task 5.2: Configure ArgoCD CLI (30 min) <pre><code># Location: scripts/configure-argocd.sh\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create script to configure ArgoCD CLI:\n\n1. Install argocd CLI if not present\n2. Port-forward to argocd-server (8080:443)\n3. Login with credentials\n4. Add local cluster\n5. Create app project \"platform\"\n6. Set up repository credentials for GitHub\n7. Verify configuration\n\nInclude error handling and validation steps.\n</code></pre></p> <p>Validation: <pre><code># Deploy ArgoCD\nkubectl apply -f platform/apps/argocd/install.yaml\nkubectl wait --for=condition=Ready pods -n argocd --all --timeout=300s\n\n# Access UI\nkubectl port-forward -n argocd svc/argocd-server 8080:443 &amp;\n# Open browser: https://localhost:8080\n\n# CLI login\nargocd login localhost:8080 --username admin --password $(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d)\n\n# Verify\nargocd cluster list\nargocd app list\n</code></pre></p>"},{"location":"implementation-plan/week1-detailed-tasks/#afternoon-3-4-hours-issues-6-7-git-structure-app-of-apps","title":"Afternoon (3-4 hours): Issues #6 &amp; #7 - Git Structure &amp; App-of-Apps","text":"<p>Task 6.1: Create Git repository structure (90 min) <pre><code># Location: platform/apps/\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create comprehensive Git repository structure for platform components:\n\nDirectory structure:\nplatform/\n\u251c\u2500\u2500 apps/\n\u2502   \u251c\u2500\u2500 argocd/                 # ArgoCD itself\n\u2502   \u251c\u2500\u2500 ingress-nginx/          # Ingress controller\n\u2502   \u251c\u2500\u2500 local-path-storage/     # Storage provisioner\n\u2502   \u251c\u2500\u2500 backstage/              # Developer portal (future)\n\u2502   \u251c\u2500\u2500 jenkins/                # CI/CD (future)\n\u2502   \u251c\u2500\u2500 harbor/                 # Container registry (future)\n\u2502   \u251c\u2500\u2500 sonarqube/              # Code quality (future)\n\u2502   \u251c\u2500\u2500 prometheus/             # Monitoring (future)\n\u2502   \u251c\u2500\u2500 grafana/                # Dashboards (future)\n\u2502   \u2514\u2500\u2500 dora-metrics/           # DORA service (future)\n\u251c\u2500\u2500 bootstrap/\n\u2502   \u251c\u2500\u2500 app-of-apps.yaml        # Root application\n\u2502   \u2514\u2500\u2500 README.md               # Bootstrap instructions\n\u2514\u2500\u2500 README.md                   # Platform apps overview\n\nEach app directory contains:\n- application.yaml (ArgoCD Application manifest)\n- values.yaml (Helm values if using Helm)\n- kustomization.yaml (if using Kustomize)\n- README.md (app-specific documentation)\n\nCreate placeholder directories for future apps.\nAdd .gitkeep files to maintain empty directories.\n</code></pre></p> <p>Task 6.2: Create app templates (60 min) <pre><code># Location: platform/templates/\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create reusable templates for ArgoCD Applications:\n\n1. helm-app-template.yaml\n   - Template for Helm-based apps\n   - Variables: {APP_NAME}, {NAMESPACE}, {CHART_REPO}, {CHART_NAME}\n   - Standard sync policy\n   - Automated pruning and self-heal\n\n2. kustomize-app-template.yaml\n   - Template for Kustomize-based apps\n   - Variables: {APP_NAME}, {NAMESPACE}, {PATH}\n\n3. generate-app.sh\n   - Script to generate application from template\n   - Usage: ./generate-app.sh --name myapp --type helm --chart mychart\n\nInclude documentation on template usage.\n</code></pre></p> <p>Task 7.1: Implement app-of-apps pattern (90 min) <pre><code># Location: platform/bootstrap/\n</code></pre></p> <p>Copilot Prompt: <pre><code>Create app-of-apps pattern for managing all platform applications:\n\n1. app-of-apps.yaml - Root ArgoCD Application\n   - Name: platform-bootstrap\n   - Source: platform/apps/\n   - Destination: Multiple namespaces\n   - Sync wave: 0 (deploy first)\n   - Automated sync with prune\n   - Uses ApplicationSet for dynamic app discovery\n\n2. applicationset.yaml - ApplicationSet for auto-discovery\n   - Git directory generator\n   - Path: platform/apps/*/application.yaml\n   - Exclude certain directories (templates, common)\n   - Preserve application order with sync waves\n\n3. bootstrap.sh - Bootstrap script\n   - Apply app-of-apps.yaml\n   - Wait for sync\n   - Verify all apps deployed\n   - Print status\n\n4. README.md - App-of-apps documentation\n   - Explain the pattern\n   - How to add new apps\n   - Sync wave ordering\n   - Troubleshooting\n\nInclude sync waves:\n- Wave 0: Infrastructure (ArgoCD, ingress, storage)\n- Wave 1: Platform services (Backstage, Jenkins)\n- Wave 2: Observability (Prometheus, Grafana)\n- Wave 3: Applications\n</code></pre></p> <p>End of Day 2 Validation: <pre><code># Apply app-of-apps\nkubectl apply -f platform/bootstrap/app-of-apps.yaml\n\n# Wait for sync\nargocd app wait platform-bootstrap --timeout 300\n\n# Verify all apps\nargocd app list\n\n# Check sync status\nargocd app get platform-bootstrap\n\n# Verify applications in cluster\nkubectl get applications -n argocd\n\n# Run acceptance test AT-E1-002\n./tests/acceptance/run-test.sh AT-E1-002\n</code></pre></p>"},{"location":"implementation-plan/week1-detailed-tasks/#day-3-documentation-validation","title":"Day 3: Documentation &amp; Validation","text":"<p>Issue: #8, plus documentation Estimated Time: 6-8 hours Goal: Complete documentation and validate Week 1 deliverables</p>"},{"location":"implementation-plan/week1-detailed-tasks/#morning-4-hours-documentation","title":"Morning (4 hours): Documentation","text":"<p>Task: Create comprehensive Week 1 documentation</p> <ol> <li>Architecture Diagrams (90 min) <pre><code># Location: docs/architecture/diagrams/\n</code></pre></li> </ol> <p>Create: - infrastructure-overview.mermaid (C4 Context) - kubernetes-cluster.mermaid (Nodes, pods, services) - gitops-workflow.mermaid (Git \u2192 ArgoCD \u2192 K8s) - network-topology.mermaid (Ingress, services, pods)</p> <p>Copilot Prompt: <pre><code>Create Mermaid diagrams for Fawkes architecture:\n\n1. infrastructure-overview.mermaid\n   - C4 Context diagram\n   - Show: Developer, Git Repo, K8s Cluster, Platform Components\n   - Relationships and data flows\n\n2. kubernetes-cluster.mermaid\n   - Show 4-node cluster\n   - Control plane components\n   - Worker node components\n   - Storage and networking\n\n3. gitops-workflow.mermaid\n   - Sequence diagram\n   - Developer commits \u2192 Git push \u2192 ArgoCD sync \u2192 K8s apply\n   - Include rollback flow\n\n4. network-topology.mermaid\n   - Show ingress controller\n   - Service mesh (if applicable)\n   - Pod networking\n   - External access points\n</code></pre></p> <ol> <li>Runbook Updates (90 min)</li> </ol> <p>Update these runbooks: - docs/runbooks/local-cluster-setup.md - docs/runbooks/argocd-management.md (new) - docs/runbooks/gitops-workflow.md (new) - docs/runbooks/troubleshooting-week1.md (new)</p> <ol> <li>README Updates (60 min)</li> </ol> <p>Update: - platform/apps/README.md - infra/README.md - Root README.md (add Week 1 status)</p>"},{"location":"implementation-plan/week1-detailed-tasks/#afternoon-3-4-hours-validation-testing","title":"Afternoon (3-4 hours): Validation &amp; Testing","text":"<p>Task 8.1: Run all acceptance tests (90 min)</p> <pre><code># Run AT-E1-001\n./tests/acceptance/run-test.sh AT-E1-001\n\n# Run AT-E1-002\n./tests/acceptance/run-test.sh AT-E1-002\n\n# Generate test report\n./tests/acceptance/generate-report.sh --week 1\n</code></pre> <p>Task 8.2: Resource optimization (60 min)</p> <pre><code># Check resource usage\nkubectl top nodes\nkubectl top pods -A\n\n# Optimize if needed:\n# - Reduce replica counts\n# - Adjust resource requests/limits\n# - Enable pod disruption budgets\n\n# Document optimizations in:\n# docs/optimization/week1-resource-tuning.md\n</code></pre> <p>Task 8.3: Create demo video (90 min)</p> <p>Record screen capture demonstrating: 1. Cluster deployment (2 min) 2. ArgoCD UI tour (3 min) 3. Deploying an app via GitOps (5 min) 4. Viewing synced resources (2 min) 5. Rollback demonstration (3 min)</p> <p>Upload to: docs/videos/week1-demo.mp4</p> <p>End of Day 3 Validation: <pre><code># All tests passing\n./tests/acceptance/run-all-week1.sh\n\n# Documentation complete\nfind docs/ -name \"*.md\" | wc -l  # Should be increased\n\n# Resource usage acceptable\nkubectl top nodes  # All &lt;70%\n\n# Demo video created\ntest -f docs/videos/week1-demo.mp4\n</code></pre></p>"},{"location":"implementation-plan/week1-detailed-tasks/#days-4-5-buffer-week-2-prep","title":"Days 4-5: Buffer &amp; Week 2 Prep","text":"<p>Use for: - Catching up on any delayed tasks - Fixing bugs discovered during testing - Additional documentation - Preparing for Week 2 (Backstage, Jenkins) - Team review (if applicable)</p>"},{"location":"implementation-plan/week1-detailed-tasks/#week-1-definition-of-done","title":"\u2705 Week 1 Definition of Done","text":"<ul> <li>[ ] Local 4-node K8s cluster deployed and healthy</li> <li>[ ] Ingress controller serving traffic</li> <li>[ ] Persistent storage working</li> <li>[ ] ArgoCD managing all platform components</li> <li>[ ] Git repository structure established</li> <li>[ ] App-of-apps pattern implemented</li> <li>[ ] AT-E1-001 acceptance test passing</li> <li>[ ] AT-E1-002 acceptance test passing</li> <li>[ ] All documentation complete</li> <li>[ ] Demo video created</li> <li>[ ] Resource usage &lt;70% CPU/Memory</li> <li>[ ] Zero critical bugs outstanding</li> </ul>"},{"location":"implementation-plan/week1-detailed-tasks/#progress-tracking","title":"\ud83d\udcca Progress Tracking","text":"<p>Update daily in PROJECT_STATUS.md:</p> <pre><code>### Week 1 Progress\n\n**Day 1**: \u2705 Cluster deployment complete\n- Issue #1: \u2705 Complete\n- Issue #2: \u2705 Complete\n- Issue #3: \u2705 Complete\n\n**Day 2**: \u2705 ArgoCD and GitOps complete\n- Issue #5: \u2705 Complete\n- Issue #6: \u2705 Complete\n- Issue #7: \u2705 Complete\n\n**Day 3**: \u2705 Documentation and validation\n- Issue #8: \u2705 Complete\n- All Week 1 docs: \u2705 Complete\n\n**Days 4-5**: Buffer used for [describe what was done]\n\n**Week 1 Status**: \u2705 COMPLETE\n</code></pre>"},{"location":"implementation-plan/week1-detailed-tasks/#handoff-to-week-2","title":"\ud83d\ude80 Handoff to Week 2","text":"<p>Once Week 1 is complete, you're ready for:</p> <p>Week 2 Focus: Developer Portal &amp; CI/CD - Issue #9: Deploy Backstage - Issue #14: Deploy Jenkins - Issue #17: Deploy Harbor</p> <p>Prerequisites Met: - \u2705 K8s cluster operational - \u2705 GitOps workflow established - \u2705 Can deploy new apps via ArgoCD</p> <p>Start Week 2 with: <pre><code># Begin Backstage deployment\nargocd app create backstage \\\n  --repo https://github.com/paruff/fawkes \\\n  --path platform/apps/backstage \\\n  --dest-server https://kubernetes.default.svc \\\n  --dest-namespace backstage \\\n  --sync-policy automated\n</code></pre></p>"},{"location":"implementation-plan/week1-detailed-tasks/#getting-help","title":"\ud83c\udd98 Getting Help","text":"<p>If stuck on any task:</p> <ol> <li>Check docs: Search docs/ for related content</li> <li>Review ADRs: See why decisions were made</li> <li>Test commands: Validation commands in each task</li> <li>New chat: Start fresh chat with specific question</li> <li>GitHub search: Look for similar issues/PRs</li> </ol> <p>Chat template: <pre><code>Working on Fawkes Epic 1, Week 1, Day X.\n\nCurrent task: Issue #Y - [Title]\nProblem: [Specific issue]\nWhat I've tried: [Commands/approaches]\nError message: [If applicable]\n\nContext: See Week 1 Detailed Tasks document.\n</code></pre></p> <p>END OF WEEK 1 DETAILED TASKS</p>"},{"location":"observability/centralized-logging/","title":"Centralized Log Management with OpenTelemetry","text":""},{"location":"observability/centralized-logging/#overview","title":"Overview","text":"<p>Fawkes implements centralized, structured logging for all Kubernetes workloads using OpenTelemetry Collector and OTLP. This enables reliable correlation of log events with traces and metrics, accelerating Mean Time to Resolution (MTTR) for application and platform incidents.</p> <p>Reference: See ADR-011 Centralized Log Management for architectural decisions.</p>"},{"location":"observability/centralized-logging/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Kubernetes Cluster                                            \u2502\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502  \u2502 Application  \u2502  \u2502 Application  \u2502  \u2502 Platform     \u2502        \u2502\n\u2502  \u2502 Pod          \u2502  \u2502 Pod          \u2502  \u2502 Service Pod  \u2502        \u2502\n\u2502  \u2502              \u2502  \u2502              \u2502  \u2502              \u2502        \u2502\n\u2502  \u2502 stdout/stderr\u2502  \u2502 stdout/stderr\u2502  \u2502 stdout/stderr\u2502        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502         \u2502                  \u2502                  \u2502                 \u2502\n\u2502         \u25bc                  \u25bc                  \u25bc                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502 /var/log/containers/*.log                            \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502         \u2502                                                       \u2502\n\u2502         \u25bc                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502 OpenTelemetry Collector DaemonSet                   \u2502      \u2502\n\u2502  \u2502 - filelog receiver: Tail container logs             \u2502      \u2502\n\u2502  \u2502 - k8sattributes: Add Kubernetes metadata            \u2502      \u2502\n\u2502  \u2502 - otlphttp exporter: Send to OpenSearch             \u2502      \u2502\n\u2502  \u2502 - memory_limiter: Buffer during outages             \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502                      \u2502 OTLP/HTTP                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  OpenSearch Cluster                                              \u2502\n\u2502  - Centralized log storage and search                           \u2502\n\u2502  - OpenSearch Dashboards for visualization                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"observability/centralized-logging/#key-features","title":"Key Features","text":""},{"location":"observability/centralized-logging/#1-log-forwarding","title":"1. Log Forwarding","text":"<p>The OpenTelemetry Collector Agent runs as a DaemonSet on every node and collects logs from all containers:</p> <ul> <li>Source: <code>/var/log/containers/*.log</code></li> <li>Format: Kubernetes container log format (CRI/Docker JSON)</li> <li>Receiver: <code>filelog</code> receiver with custom operators</li> </ul>"},{"location":"observability/centralized-logging/#2-kubernetes-context-enrichment","title":"2. Kubernetes Context Enrichment","text":"<p>Every log record is enriched with Kubernetes metadata via the <code>k8sattributes</code> processor:</p> Attribute Description <code>k8s.pod.name</code> Pod name <code>k8s.namespace.name</code> Namespace name <code>k8s.container.name</code> Container name <code>k8s.deployment.name</code> Deployment name (if applicable) <code>k8s.node.name</code> Node where pod is running <code>cluster</code> Cluster identifier <code>environment</code> Environment (development, staging, production)"},{"location":"observability/centralized-logging/#3-trace-correlation","title":"3. Trace Correlation","text":"<p>Logs are automatically correlated with traces when applications use OpenTelemetry instrumentation:</p> <ul> <li>traceId: 32-character hexadecimal trace identifier</li> <li>spanId: 16-character hexadecimal span identifier</li> </ul> <p>This enables seamless navigation from logs to traces in observability tools.</p>"},{"location":"observability/centralized-logging/#4-failure-handling","title":"4. Failure Handling","text":"<p>The collector is configured for resilience during backend unavailability:</p> <ul> <li>Memory Limiter: 800MiB limit with 200MiB spike limit</li> <li>Batch Processor: Queue-based batching for efficient export</li> <li>Retry on Failure: Automatic retries with exponential backoff</li> <li>Sending Queue: 5000-item queue for 5+ minute buffering</li> </ul>"},{"location":"observability/centralized-logging/#configuration","title":"Configuration","text":""},{"location":"observability/centralized-logging/#opentelemetry-collector","title":"OpenTelemetry Collector","text":"<p>The collector configuration is defined in:</p> <pre><code>platform/apps/opentelemetry/otel-collector-application.yaml\n</code></pre> <p>Key configuration sections:</p>"},{"location":"observability/centralized-logging/#filelog-receiver","title":"Filelog Receiver","text":"<pre><code>filelog:\n  include:\n    - /var/log/containers/*.log\n  exclude:\n    - /var/log/containers/*otel-collector*.log\n  start_at: end\n  include_file_path: true\n</code></pre>"},{"location":"observability/centralized-logging/#k8s-attributes-processor","title":"K8s Attributes Processor","text":"<pre><code>k8sattributes:\n  extract:\n    metadata:\n      - k8s.namespace.name\n      - k8s.pod.name\n      - k8s.container.name\n      - k8s.deployment.name\n      # ... more attributes\n</code></pre>"},{"location":"observability/centralized-logging/#opensearch-exporter","title":"OpenSearch Exporter","text":"<pre><code>opensearch:\n  http:\n    endpoint: \"http://opensearch-cluster-master.logging.svc.cluster.local:9200\"\n  logs_index: \"otel-logs\"\n  retry:\n    enabled: true\n    max_elapsed_time: 300s\n  sending_queue:\n    enabled: true\n    queue_size: 5000\n</code></pre>"},{"location":"observability/centralized-logging/#opensearch-index-templates","title":"OpenSearch Index Templates","text":"<p>Index templates are defined in:</p> <pre><code>platform/apps/opensearch/index-template.yaml\n</code></pre> <p>Templates ensure proper mapping for: - OTLP log format (<code>otel-logs-*</code>) - Application logs (<code>application-logs-*</code>) - Kubernetes logs (<code>kubernetes-logs-*</code>)</p>"},{"location":"observability/centralized-logging/#usage","title":"Usage","text":""},{"location":"observability/centralized-logging/#searching-logs-in-opensearch","title":"Searching Logs in OpenSearch","text":"<p>Access OpenSearch Dashboards and use these query patterns:</p> <p>Find logs from a specific namespace:</p> <pre><code>resource.attributes.k8s.namespace.name: \"my-namespace\"\n</code></pre> <p>Find logs with a specific trace ID:</p> <pre><code>traceId: \"&lt;your-32-character-trace-id&gt;\"\n</code></pre> <p>Find error logs from a deployment:</p> <pre><code>resource.attributes.k8s.deployment.name: \"my-app\" AND severityText: \"ERROR\"\n</code></pre>"},{"location":"observability/centralized-logging/#structured-logging-best-practices","title":"Structured Logging Best Practices","text":"<p>For optimal trace correlation, applications should emit structured JSON logs:</p> <pre><code>{\n  \"@timestamp\": \"2024-12-07T10:30:00.123Z\",\n  \"level\": \"INFO\",\n  \"message\": \"User login successful\",\n  \"traceId\": \"&lt;32-character-hex-trace-id&gt;\",\n  \"spanId\": \"&lt;16-character-hex-span-id&gt;\",\n  \"userId\": \"user-123\"\n}\n</code></pre>"},{"location":"observability/centralized-logging/#required-fields","title":"Required Fields","text":"Field Type Description <code>level</code> keyword Log level (ERROR, WARN, INFO, DEBUG) <code>message</code> text Human-readable message <code>traceId</code> keyword OpenTelemetry trace ID (optional) <code>spanId</code> keyword OpenTelemetry span ID (optional)"},{"location":"observability/centralized-logging/#environment-variables","title":"Environment Variables","text":"<p>The following environment variables are used by the collector:</p> Variable Description <code>K8S_NODE_NAME</code> Current node name (auto-populated) <code>NODE_IP</code> Node IP address (auto-populated)"},{"location":"observability/centralized-logging/#monitoring","title":"Monitoring","text":""},{"location":"observability/centralized-logging/#collector-health","title":"Collector Health","text":"<p>Check collector health:</p> <pre><code>kubectl port-forward -n monitoring daemonset/otel-collector 13133:13133\ncurl http://localhost:13133/\n</code></pre>"},{"location":"observability/centralized-logging/#zpages-for-debugging","title":"ZPages for Debugging","text":"<p>Access collector internal diagnostics:</p> <pre><code>kubectl port-forward -n monitoring daemonset/otel-collector 55679:55679\n# Open http://localhost:55679/debug/tracez\n</code></pre>"},{"location":"observability/centralized-logging/#metrics","title":"Metrics","text":"<p>The collector exposes Prometheus metrics at port 8888: - <code>otelcol_receiver_accepted_log_records</code>: Logs received - <code>otelcol_exporter_sent_log_records</code>: Logs exported - <code>otelcol_exporter_queue_size</code>: Current queue size</p>"},{"location":"observability/centralized-logging/#troubleshooting","title":"Troubleshooting","text":""},{"location":"observability/centralized-logging/#logs-not-appearing-in-opensearch","title":"Logs Not Appearing in OpenSearch","text":"<ol> <li>Check collector pods are running:</li> </ol> <pre><code>kubectl get pods -n monitoring -l app.kubernetes.io/name=opentelemetry-collector\n</code></pre> <ol> <li>Check collector logs:</li> </ol> <pre><code>kubectl logs -n monitoring -l app.kubernetes.io/name=opentelemetry-collector --tail=100\n</code></pre> <ol> <li>Verify OpenSearch connectivity:</li> </ol> <pre><code>kubectl exec -n monitoring -it &lt;collector-pod&gt; -- curl http://opensearch-cluster-master.logging.svc.cluster.local:9200/_cluster/health\n</code></pre>"},{"location":"observability/centralized-logging/#missing-kubernetes-attributes","title":"Missing Kubernetes Attributes","text":"<p>Ensure the collector service account has proper RBAC permissions to read pod metadata.</p>"},{"location":"observability/centralized-logging/#high-memory-usage","title":"High Memory Usage","text":"<p>If the collector is using too much memory, adjust the <code>memory_limiter</code> settings or increase resource limits.</p>"},{"location":"observability/centralized-logging/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Overview</li> <li>ADR-011 Centralized Log Management</li> <li>Module 13: Observability</li> </ul>"},{"location":"observability/distributed-tracing/","title":"Distributed Tracing with OpenTelemetry and Tempo","text":""},{"location":"observability/distributed-tracing/#overview","title":"Overview","text":"<p>Fawkes implements centralized distributed tracing for all platform services and applications using OpenTelemetry for instrumentation and Grafana Tempo for trace storage. This enables end-to-end request visibility across service boundaries, performance analysis, and rapid root cause identification.</p> <p>Reference: See ADR-013 Distributed Tracing for architectural decisions.</p>"},{"location":"observability/distributed-tracing/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Applications &amp; Platform Services                                   \u2502\n\u2502                                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Backstage  \u2502  \u2502 Jenkins    \u2502  \u2502 ArgoCD     \u2502  \u2502 Custom Apps  \u2502 \u2502\n\u2502  \u2502 (Node.js)  \u2502  \u2502 (Java)     \u2502  \u2502 (Go)       \u2502  \u2502 (Any Lang)   \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502        \u2502               \u2502               \u2502                \u2502          \u2502\n\u2502        \u2502 OpenTelemetry SDK / Auto-instrumentation       \u2502          \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                              \u2502                                      \u2502\n\u2502                              \u2502 OTLP (gRPC/HTTP)                    \u2502\n\u2502                              \u25bc                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 OpenTelemetry Collector DaemonSet                           \u2502  \u2502\n\u2502  \u2502 - OTLP receiver: Accepts traces from applications           \u2502  \u2502\n\u2502  \u2502 - K8s attributes: Enriches with pod/namespace metadata      \u2502  \u2502\n\u2502  \u2502 - Sampling: Configurable probabilistic sampling             \u2502  \u2502\n\u2502  \u2502 - Security: Scrubs sensitive data (auth headers, etc.)      \u2502  \u2502\n\u2502  \u2502 - Batching: Efficient export to Tempo                       \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502 OTLP/gRPC                           \u2502\n\u2502                              \u25bc                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Grafana Tempo                                                \u2502  \u2502\n\u2502  \u2502 - Trace storage and querying                                 \u2502  \u2502\n\u2502  \u2502 - TraceQL for advanced queries                               \u2502  \u2502\n\u2502  \u2502 - Service dependency graphs                                  \u2502  \u2502\n\u2502  \u2502 - Metrics generation (RED metrics from traces)               \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                      \u2502\n\u2502                              \u25bc                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Grafana                                                      \u2502  \u2502\n\u2502  \u2502 - Trace visualization and flame graphs                       \u2502  \u2502\n\u2502  \u2502 - Trace-to-logs correlation (OpenSearch)                     \u2502  \u2502\n\u2502  \u2502 - Trace-to-metrics correlation (Prometheus)                  \u2502  \u2502\n\u2502  \u2502 - Service dependency node graph                              \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"observability/distributed-tracing/#key-features","title":"Key Features","text":""},{"location":"observability/distributed-tracing/#1-trace-generation-and-collection","title":"1. Trace Generation and Collection","text":"<p>The OpenTelemetry Collector receives traces via OTLP protocol from instrumented applications:</p> <ul> <li>Protocol: OTLP over gRPC (port 4317) and HTTP (port 4318)</li> <li>Format: W3C Trace Context standard (<code>traceparent</code>, <code>tracestate</code> headers)</li> <li>Enrichment: Automatic Kubernetes metadata (pod, namespace, deployment)</li> </ul>"},{"location":"observability/distributed-tracing/#2-cross-service-propagation","title":"2. Cross-Service Propagation","text":"<p>Traces are automatically propagated across service boundaries using W3C Trace Context:</p> Header Purpose <code>traceparent</code> Contains trace ID, span ID, and trace flags <code>tracestate</code> Vendor-specific trace context"},{"location":"observability/distributed-tracing/#3-trace-log-correlation","title":"3. Trace-Log Correlation","text":"<p>Every trace is correlated with application logs:</p> Attribute Description <code>trace_id</code> 32-character hexadecimal trace identifier <code>span_id</code> 16-character hexadecimal span identifier <p>Click on a trace ID in logs to jump directly to the trace in Grafana.</p>"},{"location":"observability/distributed-tracing/#4-performance-visibility","title":"4. Performance Visibility","text":"<p>Traces include key performance attributes:</p> <ul> <li>HTTP method, status code, and route</li> <li>Database query duration and statement (hashed)</li> <li>External service call latency</li> <li>Custom span attributes</li> </ul>"},{"location":"observability/distributed-tracing/#5-sampling-strategy","title":"5. Sampling Strategy","text":"<p>Development environment uses 100% sampling for full visibility. Production can be configured for:</p> <ul> <li>Head-based sampling: 10% of all requests</li> <li>Always sample: Errors and requests &gt; 1 second latency</li> <li>Tail-based sampling: Keep interesting traces after collection</li> </ul>"},{"location":"observability/distributed-tracing/#configuration","title":"Configuration","text":""},{"location":"observability/distributed-tracing/#opentelemetry-collector","title":"OpenTelemetry Collector","text":"<p>The traces pipeline is configured in:</p> <pre><code>platform/apps/opentelemetry/otel-collector-application.yaml\n</code></pre> <p>Key configuration:</p> <pre><code># Traces pipeline configuration\ntraces:\n  receivers:\n    - otlp\n  processors:\n    - memory_limiter\n    - probabilistic_sampler\n    - k8sattributes\n    - resourcedetection\n    - attributes/traces\n    - transform/traces\n    - batch/traces\n  exporters:\n    - otlp/tempo\n</code></pre>"},{"location":"observability/distributed-tracing/#grafana-tempo","title":"Grafana Tempo","text":"<p>Tempo is deployed as the trace storage backend:</p> <pre><code>platform/apps/tempo/tempo-application.yaml\n</code></pre> <p>Key features: - OTLP ingestion on ports 4317 (gRPC) and 4318 (HTTP) - 7-day trace retention - Metrics generation for RED metrics - TraceQL query support</p>"},{"location":"observability/distributed-tracing/#grafana-data-sources","title":"Grafana Data Sources","text":"<p>Grafana is configured with trace correlation:</p> <pre><code>platform/apps/grafana/helm-release.yml\n</code></pre> <p>Data sources configured: - Tempo: Trace storage and visualization - Prometheus: Trace-to-metrics correlation - OpenSearch: Trace-to-logs correlation</p>"},{"location":"observability/distributed-tracing/#application-instrumentation","title":"Application Instrumentation","text":""},{"location":"observability/distributed-tracing/#java-applications-spring-boot-jenkins","title":"Java Applications (Spring Boot, Jenkins)","text":"<pre><code># Download OpenTelemetry Java agent\nwget https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar\n\n# Add to JVM arguments\njava -javaagent:opentelemetry-javaagent.jar \\\n     -Dotel.service.name=my-java-app \\\n     -Dotel.exporter.otlp.endpoint=http://otel-collector.monitoring.svc.cluster.local:4317 \\\n     -jar my-app.jar\n</code></pre>"},{"location":"observability/distributed-tracing/#python-applications-fastapi-django","title":"Python Applications (FastAPI, Django)","text":"<pre><code># Install OpenTelemetry packages\npip install opentelemetry-distro opentelemetry-exporter-otlp\n\n# Auto-instrument application\nopentelemetry-bootstrap -a install\nopentelemetry-instrument \\\n  --service_name my-python-app \\\n  --exporter_otlp_endpoint http://otel-collector.monitoring.svc.cluster.local:4317 \\\n  python app.py\n</code></pre>"},{"location":"observability/distributed-tracing/#nodejs-applications-backstage-express","title":"Node.js Applications (Backstage, Express)","text":"<pre><code>// tracing.js - Add at the very top of your application\nconst { NodeSDK } = require('@opentelemetry/sdk-node');\nconst { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-grpc');\nconst { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');\n\nconst sdk = new NodeSDK({\n  serviceName: 'my-nodejs-app',\n  traceExporter: new OTLPTraceExporter({\n    url: 'grpc://otel-collector.monitoring.svc.cluster.local:4317',\n  }),\n  instrumentations: [getNodeAutoInstrumentations()],\n});\n\nsdk.start();\n</code></pre>"},{"location":"observability/distributed-tracing/#go-applications-argocd-custom-controllers","title":"Go Applications (ArgoCD, Custom Controllers)","text":"<pre><code>import (\n    \"go.opentelemetry.io/otel\"\n    \"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc\"\n    \"go.opentelemetry.io/otel/sdk/resource\"\n    sdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n    semconv \"go.opentelemetry.io/otel/semconv/v1.17.0\"\n)\n\nfunc initTracer() (*sdktrace.TracerProvider, error) {\n    exporter, err := otlptracegrpc.New(context.Background(),\n        otlptracegrpc.WithEndpoint(\"otel-collector.monitoring.svc.cluster.local:4317\"),\n        otlptracegrpc.WithInsecure(),\n    )\n    if err != nil {\n        return nil, err\n    }\n\n    tp := sdktrace.NewTracerProvider(\n        sdktrace.WithBatcher(exporter),\n        sdktrace.WithResource(resource.NewWithAttributes(\n            semconv.SchemaURL,\n            semconv.ServiceName(\"my-go-app\"),\n        )),\n    )\n    otel.SetTracerProvider(tp)\n    return tp, nil\n}\n</code></pre>"},{"location":"observability/distributed-tracing/#usage","title":"Usage","text":""},{"location":"observability/distributed-tracing/#querying-traces-in-grafana","title":"Querying Traces in Grafana","text":"<p>Access Grafana at <code>http://grafana.127.0.0.1.nip.io</code> and navigate to Explore \u2192 Tempo.</p>"},{"location":"observability/distributed-tracing/#find-traces-by-service","title":"Find traces by service","text":"<pre><code>{resource.service.name=\"backstage\"}\n</code></pre>"},{"location":"observability/distributed-tracing/#find-slow-traces-1-second","title":"Find slow traces (&gt; 1 second)","text":"<pre><code>{duration &gt; 1s}\n</code></pre>"},{"location":"observability/distributed-tracing/#find-traces-with-errors","title":"Find traces with errors","text":"<pre><code>{status = error}\n</code></pre>"},{"location":"observability/distributed-tracing/#find-database-queries","title":"Find database queries","text":"<pre><code>{span.db.system = \"postgresql\"}\n</code></pre>"},{"location":"observability/distributed-tracing/#find-traces-by-http-route","title":"Find traces by HTTP route","text":"<pre><code>{span.http.route = \"/api/catalog/*\"}\n</code></pre>"},{"location":"observability/distributed-tracing/#trace-to-logs-correlation","title":"Trace-to-Logs Correlation","text":"<ol> <li>Open a trace in Grafana Tempo</li> <li>Click on any span</li> <li>Click \"Logs for this span\" to jump to OpenSearch logs</li> <li>Logs are filtered by trace ID and time range</li> </ol>"},{"location":"observability/distributed-tracing/#trace-to-metrics-correlation","title":"Trace-to-Metrics Correlation","text":"<ol> <li>Open a Prometheus dashboard</li> <li>Click on a data point with exemplars</li> <li>Click \"View Trace\" to jump to the associated trace</li> </ol>"},{"location":"observability/distributed-tracing/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>TEMPO_URL</code> Tempo API endpoint <code>http://tempo.monitoring.svc.cluster.local:3200</code> <code>TEMPO_OTLP_GRPC_ENDPOINT</code> OTLP gRPC ingestion endpoint <code>tempo.monitoring.svc.cluster.local:4317</code> <code>TEMPO_OTLP_HTTP_ENDPOINT</code> OTLP HTTP ingestion endpoint <code>http://tempo.monitoring.svc.cluster.local:4318</code> <code>TRACE_SAMPLING_PERCENTAGE</code> Sampling rate (1-100) <code>100</code> (development) <code>TRACE_CLUSTER_NAME</code> Cluster identifier <code>fawkes-dev</code> <code>TRACE_ENVIRONMENT</code> Environment label <code>development</code>"},{"location":"observability/distributed-tracing/#monitoring","title":"Monitoring","text":""},{"location":"observability/distributed-tracing/#tempo-health","title":"Tempo Health","text":"<p>Check Tempo health via API:</p> <pre><code>kubectl port-forward -n monitoring svc/tempo 3200:3200\ncurl http://localhost:3200/ready\n</code></pre>"},{"location":"observability/distributed-tracing/#collector-metrics","title":"Collector Metrics","text":"<p>The OpenTelemetry Collector exposes metrics at port 8888:</p> <ul> <li><code>otelcol_receiver_accepted_spans</code>: Spans received</li> <li><code>otelcol_exporter_sent_spans</code>: Spans exported to Tempo</li> <li><code>otelcol_exporter_send_failed_spans</code>: Export failures</li> <li><code>otelcol_processor_batch_batch_send_size</code>: Batch sizes</li> </ul>"},{"location":"observability/distributed-tracing/#zpages-for-debugging","title":"ZPages for Debugging","text":"<p>Access collector internal diagnostics:</p> <pre><code>kubectl port-forward -n monitoring daemonset/otel-collector 55679:55679\n# Open http://localhost:55679/debug/tracez\n</code></pre>"},{"location":"observability/distributed-tracing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"observability/distributed-tracing/#traces-not-appearing-in-tempo","title":"Traces Not Appearing in Tempo","text":"<ol> <li>Check collector pods are running:</li> </ol> <pre><code>kubectl get pods -n monitoring -l app.kubernetes.io/name=opentelemetry-collector\n</code></pre> <ol> <li>Check collector logs for export errors:</li> </ol> <pre><code>kubectl logs -n monitoring -l app.kubernetes.io/name=opentelemetry-collector --tail=100 | grep -i error\n</code></pre> <ol> <li>Verify Tempo connectivity:</li> </ol> <pre><code>kubectl exec -n monitoring -it &lt;collector-pod&gt; -- wget -qO- http://tempo.monitoring.svc.cluster.local:3200/ready\n</code></pre>"},{"location":"observability/distributed-tracing/#missing-kubernetes-attributes","title":"Missing Kubernetes Attributes","text":"<p>Ensure the collector service account has proper RBAC permissions to read pod metadata.</p>"},{"location":"observability/distributed-tracing/#application-not-sending-traces","title":"Application Not Sending Traces","text":"<ol> <li>Verify OTEL SDK is properly initialized</li> <li>Check <code>OTEL_EXPORTER_OTLP_ENDPOINT</code> environment variable</li> <li>Verify network connectivity to collector (port 4317/4318)</li> </ol>"},{"location":"observability/distributed-tracing/#high-trace-volume-cost","title":"High Trace Volume / Cost","text":"<ol> <li>Reduce <code>TRACE_SAMPLING_PERCENTAGE</code> (e.g., 10 for production)</li> <li>Configure tail-based sampling for error/latency-focused collection</li> <li>Review span cardinality and reduce high-cardinality attributes</li> </ol>"},{"location":"observability/distributed-tracing/#best-practices","title":"Best Practices","text":""},{"location":"observability/distributed-tracing/#span-naming","title":"Span Naming","text":"<ul> <li>Use semantic, action-based names: <code>GET /api/users/{id}</code>, <code>db.query</code></li> <li>Avoid high-cardinality values in span names (user IDs, timestamps)</li> <li>Be consistent across services</li> </ul>"},{"location":"observability/distributed-tracing/#span-attributes","title":"Span Attributes","text":"<ul> <li>Include relevant context: <code>user.id</code>, <code>order.id</code>, <code>feature.flag</code></li> <li>Avoid sensitive data: passwords, tokens, PII</li> <li>Use OpenTelemetry semantic conventions</li> </ul>"},{"location":"observability/distributed-tracing/#error-handling","title":"Error Handling","text":"<pre><code>span.RecordError(err)\nspan.SetStatus(codes.Error, err.Error())\n</code></pre>"},{"location":"observability/distributed-tracing/#custom-spans","title":"Custom Spans","text":"<p>Create spans for significant operations:</p> <pre><code>ctx, span := tracer.Start(ctx, \"process-order\",\n    trace.WithAttributes(\n        attribute.String(\"order.id\", orderID),\n        attribute.Int(\"order.items\", len(items)),\n    ),\n)\ndefer span.End()\n</code></pre>"},{"location":"observability/distributed-tracing/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Overview</li> <li>ADR-013 Distributed Tracing</li> <li>Centralized Logging</li> <li>Module 13: Observability</li> </ul>"},{"location":"observability/dora-metrics-guide/","title":"DORA Metrics Definition Guide","text":""},{"location":"observability/dora-metrics-guide/#overview","title":"Overview","text":"<p>This guide explains how each of the five DORA metrics is calculated within the Fawkes platform using Apache DevLake.</p> <p>DORA (DevOps Research and Assessment) metrics are industry-standard measures of software delivery performance. They help teams understand their delivery velocity, stability, and identify areas for improvement.</p>"},{"location":"observability/dora-metrics-guide/#gitops-architecture-and-data-sources","title":"GitOps Architecture and Data Sources","text":"<p>In Fawkes, we follow a GitOps pattern where: - ArgoCD performs the actual deployments to Kubernetes - Jenkins handles CI (build, test, scan) and updates the GitOps repository - GitHub provides commit and PR data - Observability provides incident data</p> <p>This architecture affects where DORA metrics are sourced:</p> DORA Metric Primary Source Why Deployment Frequency ArgoCD ArgoCD syncs are the actual deployments Lead Time for Changes Git + ArgoCD Commit time \u2192 ArgoCD sync completion Change Failure Rate ArgoCD + Incidents Failed syncs + production incidents MTTR Observability + ArgoCD Incident creation \u2192 restore deployment Operational Performance Prometheus SLO/SLI adherence metrics <p>Jenkins provides complementary CI metrics: - Build success/failure rates - Test coverage and flakiness - Quality gate pass rates - Rework metrics (retries, repeated failures)</p>"},{"location":"observability/dora-metrics-guide/#the-five-dora-metrics","title":"The Five DORA Metrics","text":""},{"location":"observability/dora-metrics-guide/#1-deployment-frequency","title":"1. Deployment Frequency","text":"<p>Definition: How often code changes are deployed to production.</p> <p>Primary Data Source: ArgoCD sync events</p> <p>In a GitOps architecture, Jenkins does not deploy directly. Instead: 1. Jenkins builds and tests code 2. Jenkins updates the GitOps repository with new image tags 3. ArgoCD detects the change and syncs to Kubernetes 4. The ArgoCD sync is the actual deployment event</p> <p>Calculation: <pre><code>Deployment Frequency = Number of successful ArgoCD syncs to production / Time period\n</code></pre></p> <p>Performance Levels: | Level | Frequency | |-------|-----------| | Elite | Multiple times per day | | High | Once per day to once per week | | Medium | Once per week to once per month | | Low | Less than once per month |</p> <p>Fawkes Implementation: - DevLake ArgoCD plugin collects sync events - Production environments identified by app name pattern (e.g., <code>*-prod</code>) - Grafana dashboard displays daily/weekly/monthly trends</p>"},{"location":"observability/dora-metrics-guide/#2-lead-time-for-changes","title":"2. Lead Time for Changes","text":"<p>Definition: Time from code commit to running in production.</p> <p>Data Sources: - GitHub: Commit timestamps - ArgoCD: Sync completion timestamps</p> <p>Calculation: <pre><code>Lead Time = ArgoCD Sync Timestamp - First Commit Timestamp\n</code></pre></p> <p>The lead time includes: 1. Development Time: Time spent coding 2. Review Time: Time in code review/PR process 3. CI Time: Jenkins build and test execution 4. GitOps Sync Time: ArgoCD reconciliation</p> <p>Performance Levels: | Level | Lead Time | |-------|-----------| | Elite | Less than 1 hour | | High | 1 hour to 1 day | | Medium | 1 day to 1 week | | Low | More than 1 week |</p> <p>Fawkes Implementation: - DevLake correlates GitHub commits with ArgoCD syncs - Commit SHA links are used for correlation - Pipeline stages are tracked for detailed breakdown</p>"},{"location":"observability/dora-metrics-guide/#3-change-failure-rate-cfr","title":"3. Change Failure Rate (CFR)","text":"<p>Definition: Percentage of deployments that cause a failure in production.</p> <p>Data Sources: - ArgoCD: Sync status (success/failed/degraded) - Observability: Incident records from Alertmanager - Webhooks: Manual incident creation</p> <p>Calculation: <pre><code>CFR = (Failed ArgoCD Syncs + Production Incidents) / Total ArgoCD Syncs \u00d7 100%\n</code></pre></p> <p>A deployment is considered a failure if: - The ArgoCD sync fails or enters degraded state - An incident is created within a configured time window after sync - A rollback sync is triggered</p> <p>Performance Levels: | Level | CFR | |-------|-----| | Elite | 0-5% | | High | 5-10% | | Medium | 10-15% | | Low | 15%+ |</p> <p>Fawkes Implementation: - ArgoCD sync failures are automatically tracked - Observability platform sends incident webhooks - Correlation with recent syncs determines CFR attribution</p>"},{"location":"observability/dora-metrics-guide/#4-mean-time-to-restore-mttr","title":"4. Mean Time to Restore (MTTR)","text":"<p>Definition: Average time to restore service after a production incident.</p> <p>Data Sources: - Observability: Incident creation timestamps (from Alertmanager) - ArgoCD: Restore sync completion timestamps - Webhooks: Manual incident resolution events</p> <p>Calculation: <pre><code>MTTR = Sum(Resolution Time - Creation Time) / Number of Incidents\n</code></pre></p> <p>Resolution is detected when: - A subsequent successful ArgoCD sync occurs - Alertmanager alert resolves - Manual resolution via webhook/API</p> <p>Performance Levels: | Level | MTTR | |-------|------| | Elite | Less than 1 hour | | High | 1 hour to 1 day | | Medium | 1 day to 1 week | | Low | More than 1 week |</p> <p>Fawkes Implementation: - Incidents are created automatically from Alertmanager - ArgoCD restore syncs are correlated with open incidents - Grafana dashboard shows MTTR trends by severity</p>"},{"location":"observability/dora-metrics-guide/#5-operational-performance-reliability","title":"5. Operational Performance (Reliability)","text":"<p>Definition: Measures the reliability and performance of services in production.</p> <p>Data Sources: - Prometheus: Latency, error rate, availability metrics - SLO/SLI Definitions: Target thresholds</p> <p>Calculation: <pre><code>Operational Performance = Actual Uptime / Target Uptime \u00d7 100%\n</code></pre></p> <p>Or based on SLO adherence: <pre><code>SLO Adherence = Time within SLO / Total Time \u00d7 100%\n</code></pre></p> <p>Key Indicators: - Availability: Percentage of time service is operational - Latency P99: 99th percentile response time - Error Rate: Percentage of failed requests</p> <p>Performance Levels: | Level | SLO Adherence | |-------|---------------| | Elite | 99.99%+ | | High | 99.9-99.99% | | Medium | 99-99.9% | | Low | Below 99% |</p>"},{"location":"observability/dora-metrics-guide/#jenkins-cirework-metrics","title":"Jenkins CI/Rework Metrics","text":"<p>While DORA metrics focus on deployment and production, Jenkins provides valuable CI quality metrics:</p>"},{"location":"observability/dora-metrics-guide/#build-success-rate","title":"Build Success Rate","text":"<p><pre><code>Build Success Rate = Successful Builds / Total Builds \u00d7 100%\n</code></pre> Tracks the reliability of the CI pipeline.</p>"},{"location":"observability/dora-metrics-guide/#rework-rate","title":"Rework Rate","text":"<p><pre><code>Rework Rate = Retry Builds / Unique Commits \u00d7 100%\n</code></pre> Measures how often builds need to be re-run for the same code.</p>"},{"location":"observability/dora-metrics-guide/#quality-gate-pass-rate","title":"Quality Gate Pass Rate","text":"<p><pre><code>QG Pass Rate = Passed Quality Gates / Total Scans \u00d7 100%\n</code></pre> Tracks SonarQube quality gate success over time.</p>"},{"location":"observability/dora-metrics-guide/#test-flakiness","title":"Test Flakiness","text":"<p><pre><code>Flakiness = Flaky Test Runs / Total Test Runs \u00d7 100%\n</code></pre> Identifies non-deterministic test failures.</p>"},{"location":"observability/dora-metrics-guide/#build-duration-trend","title":"Build Duration Trend","text":"<p>Tracks average and P95 build durations over time.</p> <p>Example Jenkins Pipeline Usage: <pre><code>@Library('fawkes-pipeline-library') _\n\n// Record build metrics\ndoraMetrics.recordBuild(\n    service: 'my-service',\n    status: 'success',\n    stage: 'build'\n)\n\n// Record quality gate results\ndoraMetrics.recordQualityGate(\n    service: 'my-service',\n    passed: true,\n    coveragePercent: 85,\n    vulnerabilities: 0\n)\n\n// Record test results for flakiness tracking\ndoraMetrics.recordTestResults(\n    service: 'my-service',\n    totalTests: 150,\n    passedTests: 148,\n    failedTests: 2,\n    flakyTests: 1\n)\n\n// At pipeline end\ndoraMetrics.recordPipelineComplete(service: 'my-service')\n</code></pre></p>"},{"location":"observability/dora-metrics-guide/#data-flow-architecture","title":"Data Flow Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Data Sources                              \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502   GitHub     \u2502  \u2502   ArgoCD     \u2502  \u2502   Jenkins    \u2502          \u2502\n\u2502  \u2502              \u2502  \u2502  (PRIMARY)   \u2502  \u2502   (CI/QA)    \u2502          \u2502\n\u2502  \u2502 \u2022 Commits    \u2502  \u2502              \u2502  \u2502              \u2502          \u2502\n\u2502  \u2502 \u2022 PRs        \u2502  \u2502 \u2022 Syncs      \u2502  \u2502 \u2022 Builds     \u2502          \u2502\n\u2502  \u2502 \u2022 Branches   \u2502  \u2502 \u2022 Deploys    \u2502  \u2502 \u2022 Tests      \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2022 Rollbacks  \u2502  \u2502 \u2022 Scans      \u2502          \u2502\n\u2502         \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502         \u2502                 \u2502                  \u2502                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502                  \u2502                   \u2502\n\u2502  \u2502 Observability\u2502        \u2502                  \u2502                   \u2502\n\u2502  \u2502              \u2502        \u2502                  \u2502                   \u2502\n\u2502  \u2502 \u2022 Incidents  \u2502        \u2502                  \u2502                   \u2502\n\u2502  \u2502 \u2022 Alerts     \u2502        \u2502                  \u2502                   \u2502\n\u2502  \u2502 \u2022 SLOs       \u2502        \u2502                  \u2502                   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502                  \u2502                   \u2502\n\u2502         \u2502                 \u2502                  \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502    API          \u2502    API           \u2502    Webhook\n          \u25bc                 \u25bc                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      DevLake Platform                            \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                     Collectors                              \u2502 \u2502\n\u2502  \u2502  GitHub   \u2502  ArgoCD     \u2502  Jenkins   \u2502  Webhook            \u2502 \u2502\n\u2502  \u2502  Plugin   \u2502  Plugin     \u2502  Plugin    \u2502  Plugin             \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                              \u2502                                    \u2502\n\u2502                              \u25bc                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                   Data Processing                           \u2502 \u2502\n\u2502  \u2502  \u2022 Commit \u2192 ArgoCD Sync Correlation (Lead Time)            \u2502 \u2502\n\u2502  \u2502  \u2022 ArgoCD Sync Frequency (Deployment Frequency)            \u2502 \u2502\n\u2502  \u2502  \u2022 Sync Failures + Incidents (CFR)                         \u2502 \u2502\n\u2502  \u2502  \u2022 Incident \u2192 Restore Sync (MTTR)                          \u2502 \u2502\n\u2502  \u2502  \u2022 Jenkins Build Metrics (Rework)                          \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                              \u2502                                    \u2502\n\u2502                              \u25bc                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                      MySQL Database                         \u2502 \u2502\n\u2502  \u2502  Raw events, domain models, calculated metrics              \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                              \u2502                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n                               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Visualization                               \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502   Grafana    \u2502  \u2502  Backstage   \u2502  \u2502  DevLake UI  \u2502          \u2502\n\u2502  \u2502  Dashboards  \u2502  \u2502   Plugin     \u2502  \u2502              \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"observability/dora-metrics-guide/#accessing-dora-metrics","title":"Accessing DORA Metrics","text":""},{"location":"observability/dora-metrics-guide/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Access the DORA metrics dashboards at: - URL: <code>http://devlake-grafana.127.0.0.1.nip.io</code> - Credentials: Use the Grafana admin credentials</p> <p>Available dashboards: - DORA Overview - All metrics at a glance - Deployment Frequency - Detailed deploy trends - Lead Time for Changes - Time breakdown by stage - Change Failure Rate - Failure analysis - Mean Time to Restore - Incident resolution trends</p>"},{"location":"observability/dora-metrics-guide/#backstage-developer-portal","title":"Backstage Developer Portal","text":"<p>DORA metrics are integrated into Backstage service pages: 1. Navigate to your service in the Backstage catalog 2. Click the \"DORA Metrics\" tab 3. View the five metrics with performance ratings</p>"},{"location":"observability/dora-metrics-guide/#devlake-ui","title":"DevLake UI","text":"<p>Access the DevLake configuration UI at: - URL: <code>http://devlake.127.0.0.1.nip.io</code> - Configure data sources and projects</p>"},{"location":"observability/dora-metrics-guide/#jenkins-pipeline","title":"Jenkins Pipeline","text":"<p>View DORA metrics summary in pipeline output: <pre><code>doraMetrics.getMetricsSummary('my-service')\n</code></pre></p>"},{"location":"observability/dora-metrics-guide/#best-practices","title":"Best Practices","text":""},{"location":"observability/dora-metrics-guide/#improving-deployment-frequency","title":"Improving Deployment Frequency","text":"<ul> <li>Adopt trunk-based development</li> <li>Use feature flags for incremental releases</li> <li>Automate deployment pipelines</li> <li>Reduce batch sizes</li> </ul>"},{"location":"observability/dora-metrics-guide/#reducing-lead-time","title":"Reducing Lead Time","text":"<ul> <li>Implement fast code review processes</li> <li>Use automated testing</li> <li>Parallelize CI stages</li> <li>Enable self-service deployments</li> </ul>"},{"location":"observability/dora-metrics-guide/#lowering-change-failure-rate","title":"Lowering Change Failure Rate","text":"<ul> <li>Increase test coverage</li> <li>Implement canary deployments</li> <li>Use feature flags for gradual rollouts</li> <li>Conduct thorough code reviews</li> </ul>"},{"location":"observability/dora-metrics-guide/#reducing-mttr","title":"Reducing MTTR","text":"<ul> <li>Implement robust monitoring and alerting</li> <li>Create runbooks for common issues</li> <li>Use automated rollbacks</li> <li>Practice incident response drills</li> </ul>"},{"location":"observability/dora-metrics-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"observability/dora-metrics-guide/#missing-metrics","title":"Missing Metrics","text":"<p>Problem: DORA metrics show N/A</p> <p>Solutions: 1. Verify data source connections in DevLake UI 2. Check that Jenkins is sending deployment events 3. Ensure GitHub collector is configured correctly 4. Run a manual data collection in DevLake</p>"},{"location":"observability/dora-metrics-guide/#incorrect-calculations","title":"Incorrect Calculations","text":"<p>Problem: Metrics don't match expectations</p> <p>Solutions: 1. Verify commit SHAs are being recorded 2. Check time zone configurations 3. Review the deployment pattern regex 4. Validate incident correlation settings</p>"},{"location":"observability/dora-metrics-guide/#no-data-in-grafana","title":"No Data in Grafana","text":"<p>Problem: Grafana dashboards are empty</p> <p>Solutions: 1. Verify DevLake data sync completed 2. Check Grafana data source configuration 3. Adjust time range in dashboard 4. Run DevLake blueprint manually</p>"},{"location":"observability/dora-metrics-guide/#references","title":"References","text":"<ul> <li>DORA Research</li> <li>Apache DevLake Documentation</li> <li>ADR-016: DevLake DORA Strategy</li> <li>ADR-012: Metrics Monitoring</li> </ul>"},{"location":"patterns/","title":"Implementation Patterns","text":"<p>These patterns provide proven approaches to implementing DORA capabilities in your organization.</p>"},{"location":"patterns/#fast-flow-patterns","title":"Fast Flow Patterns","text":"Pattern Description Related Tools Continuous Delivery Automated deployment pipeline patterns ArgoCD, Jenkins, Argo Rollouts Infrastructure as Code Managing infrastructure through code Terraform, Kubernetes Database Changes Safe database deployment patterns Flyway, Liquibase"},{"location":"patterns/#fast-feedback-patterns","title":"Fast Feedback Patterns","text":"Pattern Description Related Tools Test Automation Comprehensive testing strategies Selenium, JUnit Monitoring Observability implementation Prometheus, Grafana Chaos Engineering Resilience testing patterns Chaos Mesh"},{"location":"patterns/#fast-recovery-patterns","title":"Fast Recovery Patterns","text":"Pattern Description Related Tools Shift Left Security Early security testing patterns OWASP ZAP Quality Gates Code quality enforcement SonarQube Incident Response Quick recovery patterns PagerDuty <p>View Capabilities Explore Tools</p>"},{"location":"patterns/continuous-delivery/","title":"Continuous Delivery Pattern","text":"<p>Continuous Delivery (CD) is a software development practice where code changes are automatically prepared for production release. According to DORA research, it's one of the key capabilities that drives high performance in technology organizations.</p>"},{"location":"patterns/continuous-delivery/#core-principles","title":"Core Principles","text":"Principle Description Implementation Trunk-Based Development Work in small batches with short-lived branches Git workflow with feature flags Automation Automate build, test, and deployment processes Jenkins, GitHub Actions Comprehensive Testing Implement automated testing at all levels Selenium, JUnit, Cypress GitOps Use Git as single source of truth ArgoCD, Flux"},{"location":"patterns/continuous-delivery/#implementation-guide","title":"Implementation Guide","text":""},{"location":"patterns/continuous-delivery/#1-version-control-practices","title":"1. Version Control Practices","text":"<pre><code># Trunk-based development workflow\ngit checkout -b feature/small-change\n# Make small, incremental changes\ngit commit -am \"feat: add new feature behind flag\"\ngit push origin feature/small-change\n# Merge to trunk within 24 hours\n</code></pre>"},{"location":"patterns/continuous-delivery/#2-deployment-pipeline","title":"2. Deployment Pipeline","text":"<pre><code># Example Jenkins Pipeline\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make build'\n            }\n        }\n        stage('Test') {\n            parallel {\n                stage('Unit') {\n                    steps { sh 'make test-unit' }\n                }\n                stage('Integration') {\n                    steps { sh 'make test-integration' }\n                }\n            }\n        }\n        stage('Deploy') {\n            steps {\n                sh 'make deploy'\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"patterns/continuous-delivery/#3-feature-flags","title":"3. Feature Flags","text":"<pre><code>public class FeatureFlags {\n    private static final String FLAG_NEW_FEATURE = \"new-feature\";\n\n    public boolean isEnabled(String flag) {\n        return LaunchDarkly.client().boolVariation(flag, user, false);\n    }\n}\n</code></pre>"},{"location":"patterns/continuous-delivery/#key-metrics","title":"Key Metrics","text":"<p>Based on DORA research, track these metrics:</p> Metric Elite Performance Implementation Deployment Frequency Multiple deploys per day <code>deployment_frequency = deploys / time_period</code> Lead Time for Changes Less than one hour <code>lead_time = time_to_production - commit_time</code> Change Failure Rate 0-15% <code>failure_rate = failed_deploys / total_deploys</code> Time to Restore Less than one hour <code>mttr = restore_time - failure_time</code>"},{"location":"patterns/continuous-delivery/#best-practices","title":"Best Practices","text":""},{"location":"patterns/continuous-delivery/#1-build-process","title":"1. Build Process","text":"<ul> <li>Use deterministic builds</li> <li>Cache dependencies</li> <li>Implement parallel processing</li> </ul>"},{"location":"patterns/continuous-delivery/#2-testing-strategy","title":"2. Testing Strategy","text":"<ul> <li>Maintain test pyramid</li> <li>Automate all tests</li> <li>Include security testing</li> </ul>"},{"location":"patterns/continuous-delivery/#3-deployment-process","title":"3. Deployment Process","text":"<pre><code># Example ArgoCD Application\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: fawkes-app\nspec:\n  source:\n    repoURL: https://github.com/paruff/fawkes.git\n    path: kubernetes\n    targetRevision: HEAD\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: production\n</code></pre>"},{"location":"patterns/continuous-delivery/#common-anti-patterns","title":"Common Anti-Patterns","text":"<p>\u274c Avoid These Practices: - Long-lived feature branches - Manual deployment steps - Infrequent integration - Environment-specific builds</p> <p>\u2705 Instead Do This: - Merge to trunk daily - Automate everything - Practice continuous integration - Build once, deploy many times</p>"},{"location":"patterns/continuous-delivery/#tools-integration","title":"Tools Integration","text":"Category Tools Purpose CI/CD Jenkins, GitHub Actions Pipeline automation Version Control Git Source code management Testing Selenium, JUnit Automated testing Deployment ArgoCD, Argo Rollouts Deployment automation Monitoring Prometheus, Grafana Performance tracking"},{"location":"patterns/continuous-delivery/#references","title":"References","text":"<ul> <li>Accelerate: Building and Scaling High Performing Technology Organizations</li> <li>2023 State of DevOps Report</li> <li>Continuous Delivery</li> </ul> <p>View Examples  Implementation Guide </p>"},{"location":"patterns/infrastructure-as-code/","title":"Infrastructure as Code Pattern","text":"<p>Infrastructure as Code (IaC) is a key capability identified in DORA research that enables high-performing organizations to manage their infrastructure using version-controlled declarative configurations.</p>"},{"location":"patterns/infrastructure-as-code/#core-principles","title":"Core Principles","text":"Principle Description Implementation Declarative Define desired state, not steps Terraform, ARM templates Version Control Track all infrastructure changes Git Immutable Replace rather than modify Containers, VM images Idempotent Same input yields same result Terraform state"},{"location":"patterns/infrastructure-as-code/#implementation-guide","title":"Implementation Guide","text":""},{"location":"patterns/infrastructure-as-code/#1-infrastructure-definition","title":"1. Infrastructure Definition","text":"<pre><code># Example Terraform Configuration\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~&gt; 3.0\"\n    }\n  }\n}\n\nresource \"azurerm_kubernetes_cluster\" \"main\" {\n  name                = \"fawkes-aks\"\n  location            = \"eastus\"\n  resource_group_name = azurerm_resource_group.main.name\n  dns_prefix          = \"fawkes\"\n\n  default_node_pool {\n    name       = \"default\"\n    node_count = 3\n    vm_size    = \"Standard_D2_v2\"\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n}\n</code></pre>"},{"location":"patterns/infrastructure-as-code/#2-gitops-integration","title":"2. GitOps Integration","text":"<pre><code># ArgoCD Application for Infrastructure\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: fawkes-infrastructure\nspec:\n  source:\n    repoURL: https://github.com/paruff/fawkes.git\n    path: infrastructure/terraform\n    targetRevision: HEAD\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: infrastructure\n</code></pre>"},{"location":"patterns/infrastructure-as-code/#best-practices","title":"Best Practices","text":""},{"location":"patterns/infrastructure-as-code/#1-code-organization","title":"1. Code Organization","text":"<pre><code>infrastructure/\n\u251c\u2500\u2500 environments/\n\u2502   \u251c\u2500\u2500 production/\n\u2502   \u2502   \u2514\u2500\u2500 main.tf\n\u2502   \u2514\u2500\u2500 staging/\n\u2502       \u2514\u2500\u2500 main.tf\n\u251c\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 kubernetes/\n\u2502   \u2502   \u2514\u2500\u2500 main.tf\n\u2502   \u2514\u2500\u2500 networking/\n\u2502       \u2514\u2500\u2500 main.tf\n\u2514\u2500\u2500 shared/\n    \u2514\u2500\u2500 variables.tf\n</code></pre>"},{"location":"patterns/infrastructure-as-code/#2-security-controls","title":"2. Security Controls","text":"<pre><code># Example Security Policy\nresource \"azurerm_key_vault\" \"main\" {\n  name                = \"fawkes-vault\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n  tenant_id          = data.azurerm_client_config.current.tenant_id\n\n  sku_name = \"standard\"\n\n  network_acls {\n    default_action = \"Deny\"\n    bypass         = \"AzureServices\"\n  }\n}\n</code></pre>"},{"location":"patterns/infrastructure-as-code/#key-metrics","title":"Key Metrics","text":"<p>Based on DORA research, track these infrastructure metrics:</p> Metric Elite Performance Implementation Infrastructure Change Success Rate &gt; 95% <code>success_rate = successful_changes / total_changes</code> Infrastructure Recovery Time &lt; 1 hour <code>recovery_time = restore_time - failure_time</code> Infrastructure Deployment Time &lt; 30 minutes <code>deployment_time = end_time - start_time</code>"},{"location":"patterns/infrastructure-as-code/#testing-strategy","title":"Testing Strategy","text":""},{"location":"patterns/infrastructure-as-code/#1-unit-testing","title":"1. Unit Testing","text":"<pre><code># Example Terraform Test\nprovider \"test\" {}\n\nresource \"test_assertions\" \"network\" {\n  component = \"network\"\n\n  equal \"cidr_block\" {\n    description = \"CIDR block should match expected value\"\n    got         = module.network.cidr_block\n    want        = \"10.0.0.0/16\"\n  }\n}\n</code></pre>"},{"location":"patterns/infrastructure-as-code/#2-integration-testing","title":"2. Integration Testing","text":"<pre><code>#!/bin/bash\n# Infrastructure Integration Test\nterraform init\nterraform plan -out=tfplan\nterraform apply tfplan\n\n# Validate resources\naz aks show --name fawkes-aks --resource-group fawkes-rg\n</code></pre>"},{"location":"patterns/infrastructure-as-code/#common-anti-patterns","title":"Common Anti-Patterns","text":"<p>\u274c Avoid These Practices: - Manual infrastructure changes - Untested infrastructure code - Sharing state files - Hard-coded credentials</p> <p>\u2705 Instead Do This: - Automate all changes - Implement comprehensive testing - Use remote state storage - Use secrets management</p>"},{"location":"patterns/infrastructure-as-code/#tools-integration","title":"Tools Integration","text":"Category Tools Purpose IaC Terraform, Pulumi Infrastructure definition Version Control Git Configuration management CI/CD Azure DevOps, GitHub Actions Automation Testing Terratest, Inspec Validation Security Checkov, tfsec Security scanning"},{"location":"patterns/infrastructure-as-code/#references","title":"References","text":"<ul> <li>2023 State of DevOps Report</li> <li>Accelerate: Building and Scaling High Performing Technology Organizations</li> <li>Infrastructure as Code by Kief Morris</li> </ul> <p>View Examples  Implementation Guide </p>"},{"location":"patterns/test-automation/","title":"Test Automation Pattern","text":"<p>Test automation is a critical capability identified in DORA research that enables organizations to achieve elite performance through rapid, reliable feedback cycles. According to the research, elite performers automate 95% of their tests.</p>"},{"location":"patterns/test-automation/#core-principles","title":"Core Principles","text":"Principle Description Implementation Test Pyramid Balance test types for optimal coverage Unit (70%), Integration (20%), E2E (10%) Shift Left Test early in development cycle CI pipeline integration Reliability Tests should be deterministic Avoid flaky tests Speed Quick feedback loops Parallel test execution Trunk-Based Support frequent integration Pre-merge testing"},{"location":"patterns/test-automation/#implementation-guide","title":"Implementation Guide","text":""},{"location":"patterns/test-automation/#1-unit-testing","title":"1. Unit Testing","text":"<pre><code>@Test\nvoid deploymentFrequencyCalculation() {\n    // Arrange\n    DeploymentMetrics metrics = new DeploymentMetrics();\n    List&lt;Deployment&gt; deployments = Arrays.asList(\n        new Deployment(\"2023-01-01\"),\n        new Deployment(\"2023-01-02\")\n    );\n\n    // Act\n    double frequency = metrics.calculateFrequency(deployments);\n\n    // Assert\n    assertEquals(2.0, frequency, \"Should calculate correct deployment frequency\");\n}\n\n@Test\nvoid shouldHandleNoDeployments() {\n    // Arrange\n    DeploymentMetrics metrics = new DeploymentMetrics();\n    List&lt;Deployment&gt; deployments = Collections.emptyList();\n\n    // Act &amp; Assert\n    assertDoesNotThrow(() -&gt; metrics.calculateFrequency(deployments));\n    assertEquals(0.0, metrics.calculateFrequency(deployments));\n}\n</code></pre>"},{"location":"patterns/test-automation/#2-integration-testing-with-testcontainers","title":"2. Integration Testing with TestContainers","text":"<pre><code>@TestContainer\nclass DeploymentRepositoryTest {\n    @Container\n    static PostgreSQLContainer&lt;?&gt; postgres = new PostgreSQLContainer&lt;&gt;(\"postgres:14\")\n        .withDatabaseName(\"testdb\")\n        .withUsername(\"test\")\n        .withPassword(\"test\");\n\n    @Test\n    void shouldPersistDeployment() {\n        // Arrange\n        DeploymentRepository repository = new DeploymentRepository(postgres.getJdbcUrl());\n        Deployment deployment = new Deployment(\"2023-01-01\");\n\n        // Act\n        repository.save(deployment);\n\n        // Assert\n        Optional&lt;Deployment&gt; found = repository.findById(deployment.getId());\n        assertTrue(found.isPresent());\n        assertEquals(\"2023-01-01\", found.get().getDate());\n    }\n}\n</code></pre>"},{"location":"patterns/test-automation/#3-end-to-end-testing-with-cypress","title":"3. End-to-End Testing with Cypress","text":"<pre><code>describe('Deployment Pipeline', () =&gt; {\n  beforeEach(() =&gt; {\n    cy.intercept('GET', '/api/deployments').as('getDeployments');\n    cy.login(); // Custom command for authentication\n  });\n\n  it('shows deployment metrics dashboard', () =&gt; {\n    // Arrange\n    cy.visit('/dashboard');\n\n    // Act\n    cy.wait('@getDeployments');\n\n    // Assert\n    cy.get('[data-testid=\"deployment-frequency\"]').should('be.visible');\n    cy.get('[data-testid=\"lead-time\"]').should('be.visible');\n    cy.get('[data-testid=\"change-failure-rate\"]').should('be.visible');\n    cy.get('[data-testid=\"mttr\"]').should('be.visible');\n  });\n\n  it('creates new deployment', () =&gt; {\n    // Arrange\n    cy.visit('/deployments/new');\n\n    // Act\n    cy.get('[data-testid=\"service-name\"]').type('fawkes-web');\n    cy.get('[data-testid=\"version\"]').type('1.0.0');\n    cy.get('[data-testid=\"submit\"]').click();\n\n    // Assert\n    cy.get('[data-testid=\"success-message\"]')\n      .should('be.visible')\n      .and('contain', 'Deployment created successfully');\n  });\n});\n</code></pre>"},{"location":"patterns/test-automation/#continuous-integration-pipeline","title":"Continuous Integration Pipeline","text":"<pre><code># GitHub Actions workflow for test automation\nname: Test Automation\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up JDK\n        uses: actions/setup-java@v3\n        with:\n          java-version: '17'\n          distribution: 'temurin'\n\n      - name: Unit Tests\n        run: ./gradlew test\n\n      - name: Integration Tests\n        run: ./gradlew integrationTest\n\n      - name: E2E Tests\n        uses: cypress-io/github-action@v6\n        with:\n          browser: chrome\n          config-file: cypress.config.js\n\n      - name: Upload Test Reports\n        if: always()\n        uses: actions/upload-artifact@v3\n        with:\n          name: test-reports\n          path: build/reports/tests/\n</code></pre>"},{"location":"patterns/test-automation/#test-coverage-goals","title":"Test Coverage Goals","text":"Test Type Coverage Target Run Frequency Max Duration Unit 80% Every commit 3 minutes Integration 60% Every PR 10 minutes E2E 40% Daily 30 minutes"},{"location":"patterns/test-automation/#performance-metrics","title":"Performance Metrics","text":"<p>According to DORA research, elite performers achieve:</p> <ul> <li>Test Runtime: &lt; 10 minutes for the full suite</li> <li>Test Reliability: &gt; 95% pass rate</li> <li>Coverage: &gt; 80% of critical paths</li> <li>Automation: &gt; 95% of all tests</li> </ul> <p>View Example Project  Testing Guide </p>"},{"location":"playbooks/","title":"Playbooks","text":"<p>Playbooks are consultant-ready guides that combine the Di\u00e1taxis documentation framework into complete, actionable implementation packages. Each playbook follows a structured format designed to help consultants deliver successful Fawkes implementations while communicating business value to stakeholders.</p>"},{"location":"playbooks/#playbook-structure","title":"Playbook Structure","text":"<p>Every playbook follows the same five-section structure, mapped to Di\u00e1taxis quadrants:</p> Section Di\u00e1taxis Quadrant Purpose I. Business Objective Explanation / Conceptual Defines the \"why\"\u2014the risk mitigated, compliance goal achieved, and value to the client II. Technical Prerequisites Reference Lists necessary Fawkes components and versions, linking to detailed Reference documentation III. Implementation Steps How-to Guide (Core) Step-by-step procedure to execute the objective using Fawkes components IV. Validation &amp; Success Metrics How-to Guide / Reference Instructions to verify outcomes (e.g., checking Kyverno reports, viewing DORA metrics) V. Client Presentation Talking Points Explanation / Conceptual Ready-to-use business language for communicating success to client executives"},{"location":"playbooks/#available-playbooks","title":"Available Playbooks","text":""},{"location":"playbooks/#platform-setup","title":"Platform Setup","text":"Playbook Business Value Complexity Status Platform Bootstrap Establish foundation for elite delivery \u2b50\u2b50 \ud83d\udea7 Coming soon Multi-Cloud Strategy Reduce vendor lock-in risk \u2b50\u2b50\u2b50 \ud83d\udea7 Coming soon GitOps Foundation Enable declarative infrastructure \u2b50\u2b50 \ud83d\udea7 Coming soon"},{"location":"playbooks/#dora-excellence","title":"DORA Excellence","text":"Playbook Business Value Complexity Status DORA Metrics Implementation Data-driven delivery improvement \u2b50\u2b50 \u2705 Available Deployment Frequency Optimization Faster time to market \u2b50\u2b50 \ud83d\udea7 Coming soon Lead Time Reduction Rapid value delivery \u2b50\u2b50\u2b50 \ud83d\udea7 Coming soon Change Failure Rate Reduction Improved quality \u2b50\u2b50\u2b50 \ud83d\udea7 Coming soon MTTR Improvement Enhanced reliability \u2b50\u2b50\u2b50 \ud83d\udea7 Coming soon"},{"location":"playbooks/#security-compliance","title":"Security &amp; Compliance","text":"Playbook Business Value Complexity Status Security Scanning Pipeline Shift-left security posture \u2b50\u2b50 \ud83d\udea7 Coming soon Policy Enforcement with Kyverno Automated compliance \u2b50\u2b50 \ud83d\udea7 Coming soon Secrets Management Reduced security risk \u2b50\u2b50 \ud83d\udea7 Coming soon"},{"location":"playbooks/#observability","title":"Observability","text":"Playbook Business Value Complexity Status Full-Stack Observability Proactive incident detection \u2b50\u2b50\u2b50 \ud83d\udea7 Coming soon SLO-Based Alerting Customer-focused reliability \u2b50\u2b50\u2b50 \ud83d\udea7 Coming soon Cost Visibility FinOps enablement \u2b50\u2b50 \ud83d\udea7 Coming soon"},{"location":"playbooks/#using-playbooks","title":"Using Playbooks","text":""},{"location":"playbooks/#for-consultants","title":"For Consultants","text":"<ol> <li>Before the engagement: Review the Business Objective to align with client goals</li> <li>During planning: Check Technical Prerequisites against client environment</li> <li>During implementation: Follow Implementation Steps systematically</li> <li>After completion: Use Validation steps to demonstrate success</li> <li>In stakeholder meetings: Reference Client Presentation Talking Points</li> </ol>"},{"location":"playbooks/#for-internal-teams","title":"For Internal Teams","text":"<ol> <li>Evaluate fit: Match playbooks to your organizational objectives</li> <li>Assess readiness: Verify prerequisites are in place</li> <li>Execute implementation: Follow steps for consistent results</li> <li>Measure success: Use provided metrics to track improvement</li> </ol>"},{"location":"playbooks/#playbook-template","title":"Playbook Template","text":"<p>Creating a new playbook? Use the Playbook Template to ensure consistency across all playbooks.</p>"},{"location":"playbooks/#related-documentation","title":"Related Documentation","text":"<ul> <li>Tutorials - Learning-oriented introductions to concepts</li> <li>How-To Guides - Additional task-oriented procedures</li> <li>Explanation - Deeper conceptual background</li> <li>Reference - Detailed technical specifications</li> </ul> <p>View Template  Start DORA Playbook </p>"},{"location":"playbooks/TEMPLATE/","title":"Playbook: [TITLE]","text":"<p>Estimated Duration: [X hours/days] Complexity: \u2b50\u2b50 [Low/Medium/High] Target Audience: [Platform Engineers / DevOps Engineers / Consultants]</p>"},{"location":"playbooks/TEMPLATE/#i-business-objective","title":"I. Business Objective","text":"<p>Di\u00e1taxis: Explanation / Conceptual</p> <p>This section defines the \"why\"\u2014the risk mitigated, compliance goal achieved, and value delivered.</p>"},{"location":"playbooks/TEMPLATE/#what-were-solving","title":"What We're Solving","text":"<p>[Describe the business problem or opportunity in plain language. Focus on outcomes, not technology.]</p> <p>Example: Organizations struggle to measure software delivery performance, making it impossible to identify bottlenecks or demonstrate improvement to stakeholders.</p>"},{"location":"playbooks/TEMPLATE/#risk-mitigation","title":"Risk Mitigation","text":"Risk Impact Without Action How This Playbook Helps [Risk 1] [Impact] [Mitigation] [Risk 2] [Impact] [Mitigation]"},{"location":"playbooks/TEMPLATE/#expected-outcomes","title":"Expected Outcomes","text":"<ul> <li>\u2705 [Measurable outcome 1]</li> <li>\u2705 [Measurable outcome 2]</li> <li>\u2705 [Measurable outcome 3]</li> </ul>"},{"location":"playbooks/TEMPLATE/#business-value","title":"Business Value","text":"Metric Before After Improvement [Metric 1] [Baseline] [Target] [% or X improvement] [Metric 2] [Baseline] [Target] [% or X improvement]"},{"location":"playbooks/TEMPLATE/#ii-technical-prerequisites","title":"II. Technical Prerequisites","text":"<p>Di\u00e1taxis: Reference</p> <p>This section lists required Fawkes components, versions, and environment specifications.</p>"},{"location":"playbooks/TEMPLATE/#required-fawkes-components","title":"Required Fawkes Components","text":"Component Minimum Version Required Documentation Kubernetes 1.28+ \u2705 Link to reference docs [Component 2] [Version] \u2705 Link to reference docs [Component 3] [Version] \u2b1c Optional Link to reference docs"},{"location":"playbooks/TEMPLATE/#environment-requirements","title":"Environment Requirements","text":"<pre><code># Minimum cluster resources\nnodes: 3\ncpu_per_node: 4 cores\nmemory_per_node: 16 GB\nstorage: 100 GB\n\n# Network requirements\ningress_controller: nginx or traefik\nexternal_dns: required for production\ncertificates: cert-manager recommended\n</code></pre>"},{"location":"playbooks/TEMPLATE/#access-requirements","title":"Access Requirements","text":"<ul> <li>[ ] Cluster admin access to Kubernetes</li> <li>[ ] Git repository access with push permissions</li> <li>[ ] [Cloud provider] account with appropriate IAM permissions</li> <li>[ ] [Additional access requirements]</li> </ul>"},{"location":"playbooks/TEMPLATE/#pre-implementation-checklist","title":"Pre-Implementation Checklist","text":"<ul> <li>[ ] Prerequisites verified on target environment</li> <li>[ ] Stakeholder approval obtained</li> <li>[ ] Rollback plan documented</li> <li>[ ] Communication plan in place</li> </ul>"},{"location":"playbooks/TEMPLATE/#iii-implementation-steps","title":"III. Implementation Steps","text":"<p>Di\u00e1taxis: How-to Guide (Core)</p> <p>This is the core of the playbook\u2014step-by-step procedures using Fawkes components.</p>"},{"location":"playbooks/TEMPLATE/#step-1-first-major-step","title":"Step 1: [First Major Step]","text":"<p>Objective: [What this step accomplishes]</p> <p>Estimated Time: [X minutes/hours]</p> <pre><code># Example commands\nkubectl apply -f [manifest]\n</code></pre> <p>Verification: [How to confirm this step completed successfully]</p> Expected Output <pre><code>[Example of what successful output looks like]\n</code></pre>"},{"location":"playbooks/TEMPLATE/#step-2-second-major-step","title":"Step 2: [Second Major Step]","text":"<p>Objective: [What this step accomplishes]</p> <p>Estimated Time: [X minutes/hours]</p> <ol> <li>[Sub-step 1]</li> <li>[Sub-step 2]</li> <li>[Sub-step 3]</li> </ol> <pre><code># Example configuration\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: example-config\ndata:\n  key: value\n</code></pre> <p>Verification: [How to confirm this step completed successfully]</p>"},{"location":"playbooks/TEMPLATE/#step-3-third-major-step","title":"Step 3: [Third Major Step]","text":"<p>Objective: [What this step accomplishes]</p> <p>Estimated Time: [X minutes/hours]</p> <p>[Detailed instructions with code examples, screenshots, or diagrams as needed]</p> <p>Common Pitfall</p> <p>[Describe a common mistake and how to avoid it]</p>"},{"location":"playbooks/TEMPLATE/#iv-validation-success-metrics","title":"IV. Validation &amp; Success Metrics","text":"<p>Di\u00e1taxis: How-to Guide / Reference</p> <p>Instructions for verifying the implementation and measuring success.</p>"},{"location":"playbooks/TEMPLATE/#functional-validation","title":"Functional Validation","text":""},{"location":"playbooks/TEMPLATE/#test-1-validation-test-name","title":"Test 1: [Validation Test Name]","text":"<pre><code># Commands to validate functionality\n[validation commands]\n</code></pre> <p>Expected Result: [What success looks like]</p>"},{"location":"playbooks/TEMPLATE/#test-2-validation-test-name","title":"Test 2: [Validation Test Name]","text":"<pre><code># Commands to validate functionality\n[validation commands]\n</code></pre> <p>Expected Result: [What success looks like]</p>"},{"location":"playbooks/TEMPLATE/#success-metrics","title":"Success Metrics","text":"Metric How to Measure Target Value Dashboard Link [Metric 1] [Measurement method] [Target] [Link to dashboard] [Metric 2] [Measurement method] [Target] [Link to dashboard]"},{"location":"playbooks/TEMPLATE/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] [Verification item 1]</li> <li>[ ] [Verification item 2]</li> <li>[ ] [Verification item 3]</li> <li>[ ] [Verification item 4]</li> </ul>"},{"location":"playbooks/TEMPLATE/#dora-metrics-impact","title":"DORA Metrics Impact","text":"<p>After implementation, expect to see improvement in these DORA metrics:</p> DORA Metric Expected Impact Measurement Timeline Deployment Frequency [X% improvement] [2-4 weeks] Lead Time for Changes [X% reduction] [2-4 weeks] Change Failure Rate [X% reduction] [4-8 weeks] Time to Restore [X% reduction] [4-8 weeks]"},{"location":"playbooks/TEMPLATE/#v-client-presentation-talking-points","title":"V. Client Presentation Talking Points","text":"<p>Di\u00e1taxis: Explanation / Conceptual</p> <p>Ready-to-use business language for communicating success to client executives.</p>"},{"location":"playbooks/TEMPLATE/#executive-summary","title":"Executive Summary","text":"<p>[2-3 sentence summary of what was accomplished and its business value, suitable for C-level audience]</p>"},{"location":"playbooks/TEMPLATE/#key-messages-for-stakeholders","title":"Key Messages for Stakeholders","text":""},{"location":"playbooks/TEMPLATE/#for-technical-leaders-cto-vp-engineering","title":"For Technical Leaders (CTO, VP Engineering)","text":"<ul> <li>\"We've implemented [capability] which enables [technical benefit]\"</li> <li>\"This positions your organization to achieve [industry benchmark] performance\"</li> <li>\"Teams can now [specific improvement] without [previous blocker]\"</li> </ul>"},{"location":"playbooks/TEMPLATE/#for-business-leaders-ceo-cfo","title":"For Business Leaders (CEO, CFO)","text":"<ul> <li>\"This investment reduces [risk type] by [X%], protecting [revenue/reputation]\"</li> <li>\"Your teams can now deliver [X times] faster, accelerating time to market\"</li> <li>\"This capability enables [compliance/competitive advantage]\"</li> </ul>"},{"location":"playbooks/TEMPLATE/#demonstration-script","title":"Demonstration Script","text":"<ol> <li>Open: \"[Dashboard/Tool name] shows our current state...\"</li> <li>Show improvement: \"Compare this to [baseline/before state]...\"</li> <li>Connect to value: \"This means your organization can now...\"</li> <li>Next steps: \"Building on this foundation, we can...\"</li> </ol>"},{"location":"playbooks/TEMPLATE/#common-executive-questions-answers","title":"Common Executive Questions &amp; Answers","text":"How does this compare to industry benchmarks? <p>According to DORA research, organizations with [this capability] are [X times] more likely to achieve their organizational performance goals. Your current metrics place you in the [Elite/High/Medium/Low] performance category.</p> What's the ROI on this implementation? <p>Based on [metrics], this implementation delivers [X% improvement] which translates to approximately [time/cost savings]. Industry research suggests organizations see [typical ROI] from similar investments.</p> What's the risk if we don't maintain this? <p>Without continued attention, [specific degradation risk]. We recommend [maintenance activities] to sustain these improvements.</p>"},{"location":"playbooks/TEMPLATE/#follow-up-actions","title":"Follow-Up Actions","text":"Action Owner Timeline Schedule review meeting Consultant [+1 week] Begin [next phase] Client team [+2 weeks] Conduct training Consultant [+1-2 weeks]"},{"location":"playbooks/TEMPLATE/#appendix","title":"Appendix","text":""},{"location":"playbooks/TEMPLATE/#related-resources","title":"Related Resources","text":"<p>When creating a playbook, link to relevant existing documentation:</p> <ul> <li>Tutorial: Link to learning introduction for these concepts</li> <li>How-To: Link to additional procedural guides</li> <li>Reference: Link to technical specifications</li> <li>Explanation: Link to deeper conceptual background</li> </ul>"},{"location":"playbooks/TEMPLATE/#troubleshooting","title":"Troubleshooting","text":"Issue Possible Cause Resolution [Issue 1] [Cause] [Steps to resolve] [Issue 2] [Cause] [Steps to resolve]"},{"location":"playbooks/TEMPLATE/#change-log","title":"Change Log","text":"Date Version Changes YYYY-MM-DD 1.0 Initial release"},{"location":"playbooks/dora-metrics-implementation/","title":"Playbook: DORA Metrics Implementation","text":"<p>Estimated Duration: 4-8 hours Complexity: \u2b50\u2b50 Medium Target Audience: Platform Engineers / DevOps Engineers / Consultants</p>"},{"location":"playbooks/dora-metrics-implementation/#i-business-objective","title":"I. Business Objective","text":"<p>Di\u00e1taxis: Explanation / Conceptual</p> <p>This section defines the \"why\"\u2014the risk mitigated, compliance goal achieved, and value delivered.</p>"},{"location":"playbooks/dora-metrics-implementation/#what-were-solving","title":"What We're Solving","text":"<p>Organizations often struggle to objectively measure their software delivery performance. Without data, improvement efforts are based on intuition rather than evidence, making it impossible to identify true bottlenecks, demonstrate progress to stakeholders, or justify investment in engineering improvements.</p> <p>DORA (DevOps Research and Assessment) research has identified four key metrics that reliably predict software delivery and organizational performance. This playbook implements automated collection and visualization of these metrics within the Fawkes platform.</p>"},{"location":"playbooks/dora-metrics-implementation/#risk-mitigation","title":"Risk Mitigation","text":"Risk Impact Without Action How This Playbook Helps Invisible bottlenecks Teams waste effort on wrong improvements Data reveals actual constraints Unable to demonstrate improvement Stakeholders lose confidence in engineering Dashboards show measurable progress Slow incident response Prolonged outages damage customer trust MTTR tracking drives faster recovery High change failure rate Quality issues erode user satisfaction Early detection enables proactive fixes"},{"location":"playbooks/dora-metrics-implementation/#expected-outcomes","title":"Expected Outcomes","text":"<ul> <li>\u2705 Automated collection of all four DORA metrics</li> <li>\u2705 Real-time dashboards showing current performance levels</li> <li>\u2705 Historical trend analysis for improvement tracking</li> <li>\u2705 Team-level breakdowns for targeted interventions</li> <li>\u2705 Alerts for performance degradation</li> </ul>"},{"location":"playbooks/dora-metrics-implementation/#business-value","title":"Business Value","text":"Metric Before After Improvement Visibility into delivery performance None/Manual Automated, Real-time \u221e improvement Time to identify bottlenecks Days/Weeks Minutes 90%+ reduction Engineering productivity discussions Opinion-based Data-driven Qualitative shift Stakeholder confidence Low High Measurable progress"},{"location":"playbooks/dora-metrics-implementation/#ii-technical-prerequisites","title":"II. Technical Prerequisites","text":"<p>Di\u00e1taxis: Reference</p> <p>This section lists required Fawkes components, versions, and environment specifications.</p>"},{"location":"playbooks/dora-metrics-implementation/#required-fawkes-components","title":"Required Fawkes Components","text":"Component Minimum Version Required Documentation Kubernetes 1.28+ \u2705 See Getting Started Prometheus 2.47+ \u2705 See Prometheus Tool Grafana 10.2+ \u2705 See Observability Jenkins 2.426+ \u2705 See Jenkins Tool ArgoCD 2.9+ \u2705 See GitOps Module DevLake 0.19+ \u2b1c Optional See DevLake ADR"},{"location":"playbooks/dora-metrics-implementation/#environment-requirements","title":"Environment Requirements","text":"<pre><code># Minimum cluster resources for DORA metrics stack\nnodes: 3\ncpu_per_node: 4 cores\nmemory_per_node: 16 GB\nstorage: 50 GB (for metrics retention)\n\n# Network requirements\ningress_controller: nginx or traefik\nexternal_access: required for dashboards\n</code></pre>"},{"location":"playbooks/dora-metrics-implementation/#access-requirements","title":"Access Requirements","text":"<ul> <li>[ ] Cluster admin access to Kubernetes</li> <li>[ ] Git repository webhook configuration rights</li> <li>[ ] Jenkins admin access for plugin installation</li> <li>[ ] ArgoCD admin access for webhook configuration</li> </ul>"},{"location":"playbooks/dora-metrics-implementation/#pre-implementation-checklist","title":"Pre-Implementation Checklist","text":"<ul> <li>[ ] CI/CD pipeline (Jenkins) is operational</li> <li>[ ] GitOps (ArgoCD) is deployed and managing applications</li> <li>[ ] Prometheus and Grafana are running in the cluster</li> <li>[ ] At least one application is being deployed via GitOps</li> <li>[ ] Stakeholder approval for metrics collection obtained</li> </ul>"},{"location":"playbooks/dora-metrics-implementation/#iii-implementation-steps","title":"III. Implementation Steps","text":"<p>Di\u00e1taxis: How-to Guide (Core)</p> <p>This is the core of the playbook\u2014step-by-step procedures using Fawkes components.</p>"},{"location":"playbooks/dora-metrics-implementation/#step-1-configure-deployment-event-collection","title":"Step 1: Configure Deployment Event Collection","text":"<p>Objective: Capture deployment events from ArgoCD to measure deployment frequency and lead time.</p> <p>Estimated Time: 45 minutes</p> <ol> <li>Create the DORA metrics namespace:</li> </ol> <pre><code>kubectl create namespace dora-metrics\n</code></pre> <ol> <li>Deploy the deployment event collector:</li> </ol> <pre><code># dora-deployment-collector.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: dora-collector-config\n  namespace: dora-metrics\ndata:\n  config.yaml: |\n    collectors:\n      - type: argocd\n        webhook_path: /webhooks/argocd\n        metrics:\n          - deployment_frequency\n          - lead_time_for_changes\n      - type: jenkins\n        webhook_path: /webhooks/jenkins\n        metrics:\n          - build_time\n          - pipeline_success_rate\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dora-collector\n  namespace: dora-metrics\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dora-collector\n  template:\n    metadata:\n      labels:\n        app: dora-collector\n    spec:\n      containers:\n      - name: collector\n        image: fawkes/dora-collector:v1.0.0\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: config\n          mountPath: /etc/dora\n      volumes:\n      - name: config\n        configMap:\n          name: dora-collector-config\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dora-collector\n  namespace: dora-metrics\nspec:\n  selector:\n    app: dora-collector\n  ports:\n  - port: 8080\n    targetPort: 8080\n</code></pre> <ol> <li>Apply the configuration:</li> </ol> <pre><code>kubectl apply -f dora-deployment-collector.yaml\n</code></pre> <p>Verification: Check that the collector pod is running:</p> <pre><code>kubectl get pods -n dora-metrics -l app=dora-collector\n</code></pre> Expected Output <pre><code>NAME                              READY   STATUS    RESTARTS   AGE\ndora-collector-7d9f8b6c4f-x2k9j   1/1     Running   0          30s\n</code></pre>"},{"location":"playbooks/dora-metrics-implementation/#step-2-configure-argocd-webhooks","title":"Step 2: Configure ArgoCD Webhooks","text":"<p>Objective: Connect ArgoCD deployment events to the DORA collector.</p> <p>Estimated Time: 30 minutes</p> <ol> <li>Get the DORA collector service endpoint:</li> </ol> <pre><code>kubectl get svc dora-collector -n dora-metrics -o jsonpath='{.spec.clusterIP}'\n</code></pre> <ol> <li>Configure ArgoCD notifications to send deployment events:</li> </ol> <pre><code># argocd-notifications-cm.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-notifications-cm\n  namespace: argocd\ndata:\n  service.webhook.dora: |\n    url: http://dora-collector.dora-metrics:8080/webhooks/argocd\n    headers:\n    - name: Content-Type\n      value: application/json\n  template.deployment-event: |\n    webhook:\n      dora:\n        method: POST\n        body: |\n          {\n            \"application\": \"{{.app.metadata.name}}\",\n            \"status\": \"{{.app.status.sync.status}}\",\n            \"revision\": \"{{.app.status.sync.revision}}\",\n            \"timestamp\": \"{{.app.status.operationState.finishedAt}}\"\n          }\n  trigger.on-sync-succeeded: |\n    - when: app.status.sync.status == 'Synced'\n      send: [deployment-event]\n</code></pre> <ol> <li>Apply the notification configuration:</li> </ol> <pre><code>kubectl apply -f argocd-notifications-cm.yaml\n</code></pre> <p>Verification: Trigger a deployment and check for webhook delivery.</p>"},{"location":"playbooks/dora-metrics-implementation/#step-3-configure-jenkins-pipeline-metrics","title":"Step 3: Configure Jenkins Pipeline Metrics","text":"<p>Objective: Capture build and pipeline metrics from Jenkins.</p> <p>Estimated Time: 45 minutes</p> <ol> <li>Install the Prometheus metrics plugin in Jenkins:</li> </ol> <pre><code>// In Jenkins shared library\n// vars/doraMetrics.groovy\ndef recordDeployment(Map config) {\n    def startTime = config.startTime ?: currentBuild.startTimeInMillis\n    def endTime = System.currentTimeMillis()\n    def leadTime = endTime - startTime\n\n    sh \"\"\"\n        curl -X POST http://dora-collector.dora-metrics:8080/metrics/deployment \\\\\n            -H 'Content-Type: application/json' \\\\\n            -d '{\n                \"service\": \"${config.service}\",\n                \"environment\": \"${config.environment}\",\n                \"commit_sha\": \"${config.commitSha}\",\n                \"lead_time_ms\": ${leadTime},\n                \"status\": \"${currentBuild.result ?: 'SUCCESS'}\"\n            }'\n    \"\"\"\n}\n\ndef recordFailure(Map config) {\n    sh \"\"\"\n        curl -X POST http://dora-collector.dora-metrics:8080/metrics/failure \\\\\n            -H 'Content-Type: application/json' \\\\\n            -d '{\n                \"service\": \"${config.service}\",\n                \"environment\": \"${config.environment}\",\n                \"type\": \"${config.type}\",\n                \"detected_at\": \"${new Date().toInstant()}\"\n            }'\n    \"\"\"\n}\n</code></pre> <ol> <li>Update pipelines to emit DORA metrics:</li> </ol> <pre><code>// Example Jenkinsfile integration\n@Library('fawkes-shared-library') _\n\npipeline {\n    agent any\n    stages {\n        stage('Deploy') {\n            steps {\n                script {\n                    // Deployment logic here\n                    sh 'kubectl apply -f manifests/'\n\n                    // Record deployment for DORA metrics\n                    doraMetrics.recordDeployment(\n                        service: 'my-service',\n                        environment: 'production',\n                        commitSha: env.GIT_COMMIT\n                    )\n                }\n            }\n        }\n    }\n    post {\n        failure {\n            script {\n                doraMetrics.recordFailure(\n                    service: 'my-service',\n                    environment: 'production',\n                    type: 'deployment_failure'\n                )\n            }\n        }\n    }\n}\n</code></pre> <p>Verification: Run a pipeline and verify metrics are being collected.</p> <p>Common Pitfall</p> <p>Ensure the Jenkins service account has network access to the dora-collector service. If using network policies, create appropriate rules.</p>"},{"location":"playbooks/dora-metrics-implementation/#step-4-configure-incident-tracking-for-mttr","title":"Step 4: Configure Incident Tracking for MTTR","text":"<p>Objective: Track incident detection and resolution for Mean Time to Restore measurement.</p> <p>Estimated Time: 30 minutes</p> <ol> <li>Configure Prometheus alerting to record incidents:</li> </ol> <pre><code># prometheus-dora-rules.yaml\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: dora-incident-rules\n  namespace: monitoring\nspec:\n  groups:\n  - name: dora-incidents\n    rules:\n    - alert: ServiceDown\n      expr: up{job=~\".*production.*\"} == 0\n      for: 1m\n      labels:\n        severity: critical\n        dora_incident: \"true\"\n      annotations:\n        summary: \"Service {{ $labels.job }} is down\"\n\n    - alert: HighErrorRate\n      expr: rate(http_requests_total{status=~\"5..\"}[5m]) &gt; 0.1\n      for: 2m\n      labels:\n        severity: warning\n        dora_incident: \"true\"\n      annotations:\n        summary: \"High error rate for {{ $labels.service }}\"\n</code></pre> <ol> <li>Configure Alertmanager to notify DORA collector:</li> </ol> <pre><code># alertmanager-dora-config.yaml\nreceivers:\n  - name: dora-collector\n    webhook_configs:\n      - url: 'http://dora-collector.dora-metrics:8080/webhooks/alertmanager'\n        send_resolved: true\n\nroute:\n  receiver: dora-collector\n  routes:\n    - match:\n        dora_incident: \"true\"\n      receiver: dora-collector\n</code></pre> <p>Verification: Trigger a test alert and verify it's recorded.</p>"},{"location":"playbooks/dora-metrics-implementation/#step-5-deploy-dora-metrics-dashboard","title":"Step 5: Deploy DORA Metrics Dashboard","text":"<p>Objective: Create visualization dashboards for all four DORA metrics.</p> <p>Estimated Time: 30 minutes</p> <ol> <li>Deploy the DORA Grafana dashboard:</li> </ol> <pre><code># dora-dashboard-configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: dora-dashboard\n  namespace: monitoring\n  labels:\n    grafana_dashboard: \"true\"\ndata:\n  dora-metrics.json: |\n    {\n      \"title\": \"DORA Metrics Dashboard\",\n      \"panels\": [\n        {\n          \"title\": \"Deployment Frequency\",\n          \"type\": \"stat\",\n          \"targets\": [{\n            \"expr\": \"sum(increase(dora_deployments_total[7d]))\"\n          }]\n        },\n        {\n          \"title\": \"Lead Time for Changes\",\n          \"type\": \"gauge\",\n          \"targets\": [{\n            \"expr\": \"avg(dora_lead_time_seconds)\"\n          }]\n        },\n        {\n          \"title\": \"Change Failure Rate\",\n          \"type\": \"gauge\",\n          \"targets\": [{\n            \"expr\": \"sum(dora_deployment_failures_total) / sum(dora_deployments_total) * 100\"\n          }]\n        },\n        {\n          \"title\": \"Mean Time to Restore\",\n          \"type\": \"gauge\",\n          \"targets\": [{\n            \"expr\": \"avg(dora_mttr_seconds)\"\n          }]\n        }\n      ]\n    }\n</code></pre> <ol> <li>Apply the dashboard:</li> </ol> <pre><code>kubectl apply -f dora-dashboard-configmap.yaml\n</code></pre> <p>Verification: Access Grafana and verify the DORA dashboard is visible.</p>"},{"location":"playbooks/dora-metrics-implementation/#iv-validation-success-metrics","title":"IV. Validation &amp; Success Metrics","text":"<p>Di\u00e1taxis: How-to Guide / Reference</p> <p>Instructions for verifying the implementation and measuring success.</p>"},{"location":"playbooks/dora-metrics-implementation/#functional-validation","title":"Functional Validation","text":""},{"location":"playbooks/dora-metrics-implementation/#test-1-deployment-frequency-collection","title":"Test 1: Deployment Frequency Collection","text":"<pre><code># Trigger a test deployment\nkubectl set image deployment/test-app app=nginx:latest -n test\n\n# Check metrics endpoint\nkubectl exec -n dora-metrics deploy/dora-collector -- \\\n  curl -s localhost:8080/metrics | grep dora_deployments_total\n</code></pre> <p>Expected Result: Metric should show at least 1 deployment recorded.</p>"},{"location":"playbooks/dora-metrics-implementation/#test-2-lead-time-calculation","title":"Test 2: Lead Time Calculation","text":"<pre><code># Query Prometheus for lead time\nkubectl exec -n monitoring deploy/prometheus -- \\\n  promtool query instant 'avg(dora_lead_time_seconds)'\n</code></pre> <p>Expected Result: Returns a valid duration in seconds.</p>"},{"location":"playbooks/dora-metrics-implementation/#test-3-mttr-recording","title":"Test 3: MTTR Recording","text":"<pre><code># Simulate an incident resolution\ncurl -X POST http://dora-collector.dora-metrics:8080/incidents/resolve \\\n  -d '{\"incident_id\": \"test-123\", \"resolved_at\": \"'$(date -Iseconds)'\"}'\n\n# Verify MTTR metric\nkubectl exec -n monitoring deploy/prometheus -- \\\n  promtool query instant 'dora_mttr_seconds'\n</code></pre> <p>Expected Result: MTTR metric is populated.</p>"},{"location":"playbooks/dora-metrics-implementation/#success-metrics","title":"Success Metrics","text":"Metric How to Measure Target Value Dashboard Link Data Collection Check <code>dora_*</code> metrics exist All 4 metrics present /grafana/dora Dashboard Load Grafana dashboard loads &lt; 3 seconds /grafana/dora Historical Data Query 7-day data Data available /grafana/dora"},{"location":"playbooks/dora-metrics-implementation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All four DORA metrics are being collected</li> <li>[ ] Grafana dashboard displays correctly</li> <li>[ ] Team-level filtering works</li> <li>[ ] Historical trend data is accumulating</li> <li>[ ] Alerts trigger correctly for metric degradation</li> </ul>"},{"location":"playbooks/dora-metrics-implementation/#dora-metrics-impact","title":"DORA Metrics Impact","text":"<p>This playbook establishes the foundation for measuring DORA metrics. After 2-4 weeks of data collection, you'll be able to:</p> DORA Metric Initial Baseline Typical Elite Target Deployment Frequency Measured Multiple per day Lead Time for Changes Measured &lt; 1 hour Change Failure Rate Measured 0-15% Time to Restore Measured &lt; 1 hour"},{"location":"playbooks/dora-metrics-implementation/#v-client-presentation-talking-points","title":"V. Client Presentation Talking Points","text":"<p>Di\u00e1taxis: Explanation / Conceptual</p> <p>Ready-to-use business language for communicating success to client executives.</p>"},{"location":"playbooks/dora-metrics-implementation/#executive-summary","title":"Executive Summary","text":"<p>We've implemented automated measurement of software delivery performance using the industry-standard DORA metrics framework. Your organization now has real-time visibility into deployment frequency, lead time, change failure rate, and recovery time\u2014the four metrics that DORA research proves correlate with business performance. This data-driven foundation enables targeted improvements and demonstrates engineering progress to stakeholders.</p>"},{"location":"playbooks/dora-metrics-implementation/#key-messages-for-stakeholders","title":"Key Messages for Stakeholders","text":""},{"location":"playbooks/dora-metrics-implementation/#for-technical-leaders-cto-vp-engineering","title":"For Technical Leaders (CTO, VP Engineering)","text":"<ul> <li>\"We've implemented automated DORA metrics collection that tracks all four key performance indicators across your delivery pipeline\"</li> <li>\"This positions your organization to identify bottlenecks with data rather than intuition\u2014teams can now see exactly where time is spent in the delivery process\"</li> <li>\"Elite performers in the DORA research deploy on-demand, have lead times under one hour, fail less than 15% of the time, and recover in under one hour. You now have the data to benchmark and improve toward these targets.\"</li> </ul>"},{"location":"playbooks/dora-metrics-implementation/#for-business-leaders-ceo-cfo","title":"For Business Leaders (CEO, CFO)","text":"<ul> <li>\"This investment gives you visibility into engineering productivity for the first time\u2014you'll see exactly how fast features move from idea to customer\"</li> <li>\"DORA research proves that organizations with elite software delivery performance are 2x more likely to exceed their business goals. These metrics are your leading indicator.\"</li> <li>\"Faster, more reliable software delivery translates directly to faster time-to-market and reduced risk of outages that impact customers and revenue\"</li> </ul>"},{"location":"playbooks/dora-metrics-implementation/#demonstration-script","title":"Demonstration Script","text":"<ol> <li> <p>Open: \"Let me show you the DORA Metrics Dashboard in Grafana. This gives us real-time visibility into four key performance indicators...\"</p> </li> <li> <p>Show Deployment Frequency: \"This shows how often we're deploying to production. Elite performers deploy on-demand, multiple times per day. Our current rate is [X]...\"</p> </li> <li> <p>Show Lead Time: \"Lead time measures the time from when a developer commits code to when it's running in production. Elite performers achieve this in under one hour. We're currently at [X]...\"</p> </li> <li> <p>Show Change Failure Rate: \"This shows what percentage of our deployments cause problems. Elite teams are below 15%. We're at [X%]...\"</p> </li> <li> <p>Show MTTR: \"When something does go wrong, how quickly do we recover? Elite teams restore service in under an hour. Our current mean time to restore is [X]...\"</p> </li> <li> <p>Connect to value: \"By tracking these metrics, we can identify exactly where to focus improvement efforts and demonstrate progress to the business.\"</p> </li> </ol>"},{"location":"playbooks/dora-metrics-implementation/#common-executive-questions-answers","title":"Common Executive Questions &amp; Answers","text":"How does this compare to industry benchmarks? <p>According to the 2023 State of DevOps Report from DORA, elite performers deploy on demand (often multiple times per day), have lead times under one hour, a change failure rate of 0-15%, and recover from failures in under one hour. Your current metrics place you in the [Elite/High/Medium/Low] performance category, which aligns with approximately [X%] of organizations studied.</p> What's the ROI on this implementation? <p>The primary ROI is in enabling data-driven improvement. Organizations that improve from Medium to Elite performance see 2x improvement in organizational performance goals according to DORA research. Additionally, by identifying bottlenecks, we typically see 20-30% improvement in developer productivity within the first quarter.</p> What's the risk if we don't maintain this? <p>Without continued attention, metrics data quality may degrade as systems change. We recommend quarterly reviews of data collection configuration as part of normal platform maintenance. The cost of maintenance is minimal compared to the value of continued visibility.</p> What's the next step after implementing metrics? <p>With baseline metrics established, the next step is to identify your primary bottleneck. Typically, this is either deployment frequency (solved by automation) or lead time (solved by pipeline optimization). We can run a focused improvement sprint targeting your biggest constraint.</p>"},{"location":"playbooks/dora-metrics-implementation/#follow-up-actions","title":"Follow-Up Actions","text":"Action Owner Timeline Review baseline metrics after 2 weeks Engineering Lead +2 weeks Identify primary improvement opportunity Platform Team +3 weeks Begin targeted improvement playbook Consultant/Team +4 weeks Schedule stakeholder review Consultant +6 weeks"},{"location":"playbooks/dora-metrics-implementation/#appendix","title":"Appendix","text":""},{"location":"playbooks/dora-metrics-implementation/#related-resources","title":"Related Resources","text":"<ul> <li>Module 2: DORA Metrics - Conceptual background on the four key metrics</li> <li>Prometheus Tool Reference - Metrics collection details</li> <li>DORA Metrics Guide - Detailed DORA implementation guide</li> </ul>"},{"location":"playbooks/dora-metrics-implementation/#troubleshooting","title":"Troubleshooting","text":"Issue Possible Cause Resolution Metrics not appearing Webhook not configured Verify ArgoCD/Jenkins webhook settings Dashboard empty Prometheus not scraping Check Prometheus targets and scrape config Incorrect lead time Clock skew Ensure NTP sync across nodes Missing deployments Network policy blocking Add network policy for dora-metrics namespace"},{"location":"playbooks/dora-metrics-implementation/#change-log","title":"Change Log","text":"Date Version Changes 2024-01-15 1.0 Initial release"},{"location":"playbooks/ingress-controller/","title":"Playbook: Deploy NGINX Ingress Controller","text":"<p>Estimated Duration: 2 hours Complexity: \u2b50\u2b50 Medium Target Audience: Platform Engineers / DevOps Engineers</p>"},{"location":"playbooks/ingress-controller/#i-business-objective","title":"I. Business Objective","text":"<p>Di\u00e1taxis: Explanation / Conceptual</p> <p>This section defines the \"why\"\u2014the risk mitigated, compliance goal achieved, and value delivered.</p>"},{"location":"playbooks/ingress-controller/#what-were-solving","title":"What We're Solving","text":"<p>Organizations need secure, reliable HTTP/HTTPS access to internal platform services. Without a proper ingress controller, services are either inaccessible or exposed through insecure methods like NodePort, leading to security risks and operational complexity.</p>"},{"location":"playbooks/ingress-controller/#risk-mitigation","title":"Risk Mitigation","text":"Risk Impact Without Action How This Playbook Helps Insecure service exposure Services exposed via insecure protocols (HTTP), potential data breaches TLS termination at ingress layer, automatic HTTPS redirect Lack of centralized routing Manual port management, service discovery issues Single entry point for all platform services No load balancing Single points of failure, poor resource utilization High availability with 2+ replicas and pod anti-affinity Missing observability Cannot track request patterns or diagnose issues Prometheus metrics for monitoring and alerting"},{"location":"playbooks/ingress-controller/#expected-outcomes","title":"Expected Outcomes","text":"<ul> <li>\u2705 Platform services accessible via HTTP/HTTPS</li> <li>\u2705 TLS termination configured with self-signed certificates for local/development</li> <li>\u2705 High availability ingress controller (2 replicas)</li> <li>\u2705 Prometheus metrics enabled for observability</li> <li>\u2705 Test ingress route returning 200 OK</li> </ul>"},{"location":"playbooks/ingress-controller/#business-value","title":"Business Value","text":"Metric Before After Improvement Service Accessibility Manual port forwarding HTTP/HTTPS endpoints 100% improvement Security Posture Insecure NodePort TLS-encrypted ingress High security Service Discovery Manual configuration DNS-based routing Automated Observability None Prometheus metrics Full visibility"},{"location":"playbooks/ingress-controller/#ii-technical-prerequisites","title":"II. Technical Prerequisites","text":"<p>Di\u00e1taxis: Reference</p> <p>This section lists required Fawkes components, versions, and environment specifications.</p>"},{"location":"playbooks/ingress-controller/#required-fawkes-components","title":"Required Fawkes Components","text":"Component Minimum Version Required Documentation Kubernetes 1.28+ \u2705 Kubernetes Docs ArgoCD 2.8+ \u2705 ArgoCD Docs Helm 3.0+ \u2705 Helm Docs kubectl 1.28+ \u2705 kubectl Docs"},{"location":"playbooks/ingress-controller/#environment-requirements","title":"Environment Requirements","text":"<pre><code># Minimum cluster resources\nnodes: 1 (dev) or 3+ (prod)\ncpu_per_node: 2 cores\nmemory_per_node: 4 GB\nstorage: 10 GB\n\n# Network requirements\nload_balancer: MetalLB (local) or cloud provider LB (AWS/Azure/GCP)\ndns: nip.io (local) or ExternalDNS (production)\ncertificates: Self-signed (local) or cert-manager with Let's Encrypt (production)\n</code></pre>"},{"location":"playbooks/ingress-controller/#access-requirements","title":"Access Requirements","text":"<ul> <li>[ ] Cluster admin access to Kubernetes</li> <li>[ ] Git repository access with push permissions</li> <li>[ ] Access to deploy ArgoCD applications</li> <li>[ ] Ability to create LoadBalancer services</li> </ul>"},{"location":"playbooks/ingress-controller/#pre-implementation-checklist","title":"Pre-Implementation Checklist","text":"<ul> <li>[ ] Kubernetes cluster running and accessible</li> <li>[ ] ArgoCD deployed and configured</li> <li>[ ] LoadBalancer support available (MetalLB, cloud provider)</li> <li>[ ] Namespace <code>fawkes</code> exists for ArgoCD applications</li> </ul>"},{"location":"playbooks/ingress-controller/#iii-implementation-steps","title":"III. Implementation Steps","text":"<p>Di\u00e1taxis: How-to Guide (Core)</p> <p>This is the core of the playbook\u2014step-by-step procedures using Fawkes components.</p>"},{"location":"playbooks/ingress-controller/#step-1-deploy-nginx-ingress-controller-via-argocd","title":"Step 1: Deploy NGINX Ingress Controller via ArgoCD","text":"<p>Objective: Deploy the NGINX Ingress Controller using the ArgoCD Application manifest</p> <p>Estimated Time: 10 minutes</p> <pre><code># Navigate to the platform apps directory\ncd platform/apps/ingress-nginx\n\n# Apply the ArgoCD Application\nkubectl apply -f ingress-nginx-application.yaml\n</code></pre> <p>Verification: Check that the ArgoCD Application is created and syncing</p> <pre><code>kubectl get application -n fawkes ingress-nginx\n</code></pre> Expected Output <pre><code>NAME            SYNC STATUS   HEALTH STATUS\ningress-nginx   Synced        Healthy\n</code></pre>"},{"location":"playbooks/ingress-controller/#step-2-verify-ingress-controller-deployment","title":"Step 2: Verify Ingress Controller Deployment","text":"<p>Objective: Ensure the ingress controller pods and services are running</p> <p>Estimated Time: 5 minutes</p> <ol> <li> <p>Check pod status:    <pre><code>kubectl get pods -n ingress-nginx\n</code></pre></p> </li> <li> <p>Check service status:    <pre><code>kubectl get svc -n ingress-nginx\n</code></pre></p> </li> <li> <p>Verify LoadBalancer has external IP assigned:    <pre><code>kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}'\n</code></pre></p> </li> </ol> <p>Verification: All pods should be in <code>Running</code> state and LoadBalancer service should have an external IP</p> Expected Output <pre><code>NAME                                       READY   STATUS    RESTARTS   AGE\ningress-nginx-controller-&lt;hash&gt;            1/1     Running   0          2m\ningress-nginx-controller-&lt;hash&gt;            1/1     Running   0          2m\ningress-nginx-defaultbackend-&lt;hash&gt;        1/1     Running   0          2m\n</code></pre> <p>Common Pitfall</p> <p>If LoadBalancer is stuck in <code>&lt;Pending&gt;</code> state, verify that your cluster has LoadBalancer support (MetalLB for local, cloud provider LB for cloud environments).</p>"},{"location":"playbooks/ingress-controller/#step-3-deploy-test-ingress","title":"Step 3: Deploy Test Ingress","text":"<p>Objective: Deploy a test application with ingress to validate the controller</p> <p>Estimated Time: 10 minutes</p> <pre><code># Generate self-signed TLS certificate for testing\ncd platform/apps/ingress-nginx\n./generate-test-cert.sh\n\n# Deploy the test ingress with echo server\nkubectl apply -f test-ingress.yaml\n</code></pre> <p>Verification: Check that the ingress resource is created and has an address</p> <pre><code>kubectl get ingress -n ingress-test\n</code></pre> Expected Output <pre><code>NAME              CLASS   HOSTS                       ADDRESS         PORTS   AGE\necho-server       nginx   test.127.0.0.1.nip.io      192.168.1.100   80      1m\necho-server-tls   nginx   test-tls.127.0.0.1.nip.io  192.168.1.100   80,443  1m\n</code></pre> <p>TLS Certificate</p> <p>The <code>generate-test-cert.sh</code> script creates a self-signed certificate valid for <code>*.127.0.0.1.nip.io</code>. This certificate is only for testing and should not be used in production. For production, use cert-manager with Let's Encrypt.</p>"},{"location":"playbooks/ingress-controller/#step-4-test-http-access","title":"Step 4: Test HTTP Access","text":"<p>Objective: Verify HTTP traffic is routed correctly through the ingress</p> <p>Estimated Time: 5 minutes</p> <ol> <li> <p>Get the LoadBalancer IP:    <pre><code>LB_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\necho \"LoadBalancer IP: $LB_IP\"\n</code></pre></p> </li> <li> <p>Test HTTP endpoint:    <pre><code>curl -H \"Host: test.127.0.0.1.nip.io\" http://$LB_IP\n</code></pre></p> </li> </ol> <p>Or if using nip.io DNS:    <pre><code>curl http://test.127.0.0.1.nip.io\n</code></pre></p> <p>Verification: You should receive a JSON response from the echo server with request details</p> Expected Output <pre><code>{\n  \"host\": {\n    \"hostname\": \"test.127.0.0.1.nip.io\",\n    \"ip\": \"::ffff:10.244.0.1\",\n    \"ips\": []\n  },\n  \"http\": {\n    \"method\": \"GET\",\n    \"baseUrl\": \"\",\n    \"originalUrl\": \"/\",\n    \"protocol\": \"http\"\n  },\n  \"request\": {\n    \"params\": {\n      \"0\": \"/\"\n    },\n    \"query\": {},\n    \"cookies\": {},\n    \"body\": {},\n    \"headers\": {\n      \"host\": \"test.127.0.0.1.nip.io\",\n      \"user-agent\": \"curl/7.68.0\",\n      \"accept\": \"*/*\"\n    }\n  },\n  \"environment\": {\n    \"PATH\": \"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n    \"HOSTNAME\": \"echo-server-&lt;hash&gt;\",\n    \"PORT\": \"80\"\n  }\n}\n</code></pre>"},{"location":"playbooks/ingress-controller/#step-5-test-https-access-optional","title":"Step 5: Test HTTPS Access (Optional)","text":"<p>Objective: Verify TLS termination is working with self-signed certificate</p> <p>Estimated Time: 5 minutes</p> <pre><code># Test HTTPS endpoint (use -k to skip certificate verification for self-signed cert)\ncurl -k https://test-tls.127.0.0.1.nip.io\n</code></pre> <p>Verification: You should receive the same JSON response, but over HTTPS</p>"},{"location":"playbooks/ingress-controller/#step-6-verify-metrics","title":"Step 6: Verify Metrics","text":"<p>Objective: Confirm Prometheus metrics are exposed</p> <p>Estimated Time: 5 minutes</p> <pre><code># Port-forward to metrics endpoint\nkubectl port-forward -n ingress-nginx svc/ingress-nginx-controller-metrics 10254:10254 &amp;\n\n# Query metrics\ncurl http://localhost:10254/metrics | grep nginx_ingress_controller_requests\n</code></pre> <p>Verification: You should see metrics output including request counters</p>"},{"location":"playbooks/ingress-controller/#iv-validation-success-metrics","title":"IV. Validation &amp; Success Metrics","text":"<p>Di\u00e1taxis: How-to Guide / Reference</p> <p>Instructions for verifying the implementation and measuring success.</p>"},{"location":"playbooks/ingress-controller/#functional-validation","title":"Functional Validation","text":""},{"location":"playbooks/ingress-controller/#test-1-ingress-controller-health","title":"Test 1: Ingress Controller Health","text":"<pre><code>kubectl get pods -n ingress-nginx\nkubectl get svc -n ingress-nginx\n</code></pre> <p>Expected Result: All pods Running, LoadBalancer service has external IP</p>"},{"location":"playbooks/ingress-controller/#test-2-http-routing","title":"Test 2: HTTP Routing","text":"<pre><code>curl http://test.127.0.0.1.nip.io\n</code></pre> <p>Expected Result: 200 OK response with echo server JSON</p>"},{"location":"playbooks/ingress-controller/#test-3-httpstls","title":"Test 3: HTTPS/TLS","text":"<pre><code>curl -k https://test-tls.127.0.0.1.nip.io\n</code></pre> <p>Expected Result: 200 OK response over HTTPS</p>"},{"location":"playbooks/ingress-controller/#test-4-metrics-endpoint","title":"Test 4: Metrics Endpoint","text":"<pre><code>kubectl port-forward -n ingress-nginx svc/ingress-nginx-controller-metrics 10254:10254\ncurl http://localhost:10254/metrics\n</code></pre> <p>Expected Result: Prometheus metrics output</p>"},{"location":"playbooks/ingress-controller/#success-metrics","title":"Success Metrics","text":"Metric How to Measure Target Value Dashboard Link Pod Availability <code>kubectl get pods -n ingress-nginx</code> 100% Running N/A Request Success Rate Prometheus metric <code>nginx_ingress_controller_requests</code> &gt;99% 2xx responses Grafana Response Time Prometheus metric <code>nginx_ingress_controller_request_duration_seconds</code> &lt;100ms p95 Grafana Controller Uptime Pod uptime &gt;99.9% Kubernetes Dashboard"},{"location":"playbooks/ingress-controller/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Ingress controller pods running (2 replicas)</li> <li>[ ] LoadBalancer service has external IP</li> <li>[ ] Default backend pod running</li> <li>[ ] Test ingress route returns 200 OK</li> <li>[ ] HTTPS with self-signed cert works</li> <li>[ ] Prometheus metrics accessible</li> <li>[ ] ArgoCD Application synced and healthy</li> </ul>"},{"location":"playbooks/ingress-controller/#dora-metrics-impact","title":"DORA Metrics Impact","text":"<p>After implementation, expect to see improvement in these DORA metrics:</p> DORA Metric Expected Impact Measurement Timeline Deployment Frequency 20% improvement - easier service deployment 2-4 weeks Lead Time for Changes 15% reduction - faster service exposure 2-4 weeks Change Failure Rate 10% reduction - standardized ingress patterns 4-8 weeks Time to Restore 25% reduction - centralized routing for debugging 4-8 weeks"},{"location":"playbooks/ingress-controller/#v-client-presentation-talking-points","title":"V. Client Presentation Talking Points","text":"<p>Di\u00e1taxis: Explanation / Conceptual</p> <p>Ready-to-use business language for communicating success to client executives.</p>"},{"location":"playbooks/ingress-controller/#executive-summary","title":"Executive Summary","text":"<p>We've deployed a production-grade NGINX Ingress Controller that provides secure, high-availability HTTP/HTTPS access to all platform services. This enables teams to expose services externally with automatic TLS encryption, load balancing, and comprehensive observability, reducing security risks and accelerating service delivery.</p>"},{"location":"playbooks/ingress-controller/#key-messages-for-stakeholders","title":"Key Messages for Stakeholders","text":""},{"location":"playbooks/ingress-controller/#for-technical-leaders-cto-vp-engineering","title":"For Technical Leaders (CTO, VP Engineering)","text":"<ul> <li>\"We've implemented a high-availability Layer 7 ingress controller that provides centralized HTTP/HTTPS routing for all platform services\"</li> <li>\"This positions your organization to achieve enterprise-grade security with TLS termination and automatic HTTPS redirect\"</li> <li>\"Teams can now expose services externally without manual port management or security risks\"</li> </ul>"},{"location":"playbooks/ingress-controller/#for-business-leaders-ceo-cfo","title":"For Business Leaders (CEO, CFO)","text":"<ul> <li>\"This investment reduces security risk by ensuring all external traffic is encrypted and properly authenticated\"</li> <li>\"Your teams can now deliver services 20% faster with standardized ingress patterns\"</li> <li>\"This capability enables compliance with security standards requiring encrypted communications\"</li> </ul>"},{"location":"playbooks/ingress-controller/#demonstration-script","title":"Demonstration Script","text":"<ol> <li>Open: \"Let's look at the NGINX Ingress Controller dashboard showing our current routing configuration...\"</li> <li>Show improvement: \"Compare this to the previous manual port forwarding approach where each service required individual configuration...\"</li> <li>Connect to value: \"This means your organization can now expose new services in minutes instead of hours, with built-in security and monitoring\"</li> <li>Next steps: \"Building on this foundation, we can integrate cert-manager for automated Let's Encrypt certificates and ExternalDNS for automatic DNS management\"</li> </ol>"},{"location":"playbooks/ingress-controller/#common-executive-questions-answers","title":"Common Executive Questions &amp; Answers","text":"How does this compare to industry benchmarks? <p>According to CNCF research, organizations with automated ingress controllers achieve 30-40% faster service deployment times and 50% fewer security incidents related to service exposure. Your implementation follows cloud-native best practices with high availability and security by default.</p> What's the ROI on this implementation? <p>Based on current metrics, this implementation delivers approximately 2 hours saved per service deployment through automation. With 10+ services, this translates to 20+ hours saved monthly. The security improvements reduce risk of data breaches which can cost millions.</p> What's the risk if we don't maintain this? <p>Without continued attention, the ingress controller could become a single point of failure. We recommend monthly reviews of ingress configurations, quarterly security updates, and integration with cert-manager for automated certificate renewal to sustain these improvements.</p>"},{"location":"playbooks/ingress-controller/#follow-up-actions","title":"Follow-Up Actions","text":"Action Owner Timeline Schedule ingress review meeting Platform Team +1 week Integrate cert-manager for Let's Encrypt Platform Team +2 weeks Deploy ExternalDNS for automated DNS Platform Team +2 weeks Conduct team training on ingress patterns Consultant +1-2 weeks"},{"location":"playbooks/ingress-controller/#appendix","title":"Appendix","text":""},{"location":"playbooks/ingress-controller/#related-resources","title":"Related Resources","text":"<ul> <li>Tutorial: Getting Started with Fawkes</li> <li>How-To: Configure Ingress TLS</li> <li>Reference: Ingress Access Guide</li> <li>Explanation: Networking Stack</li> </ul>"},{"location":"playbooks/ingress-controller/#troubleshooting","title":"Troubleshooting","text":"Issue Possible Cause Resolution LoadBalancer stuck in Pending No LoadBalancer provider Install MetalLB for local or verify cloud provider LB support Ingress not accessible DNS not resolving Use direct IP access or configure /etc/hosts 503 Service Unavailable Backend service not running Verify backend pods: <code>kubectl get pods -n &lt;namespace&gt;</code> Certificate errors Self-signed certificate Use <code>-k</code> flag with curl or install cert-manager for valid certs High latency Resource constraints Increase controller resources in values.yaml Pods not starting Resource quota exceeded Check resource quotas: <code>kubectl describe quota -n ingress-nginx</code>"},{"location":"playbooks/ingress-controller/#change-log","title":"Change Log","text":"Date Version Changes 2024-12-10 1.0 Initial release - NGINX Ingress Controller deployment"},{"location":"reference/","title":"Reference","text":"<p>Reference documentation is information-oriented. It provides technical descriptions of components, APIs, configurations, and specifications.</p>"},{"location":"reference/#what-youll-find-here","title":"What You'll Find Here","text":"<p>Reference content in Fawkes is designed to:</p> <ul> <li>Describe the machinery accurately and comprehensively</li> <li>Be structured for quick lookup and navigation</li> <li>Provide authoritative, correct information</li> <li>Serve as the definitive source for technical specifications</li> </ul>"},{"location":"reference/#platform-components","title":"Platform Components","text":""},{"location":"reference/#infrastructure","title":"Infrastructure","text":"Component Version Status Kubernetes 1.28+ See existing tools Terraform 1.6+ See existing tools Crossplane 1.14+ \ud83d\udea7 Reference coming soon"},{"location":"reference/#cicd","title":"CI/CD","text":"Component Version Status Jenkins 2.426+ See Jenkins tool doc ArgoCD 2.9+ \ud83d\udea7 Reference coming soon GitHub Actions N/A \ud83d\udea7 Reference coming soon"},{"location":"reference/#observability","title":"Observability","text":"Component Version Status Prometheus 2.47+ See Prometheus tool doc Grafana 10.2+ \ud83d\udea7 Reference coming soon OpenSearch 2.11+ See Centralized Logging Grafana Tempo 2.3+ See Distributed Tracing"},{"location":"reference/#collaboration","title":"Collaboration","text":"Component Version Status Mattermost 9.2+ \ud83d\udea7 Reference coming soon Focalboard 7.11+ See Focalboard tool doc Backstage 1.21+ \ud83d\udea7 Reference coming soon"},{"location":"reference/#security","title":"Security","text":"Component Version Status SonarQube 10.3+ \ud83d\udea7 Reference coming soon Trivy 0.47+ \ud83d\udea7 Reference coming soon Kyverno 1.11+ \ud83d\udea7 Reference coming soon External Secrets 0.9+ \ud83d\udea7 Reference coming soon"},{"location":"reference/#api-reference","title":"API Reference","text":"<p>REST API specifications for platform services.</p> API Description Status Backstage Plugins API Internal Backstage plugins (Che Launcher, DevLake Dashboard) \u2705 Available Jenkins Webhook API Trigger Jenkins pipelines via webhooks \u2705 Available"},{"location":"reference/#custom-resource-definitions-crds","title":"Custom Resource Definitions (CRDs)","text":"<p>Field-level specifications for Kubernetes custom resources and Devfiles.</p> CRD Description Status Golden Path Devfile Eclipse Che workspace configuration specification \u2705 Available"},{"location":"reference/#configuration-reference","title":"Configuration Reference","text":"<p>Helm values and configuration tables for platform components.</p> Component Description Status Jenkins Helm Values Complete Jenkins Helm chart configuration \u2705 Available Prometheus Helm Values Complete Prometheus monitoring configuration \u2705 Available See Configuration Guide General platform configuration \u2705 Available"},{"location":"reference/#policy-reference","title":"Policy Reference","text":"<p>Complete listings of active policies and their enforcement modes.</p> Policy Type Description Status Kyverno Policy List All active Kyverno policies (security, mutation, generation) \u2705 Available"},{"location":"reference/#catalog-reference","title":"Catalog Reference","text":"<p>Service types and capabilities available in the platform.</p> Catalog Description Status Service Types Supported services and deployment patterns \u2705 Available"},{"location":"reference/#glossary","title":"Glossary","text":"Resource Description Glossary Fawkes-specific terms, concepts, and acronyms"},{"location":"reference/#command-reference","title":"Command Reference","text":"<p>CLI documentation is under development. The following will be available:</p> <ul> <li>fawkes CLI - Platform management commands</li> <li>ignite.sh - Bootstrap script reference</li> </ul>"},{"location":"reference/#how-reference-differs-from-other-documentation","title":"How Reference Differs from Other Documentation","text":"Reference Explanation How-To States facts Discusses ideas Shows steps Lists options Provides context Solves problems Describes APIs Explains decisions Gives instructions Technical specs Background info Task completion <p>View Tools  Configuration Guide </p>"},{"location":"reference/glossary/","title":"Glossary","text":"<p>This glossary provides definitions for Fawkes platform-specific terms, concepts, and acronyms.</p>"},{"location":"reference/glossary/#a","title":"A","text":""},{"location":"reference/glossary/#argocd","title":"ArgoCD","text":"<p>GitOps continuous delivery tool for Kubernetes. Monitors Git repositories and automatically syncs application state to the cluster.</p>"},{"location":"reference/glossary/#application-catalog","title":"Application Catalog","text":"<p>Central registry of all applications and services managed by the Fawkes platform, stored in Backstage.</p>"},{"location":"reference/glossary/#b","title":"B","text":""},{"location":"reference/glossary/#backstage","title":"Backstage","text":"<p>Developer portal that provides a unified interface for platform services, documentation, and software catalog.</p>"},{"location":"reference/glossary/#bdd-behavior-driven-development","title":"BDD (Behavior-Driven Development)","text":"<p>Testing methodology using Gherkin syntax to describe system behavior in plain language.</p>"},{"location":"reference/glossary/#buildpack","title":"Buildpack","text":"<p>Cloud Native Buildpacks technology that transforms application source code into OCI images without requiring a Dockerfile.</p>"},{"location":"reference/glossary/#c","title":"C","text":""},{"location":"reference/glossary/#clusterpolicy","title":"ClusterPolicy","text":"<p>Kyverno policy resource that applies validation, mutation, or generation rules cluster-wide across all namespaces.</p>"},{"location":"reference/glossary/#crd-custom-resource-definition","title":"CRD (Custom Resource Definition)","text":"<p>Kubernetes extension mechanism that allows defining custom resource types beyond built-in objects.</p>"},{"location":"reference/glossary/#crossplane","title":"Crossplane","text":"<p>Infrastructure-as-code tool that extends Kubernetes to manage cloud resources using declarative YAML.</p>"},{"location":"reference/glossary/#d","title":"D","text":""},{"location":"reference/glossary/#devlake-apache-devlake","title":"DevLake (Apache DevLake)","text":"<p>Data platform for collecting and analyzing DORA metrics from multiple sources (Jenkins, GitHub, etc.).</p>"},{"location":"reference/glossary/#devfile","title":"Devfile","text":"<p>YAML specification that defines development environment configuration for Eclipse Che workspaces.</p>"},{"location":"reference/glossary/#dora-metrics","title":"DORA Metrics","text":"<p>Four key metrics measuring software delivery performance: Deployment Frequency, Lead Time for Changes, Change Failure Rate, Time to Restore Service.</p>"},{"location":"reference/glossary/#e","title":"E","text":""},{"location":"reference/glossary/#eclipse-che","title":"Eclipse Che","text":"<p>Cloud-based IDE providing containerized development environments defined by Devfiles.</p>"},{"location":"reference/glossary/#external-secrets-operator","title":"External Secrets Operator","text":"<p>Kubernetes operator that synchronizes secrets from external secret management systems (Vault, AWS Secrets Manager) into Kubernetes Secrets.</p>"},{"location":"reference/glossary/#f","title":"F","text":""},{"location":"reference/glossary/#fawkes","title":"Fawkes","text":"<p>Internal Developer Platform (IDP) for elite software delivery performance. Integrates GitOps, CI/CD, observability, and learning.</p>"},{"location":"reference/glossary/#focalboard","title":"Focalboard","text":"<p>Open-source project management tool integrated into the Fawkes platform for sprint planning and tracking.</p>"},{"location":"reference/glossary/#g","title":"G","text":""},{"location":"reference/glossary/#gitops","title":"GitOps","text":"<p>Operational framework using Git as the single source of truth for declarative infrastructure and applications.</p>"},{"location":"reference/glossary/#golden-path","title":"Golden Path","text":"<p>Standardized, opinionated CI/CD pipeline enforcing best practices for build, test, security scanning, and deployment.</p>"},{"location":"reference/glossary/#grafana","title":"Grafana","text":"<p>Visualization and analytics platform for metrics, logs, and traces.</p>"},{"location":"reference/glossary/#i","title":"I","text":""},{"location":"reference/glossary/#idp-internal-developer-platform","title":"IDP (Internal Developer Platform)","text":"<p>Self-service platform abstracting infrastructure complexity and providing standardized workflows for developers.</p>"},{"location":"reference/glossary/#ignite","title":"Ignite","text":"<p>Bootstrap script (<code>ignite.sh</code>) for initializing the Fawkes platform in a new environment.</p>"},{"location":"reference/glossary/#j","title":"J","text":""},{"location":"reference/glossary/#jcasc-jenkins-configuration-as-code","title":"JCasC (Jenkins Configuration as Code)","text":"<p>Plugin allowing Jenkins configuration to be defined in YAML rather than manual UI setup.</p>"},{"location":"reference/glossary/#k","title":"K","text":""},{"location":"reference/glossary/#kustomize","title":"Kustomize","text":"<p>Kubernetes configuration management tool using overlays to customize base manifests for different environments.</p>"},{"location":"reference/glossary/#kyverno","title":"Kyverno","text":"<p>Kubernetes-native policy engine for validation, mutation, and generation of resources.</p>"},{"location":"reference/glossary/#m","title":"M","text":""},{"location":"reference/glossary/#mattermost","title":"Mattermost","text":"<p>Open-source team collaboration platform integrated into Fawkes for ChatOps and notifications.</p>"},{"location":"reference/glossary/#o","title":"O","text":""},{"location":"reference/glossary/#opensearch","title":"OpenSearch","text":"<p>Distributed search and analytics engine used for centralized logging in Fawkes.</p>"},{"location":"reference/glossary/#opentelemetry-otel","title":"OpenTelemetry (OTel)","text":"<p>Vendor-neutral observability framework for generating and collecting telemetry data (traces, metrics, logs).</p>"},{"location":"reference/glossary/#p","title":"P","text":""},{"location":"reference/glossary/#pod-security-standards","title":"Pod Security Standards","text":"<p>Kubernetes security policies defining privilege levels: Privileged, Baseline, Restricted.</p>"},{"location":"reference/glossary/#policyreport","title":"PolicyReport","text":"<p>Custom resource generated by Kyverno containing audit results of policy evaluations.</p>"},{"location":"reference/glossary/#prometheus","title":"Prometheus","text":"<p>Time-series database and monitoring system for collecting and querying metrics.</p>"},{"location":"reference/glossary/#s","title":"S","text":""},{"location":"reference/glossary/#sonarqube","title":"SonarQube","text":"<p>Static application security testing (SAST) platform analyzing code quality and security vulnerabilities.</p>"},{"location":"reference/glossary/#starter-project","title":"Starter Project","text":"<p>Pre-configured template repository referenced in a Devfile for bootstrapping new applications.</p>"},{"location":"reference/glossary/#t","title":"T","text":""},{"location":"reference/glossary/#tempo-grafana-tempo","title":"Tempo (Grafana Tempo)","text":"<p>Distributed tracing backend storing and querying OpenTelemetry traces.</p>"},{"location":"reference/glossary/#trivy","title":"Trivy","text":"<p>Container image and filesystem vulnerability scanner.</p>"},{"location":"reference/glossary/#trunk-based-development","title":"Trunk-Based Development","text":"<p>Source control branching model where developers work on a single main branch with short-lived feature branches.</p>"},{"location":"reference/glossary/#v","title":"V","text":""},{"location":"reference/glossary/#vault-hashicorp-vault","title":"Vault (HashiCorp Vault)","text":"<p>Secrets management system providing secure storage and access control for sensitive data.</p>"},{"location":"reference/glossary/#vault-agent","title":"Vault Agent","text":"<p>Sidecar container that automatically retrieves secrets from Vault and injects them into application pods.</p>"},{"location":"reference/glossary/#y","title":"Y","text":""},{"location":"reference/glossary/#yaml-yaml-aint-markup-language","title":"YAML (YAML Ain't Markup Language)","text":"<p>Human-readable data serialization language used throughout Kubernetes and Fawkes configurations.</p>"},{"location":"reference/glossary/#acronyms-quick-reference","title":"Acronyms Quick Reference","text":"Acronym Full Term API Application Programming Interface BDD Behavior-Driven Development CI/CD Continuous Integration / Continuous Delivery CRD Custom Resource Definition DORA DevOps Research and Assessment IaC Infrastructure as Code IDP Internal Developer Platform JCasC Jenkins Configuration as Code K8s Kubernetes OIDC OpenID Connect OTel OpenTelemetry RBAC Role-Based Access Control SAST Static Application Security Testing TLS Transport Layer Security YAML YAML Ain't Markup Language <p>Note: This glossary is information-oriented reference material. For learning workflows, see Tutorials. For task-specific guidance, see How-To Guides.</p>"},{"location":"reference/score-specification/","title":"SCORE Specification Reference for Fawkes","text":"<p>This document describes the SCORE workload specification fields supported by the Fawkes platform.</p>"},{"location":"reference/score-specification/#overview","title":"Overview","text":"<p>SCORE (Specification for Container Orchestration and Runtime Execution) is an open-source, platform-agnostic workload specification. Fawkes uses SCORE to provide a simplified, portable way to define application workloads.</p> <p>SCORE Homepage: https://score.dev</p> <p>Fawkes Implementation: The Fawkes platform translates SCORE workload specifications into Kubernetes manifests using the SCORE transformer component.</p>"},{"location":"reference/score-specification/#document-structure","title":"Document Structure","text":"<pre><code>apiVersion: score.dev/v1b1\nmetadata: {...}\ncontainers: {...}\nservice: {...}\nresources: {...}\nroute: {...}\nextensions: {...}\n</code></pre>"},{"location":"reference/score-specification/#core-fields-score-standard","title":"Core Fields (SCORE Standard)","text":""},{"location":"reference/score-specification/#apiversion","title":"apiVersion","text":"<p>Type: <code>string</code> Required: Yes Supported Values: <code>score.dev/v1b1</code></p> <p>Specifies the SCORE API version.</p> <p>Example: <pre><code>apiVersion: score.dev/v1b1\n</code></pre></p>"},{"location":"reference/score-specification/#metadata","title":"metadata","text":"<p>Type: <code>object</code> Required: Yes</p> <p>Metadata about the workload.</p>"},{"location":"reference/score-specification/#metadataname","title":"metadata.name","text":"<p>Type: <code>string</code> Required: Yes Constraints:  - Must be a valid Kubernetes resource name - Lowercase alphanumeric characters, <code>-</code> only - Max 63 characters</p> <p>The name of the workload. This becomes the base name for all generated Kubernetes resources.</p> <p>Example: <pre><code>metadata:\n  name: my-service\n</code></pre></p>"},{"location":"reference/score-specification/#containers","title":"containers","text":"<p>Type: <code>object</code> Required: Yes</p> <p>Map of container definitions. Each key is the container name.</p>"},{"location":"reference/score-specification/#containersimage","title":"containers..image <p>Type: <code>string</code> Required: Yes</p> <p>Container image reference.</p> <p>Example: <pre><code>containers:\n  web:\n    image: \"harbor.fawkes.local/my-team/my-app:v1.0.0\"\n</code></pre></p>","text":""},{"location":"reference/score-specification/#containerscommand","title":"containers..command <p>Type: <code>array of strings</code> Required: No</p> <p>Override the container's entrypoint.</p> <p>Example: <pre><code>containers:\n  web:\n    command: [\"/app/server\"]\n</code></pre></p>","text":""},{"location":"reference/score-specification/#containersargs","title":"containers..args <p>Type: <code>array of strings</code> Required: No</p> <p>Override the container's arguments.</p> <p>Example: <pre><code>containers:\n  web:\n    args: [\"--port\", \"8080\", \"--workers\", \"4\"]\n</code></pre></p>","text":""},{"location":"reference/score-specification/#containersresources","title":"containers..resources <p>Type: <code>object</code> Required: Recommended</p> <p>Resource requests and limits.</p> <p>Sub-fields: - <code>requests.cpu</code>: CPU request (e.g., <code>\"100m\"</code>, <code>\"0.5\"</code>) - <code>requests.memory</code>: Memory request (e.g., <code>\"128Mi\"</code>, <code>\"1Gi\"</code>) - <code>limits.cpu</code>: CPU limit - <code>limits.memory</code>: Memory limit</p> <p>Example: <pre><code>containers:\n  web:\n    resources:\n      requests:\n        cpu: \"250m\"\n        memory: \"256Mi\"\n      limits:\n        cpu: \"500m\"\n        memory: \"512Mi\"\n</code></pre></p> <p>Best Practices: - Always set both requests and limits - Memory limits should be 1.5-2x requests - CPU limits can be higher for burstable workloads</p>","text":""},{"location":"reference/score-specification/#containersvariables","title":"containers..variables <p>Type: <code>object</code> Required: No</p> <p>Environment variables for the container. Values can reference resources using <code>${resources.&lt;name&gt;.&lt;field&gt;}</code>.</p> <p>Example: <pre><code>containers:\n  web:\n    variables:\n      LOG_LEVEL: \"info\"\n      DATABASE_URL: \"${resources.db.connection_string}\"\n      REDIS_URL: \"${resources.cache.connection_string}\"\n      ENVIRONMENT: \"${ENVIRONMENT}\"\n</code></pre></p> <p>Variable Interpolation: - <code>${ENVIRONMENT}</code>: Replaced with target environment (dev, staging, prod) - <code>${resources.&lt;resource-name&gt;.&lt;field&gt;}</code>: Replaced with resource field values</p>","text":""},{"location":"reference/score-specification/#containerslivenessprobe","title":"containers..livenessProbe <p>Type: <code>object</code> Required: Recommended</p> <p>Liveness probe configuration.</p> <p>Supported Types: <code>httpGet</code> only (in current implementation)</p> <p>Example: <pre><code>containers:\n  web:\n    livenessProbe:\n      httpGet:\n        path: /health\n        port: 8080\n      initialDelaySeconds: 30\n      periodSeconds: 10\n      timeoutSeconds: 5\n      failureThreshold: 3\n</code></pre></p>","text":""},{"location":"reference/score-specification/#containersreadinessprobe","title":"containers..readinessProbe <p>Type: <code>object</code> Required: Recommended</p> <p>Readiness probe configuration.</p> <p>Example: <pre><code>containers:\n  web:\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n      initialDelaySeconds: 10\n      periodSeconds: 5\n</code></pre></p>","text":""},{"location":"reference/score-specification/#service","title":"service","text":"<p>Type: <code>object</code> Required: No (required if exposing ports)</p> <p>Service configuration for the workload.</p>"},{"location":"reference/score-specification/#serviceports","title":"service.ports <p>Type: <code>object</code> Required: Yes (if <code>service</code> is defined)</p> <p>Map of port definitions. Each key is the port name.</p> <p>Sub-fields: - <code>port</code>: External port (on the Service) - <code>targetPort</code>: Container port - <code>protocol</code>: Protocol (<code>tcp</code>, <code>udp</code>)</p> <p>Example: <pre><code>service:\n  ports:\n    http:\n      port: 80\n      targetPort: 8080\n      protocol: tcp\n    grpc:\n      port: 9090\n      targetPort: 9090\n      protocol: tcp\n</code></pre></p>","text":""},{"location":"reference/score-specification/#resources","title":"resources","text":"<p>Type: <code>object</code> Required: No</p> <p>Map of infrastructure resources required by the workload.</p>"},{"location":"reference/score-specification/#resource-type-postgres","title":"Resource Type: postgres <p>PostgreSQL database provisioned via CloudNativePG.</p> <p>Example: <pre><code>resources:\n  db:\n    type: postgres\n    metadata:\n      annotations:\n        fawkes.dev/storage-size: \"10Gi\"\n        fawkes.dev/version: \"15\"\n    properties:\n      database: \"myapp\"\n</code></pre></p> <p>Generated Resources: - CloudNativePG Cluster (managed externally) - ExternalSecret with connection credentials - Environment variable: <code>${resources.db.connection_string}</code></p> <p>Fawkes Annotations: - <code>fawkes.dev/storage-size</code>: Persistent volume size (default: <code>10Gi</code>) - <code>fawkes.dev/version</code>: PostgreSQL version (default: <code>15</code>)</p>","text":""},{"location":"reference/score-specification/#resource-type-redis","title":"Resource Type: redis <p>Redis cache provisioned via Redis Helm Chart.</p> <p>Example: <pre><code>resources:\n  cache:\n    type: redis\n    metadata:\n      annotations:\n        fawkes.dev/storage-size: \"2Gi\"\n    properties:\n      maxmemory-policy: \"allkeys-lru\"\n</code></pre></p> <p>Generated Resources: - Redis StatefulSet (managed externally) - ExternalSecret with connection credentials - Environment variable: <code>${resources.cache.connection_string}</code></p>","text":""},{"location":"reference/score-specification/#resource-type-secret","title":"Resource Type: secret <p>Secrets from HashiCorp Vault provisioned via External Secrets Operator.</p> <p>Example: <pre><code>resources:\n  api-keys:\n    type: secret\n    metadata:\n      annotations:\n        fawkes.dev/vault-path: \"secret/my-team/my-app/keys\"\n    properties:\n      keys:\n        - API_KEY\n        - JWT_SECRET\n</code></pre></p> <p>Generated Resources: - ExternalSecret referencing Vault - Kubernetes Secret with specified keys - Environment variables: <code>${resources.api-keys.API_KEY}</code>, etc.</p> <p>Fawkes Annotations: - <code>fawkes.dev/vault-path</code>: Path in Vault (required)</p>","text":""},{"location":"reference/score-specification/#resource-type-volume","title":"Resource Type: volume <p>Persistent volume provisioned via PersistentVolumeClaim.</p> <p>Example: <pre><code>resources:\n  uploads:\n    type: volume\n    metadata:\n      annotations:\n        fawkes.dev/storage-class: \"standard\"\n        fawkes.dev/access-mode: \"ReadWriteOnce\"\n    properties:\n      size: \"5Gi\"\n      mountPath: \"/app/uploads\"\n</code></pre></p> <p>Generated Resources: - PersistentVolumeClaim - Volume mount in container</p> <p>Fawkes Annotations: - <code>fawkes.dev/storage-class</code>: StorageClass (default: <code>standard</code>) - <code>fawkes.dev/access-mode</code>: Access mode (default: <code>ReadWriteOnce</code>)</p> <p>Properties: - <code>size</code>: Storage size (required) - <code>mountPath</code>: Path in container (required)</p>","text":""},{"location":"reference/score-specification/#route","title":"route","text":"<p>Type: <code>object</code> Required: No (required for external access)</p> <p>Ingress/route configuration for external access.</p>"},{"location":"reference/score-specification/#routehost","title":"route.host <p>Type: <code>string</code> Required: Yes (if <code>route</code> is defined)</p> <p>Hostname for the Ingress. Use <code>${ENVIRONMENT}</code> for environment interpolation.</p> <p>Example: <pre><code>route:\n  host: \"my-service.${ENVIRONMENT}.fawkes.idp\"\n</code></pre></p> <p>Dev: <code>my-service.dev.fawkes.idp</code> Prod: <code>my-service.prod.fawkes.idp</code></p>","text":""},{"location":"reference/score-specification/#routepath","title":"route.path <p>Type: <code>string</code> Required: No Default: <code>\"/\"</code></p> <p>Path prefix for routing.</p> <p>Example: <pre><code>route:\n  path: \"/api\"\n</code></pre></p>","text":""},{"location":"reference/score-specification/#routetls","title":"route.tls <p>Type: <code>object</code> Required: No</p> <p>TLS/HTTPS configuration.</p> <p>Sub-fields: - <code>enabled</code>: Boolean (default: <code>true</code>)</p> <p>Example: <pre><code>route:\n  tls:\n    enabled: true\n</code></pre></p> <p>Generated Resources: - Ingress with TLS configuration - Certificate automatically provisioned via cert-manager</p>","text":""},{"location":"reference/score-specification/#fawkes-extensions","title":"Fawkes Extensions","text":"<p>The <code>extensions.fawkes</code> section provides Fawkes-specific features beyond the SCORE standard.</p>"},{"location":"reference/score-specification/#extensionsfawkesteam","title":"extensions.fawkes.team","text":"<p>Type: <code>string</code> Required: Recommended</p> <p>Team name for RBAC and billing.</p> <p>Example: <pre><code>extensions:\n  fawkes:\n    team: my-team\n</code></pre></p>"},{"location":"reference/score-specification/#extensionsfawkesdeployment","title":"extensions.fawkes.deployment","text":"<p>Type: <code>object</code> Required: No</p> <p>Deployment-specific configuration.</p>"},{"location":"reference/score-specification/#deploymentstrategy","title":"deployment.strategy <p>Type: <code>string</code> Default: <code>\"RollingUpdate\"</code> Options: <code>RollingUpdate</code>, <code>Recreate</code></p> <p>Kubernetes deployment strategy.</p>","text":""},{"location":"reference/score-specification/#deploymentreplicas","title":"deployment.replicas <p>Type: <code>integer</code> Default: <code>2</code></p> <p>Number of replicas.</p>","text":""},{"location":"reference/score-specification/#deploymentautoscaling","title":"deployment.autoscaling <p>Type: <code>object</code> Required: No</p> <p>Horizontal Pod Autoscaler configuration.</p> <p>Sub-fields: - <code>enabled</code>: Boolean (default: <code>false</code>) - <code>minReplicas</code>: Minimum replicas (default: <code>2</code>) - <code>maxReplicas</code>: Maximum replicas (default: <code>10</code>) - <code>targetCPUUtilizationPercentage</code>: CPU target (default: <code>70</code>) - <code>targetMemoryUtilizationPercentage</code>: Memory target (default: <code>80</code>)</p> <p>Example: <pre><code>extensions:\n  fawkes:\n    deployment:\n      autoscaling:\n        enabled: true\n        minReplicas: 3\n        maxReplicas: 20\n        targetCPUUtilizationPercentage: 70\n        targetMemoryUtilizationPercentage: 80\n</code></pre></p>","text":""},{"location":"reference/score-specification/#extensionsfawkesobservability","title":"extensions.fawkes.observability","text":"<p>Type: <code>object</code> Required: No</p> <p>Observability configuration.</p>"},{"location":"reference/score-specification/#observabilitymetrics","title":"observability.metrics <p>Type: <code>object</code></p> <p>Prometheus metrics scraping configuration.</p> <p>Sub-fields: - <code>enabled</code>: Boolean (default: <code>false</code>) - <code>port</code>: Metrics port (default: <code>9090</code>) - <code>path</code>: Metrics path (default: <code>\"/metrics\"</code>)</p> <p>Example: <pre><code>extensions:\n  fawkes:\n    observability:\n      metrics:\n        enabled: true\n        port: 9090\n        path: \"/metrics\"\n</code></pre></p> <p>Generated Annotations: <pre><code>annotations:\n  prometheus.io/scrape: \"true\"\n  prometheus.io/port: \"9090\"\n  prometheus.io/path: \"/metrics\"\n</code></pre></p>","text":""},{"location":"reference/score-specification/#observabilitytracing","title":"observability.tracing <p>Type: <code>object</code></p> <p>OpenTelemetry distributed tracing configuration.</p> <p>Sub-fields: - <code>enabled</code>: Boolean (default: <code>false</code>) - <code>samplingRate</code>: Sampling rate (0.0-1.0, default: <code>0.1</code>)</p> <p>Example: <pre><code>extensions:\n  fawkes:\n    observability:\n      tracing:\n        enabled: true\n        samplingRate: 0.1\n</code></pre></p>","text":""},{"location":"reference/score-specification/#observabilitylogging","title":"observability.logging <p>Type: <code>object</code></p> <p>Logging configuration.</p> <p>Sub-fields: - <code>enabled</code>: Boolean (default: <code>true</code>) - <code>format</code>: Log format (<code>json</code>, <code>text</code>, default: <code>json</code>) - <code>level</code>: Log level (<code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>, default: <code>info</code>)</p>","text":""},{"location":"reference/score-specification/#extensionsfawkessecurity","title":"extensions.fawkes.security","text":"<p>Type: <code>object</code> Required: No</p> <p>Security configuration.</p>"},{"location":"reference/score-specification/#securitypodsecuritystandard","title":"security.podSecurityStandard <p>Type: <code>string</code> Default: <code>\"restricted\"</code> Options: <code>privileged</code>, <code>baseline</code>, <code>restricted</code></p> <p>Pod Security Standard level.</p>","text":""},{"location":"reference/score-specification/#securityrunasnonroot","title":"security.runAsNonRoot <p>Type: <code>boolean</code> Default: <code>true</code></p> <p>Run containers as non-root user.</p>","text":""},{"location":"reference/score-specification/#securityrunasuser","title":"security.runAsUser <p>Type: <code>integer</code> Default: <code>65534</code></p> <p>User ID to run containers as.</p>","text":""},{"location":"reference/score-specification/#securitynetworkpolicy","title":"security.networkPolicy <p>Type: <code>object</code></p> <p>NetworkPolicy configuration.</p> <p>Sub-fields: - <code>enabled</code>: Boolean (default: <code>false</code>) - <code>allowedNamespaces</code>: Array of allowed namespaces</p> <p>Example: <pre><code>extensions:\n  fawkes:\n    security:\n      runAsNonRoot: true\n      runAsUser: 65534\n      networkPolicy:\n        enabled: true\n        allowedNamespaces:\n          - \"my-team\"\n          - \"fawkes\"\n</code></pre></p>","text":""},{"location":"reference/score-specification/#extensionsfawkesdora","title":"extensions.fawkes.dora","text":"<p>Type: <code>object</code> Required: No</p> <p>DORA metrics tracking configuration.</p> <p>Sub-fields: - <code>enabled</code>: Boolean (default: <code>true</code>)</p> <p>Example: <pre><code>extensions:\n  fawkes:\n    dora:\n      enabled: true\n</code></pre></p>"},{"location":"reference/score-specification/#complete-example","title":"Complete Example","text":"<pre><code>apiVersion: score.dev/v1b1\n\nmetadata:\n  name: fullstack-app\n\ncontainers:\n  web:\n    image: \"harbor.fawkes.local/team-a/app:v2.1.0\"\n    resources:\n      requests: {cpu: \"500m\", memory: \"512Mi\"}\n      limits: {cpu: \"1000m\", memory: \"1Gi\"}\n    variables:\n      LOG_LEVEL: \"info\"\n      DATABASE_URL: \"${resources.db.connection_string}\"\n      REDIS_URL: \"${resources.cache.connection_string}\"\n      API_KEY: \"${resources.secrets.API_KEY}\"\n    livenessProbe:\n      httpGet: {path: /health, port: 8080}\n      initialDelaySeconds: 30\n    readinessProbe:\n      httpGet: {path: /ready, port: 8080}\n      initialDelaySeconds: 10\n\nservice:\n  ports:\n    http: {port: 80, targetPort: 8080, protocol: tcp}\n\nresources:\n  db:\n    type: postgres\n    properties: {database: \"appdb\"}\n  cache:\n    type: redis\n  secrets:\n    type: secret\n    metadata:\n      annotations:\n        fawkes.dev/vault-path: \"secret/team-a/app\"\n    properties:\n      keys: [API_KEY, JWT_SECRET]\n  uploads:\n    type: volume\n    properties: {size: \"10Gi\", mountPath: \"/app/uploads\"}\n\nroute:\n  host: \"app.${ENVIRONMENT}.fawkes.idp\"\n  path: \"/\"\n  tls: {enabled: true}\n\nextensions:\n  fawkes:\n    team: team-a\n    deployment:\n      autoscaling:\n        enabled: true\n        minReplicas: 3\n        maxReplicas: 20\n    observability:\n      metrics: {enabled: true, port: 9090}\n      tracing: {enabled: true, samplingRate: 0.1}\n    security:\n      runAsNonRoot: true\n      networkPolicy:\n        enabled: true\n        allowedNamespaces: [\"team-a\", \"fawkes\"]\n</code></pre>"},{"location":"reference/score-specification/#migration-from-kubernetes-manifests","title":"Migration from Kubernetes Manifests","text":""},{"location":"reference/score-specification/#step-1-identify-core-components","title":"Step 1: Identify Core Components","text":"<p>Map your existing K8s resources to SCORE fields:</p> Kubernetes Resource SCORE Field Deployment.spec.template.spec.containers <code>containers</code> Deployment.spec.replicas <code>extensions.fawkes.deployment.replicas</code> Service.spec.ports <code>service.ports</code> Ingress.spec.rules <code>route</code> ConfigMap/Secret <code>resources</code> (type: secret) PersistentVolumeClaim <code>resources</code> (type: volume)"},{"location":"reference/score-specification/#step-2-create-scoreyaml","title":"Step 2: Create score.yaml","text":"<p>Start with a minimal <code>score.yaml</code>:</p> <pre><code>apiVersion: score.dev/v1b1\nmetadata:\n  name: my-service\ncontainers:\n  web:\n    image: &lt;from Deployment&gt;\n    resources: &lt;from Deployment&gt;\nservice:\n  ports: &lt;from Service&gt;\n</code></pre>"},{"location":"reference/score-specification/#step-3-add-resources","title":"Step 3: Add Resources","text":"<p>For each external dependency (DB, cache, etc.), add a resource:</p> <pre><code>resources:\n  db:\n    type: postgres\n</code></pre>"},{"location":"reference/score-specification/#step-4-validate","title":"Step 4: Validate","text":"<p>Generate manifests and compare:</p> <pre><code>python3 charts/score-transformer/generator.py \\\n  --score score.yaml \\\n  --environment dev \\\n  --output /tmp/generated\n\ndiff /tmp/generated/deployment.yaml old-deployment.yaml\n</code></pre>"},{"location":"reference/score-specification/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/score-specification/#common-issues","title":"Common Issues","text":""},{"location":"reference/score-specification/#invalid-score-file","title":"Invalid SCORE File <p>Error: <code>ValueError: score.yaml must have 'apiVersion' field</code></p> <p>Solution: Ensure your file starts with: <pre><code>apiVersion: score.dev/v1b1\n</code></pre></p>","text":""},{"location":"reference/score-specification/#environment-variable-not-interpolated","title":"Environment Variable Not Interpolated <p>Problem: <code>${ENVIRONMENT}</code> appears literally in generated manifests</p> <p>Solution: The transformer replaces this automatically. Check you're using the correct syntax: <pre><code>route:\n  host: \"app.${ENVIRONMENT}.fawkes.idp\"\n</code></pre></p>","text":""},{"location":"reference/score-specification/#resource-not-provisioned","title":"Resource Not Provisioned <p>Problem: Database/cache not created</p> <p>Solution: Resource provisioning happens externally to the SCORE transformer. The transformer only generates ExternalSecret references. Ensure: 1. CloudNativePG operator is installed (for postgres) 2. Redis is deployed (for redis) 3. External Secrets Operator is configured (for secrets)</p>","text":""},{"location":"reference/score-specification/#further-reading","title":"Further Reading","text":"<ul> <li>SCORE Official Documentation</li> <li>ADR-030: SCORE Integration</li> <li>Golden Path Usage Guide</li> <li>SCORE Transformer README</li> <li>Golden Path Service Template</li> </ul>"},{"location":"reference/api/backstage-plugins/","title":"Backstage Plugins API","text":""},{"location":"reference/api/backstage-plugins/#overview","title":"Overview","text":"<p>This document describes the REST APIs exposed by custom Backstage plugins integrated into the Fawkes platform. These plugins extend Backstage's functionality for Fawkes-specific workflows.</p> <p>Base URL: <code>https://backstage.fawkes.example.com/api</code></p> <p>Authentication: Backstage user session or service-to-service tokens.</p>"},{"location":"reference/api/backstage-plugins/#che-launcher-plugin","title":"Che Launcher Plugin","text":""},{"location":"reference/api/backstage-plugins/#post-che-launcherworkspaces","title":"POST /che-launcher/workspaces","text":"<p>Creates a new Eclipse Che workspace from a Devfile.</p>"},{"location":"reference/api/backstage-plugins/#request","title":"Request","text":"<p>Method: <code>POST</code></p> <p>URL: <code>/api/che-launcher/workspaces</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Bearer token from Backstage session. <code>Content-Type</code> Yes <code>application/json</code> <p>Request Body:</p> <pre><code>{\n  \"devfileUrl\": \"https://raw.githubusercontent.com/paruff/fawkes/main/platform/devfiles/goldenpath-python.yaml\",\n  \"namespace\": \"dev-workspaces\",\n  \"name\": \"my-python-workspace\"\n}\n</code></pre> Field Type Required Description <code>devfileUrl</code> String Yes URL to Devfile 2.2.2 YAML file. <code>namespace</code> String No Kubernetes namespace for workspace. Default: <code>{user}-workspaces</code>. <code>name</code> String No Workspace name. Default: auto-generated."},{"location":"reference/api/backstage-plugins/#response","title":"Response","text":"<p>Success (201 Created):</p> <pre><code>{\n  \"workspaceId\": \"workspace-abc123\",\n  \"name\": \"my-python-workspace\",\n  \"status\": \"Starting\",\n  \"ideUrl\": \"https://che.fawkes.example.com/workspace-abc123\",\n  \"devfile\": {\n    \"name\": \"goldenpath-python\",\n    \"version\": \"1.0.0\"\n  }\n}\n</code></pre> <p>Error (400 Bad Request):</p> <pre><code>{\n  \"error\": \"Invalid devfileUrl: URL must be HTTPS\"\n}\n</code></pre> <p>Error (409 Conflict):</p> <pre><code>{\n  \"error\": \"Workspace with name 'my-python-workspace' already exists\"\n}\n</code></pre>"},{"location":"reference/api/backstage-plugins/#get-che-launcherworkspaces","title":"GET /che-launcher/workspaces","text":"<p>Lists all workspaces for the authenticated user.</p>"},{"location":"reference/api/backstage-plugins/#request_1","title":"Request","text":"<p>Method: <code>GET</code></p> <p>URL: <code>/api/che-launcher/workspaces</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Bearer token. <p>Query Parameters:</p> Parameter Type Required Description <code>status</code> String No Filter by status: <code>Running</code>, <code>Stopped</code>, <code>Starting</code>, <code>Stopping</code>."},{"location":"reference/api/backstage-plugins/#response_1","title":"Response","text":"<p>Success (200 OK):</p> <pre><code>{\n  \"workspaces\": [\n    {\n      \"workspaceId\": \"workspace-abc123\",\n      \"name\": \"my-python-workspace\",\n      \"status\": \"Running\",\n      \"ideUrl\": \"https://che.fawkes.example.com/workspace-abc123\",\n      \"devfile\": {\n        \"name\": \"goldenpath-python\",\n        \"version\": \"1.0.0\"\n      },\n      \"createdAt\": \"2024-12-01T10:00:00Z\",\n      \"lastUsed\": \"2024-12-06T09:30:00Z\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"reference/api/backstage-plugins/#delete-che-launcherworkspacesworkspaceid","title":"DELETE /che-launcher/workspaces/{workspaceId}","text":"<p>Deletes a workspace.</p>"},{"location":"reference/api/backstage-plugins/#request_2","title":"Request","text":"<p>Method: <code>DELETE</code></p> <p>URL: <code>/api/che-launcher/workspaces/{workspaceId}</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Bearer token."},{"location":"reference/api/backstage-plugins/#response_2","title":"Response","text":"<p>Success (204 No Content):</p> <p>No response body.</p> <p>Error (404 Not Found):</p> <pre><code>{\n  \"error\": \"Workspace not found\"\n}\n</code></pre>"},{"location":"reference/api/backstage-plugins/#devlake-dashboard-plugin","title":"DevLake Dashboard Plugin","text":""},{"location":"reference/api/backstage-plugins/#get-devlakedora-metrics","title":"GET /devlake/dora-metrics","text":"<p>Retrieves DORA metrics for a project or team.</p>"},{"location":"reference/api/backstage-plugins/#request_3","title":"Request","text":"<p>Method: <code>GET</code></p> <p>URL: <code>/api/devlake/dora-metrics</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Bearer token. <p>Query Parameters:</p> Parameter Type Required Description <code>project</code> String No Project name (from Backstage catalog). <code>team</code> String No Team name. <code>startDate</code> String No Start date (ISO 8601). Default: 30 days ago. <code>endDate</code> String No End date (ISO 8601). Default: today."},{"location":"reference/api/backstage-plugins/#response_3","title":"Response","text":"<p>Success (200 OK):</p> <pre><code>{\n  \"project\": \"my-service\",\n  \"team\": \"platform-team\",\n  \"period\": {\n    \"startDate\": \"2024-11-01\",\n    \"endDate\": \"2024-12-01\"\n  },\n  \"metrics\": {\n    \"deploymentFrequency\": {\n      \"value\": 12,\n      \"unit\": \"deploys/week\",\n      \"trend\": \"increasing\",\n      \"performance\": \"elite\"\n    },\n    \"leadTimeForChanges\": {\n      \"value\": 2.5,\n      \"unit\": \"hours\",\n      \"trend\": \"stable\",\n      \"performance\": \"elite\"\n    },\n    \"changeFailureRate\": {\n      \"value\": 5.2,\n      \"unit\": \"percent\",\n      \"trend\": \"decreasing\",\n      \"performance\": \"high\"\n    },\n    \"timeToRestoreService\": {\n      \"value\": 0.8,\n      \"unit\": \"hours\",\n      \"trend\": \"stable\",\n      \"performance\": \"elite\"\n    }\n  }\n}\n</code></pre> <p>Performance Levels:</p> <ul> <li><code>elite</code>: Top 10% of performers.</li> <li><code>high</code>: 60-75th percentile.</li> <li><code>medium</code>: 30-60th percentile.</li> <li><code>low</code>: Below 30th percentile.</li> </ul>"},{"location":"reference/api/backstage-plugins/#get-devlakedeployment-history","title":"GET /devlake/deployment-history","text":"<p>Retrieves deployment history for a service.</p>"},{"location":"reference/api/backstage-plugins/#request_4","title":"Request","text":"<p>Method: <code>GET</code></p> <p>URL: <code>/api/devlake/deployment-history</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Bearer token. <p>Query Parameters:</p> Parameter Type Required Description <code>service</code> String Yes Service name. <code>environment</code> String No Filter by environment (<code>dev</code>, <code>staging</code>, <code>prod</code>). <code>limit</code> Integer No Number of results. Default: <code>20</code>. Max: <code>100</code>."},{"location":"reference/api/backstage-plugins/#response_4","title":"Response","text":"<p>Success (200 OK):</p> <pre><code>{\n  \"service\": \"my-service\",\n  \"deployments\": [\n    {\n      \"id\": \"deploy-789\",\n      \"version\": \"v1.2.3\",\n      \"environment\": \"prod\",\n      \"status\": \"SUCCESS\",\n      \"startTime\": \"2024-12-06T08:00:00Z\",\n      \"endTime\": \"2024-12-06T08:05:00Z\",\n      \"duration\": 300,\n      \"triggeredBy\": \"GitHub Push\",\n      \"commit\": {\n        \"sha\": \"def456...\",\n        \"message\": \"feat: add new feature\",\n        \"author\": \"developer@example.com\"\n      }\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"reference/api/backstage-plugins/#catalog-plugin-extended","title":"Catalog Plugin (Extended)","text":""},{"location":"reference/api/backstage-plugins/#post-cataloglocations","title":"POST /catalog/locations","text":"<p>Registers a new entity location (e.g., Git repository with <code>catalog-info.yaml</code>).</p>"},{"location":"reference/api/backstage-plugins/#request_5","title":"Request","text":"<p>Method: <code>POST</code></p> <p>URL: <code>/api/catalog/locations</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Bearer token. <code>Content-Type</code> Yes <code>application/json</code> <p>Request Body:</p> <pre><code>{\n  \"type\": \"url\",\n  \"target\": \"https://github.com/paruff/my-service/blob/main/catalog-info.yaml\"\n}\n</code></pre> Field Type Required Description <code>type</code> String Yes Location type: <code>url</code>, <code>file</code>. <code>target</code> String Yes URL or file path to <code>catalog-info.yaml</code>."},{"location":"reference/api/backstage-plugins/#response_5","title":"Response","text":"<p>Success (201 Created):</p> <pre><code>{\n  \"locationId\": \"location-xyz\",\n  \"type\": \"url\",\n  \"target\": \"https://github.com/paruff/my-service/blob/main/catalog-info.yaml\",\n  \"status\": \"processing\"\n}\n</code></pre> <p>Error (400 Bad Request):</p> <pre><code>{\n  \"error\": \"Invalid catalog-info.yaml: missing required field 'metadata.name'\"\n}\n</code></pre>"},{"location":"reference/api/backstage-plugins/#get-catalogentities","title":"GET /catalog/entities","text":"<p>Retrieves entities from the software catalog.</p>"},{"location":"reference/api/backstage-plugins/#request_6","title":"Request","text":"<p>Method: <code>GET</code></p> <p>URL: <code>/api/catalog/entities</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Bearer token. <p>Query Parameters:</p> Parameter Type Required Description <code>filter</code> String No Filter expression (e.g., <code>kind=Component,metadata.name=my-service</code>). <code>fields</code> String No Comma-separated list of fields to include."},{"location":"reference/api/backstage-plugins/#response_6","title":"Response","text":"<p>Success (200 OK):</p> <pre><code>[\n  {\n    \"apiVersion\": \"backstage.io/v1alpha1\",\n    \"kind\": \"Component\",\n    \"metadata\": {\n      \"name\": \"my-service\",\n      \"description\": \"Microservice for user management\",\n      \"labels\": {\n        \"app.fawkes.idp/team\": \"platform-team\"\n      }\n    },\n    \"spec\": {\n      \"type\": \"service\",\n      \"lifecycle\": \"production\",\n      \"owner\": \"platform-team\"\n    }\n  }\n]\n</code></pre>"},{"location":"reference/api/backstage-plugins/#authentication","title":"Authentication","text":"<p>All API endpoints require authentication via:</p> <ol> <li>Backstage User Session: Automatically included when using Backstage UI.</li> <li>Service Token: For service-to-service calls, use a service account token:</li> </ol> <pre><code>curl -H \"Authorization: Bearer &lt;service-token&gt;\" \\\n  https://backstage.fawkes.example.com/api/catalog/entities\n</code></pre> <p>Generate Service Token:</p> <pre><code># Create Kubernetes Secret with service account token\nkubectl create secret generic backstage-service-token \\\n  --from-literal=token=$(kubectl create token backstage-sa -n backstage)\n</code></pre>"},{"location":"reference/api/backstage-plugins/#error-codes","title":"Error Codes","text":"HTTP Code Meaning Common Causes 200 OK Success Valid request. 201 Created Resource created Workspace or entity created. 204 No Content Success (no data) Resource deleted. 400 Bad Request Invalid request Malformed JSON, missing fields. 401 Unauthorized Authentication failed Invalid or missing token. 403 Forbidden Permission denied User lacks access to resource. 404 Not Found Resource not found Invalid workspace ID, entity not in catalog. 409 Conflict Resource already exists Duplicate workspace or entity. 500 Internal Server Error Server error Check Backstage backend logs."},{"location":"reference/api/backstage-plugins/#rate-limits","title":"Rate Limits","text":"<ul> <li>User API Calls: 100 requests/minute per user.</li> <li>Service Token Calls: 1000 requests/minute per token.</li> </ul> <p>Rate Limit Headers:</p> <pre><code>X-RateLimit-Limit: 100\nX-RateLimit-Remaining: 95\nX-RateLimit-Reset: 1672531260\n</code></pre>"},{"location":"reference/api/backstage-plugins/#see-also","title":"See Also","text":"<ul> <li>Backstage Official API Documentation</li> <li>Eclipse Che REST API</li> <li>DevLake API Documentation</li> <li>Service Catalog Reference</li> </ul>"},{"location":"reference/api/jenkins-webhook/","title":"Jenkins Webhook API","text":""},{"location":"reference/api/jenkins-webhook/#overview","title":"Overview","text":"<p>The Jenkins Webhook API enables external systems (GitHub, GitLab, CI/CD orchestrators) to trigger pipeline builds programmatically. This API is used for event-driven automation and GitOps integration.</p> <p>Base URL: <code>https://jenkins.fawkes.example.com</code></p> <p>Authentication: API Token or GitHub webhook secret validation.</p>"},{"location":"reference/api/jenkins-webhook/#endpoints","title":"Endpoints","text":""},{"location":"reference/api/jenkins-webhook/#post-generic-webhook-triggerinvoke","title":"POST /generic-webhook-trigger/invoke","text":"<p>Triggers a Jenkins job via the Generic Webhook Trigger plugin.</p>"},{"location":"reference/api/jenkins-webhook/#request","title":"Request","text":"<p>Method: <code>POST</code></p> <p>URL: <code>/generic-webhook-trigger/invoke</code></p> <p>Headers:</p> Header Required Description <code>Content-Type</code> Yes Must be <code>application/json</code>. <code>X-GitHub-Event</code> No GitHub event type (for GitHub webhooks). <code>X-Hub-Signature-256</code> No HMAC signature for webhook verification (GitHub). <p>Query Parameters:</p> Parameter Type Required Description <code>token</code> String Yes Webhook token configured in Jenkins job. <p>Request Body (JSON):</p> <pre><code>{\n  \"repository\": {\n    \"name\": \"my-service\",\n    \"url\": \"https://github.com/paruff/my-service\",\n    \"clone_url\": \"https://github.com/paruff/my-service.git\"\n  },\n  \"ref\": \"refs/heads/main\",\n  \"before\": \"abc123...\",\n  \"after\": \"def456...\",\n  \"commits\": [\n    {\n      \"id\": \"def456...\",\n      \"message\": \"feat: add new feature\",\n      \"author\": {\n        \"name\": \"Developer\",\n        \"email\": \"dev@example.com\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#response","title":"Response","text":"<p>Success (200 OK):</p> <pre><code>{\n  \"jobs\": {\n    \"my-service-pipeline\": {\n      \"triggered\": true,\n      \"url\": \"https://jenkins.fawkes.example.com/job/my-service-pipeline/123/\",\n      \"buildNumber\": 123\n    }\n  }\n}\n</code></pre> <p>Error (400 Bad Request):</p> <pre><code>{\n  \"message\": \"Missing required parameter: token\"\n}\n</code></pre> <p>Error (401 Unauthorized):</p> <pre><code>{\n  \"message\": \"Invalid webhook token\"\n}\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#post-jobjobnamebuild","title":"POST /job/{jobName}/build","text":"<p>Triggers a Jenkins job directly (requires authentication).</p>"},{"location":"reference/api/jenkins-webhook/#request_1","title":"Request","text":"<p>Method: <code>POST</code></p> <p>URL: <code>/job/{jobName}/build</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Basic Auth (<code>username:apiToken</code> Base64 encoded). <p>Query Parameters:</p> Parameter Type Required Description <code>token</code> String No Build token (if configured in job). <code>delay</code> Integer No Delay before starting build (seconds). Default: <code>0</code>. <p>Request Body:</p> <p>None for parameterless jobs. For parameterized jobs, send form data:</p> <pre><code>BRANCH=main\nENVIRONMENT=dev\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#response_1","title":"Response","text":"<p>Success (201 Created):</p> <pre><code>{\n  \"location\": \"https://jenkins.fawkes.example.com/queue/item/456/\"\n}\n</code></pre> <p>Response Headers:</p> <ul> <li><code>Location</code>: URL to the queued build item.</li> </ul> <p>Error (401 Unauthorized):</p> <pre><code>{\n  \"message\": \"Authentication required\"\n}\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#post-jobjobnamebuildwithparameters","title":"POST /job/{jobName}/buildWithParameters","text":"<p>Triggers a parameterized Jenkins job.</p>"},{"location":"reference/api/jenkins-webhook/#request_2","title":"Request","text":"<p>Method: <code>POST</code></p> <p>URL: <code>/job/{jobName}/buildWithParameters</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Basic Auth (<code>username:apiToken</code> Base64 encoded). <code>Content-Type</code> Yes <code>application/x-www-form-urlencoded</code> or <code>application/json</code>. <p>Request Body (Form Data):</p> <pre><code>BRANCH=main\nENVIRONMENT=prod\nIMAGE_TAG=v1.2.3\n</code></pre> <p>Request Body (JSON):</p> <pre><code>{\n  \"parameter\": [\n    {\"name\": \"BRANCH\", \"value\": \"main\"},\n    {\"name\": \"ENVIRONMENT\", \"value\": \"prod\"},\n    {\"name\": \"IMAGE_TAG\", \"value\": \"v1.2.3\"}\n  ]\n}\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#response_2","title":"Response","text":"<p>Success (201 Created):</p> <p>Headers include <code>Location: /queue/item/789/</code>.</p> <p>Error (400 Bad Request):</p> <pre><code>{\n  \"message\": \"Missing required parameter: BRANCH\"\n}\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#get-jobjobnamelastbuildapijson","title":"GET /job/{jobName}/lastBuild/api/json","text":"<p>Retrieves status of the last build.</p>"},{"location":"reference/api/jenkins-webhook/#request_3","title":"Request","text":"<p>Method: <code>GET</code></p> <p>URL: <code>/job/{jobName}/lastBuild/api/json</code></p> <p>Headers:</p> Header Required Description <code>Authorization</code> Yes Basic Auth."},{"location":"reference/api/jenkins-webhook/#response_3","title":"Response","text":"<p>Success (200 OK):</p> <pre><code>{\n  \"number\": 123,\n  \"result\": \"SUCCESS\",\n  \"building\": false,\n  \"duration\": 45000,\n  \"timestamp\": 1672531200000,\n  \"url\": \"https://jenkins.fawkes.example.com/job/my-service/123/\",\n  \"changeSet\": {\n    \"items\": [\n      {\n        \"commitId\": \"def456...\",\n        \"msg\": \"feat: add new feature\",\n        \"author\": {\n          \"fullName\": \"Developer\"\n        }\n      }\n    ]\n  }\n}\n</code></pre> <p>Build Results:</p> <ul> <li><code>SUCCESS</code>: Build completed successfully.</li> <li><code>FAILURE</code>: Build failed.</li> <li><code>UNSTABLE</code>: Build succeeded but has test failures or warnings.</li> <li><code>ABORTED</code>: Build was manually stopped.</li> <li><code>null</code>: Build is still running.</li> </ul>"},{"location":"reference/api/jenkins-webhook/#authentication","title":"Authentication","text":""},{"location":"reference/api/jenkins-webhook/#api-token","title":"API Token","text":"<p>Generate an API token in Jenkins:</p> <ol> <li>Navigate to User Menu \u2192 Configure.</li> <li>Under API Token, click Add new Token.</li> <li>Copy the token (shown only once).</li> </ol> <p>Usage (cURL):</p> <pre><code>curl -X POST https://jenkins.fawkes.example.com/job/my-service/build \\\n  -u username:apiToken\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#github-webhook-secret","title":"GitHub Webhook Secret","text":"<p>Configure webhook secret in Jenkins job:</p> <ol> <li>In job configuration, enable Generic Webhook Trigger.</li> <li>Set Token to a random string.</li> <li>In GitHub repository settings, add webhook:</li> <li>URL: <code>https://jenkins.fawkes.example.com/generic-webhook-trigger/invoke?token=&lt;TOKEN&gt;</code></li> <li>Secret: (Optional) HMAC signature validation.</li> </ol>"},{"location":"reference/api/jenkins-webhook/#example-workflows","title":"Example Workflows","text":""},{"location":"reference/api/jenkins-webhook/#trigger-pipeline-from-github-push","title":"Trigger Pipeline from GitHub Push","text":"<p>GitHub Webhook Configuration:</p> <ul> <li>Payload URL: <code>https://jenkins.fawkes.example.com/generic-webhook-trigger/invoke?token=abc123xyz</code></li> <li>Content type: <code>application/json</code></li> <li>Events: <code>push</code></li> </ul> <p>Jenkins Job Configuration (Jenkinsfile):</p> <pre><code>@Library('fawkes-pipeline-library') _\n\ngoldenPathPipeline {\n    appName = 'my-service'\n    language = 'python'\n}\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#manual-build-with-parameters","title":"Manual Build with Parameters","text":"<p>cURL Command:</p> <pre><code>curl -X POST https://jenkins.fawkes.example.com/job/my-service/buildWithParameters \\\n  -u username:apiToken \\\n  -d \"BRANCH=feature/new-api\" \\\n  -d \"ENVIRONMENT=dev\"\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#check-build-status","title":"Check Build Status","text":"<p>cURL Command:</p> <pre><code>curl -X GET https://jenkins.fawkes.example.com/job/my-service/lastBuild/api/json \\\n  -u username:apiToken\n</code></pre> <p>Parse Result in Script:</p> <pre><code>BUILD_RESULT=$(curl -s -u username:apiToken \\\n  https://jenkins.fawkes.example.com/job/my-service/lastBuild/api/json \\\n  | jq -r '.result')\n\nif [ \"$BUILD_RESULT\" == \"SUCCESS\" ]; then\n  echo \"Build succeeded\"\nelse\n  echo \"Build failed: $BUILD_RESULT\"\nfi\n</code></pre>"},{"location":"reference/api/jenkins-webhook/#rate-limits","title":"Rate Limits","text":"<p>Jenkins does not enforce API rate limits by default. However, excessive requests may trigger throttling at the Ingress or firewall level.</p> <p>Best Practices:</p> <ul> <li>Use webhook triggers instead of polling.</li> <li>Implement exponential backoff for retries.</li> </ul>"},{"location":"reference/api/jenkins-webhook/#error-codes","title":"Error Codes","text":"HTTP Code Meaning Common Causes 200 OK Request successful Valid request. 201 Created Build queued Job triggered successfully. 400 Bad Request Invalid request Missing parameters, malformed JSON. 401 Unauthorized Authentication failed Invalid credentials or API token. 403 Forbidden Permission denied User lacks job trigger permissions. 404 Not Found Job not found Invalid job name in URL. 500 Internal Server Error Jenkins error Check Jenkins logs."},{"location":"reference/api/jenkins-webhook/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Use API Tokens: Never use passwords in scripts.</li> <li>Validate Webhook Signatures: Use HMAC verification for GitHub webhooks.</li> <li>Restrict Trigger Permissions: Limit who can trigger builds via RBAC.</li> <li>Use HTTPS Only: Ensure all API calls use TLS encryption.</li> <li>Rotate Tokens Regularly: Update API tokens every 90 days.</li> </ol>"},{"location":"reference/api/jenkins-webhook/#see-also","title":"See Also","text":"<ul> <li>Jenkins REST API Documentation</li> <li>Generic Webhook Trigger Plugin</li> <li>Golden Path Usage Guide</li> <li>Jenkins Configuration Reference</li> </ul>"},{"location":"reference/catalogue/service-types/","title":"Service Catalog Reference","text":""},{"location":"reference/catalogue/service-types/#overview","title":"Overview","text":"<p>This document lists all service types available in the Fawkes platform catalog. Services are organized by category and managed through ArgoCD GitOps workflows.</p> <p>Application Definitions Location: <code>platform/apps/</code></p>"},{"location":"reference/catalogue/service-types/#cicd-services","title":"CI/CD Services","text":"Service Version Description ArgoCD Application Status Jenkins 2.426+ CI/CD automation server with Golden Path pipeline support. <code>jenkins-application.yaml</code> \u2705 Active ArgoCD 2.9+ GitOps continuous delivery for Kubernetes. N/A (Bootstrap) \u2705 Active <p>Key Features:</p> <ul> <li>Jenkins: JCasC configuration, Kubernetes agents, GitHub integration, DORA metrics collection.</li> <li>ArgoCD: Auto-sync, health status monitoring, rollback capabilities.</li> </ul>"},{"location":"reference/catalogue/service-types/#developer-portal","title":"Developer Portal","text":"Service Version Description ArgoCD Application Status Backstage 1.21+ Software catalog and developer portal with plugins. <code>backstage-application.yaml</code> \u2705 Active Eclipse Che 7.80+ Cloud-based IDE with Devfile support. N/A \u2705 Active <p>Backstage Plugins:</p> <ul> <li>Che Launcher: Launch Eclipse Che workspaces from Backstage.</li> <li>DevLake Dashboard: View DORA metrics within Backstage.</li> <li>Catalog: Service catalog with ownership and dependency tracking.</li> </ul> <p>Eclipse Che Features:</p> <ul> <li>Devfile 2.2.2 support for workspace definitions.</li> <li>Golden Path starter projects (Python, AI/ML).</li> <li>Integrated debugging and testing.</li> </ul>"},{"location":"reference/catalogue/service-types/#observability-services","title":"Observability Services","text":"Service Version Description ArgoCD Application Status Prometheus 2.47+ Metrics collection and time-series database. N/A \u2705 Active Grafana 10.2+ Visualization and analytics platform. N/A \u2705 Active OpenSearch 2.11+ Distributed search and analytics for centralized logging. N/A \u2705 Active Grafana Tempo 2.3+ Distributed tracing backend for OpenTelemetry traces. <code>tempo-application.yaml</code> \u2705 Active OpenTelemetry Collector 0.89+ Vendor-neutral telemetry data collection and export. <code>otel-collector-application.yaml</code> \u2705 Active Apache DevLake 0.20+ DORA metrics data platform. <code>devlake-application.yaml</code> \u2705 Active <p>Observability Stack Integration:</p> <pre><code>Application\n    \u2502\n    \u251c\u2500&gt; OpenTelemetry SDK (traces, metrics, logs)\n    \u2502       \u2502\n    \u2502       \u25bc\n    \u2502   OTel Collector\n    \u2502       \u2502\n    \u2502       \u251c\u2500&gt; Tempo (traces)\n    \u2502       \u251c\u2500&gt; Prometheus (metrics)\n    \u2502       \u2514\u2500&gt; OpenSearch (logs)\n    \u2502               \u2502\n    \u2502               \u25bc\n    \u2502           Grafana (unified visualization)\n</code></pre>"},{"location":"reference/catalogue/service-types/#security-services","title":"Security Services","text":"Service Version Description ArgoCD Application Status Vault 1.15+ Secrets management and encryption. N/A \u2705 Active External Secrets Operator 0.9+ Sync secrets from Vault to Kubernetes Secrets. <code>external-secrets-operator-application.yaml</code> \u2705 Active Vault CSI Driver 1.3+ Mount Vault secrets as volumes in Pods. <code>vault-csi-driver-application.yaml</code> \u2705 Active SonarQube 10.3+ Static application security testing (SAST). <code>sonarqube-application.yaml</code> \u2705 Active Trivy 0.47+ Container image and filesystem vulnerability scanner. N/A (Jenkins plugin) \u2705 Active Kyverno 1.11+ Kubernetes-native policy engine. <code>kyverno-application.yaml</code> \u2705 Active <p>Security Workflow:</p> <ol> <li>Secrets Management: Vault stores credentials \u2192 External Secrets Operator syncs to K8s Secrets.</li> <li>SAST: SonarQube scans code during CI pipeline.</li> <li>Container Scanning: Trivy scans images during build and runtime.</li> <li>Policy Enforcement: Kyverno validates and mutates resources at admission time.</li> </ol>"},{"location":"reference/catalogue/service-types/#collaboration-services","title":"Collaboration Services","text":"Service Version Description ArgoCD Application Status Mattermost 9.2+ Team collaboration and ChatOps platform. N/A \ud83d\udea7 Planned Focalboard 7.11+ Open-source project management. <code>focalboard-application.yaml</code> \u2705 Active <p>Use Cases:</p> <ul> <li>Mattermost: ChatOps commands, build notifications, incident response.</li> <li>Focalboard: Sprint planning, backlog management, roadmaps.</li> </ul>"},{"location":"reference/catalogue/service-types/#data-services","title":"Data Services","text":"Service Version Description ArgoCD Application Status PostgreSQL 16+ Relational database (via CloudNativePG operator). <code>postgresql-application.yaml</code> \u2705 Active <p>Supported PostgreSQL Clusters:</p> Cluster Name Purpose Application <code>db-backstage-cluster</code> Backstage catalog database Backstage <code>db-sonarqube-cluster</code> SonarQube analysis database SonarQube <code>db-focalboard-cluster</code> Focalboard data storage Focalboard <p>CloudNativePG Features:</p> <ul> <li>Automated backups to S3/GCS/Azure Blob.</li> <li>High availability with streaming replication.</li> <li>Connection pooling with PgBouncer.</li> </ul>"},{"location":"reference/catalogue/service-types/#networking-services","title":"Networking Services","text":"Service Version Description ArgoCD Application Status NGINX Ingress Controller 1.9+ HTTP/HTTPS load balancing and routing. N/A \u2705 Active Cert-Manager 1.13+ Automated TLS certificate management. N/A \u2705 Active External DNS 0.14+ Automated DNS record synchronization. N/A \u2705 Active <p>Ingress Workflow:</p> <pre><code>External Request\n    \u2502\n    \u251c\u2500&gt; DNS (managed by External DNS)\n    \u2502       \u2502\n    \u2502       \u25bc\n    \u2502   NGINX Ingress Controller\n    \u2502       \u2502\n    \u2502       \u251c\u2500&gt; TLS Termination (Cert-Manager certificates)\n    \u2502       \u2502\n    \u2502       \u25bc\n    \u2502   Backend Service (e.g., Jenkins, Backstage)\n</code></pre>"},{"location":"reference/catalogue/service-types/#platform-operators","title":"Platform Operators","text":"Operator Version Description ArgoCD Application Status CloudNativePG 1.21+ PostgreSQL operator for Kubernetes. <code>cloudnativepg-operator-application.yaml</code> \u2705 Active External Secrets 0.9+ External secret store integration. <code>external-secrets-operator-application.yaml</code> \u2705 Active Kyverno 1.11+ Policy engine operator. <code>kyverno-application.yaml</code> \u2705 Active"},{"location":"reference/catalogue/service-types/#service-types-by-languageframework","title":"Service Types by Language/Framework","text":""},{"location":"reference/catalogue/service-types/#supported-application-stacks","title":"Supported Application Stacks","text":"Stack Language Framework Golden Path Support Devfile Available Python Web Python 3.11+ FastAPI, Django, Flask \u2705 Yes \u2705 <code>goldenpath-python.yaml</code> AI/ML Python 3.11+ TensorFlow, PyTorch, Jupyter \u2705 Yes \u2705 <code>goldenpath-ai.yaml</code> Java Spring Java 17+ Spring Boot \ud83d\udea7 Planned \ud83d\udea7 Planned Node.js Node 20+ Express, NestJS \ud83d\udea7 Planned \ud83d\udea7 Planned Go Go 1.21+ Gin, Echo \ud83d\udea7 Planned \ud83d\udea7 Planned"},{"location":"reference/catalogue/service-types/#service-deployment-patterns","title":"Service Deployment Patterns","text":""},{"location":"reference/catalogue/service-types/#pattern-1-argocd-application","title":"Pattern 1: ArgoCD Application","text":"<p>For platform services managed via GitOps:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: jenkins\n  namespace: fawkes\nspec:\n  source:\n    repoURL: https://charts.jenkins.io\n    chart: jenkins\n    targetRevision: 5.0.0\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: jenkins\n</code></pre>"},{"location":"reference/catalogue/service-types/#pattern-2-helm-release","title":"Pattern 2: Helm Release","text":"<p>For services deployed via Helm:</p> <pre><code>helm upgrade --install jenkins jenkins/jenkins \\\n  -f platform/apps/jenkins/values.yaml \\\n  -n jenkins --create-namespace\n</code></pre>"},{"location":"reference/catalogue/service-types/#pattern-3-kustomize","title":"Pattern 3: Kustomize","text":"<p>For services using Kustomize overlays:</p> <pre><code>kubectl apply -k platform/apps/backstage/overlays/dev\n</code></pre>"},{"location":"reference/catalogue/service-types/#adding-a-new-service-to-the-catalog","title":"Adding a New Service to the Catalog","text":"<ol> <li>Define ArgoCD Application: Create <code>platform/apps/&lt;service&gt;/&lt;service&gt;-application.yaml</code>.</li> <li>Add Helm Values: Create <code>platform/apps/&lt;service&gt;/values.yaml</code> with configuration.</li> <li>Create Namespace: Update <code>platform/apps/namespaces.yaml</code>.</li> <li>Document Configuration: Add Helm values reference to <code>docs/reference/config/&lt;service&gt;-values.md</code>.</li> <li>Commit and Sync: ArgoCD auto-syncs from Git.</li> </ol>"},{"location":"reference/catalogue/service-types/#service-status-legend","title":"Service Status Legend","text":"Icon Status Description \u2705 Active Service is deployed and operational. \ud83d\udea7 Planned Service is in development or planned for future release. \u26a0\ufe0f Deprecated Service is deprecated and will be removed."},{"location":"reference/catalogue/service-types/#see-also","title":"See Also","text":"<ul> <li>Configuration Reference</li> <li>ArgoCD Sync Guide</li> <li>Onboard Service to ArgoCD</li> <li>Platform Architecture</li> </ul>"},{"location":"reference/config/jenkins-values/","title":"Jenkins Helm Values Reference","text":""},{"location":"reference/config/jenkins-values/#overview","title":"Overview","text":"<p>This document provides a complete field-level specification for the Jenkins Helm chart configuration used in the Fawkes platform. Jenkins is deployed as the CI/CD automation server for the Golden Path pipeline.</p> <p>Helm Chart: <code>jenkins/jenkins</code> (official Jenkins Helm chart)</p> <p>Chart Repository: <code>https://charts.jenkins.io</code></p> <p>Values File Location: <code>platform/apps/jenkins/values.yaml</code></p>"},{"location":"reference/config/jenkins-values/#controller-configuration","title":"Controller Configuration","text":""},{"location":"reference/config/jenkins-values/#controllerimage","title":"<code>controller.image</code>","text":"<p>Container image configuration for the Jenkins controller.</p> Field Type Required Default Description <code>controller.image.repository</code> String No <code>jenkins/jenkins</code> Docker image repository. <code>controller.image.tag</code> String No <code>2.528.1-lts-jdk17</code> Image tag. Use Jenkins LTS version with JDK 17 for plugin compatibility. <code>controller.image.pullPolicy</code> String No <code>IfNotPresent</code> Image pull policy: <code>Always</code>, <code>IfNotPresent</code>, <code>Never</code>. <p>Example:</p> <pre><code>controller:\n  image:\n    repository: \"jenkins/jenkins\"\n    tag: \"2.528.1-lts-jdk17\"\n</code></pre>"},{"location":"reference/config/jenkins-values/#controlleradmin","title":"<code>controller.admin</code>","text":"<p>Administrative user credentials.</p> Field Type Required Default Description <code>controller.admin.username</code> String No <code>admin</code> Username for the Jenkins admin account. <code>controller.admin.password</code> String No - Password for the Jenkins admin account. Security Note: Use Kubernetes Secret instead of plaintext. <p>Security Recommendation:</p> <p>Store credentials in a Kubernetes Secret and reference via <code>controller.extraEnv</code>:</p> <pre><code>controller:\n  admin:\n    username: admin\n  extraEnv:\n    - name: ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: jenkins-admin\n          key: ADMIN_PASSWORD\n</code></pre>"},{"location":"reference/config/jenkins-values/#controllerjenkins_opts","title":"<code>controller.JENKINS_OPTS</code>","text":"<p>Java options and Jenkins runtime arguments.</p> Field Type Required Default Description <code>controller.JENKINS_OPTS</code> String No - Command-line arguments passed to Jenkins on startup. <p>Common Options:</p> <ul> <li><code>--argumentsRealm.passwd.admin=&lt;password&gt;</code> - Set admin password (use with caution).</li> <li><code>-Djenkins.install.runSetupWizard=false</code> - Skip the initial setup wizard.</li> </ul> <p>Example:</p> <pre><code>controller:\n  JENKINS_OPTS: \"--argumentsRealm.passwd.admin=changeme -Djenkins.install.runSetupWizard=false\"\n</code></pre>"},{"location":"reference/config/jenkins-values/#controllerservicetype","title":"<code>controller.serviceType</code>","text":"<p>Kubernetes Service type for the Jenkins controller.</p> Field Type Required Default Description <code>controller.serviceType</code> String No <code>ClusterIP</code> Service type: <code>ClusterIP</code>, <code>NodePort</code>, <code>LoadBalancer</code>. <p>Fawkes Default: <code>ClusterIP</code> (access via Ingress).</p>"},{"location":"reference/config/jenkins-values/#controllerexecutors","title":"<code>controller.executors</code>","text":"<p>Number of build executors on the controller node.</p> Field Type Required Default Description <code>controller.executors</code> Integer No <code>0</code> Number of executors. Best Practice: Set to <code>0</code> to force builds on agents. <p>Fawkes Default: <code>0</code> (builds run exclusively on Kubernetes agents).</p>"},{"location":"reference/config/jenkins-values/#controllerjcasc","title":"<code>controller.JCasC</code>","text":"<p>Jenkins Configuration as Code (JCasC) plugin configuration.</p> Field Type Required Default Description <code>controller.JCasC.enabled</code> Boolean No <code>true</code> Enable JCasC plugin. <code>controller.JCasC.defaultConfig</code> Boolean No <code>false</code> Use default JCasC configuration. Set to <code>false</code> for custom config. <code>controller.JCasC.configScripts</code> Object No <code>{}</code> Inline JCasC YAML configurations (key-value pairs). <p>Example:</p> <pre><code>controller:\n  JCasC:\n    enabled: true\n    defaultConfig: false\n    configScripts:\n      welcome-message: |\n        jenkins:\n          systemMessage: \"Fawkes Platform Jenkins\"\n</code></pre>"},{"location":"reference/config/jenkins-values/#controllerextraenv","title":"<code>controller.extraEnv</code>","text":"<p>Additional environment variables injected into the Jenkins controller container.</p> Field Type Required Default Description <code>controller.extraEnv</code> Array[Object] No <code>[]</code> Environment variables (standard Kubernetes <code>env</code> format). <p>Example:</p> <pre><code>controller:\n  extraEnv:\n    - name: ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: jenkins-admin\n          key: ADMIN_PASSWORD\n    - name: JAVA_OPTS\n      value: \"-Xmx2048m\"\n</code></pre>"},{"location":"reference/config/jenkins-values/#plugin-installation","title":"Plugin Installation","text":""},{"location":"reference/config/jenkins-values/#installplugins","title":"<code>installPlugins</code>","text":"<p>List of Jenkins plugins to install on startup.</p> Field Type Required Default Description <code>installPlugins</code> Array[String] No <code>[]</code> Plugin IDs with optional version (format: <code>plugin-name:version</code>). <p>Example:</p> <pre><code>installPlugins:\n  - kubernetes:4253.v7700d91739e5\n  - workflow-aggregator:596.v8c21c963d92d\n  - git:5.2.2\n  - configuration-as-code:1810.v9b_c30a_249a_4c\n</code></pre> <p>Note: Fawkes uses JCasC to manage plugin installation dynamically.</p>"},{"location":"reference/config/jenkins-values/#persistence","title":"Persistence","text":""},{"location":"reference/config/jenkins-values/#persistence_1","title":"<code>persistence</code>","text":"<p>Persistent storage configuration for Jenkins data (jobs, builds, plugins).</p> Field Type Required Default Description <code>persistence.enabled</code> Boolean No <code>false</code> Enable persistent storage. <code>persistence.size</code> String No <code>8Gi</code> Requested storage size. <code>persistence.storageClass</code> String No <code>standard</code> Kubernetes StorageClass name. <code>persistence.accessMode</code> String No <code>ReadWriteOnce</code> Volume access mode. <p>Environment-Specific Defaults:</p> <ul> <li>Local Development: <code>enabled: false</code> (to avoid PVC pending issues).</li> <li>Production: <code>enabled: true</code> with <code>storageClass: gp3</code> (AWS EBS) or equivalent.</li> </ul> <p>Example:</p> <pre><code>persistence:\n  enabled: true\n  size: 20Gi\n  storageClass: gp3\n</code></pre>"},{"location":"reference/config/jenkins-values/#service-account-and-rbac","title":"Service Account and RBAC","text":""},{"location":"reference/config/jenkins-values/#serviceaccount","title":"<code>serviceAccount</code>","text":"<p>Kubernetes ServiceAccount configuration.</p> Field Type Required Default Description <code>serviceAccount.create</code> Boolean No <code>true</code> Create a ServiceAccount for Jenkins. <code>serviceAccount.name</code> String No <code>jenkins</code> ServiceAccount name (auto-generated if not specified). <code>serviceAccount.annotations</code> Object No <code>{}</code> Annotations for the ServiceAccount (e.g., IAM roles). <p>Example (AWS IRSA):</p> <pre><code>serviceAccount:\n  create: true\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/jenkins-role\n</code></pre>"},{"location":"reference/config/jenkins-values/#rbac","title":"<code>rbac</code>","text":"<p>Role-Based Access Control configuration.</p> Field Type Required Default Description <code>rbac.create</code> Boolean No <code>true</code> Create RBAC resources (Role, RoleBinding, ClusterRole). <code>rbac.readSecrets</code> Boolean No <code>false</code> Grant permission to read Secrets (required for credentials binding). <p>Fawkes Default: <code>rbac.create: true</code> (required for Kubernetes agent provisioning).</p>"},{"location":"reference/config/jenkins-values/#ingress","title":"Ingress","text":""},{"location":"reference/config/jenkins-values/#ingress_1","title":"<code>ingress</code>","text":"<p>Ingress configuration for external access to Jenkins.</p> Field Type Required Default Description <code>ingress.enabled</code> Boolean No <code>false</code> Enable Ingress resource creation. <code>ingress.annotations</code> Object No <code>{}</code> Ingress annotations (e.g., <code>cert-manager.io/cluster-issuer</code>). <code>ingress.hosts</code> Array[Object] No <code>[]</code> Hostnames and paths for Ingress rules. <code>ingress.tls</code> Array[Object] No <code>[]</code> TLS configuration for HTTPS. <p>Example:</p> <pre><code>ingress:\n  enabled: true\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n  hosts:\n    - host: jenkins.fawkes.example.com\n      paths:\n        - path: /\n          pathType: Prefix\n  tls:\n    - secretName: jenkins-tls\n      hosts:\n        - jenkins.fawkes.example.com\n</code></pre>"},{"location":"reference/config/jenkins-values/#agent-configuration","title":"Agent Configuration","text":""},{"location":"reference/config/jenkins-values/#agent","title":"<code>agent</code>","text":"<p>Kubernetes Pod Template configuration for dynamic Jenkins agents.</p> Field Type Required Default Description <code>agent.enabled</code> Boolean No <code>true</code> Enable Kubernetes-based agent provisioning. <code>agent.image</code> String No <code>jenkins/inbound-agent</code> Default agent image. <code>agent.tag</code> String No <code>latest-jdk17</code> Agent image tag. <code>agent.resources.requests.cpu</code> String No <code>512m</code> CPU request for agents. <code>agent.resources.requests.memory</code> String No <code>512Mi</code> Memory request for agents. <code>agent.resources.limits.cpu</code> String No <code>1</code> CPU limit for agents. <code>agent.resources.limits.memory</code> String No <code>1Gi</code> Memory limit for agents. <p>Example:</p> <pre><code>agent:\n  enabled: true\n  resources:\n    requests:\n      cpu: \"500m\"\n      memory: \"1Gi\"\n    limits:\n      cpu: \"2\"\n      memory: \"4Gi\"\n</code></pre>"},{"location":"reference/config/jenkins-values/#security-context","title":"Security Context","text":""},{"location":"reference/config/jenkins-values/#controllerpodsecuritycontext","title":"<code>controller.podSecurityContext</code>","text":"<p>Security context for the Jenkins controller Pod.</p> Field Type Required Default Description <code>controller.podSecurityContext.runAsUser</code> Integer No <code>1000</code> User ID to run the container as. <code>controller.podSecurityContext.runAsNonRoot</code> Boolean No <code>true</code> Require running as non-root user. <code>controller.podSecurityContext.fsGroup</code> Integer No <code>1000</code> Filesystem group ID for volume permissions. <p>Fawkes Default (Kyverno-compliant):</p> <pre><code>controller:\n  podSecurityContext:\n    runAsUser: 1000\n    runAsNonRoot: true\n    fsGroup: 1000\n</code></pre>"},{"location":"reference/config/jenkins-values/#complete-example","title":"Complete Example","text":"<pre><code>controller:\n  image:\n    repository: \"jenkins/jenkins\"\n    tag: \"2.528.1-lts-jdk17\"\n  admin:\n    username: admin\n  JENKINS_OPTS: \"-Djenkins.install.runSetupWizard=false\"\n  serviceType: ClusterIP\n  executors: 0\n  JCasC:\n    enabled: true\n    defaultConfig: false\n  extraEnv:\n    - name: ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: jenkins-admin\n          key: ADMIN_PASSWORD\n\npersistence:\n  enabled: true\n  size: 20Gi\n  storageClass: gp3\n\nserviceAccount:\n  create: true\n\nrbac:\n  create: true\n\ningress:\n  enabled: true\n  hosts:\n    - host: jenkins.fawkes.example.com\n      paths: [\"/\"]\n</code></pre>"},{"location":"reference/config/jenkins-values/#see-also","title":"See Also","text":"<ul> <li>Jenkins Official Documentation</li> <li>Jenkins Helm Chart Repository</li> <li>Jenkins Configuration as Code Plugin</li> <li>Golden Path Usage Guide</li> </ul>"},{"location":"reference/config/prometheus-values/","title":"Prometheus Helm Values Reference","text":""},{"location":"reference/config/prometheus-values/#overview","title":"Overview","text":"<p>This document provides the configuration reference for the Prometheus monitoring system deployed in the Fawkes platform. Prometheus collects metrics from platform services and applications for observability and alerting.</p> <p>Helm Chart: <code>prometheus/prometheus</code> (Prometheus Community chart)</p> <p>Chart Repository: <code>https://prometheus-community.github.io/helm-charts</code></p> <p>Values File Location: <code>platform/apps/prometheus/values.yaml</code></p>"},{"location":"reference/config/prometheus-values/#server-configuration","title":"Server Configuration","text":""},{"location":"reference/config/prometheus-values/#serverresources","title":"<code>server.resources</code>","text":"<p>Resource allocation for the Prometheus server.</p> Field Type Required Default Description <code>server.resources.requests.cpu</code> String No <code>100m</code> CPU request (millicores). <code>server.resources.requests.memory</code> String No <code>256Mi</code> Memory request. <code>server.resources.limits.cpu</code> String No <code>200m</code> Maximum CPU allocation. <code>server.resources.limits.memory</code> String No <code>512Mi</code> Maximum memory allocation. <p>Fawkes Defaults:</p> <pre><code>server:\n  resources:\n    requests:\n      memory: 256Mi\n      cpu: 100m\n    limits:\n      memory: 512Mi\n      cpu: 200m\n</code></pre> <p>Scaling Guidelines:</p> Environment CPU Request Memory Request CPU Limit Memory Limit Development <code>100m</code> <code>256Mi</code> <code>200m</code> <code>512Mi</code> Staging <code>200m</code> <code>512Mi</code> <code>500m</code> <code>1Gi</code> Production <code>500m</code> <code>1Gi</code> <code>2</code> <code>4Gi</code>"},{"location":"reference/config/prometheus-values/#serverservice","title":"<code>server.service</code>","text":"<p>Kubernetes Service configuration for the Prometheus server.</p> Field Type Required Default Description <code>server.service.type</code> String No <code>ClusterIP</code> Service type: <code>ClusterIP</code>, <code>NodePort</code>, <code>LoadBalancer</code>. <code>server.service.port</code> Integer No <code>80</code> Service port. <code>server.service.targetPort</code> Integer No <code>9090</code> Container port. <p>Fawkes Default:</p> <pre><code>server:\n  service:\n    type: ClusterIP\n</code></pre> <p>Access Pattern: Prometheus is accessed via Ingress, not directly exposed.</p>"},{"location":"reference/config/prometheus-values/#serverpersistentvolume","title":"<code>server.persistentVolume</code>","text":"<p>Persistent storage for metrics data.</p> Field Type Required Default Description <code>server.persistentVolume.enabled</code> Boolean No <code>true</code> Enable persistent storage. <code>server.persistentVolume.size</code> String No <code>8Gi</code> Storage size. <code>server.persistentVolume.storageClass</code> String No <code>standard</code> StorageClass name. <code>server.persistentVolume.accessModes</code> Array[String] No <code>[\"ReadWriteOnce\"]</code> Volume access modes. <p>Retention Recommendations:</p> Retention Period Recommended Size Use Case 7 days <code>8Gi</code> Development 15 days <code>20Gi</code> Staging 30 days <code>50Gi</code> Production 90 days <code>150Gi</code> Long-term analysis <p>Example:</p> <pre><code>server:\n  persistentVolume:\n    enabled: true\n    size: 50Gi\n    storageClass: gp3\n</code></pre>"},{"location":"reference/config/prometheus-values/#serverretention","title":"<code>server.retention</code>","text":"<p>Metrics retention configuration.</p> Field Type Required Default Description <code>server.retention</code> String No <code>15d</code> Time-based retention (e.g., <code>7d</code>, <code>30d</code>). <code>server.retentionSize</code> String No - Size-based retention (e.g., <code>10GB</code>, <code>50GB</code>). Overrides time-based retention. <p>Example:</p> <pre><code>server:\n  retention: \"30d\"\n  retentionSize: \"45GB\"\n</code></pre>"},{"location":"reference/config/prometheus-values/#alerting-configuration","title":"Alerting Configuration","text":""},{"location":"reference/config/prometheus-values/#alertmanagerenabled","title":"<code>alertmanager.enabled</code>","text":"<p>Enable or disable Alertmanager integration.</p> Field Type Required Default Description <code>alertmanager.enabled</code> Boolean No <code>true</code> Deploy Alertmanager for alert routing. <p>Fawkes Default: <code>true</code></p>"},{"location":"reference/config/prometheus-values/#alertmanagerfiles","title":"<code>alertmanagerFiles</code>","text":"<p>Alert routing configuration.</p> Field Type Required Default Description <code>alertmanagerFiles.alertmanager.yml</code> Object No <code>{}</code> Alertmanager configuration (receivers, routes). <p>Example:</p> <pre><code>alertmanagerFiles:\n  alertmanager.yml:\n    global:\n      resolve_timeout: 5m\n    route:\n      group_by: ['alertname', 'cluster', 'service']\n      group_wait: 10s\n      group_interval: 10s\n      repeat_interval: 12h\n      receiver: 'mattermost'\n    receivers:\n      - name: 'mattermost'\n        webhook_configs:\n          - url: 'https://mattermost.fawkes.example.com/hooks/alerts'\n</code></pre>"},{"location":"reference/config/prometheus-values/#scrape-configurations","title":"Scrape Configurations","text":""},{"location":"reference/config/prometheus-values/#serverfilesprometheusyml","title":"<code>serverFiles.prometheus.yml</code>","text":"<p>Prometheus scrape configuration.</p> Field Type Required Default Description <code>serverFiles.prometheus.yml.scrape_configs</code> Array[Object] No <code>[]</code> List of scrape jobs. <p>Default Scrape Targets:</p> Job Target Metrics <code>prometheus</code> Prometheus itself Self-monitoring metrics. <code>kubernetes-apiservers</code> Kubernetes API server Control plane metrics. <code>kubernetes-nodes</code> Kubelet on each node Node metrics (CPU, memory, disk). <code>kubernetes-pods</code> Pods with <code>prometheus.io/scrape=true</code> annotation Application metrics. <code>kubernetes-service-endpoints</code> Service endpoints Service-level metrics. <p>Example Custom Scrape Job:</p> <pre><code>serverFiles:\n  prometheus.yml:\n    scrape_configs:\n      - job_name: 'jenkins'\n        static_configs:\n          - targets: ['jenkins.jenkins.svc.cluster.local:8080']\n        metrics_path: '/prometheus'\n        scrape_interval: 30s\n</code></pre>"},{"location":"reference/config/prometheus-values/#service-discovery","title":"Service Discovery","text":""},{"location":"reference/config/prometheus-values/#kubestatemetricsenabled","title":"<code>kubeStateMetrics.enabled</code>","text":"<p>Enable Kube State Metrics for Kubernetes resource metrics.</p> Field Type Required Default Description <code>kubeStateMetrics.enabled</code> Boolean No <code>true</code> Deploy kube-state-metrics. <p>Metrics Collected:</p> <ul> <li>Deployment status (replicas, available replicas)</li> <li>Pod status (phase, restarts, resource usage)</li> <li>Node status (allocatable resources, conditions)</li> <li>PersistentVolumeClaim status (phase, capacity)</li> </ul>"},{"location":"reference/config/prometheus-values/#nodeexporterenabled","title":"<code>nodeExporter.enabled</code>","text":"<p>Enable Node Exporter for node-level metrics.</p> Field Type Required Default Description <code>nodeExporter.enabled</code> Boolean No <code>true</code> Deploy node-exporter DaemonSet. <p>Metrics Collected:</p> <ul> <li>CPU usage and load average</li> <li>Memory usage (total, available, buffers, caches)</li> <li>Disk I/O and space</li> <li>Network traffic and errors</li> </ul>"},{"location":"reference/config/prometheus-values/#ingress-configuration","title":"Ingress Configuration","text":""},{"location":"reference/config/prometheus-values/#serveringress","title":"<code>server.ingress</code>","text":"<p>Ingress configuration for accessing Prometheus UI.</p> Field Type Required Default Description <code>server.ingress.enabled</code> Boolean No <code>false</code> Enable Ingress resource creation. <code>server.ingress.annotations</code> Object No <code>{}</code> Ingress annotations (e.g., <code>cert-manager.io/cluster-issuer</code>). <code>server.ingress.hosts</code> Array[String] No <code>[]</code> Hostnames for Ingress rules. <code>server.ingress.tls</code> Array[Object] No <code>[]</code> TLS configuration. <p>Example:</p> <pre><code>server:\n  ingress:\n    enabled: true\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n      nginx.ingress.kubernetes.io/auth-type: basic\n      nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth\n    hosts:\n      - prometheus.fawkes.example.com\n    tls:\n      - secretName: prometheus-tls\n        hosts:\n          - prometheus.fawkes.example.com\n</code></pre>"},{"location":"reference/config/prometheus-values/#federation-configuration","title":"Federation Configuration","text":""},{"location":"reference/config/prometheus-values/#serverglobal","title":"<code>server.global</code>","text":"<p>Global Prometheus configuration for federation.</p> Field Type Required Default Description <code>server.global.scrape_interval</code> String No <code>15s</code> Default scrape interval. <code>server.global.scrape_timeout</code> String No <code>10s</code> Default scrape timeout. <code>server.global.evaluation_interval</code> String No <code>15s</code> Rule evaluation interval. <code>server.global.external_labels</code> Object No <code>{}</code> Labels added to all metrics (e.g., <code>cluster</code>, <code>environment</code>). <p>Example:</p> <pre><code>server:\n  global:\n    scrape_interval: 15s\n    evaluation_interval: 15s\n    external_labels:\n      cluster: 'fawkes-prod'\n      environment: 'production'\n</code></pre>"},{"location":"reference/config/prometheus-values/#security-configuration","title":"Security Configuration","text":""},{"location":"reference/config/prometheus-values/#serverpodsecuritypolicy","title":"<code>server.podSecurityPolicy</code>","text":"<p>Pod Security Policy for Prometheus server.</p> Field Type Required Default Description <code>server.podSecurityPolicy.enabled</code> Boolean No <code>false</code> Enable PodSecurityPolicy (deprecated in K8s 1.25+). <p>Note: Use Kyverno policies instead for modern Kubernetes versions.</p>"},{"location":"reference/config/prometheus-values/#complete-example","title":"Complete Example","text":"<pre><code>server:\n  resources:\n    requests:\n      memory: 1Gi\n      cpu: 500m\n    limits:\n      memory: 4Gi\n      cpu: 2\n  service:\n    type: ClusterIP\n  persistentVolume:\n    enabled: true\n    size: 50Gi\n    storageClass: gp3\n  retention: \"30d\"\n  global:\n    scrape_interval: 15s\n    external_labels:\n      cluster: 'fawkes-prod'\n  ingress:\n    enabled: true\n    hosts:\n      - prometheus.fawkes.example.com\n    tls:\n      - secretName: prometheus-tls\n        hosts:\n          - prometheus.fawkes.example.com\n\nalertmanager:\n  enabled: true\n\nkubeStateMetrics:\n  enabled: true\n\nnodeExporter:\n  enabled: true\n</code></pre>"},{"location":"reference/config/prometheus-values/#see-also","title":"See Also","text":"<ul> <li>Prometheus Official Documentation</li> <li>Prometheus Helm Chart</li> <li>View DORA Metrics</li> <li>Unified Telemetry Explanation</li> </ul>"},{"location":"reference/crds/golden-path-crd/","title":"Golden Path Devfile Specification","text":""},{"location":"reference/crds/golden-path-crd/#overview","title":"Overview","text":"<p>The Golden Path Devfile is a standardized development environment configuration using the Devfile 2.2.2 specification. It defines containerized workspaces for Eclipse Che with pre-configured tools, dependencies, and development workflows.</p> <p>Schema Version: <code>2.2.2</code></p> <p>File Location: <code>platform/devfiles/goldenpath-{language}.yaml</code></p>"},{"location":"reference/crds/golden-path-crd/#top-level-fields","title":"Top-Level Fields","text":"Field Type Required Default Description <code>schemaVersion</code> String Yes - Devfile schema version. Must be <code>2.2.2</code>. <code>metadata</code> Object Yes - Workspace metadata including name, description, and tags. <code>starterProjects</code> Array No <code>[]</code> Template repositories for bootstrapping new projects. <code>components</code> Array Yes - Container definitions, volumes, and Kubernetes resources. <code>commands</code> Array No <code>[]</code> Executable tasks (build, run, test, debug). <code>events</code> Object No <code>{}</code> Lifecycle hooks (preStart, postStart, preStop, postStop)."},{"location":"reference/crds/golden-path-crd/#metadata-object","title":"<code>metadata</code> Object","text":"<p>Defines workspace identification and categorization.</p> Field Type Required Default Description <code>name</code> String Yes - Unique identifier for the Devfile. Format: <code>goldenpath-{language}</code>. <code>displayName</code> String No - Human-readable name shown in Eclipse Che workspace selector. <code>description</code> String No - Multi-line description of the development environment. <code>version</code> String No <code>1.0.0</code> Semantic version of the Devfile configuration. <code>provider</code> String No - Organization or team maintaining the Devfile. <code>supportUrl</code> String No - URL for issue tracking or support documentation. <code>tags</code> Array[String] No <code>[]</code> Keywords for categorization (e.g., <code>Python</code>, <code>FastAPI</code>, <code>Django</code>). <code>icon</code> String No - URL to icon image representing the workspace technology. <code>projectType</code> String No - High-level project category (e.g., <code>Python</code>, <code>Java</code>, <code>Node.js</code>). <code>language</code> String No - Primary programming language of the workspace."},{"location":"reference/crds/golden-path-crd/#example","title":"Example","text":"<pre><code>metadata:\n  name: goldenpath-python\n  displayName: Golden Path Python Development\n  version: 1.0.0\n  provider: Fawkes Platform Team\n  language: Python\n</code></pre>"},{"location":"reference/crds/golden-path-crd/#starterprojects-array","title":"<code>starterProjects</code> Array","text":"<p>Template repositories for creating new projects from scratch.</p>"},{"location":"reference/crds/golden-path-crd/#object-structure","title":"Object Structure","text":"Field Type Required Default Description <code>name</code> String Yes - Unique identifier for the starter project. <code>description</code> String No - Brief description of the template's purpose. <code>git</code> Object Yes - Git repository configuration. <code>git.remotes</code> Object Yes - Named remote URLs (typically <code>origin</code>). <code>git.remotes.origin</code> String Yes - HTTPS URL to the Git repository. <code>git.checkoutFrom</code> Object No - Branch or tag to checkout (defaults to <code>HEAD</code>)."},{"location":"reference/crds/golden-path-crd/#example_1","title":"Example","text":"<pre><code>starterProjects:\n  - name: python-fastapi\n    description: FastAPI microservice template\n    git:\n      remotes:\n        origin: https://github.com/paruff/fawkes-template-python-fastapi\n</code></pre>"},{"location":"reference/crds/golden-path-crd/#components-array","title":"<code>components</code> Array","text":"<p>Defines containers, volumes, and Kubernetes resources for the workspace.</p>"},{"location":"reference/crds/golden-path-crd/#container-component","title":"Container Component","text":"<p>Specifies the main development container.</p> Field Type Required Default Description <code>name</code> String Yes - Unique component name (e.g., <code>python</code>, <code>java</code>). <code>container</code> Object Yes - Container configuration. <code>container.image</code> String Yes - OCI image (format: <code>registry/repository:tag</code>). <code>container.memoryLimit</code> String No <code>2Gi</code> Maximum memory allocation (e.g., <code>4Gi</code>, <code>512Mi</code>). <code>container.memoryRequest</code> String No <code>1Gi</code> Requested memory guarantee. <code>container.cpuLimit</code> String No <code>2</code> Maximum CPU cores (e.g., <code>2</code>, <code>500m</code> for 0.5 cores). <code>container.cpuRequest</code> String No <code>500m</code> Requested CPU guarantee. <code>container.mountSources</code> Boolean No <code>true</code> Whether to mount the project source code into the container. <code>container.sourceMapping</code> String No <code>/projects</code> Path where source code is mounted. <code>container.env</code> Array[Object] No <code>[]</code> Environment variables. <code>container.endpoints</code> Array[Object] No <code>[]</code> Exposed network endpoints. <code>container.volumeMounts</code> Array[Object] No <code>[]</code> Volume mount points."},{"location":"reference/crds/golden-path-crd/#containerenv-object","title":"<code>container.env</code> Object","text":"Field Type Required Description <code>name</code> String Yes Environment variable name (uppercase convention). <code>value</code> String Yes Environment variable value."},{"location":"reference/crds/golden-path-crd/#containerendpoints-object","title":"<code>container.endpoints</code> Object","text":"Field Type Required Default Description <code>name</code> String Yes - Endpoint identifier (e.g., <code>python-app</code>, <code>debug</code>). <code>targetPort</code> Integer Yes - Container port to expose. <code>exposure</code> String No <code>public</code> Access level: <code>public</code>, <code>internal</code>, <code>none</code>. <code>protocol</code> String No <code>http</code> Protocol: <code>http</code>, <code>https</code>, <code>tcp</code>, <code>udp</code>."},{"location":"reference/crds/golden-path-crd/#containervolumemounts-object","title":"<code>container.volumeMounts</code> Object","text":"Field Type Required Description <code>name</code> String Yes Name of the volume (must match a volume component). <code>path</code> String Yes Absolute path in the container where the volume is mounted."},{"location":"reference/crds/golden-path-crd/#volume-component","title":"Volume Component","text":"<p>Defines persistent storage for workspace data.</p> Field Type Required Default Description <code>name</code> String Yes - Unique volume name. <code>volume</code> Object Yes - Volume configuration. <code>volume.size</code> String No <code>1Gi</code> Storage size (e.g., <code>2Gi</code>, <code>500Mi</code>)."},{"location":"reference/crds/golden-path-crd/#example_2","title":"Example","text":"<pre><code>components:\n  - name: python\n    container:\n      image: quay.io/devfile/universal-developer-image:ubi8-latest\n      memoryLimit: 4Gi\n      cpuLimit: \"2\"\n      env:\n        - name: PYTHON_VERSION\n          value: \"3.11\"\n      endpoints:\n        - name: python-app\n          targetPort: 8000\n          exposure: public\n      volumeMounts:\n        - name: pip-cache\n          path: /home/user/.cache/pip\n\n  - name: pip-cache\n    volume:\n      size: 2Gi\n</code></pre>"},{"location":"reference/crds/golden-path-crd/#commands-array","title":"<code>commands</code> Array","text":"<p>Executable tasks for build, run, test, and debug workflows.</p>"},{"location":"reference/crds/golden-path-crd/#object-structure_1","title":"Object Structure","text":"Field Type Required Default Description <code>id</code> String Yes - Unique command identifier (kebab-case). <code>exec</code> Object Yes - Execution configuration. <code>exec.label</code> String No - Human-readable command name shown in IDE. <code>exec.component</code> String Yes - Name of the component where the command runs. <code>exec.commandLine</code> String Yes - Shell command to execute (can be multi-line script). <code>exec.workingDir</code> String No <code>/projects</code> Directory where the command executes. Use <code>${PROJECT_SOURCE}</code>. <code>exec.group</code> Object No - Command categorization. <code>exec.group.kind</code> String Yes - Group type: <code>build</code>, <code>run</code>, <code>test</code>, <code>debug</code>. <code>exec.group.isDefault</code> Boolean No <code>false</code> Whether this is the default command for the group."},{"location":"reference/crds/golden-path-crd/#example_3","title":"Example","text":"<pre><code>commands:\n  - id: install-dependencies\n    exec:\n      label: \"Install Dependencies\"\n      component: python\n      commandLine: pip install -r requirements.txt\n      workingDir: ${PROJECT_SOURCE}\n      group:\n        kind: build\n        isDefault: true\n\n  - id: run-tests\n    exec:\n      label: \"Run Tests\"\n      component: python\n      commandLine: pytest tests/ -v\n      workingDir: ${PROJECT_SOURCE}\n      group:\n        kind: test\n        isDefault: true\n</code></pre>"},{"location":"reference/crds/golden-path-crd/#events-object","title":"<code>events</code> Object","text":"<p>Lifecycle hooks executed at specific workspace stages.</p> Field Type Required Default Description <code>preStart</code> Array[String] No <code>[]</code> Command IDs to run before workspace starts. <code>postStart</code> Array[String] No <code>[]</code> Command IDs to run after workspace starts. <code>preStop</code> Array[String] No <code>[]</code> Command IDs to run before workspace stops. <code>postStop</code> Array[String] No <code>[]</code> Command IDs to run after workspace stops."},{"location":"reference/crds/golden-path-crd/#example_4","title":"Example","text":"<pre><code>events:\n  postStart:\n    - install-dependencies\n</code></pre>"},{"location":"reference/crds/golden-path-crd/#available-golden-path-devfiles","title":"Available Golden Path Devfiles","text":"Language File Description Python <code>goldenpath-python.yaml</code> Python 3.11 with Poetry, FastAPI, Django support. AI/ML <code>goldenpath-ai.yaml</code> Python with Jupyter, TensorFlow, PyTorch."},{"location":"reference/crds/golden-path-crd/#usage","title":"Usage","text":"<p>Launch a workspace in Eclipse Che:</p> <pre><code># Using Devfile URL\nche workspace:create --devfile=https://raw.githubusercontent.com/paruff/fawkes/main/platform/devfiles/goldenpath-python.yaml\n</code></pre> <p>Reference in a custom Devfile:</p> <pre><code>parent:\n  uri: https://raw.githubusercontent.com/paruff/fawkes/main/platform/devfiles/goldenpath-python.yaml\n</code></pre>"},{"location":"reference/crds/golden-path-crd/#see-also","title":"See Also","text":"<ul> <li>Devfile 2.2.2 Schema Reference</li> <li>Eclipse Che Documentation</li> <li>Golden Path Usage Guide</li> </ul>"},{"location":"reference/policies/kyverno-policy-list/","title":"Kyverno Policy Reference","text":""},{"location":"reference/policies/kyverno-policy-list/#overview","title":"Overview","text":"<p>This document lists all active Kyverno policies deployed in the Fawkes platform. Policies enforce security standards, mutate resources for compliance, and generate default configurations.</p> <p>Policy Files Location: <code>platform/policies/</code></p> <p>Enforcement Modes:</p> <ul> <li>Enforce: Blocks non-compliant resources from being created.</li> <li>Audit: Logs violations but allows resources to be created.</li> <li>Mutate: Automatically modifies resources to comply with standards.</li> <li>Generate: Creates new resources based on triggers.</li> </ul>"},{"location":"reference/policies/kyverno-policy-list/#security-policies-enforce-mode","title":"Security Policies (Enforce Mode)","text":"<p>These policies enforce Pod Security Standards and will DENY non-compliant resources.</p> <p>Source File: <code>platform/policies/mandatory-security.yaml</code></p> Policy Name Severity Resource Type Description Enforcement Mode <code>require-run-as-non-root</code> High Pod Containers must run as non-root user. Validates <code>securityContext.runAsNonRoot=true</code>. Enforce <code>disallow-privileged-containers</code> Critical Pod Prohibits privileged containers with full host access. Enforce <code>restrict-host-namespaces</code> High Pod Disallows <code>hostNetwork</code>, <code>hostPID</code>, <code>hostIPC</code> usage. Enforce <code>disallow-host-ports</code> Medium Pod Prevents binding to host ports (<code>hostPort</code>). Enforce <code>disallow-capabilities</code> High Pod Restricts Linux capabilities beyond defaults (e.g., <code>CAP_SYS_ADMIN</code>). Enforce <code>require-seccomp-profile</code> Medium Pod Requires seccomp profile (RuntimeDefault or Localhost). Audit"},{"location":"reference/policies/kyverno-policy-list/#excluded-namespaces","title":"Excluded Namespaces","text":"<p>Security policies exclude the following system namespaces:</p> <ul> <li><code>kube-system</code></li> <li><code>kube-public</code></li> <li><code>kube-node-lease</code></li> <li><code>kyverno</code></li> <li><code>vault</code></li> </ul>"},{"location":"reference/policies/kyverno-policy-list/#resource-constraint-policies","title":"Resource Constraint Policies","text":"<p>Enforce resource management best practices.</p> <p>Source File: <code>platform/policies/resource-constraints.yaml</code></p> Policy Name Severity Resource Type Description Enforcement Mode <code>require-resource-limits</code> High Pod All containers must have CPU and memory limits. Enforce <code>require-resource-requests</code> High Pod All containers must have CPU and memory requests. Enforce <code>limit-resource-maximums</code> Medium Pod Enforces maximum CPU (8 cores) and memory (16Gi) limits. Audit <code>require-probes</code> Medium Deployment, StatefulSet Requires <code>livenessProbe</code> and <code>readinessProbe</code> for workloads. Audit"},{"location":"reference/policies/kyverno-policy-list/#default-resource-limits","title":"Default Resource Limits","text":"<p>When <code>add-default-resources</code> mutation is applied:</p> Resource Request Limit CPU <code>100m</code> <code>500m</code> Memory <code>128Mi</code> <code>512Mi</code>"},{"location":"reference/policies/kyverno-policy-list/#mutation-policies-automatic-modification","title":"Mutation Policies (Automatic Modification)","text":"<p>These policies automatically modify resources to comply with platform standards.</p> <p>Source File: <code>platform/policies/mutation-policies.yaml</code></p> Policy Name Resource Type Mutation Applied Description <code>add-platform-labels</code> Pod, Deployment, StatefulSet, DaemonSet Adds labels:\u2022 <code>app.fawkes.idp/managed-by=fawkes-platform</code>\u2022 <code>app.fawkes.idp/environment={{namespace}}</code> Ensures consistent labeling for monitoring and cost allocation. <code>add-vault-annotations</code> Pod Adds annotations:\u2022 <code>vault.hashicorp.com/agent-inject=true</code>\u2022 <code>vault.hashicorp.com/role={{namespace}}</code> Enables Vault Agent sidecar for secret injection. <code>set-ingress-class</code> Ingress Sets <code>ingressClassName=nginx</code> Standardizes Ingress controller usage. <code>set-default-security-context</code> Pod Sets:\u2022 <code>runAsNonRoot=true</code>\u2022 <code>allowPrivilegeEscalation=false</code>\u2022 <code>seccompProfile.type=RuntimeDefault</code> Applies secure defaults if not explicitly configured. <code>add-default-resources</code> Pod Adds CPU/memory requests and limits if missing (see table above). Prevents unbounded resource consumption."},{"location":"reference/policies/kyverno-policy-list/#generation-policies-resource-creation","title":"Generation Policies (Resource Creation)","text":"<p>These policies automatically create resources when triggers occur (e.g., new namespace creation).</p> <p>Source File: <code>platform/policies/generation-policies.yaml</code></p> Policy Name Trigger Generated Resource Description <code>generate-namespace-network-policy</code> New Namespace NetworkPolicy Creates default deny-all ingress NetworkPolicy for network isolation. <code>generate-namespace-resource-quota</code> New Namespace ResourceQuota Creates quota limiting namespaces to 10 Pods, 20 CPU cores, 40Gi memory. <code>generate-namespace-limit-range</code> New Namespace LimitRange Sets default and maximum resource limits for containers. <code>generate-namespace-service-account</code> New Namespace ServiceAccount Creates <code>fawkes-workload</code> ServiceAccount with standard RBAC."},{"location":"reference/policies/kyverno-policy-list/#generated-resourcequota-limits","title":"Generated ResourceQuota Limits","text":"Resource Limit Pods 10 CPU (total) 20 cores Memory (total) 40Gi Persistent Volume Claims 5 Services (LoadBalancer) 2"},{"location":"reference/policies/kyverno-policy-list/#policy-validation-workflow","title":"Policy Validation Workflow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Resource Creation Request                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Step 1: Mutation Policies (add labels, security context, etc.) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Step 2: Validation Policies (security, resource constraints)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u2502                    \u2502\n                  \u25bc (Enforce)          \u25bc (Audit)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502  DENY    \u2502          \u2502  ALLOW   \u2502\n            \u2502 Resource \u2502          \u2502 Resource \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                                       \u25bc\n                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                           \u2502 Generate PolicyReport \u2502\n                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"reference/policies/kyverno-policy-list/#checking-policy-compliance","title":"Checking Policy Compliance","text":""},{"location":"reference/policies/kyverno-policy-list/#view-policy-reports-for-a-namespace","title":"View Policy Reports for a Namespace","text":"<pre><code>kubectl get policyreport -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/policies/kyverno-policy-list/#view-cluster-wide-policy-reports","title":"View Cluster-Wide Policy Reports","text":"<pre><code>kubectl get clusterpolicyreport\n</code></pre>"},{"location":"reference/policies/kyverno-policy-list/#describe-policy-violations","title":"Describe Policy Violations","text":"<pre><code>kubectl describe policyreport -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/policies/kyverno-policy-list/#dry-run-validation","title":"Dry-Run Validation","text":"<p>Test a manifest against policies before applying:</p> <pre><code>kubectl apply --dry-run=server -f deployment.yaml\n</code></pre>"},{"location":"reference/policies/kyverno-policy-list/#policy-exceptions","title":"Policy Exceptions","text":"<p>If a workload requires a policy exception (e.g., a privileged container for a monitoring agent), create a <code>PolicyException</code>:</p> <pre><code>apiVersion: kyverno.io/v2beta1\nkind: PolicyException\nmetadata:\n  name: allow-privileged-monitoring\n  namespace: monitoring\nspec:\n  exceptions:\n    - policyName: disallow-privileged-containers\n      ruleNames:\n        - disallow-privileged\n  match:\n    any:\n      - resources:\n          kinds:\n            - Pod\n          names:\n            - node-exporter-*\n</code></pre>"},{"location":"reference/policies/kyverno-policy-list/#monitoring-policies","title":"Monitoring Policies","text":"<p>Kyverno exposes Prometheus metrics:</p> Metric Description <code>kyverno_policy_results_total</code> Total policy evaluations (by policy, result, and action). <code>kyverno_admission_review_duration_seconds</code> Latency of admission webhook processing. <code>kyverno_policy_execution_duration_seconds</code> Time taken to execute individual policies. <p>Grafana Dashboard: <code>grafana.fawkes.idp/d/kyverno</code></p>"},{"location":"reference/policies/kyverno-policy-list/#see-also","title":"See Also","text":"<ul> <li>Kyverno Official Documentation</li> <li>Pod Security Standards</li> <li>Troubleshoot Kyverno Violations</li> <li>Policy as Code Tiers Explanation</li> <li>ADR-017: Kyverno Policy Engine</li> </ul>"},{"location":"runbooks/at-e1-001-validation/","title":"AT-E1-001 Validation Tests","text":"<p>This document describes how to run the AT-E1-001 acceptance test validation for the Azure AKS cluster infrastructure.</p>"},{"location":"runbooks/at-e1-001-validation/#overview","title":"Overview","text":"<p>AT-E1-001 validates that the Azure AKS cluster meets all acceptance criteria required for the Fawkes platform:</p> <ul> <li>\u2705 K8s cluster running (Azure AKS)</li> <li>\u2705 4 worker nodes healthy and schedulable</li> <li>\u2705 Cluster metrics available (kubelet, cAdvisor)</li> <li>\u2705 StorageClass configured for persistent volumes</li> <li>\u2705 Ingress controller deployed (nginx/traefik)</li> <li>\u2705 Cluster resource limits: CPU &lt;70%, Memory &lt;70%, Disk &lt;80%</li> </ul>"},{"location":"runbooks/at-e1-001-validation/#prerequisites","title":"Prerequisites","text":"<p>Before running the validation tests, ensure you have:</p> <ol> <li> <p>Azure CLI installed and configured    <pre><code>az --version\naz login\n</code></pre></p> </li> <li> <p>kubectl installed    <pre><code>kubectl version --client\n</code></pre></p> </li> <li> <p>Python 3.8+ (for pytest-based tests)    <pre><code>python --version\npip install -r requirements-dev.txt\n</code></pre></p> </li> <li> <p>Azure AKS cluster deployed</p> </li> <li>Cluster should be deployed using the terraform configuration in <code>infra/azure/</code></li> <li>Or deployed using the ignite script: <code>./scripts/ignite.sh --provider azure --only-cluster dev</code></li> </ol>"},{"location":"runbooks/at-e1-001-validation/#running-validation-tests","title":"Running Validation Tests","text":""},{"location":"runbooks/at-e1-001-validation/#method-1-using-the-validation-script-recommended","title":"Method 1: Using the Validation Script (Recommended)","text":"<p>The validation script is a standalone bash script that performs all checks and generates a JSON report.</p> <p>Basic usage: <pre><code>./scripts/validate-at-e1-001.sh\n</code></pre></p> <p>With custom cluster: <pre><code>./scripts/validate-at-e1-001.sh \\\n  --resource-group my-rg \\\n  --cluster-name my-aks\n</code></pre></p> <p>With environment variables: <pre><code>export AZURE_RESOURCE_GROUP=fawkes-rg\nexport AZURE_CLUSTER_NAME=fawkes-aks\n./scripts/validate-at-e1-001.sh --verbose\n</code></pre></p> <p>Options: - <code>-g, --resource-group</code> - Azure resource group name (default: fawkes-rg) - <code>-c, --cluster-name</code> - AKS cluster name (default: fawkes-aks) - <code>-m, --min-nodes</code> - Minimum required nodes (default: 4) - <code>-v, --verbose</code> - Verbose output - <code>-h, --help</code> - Show help message</p> <p>Output:</p> <p>The script will: 1. Run all validation checks 2. Display results with color-coded output 3. Generate a JSON report in <code>reports/at-e1-001-validation-&lt;timestamp&gt;.json</code> 4. Print a summary of passed/failed tests 5. Exit with code 0 (success) or 1 (failure)</p>"},{"location":"runbooks/at-e1-001-validation/#method-2-using-pytest-integration-tests","title":"Method 2: Using pytest Integration Tests","text":"<p>The pytest integration tests wrap the validation script and provide additional test assertions.</p> <p>Run all AT-E1-001 tests: <pre><code>pytest tests/integration/test_at_e1_001_validation.py -v\n</code></pre></p> <p>Run with custom cluster: <pre><code>pytest tests/integration/test_at_e1_001_validation.py -v \\\n  --resource-group my-rg \\\n  --cluster-name my-aks\n</code></pre></p> <p>Run specific test: <pre><code>pytest tests/integration/test_at_e1_001_validation.py::TestATE1001Validation::test_all_nodes_ready -v\n</code></pre></p> <p>Run with markers: <pre><code># Run all smoke tests\npytest tests/integration/test_at_e1_001_validation.py -v -m smoke\n\n# Run all Azure integration tests\npytest tests/integration/ -v -m \"azure and integration\"\n</code></pre></p>"},{"location":"runbooks/at-e1-001-validation/#method-3-using-bdd-tests","title":"Method 3: Using BDD Tests","text":"<p>The existing BDD feature file includes scenarios for AT-E1-001 validation.</p> <p>Run BDD tests: <pre><code>pytest tests/bdd/features/azure_aks_provisioning.feature -v -k \"AT-E1-001\"\n</code></pre></p> <p>Or with behave: <pre><code>behave tests/bdd/features/azure_aks_provisioning.feature --tags=AT-E1-001\n</code></pre></p>"},{"location":"runbooks/at-e1-001-validation/#method-4-using-inspec","title":"Method 4: Using InSpec","text":"<p>For compliance testing, use InSpec with the Azure plugin:</p> <pre><code># Install InSpec and Azure plugin (if not already installed)\n# gem install inspec\n# inspec plugin install inspec-azure\n\n# Run InSpec tests\ninspec exec infra/azure/inspec/ \\\n  -t azure:// \\\n  --input resource_group=fawkes-rg \\\n  --input cluster_name=fawkes-aks \\\n  --reporter cli json:reports/aks-inspec.json\n</code></pre>"},{"location":"runbooks/at-e1-001-validation/#understanding-test-results","title":"Understanding Test Results","text":""},{"location":"runbooks/at-e1-001-validation/#validation-script-output","title":"Validation Script Output","text":"<p>The validation script provides:</p> <ol> <li>Real-time Progress: Each test shows PASS/FAIL status with colored output</li> <li>Summary Statistics: Total tests, passed, failed, and success rate</li> <li>JSON Report: Detailed results saved to <code>reports/</code> directory</li> </ol> <p>Example output: <pre><code>[INFO] Checking prerequisites...\n[\u2713] Prerequisites - Azure CLI: Azure CLI installed\n[\u2713] Prerequisites - kubectl: kubectl installed\n[\u2713] Prerequisites - Azure Auth: Authenticated to Azure\n[INFO] Checking if AKS cluster exists...\n[\u2713] Cluster Exists: Cluster is provisioned and running\n...\n========================================\n  AT-E1-001 Validation Summary\n========================================\nCluster: fawkes-aks (fawkes-rg)\nTotal Tests: 11\nPassed: 11\nFailed: 0\nSuccess Rate: 100.0%\n========================================\n</code></pre></p>"},{"location":"runbooks/at-e1-001-validation/#json-report-format","title":"JSON Report Format","text":"<p>The JSON report includes: <pre><code>{\n  \"test_suite\": \"AT-E1-001\",\n  \"timestamp\": \"2024-12-13T12:00:00Z\",\n  \"cluster\": {\n    \"resource_group\": \"fawkes-rg\",\n    \"name\": \"fawkes-aks\"\n  },\n  \"summary\": {\n    \"total\": 11,\n    \"passed\": 11,\n    \"failed\": 0,\n    \"success_rate\": 100.0\n  },\n  \"tests\": [\n    {\n      \"test\": \"Cluster Exists\",\n      \"status\": \"PASS\",\n      \"message\": \"Cluster is provisioned and running\"\n    }\n    // ... more tests\n  ]\n}\n</code></pre></p>"},{"location":"runbooks/at-e1-001-validation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"runbooks/at-e1-001-validation/#common-issues","title":"Common Issues","text":"<p>Issue: Azure CLI not authenticated <pre><code>[\u2717] Prerequisites - Azure Auth: Not authenticated to Azure\n</code></pre> Solution: <pre><code>az login\naz account set --subscription &lt;your-subscription-id&gt;\n</code></pre></p> <p>Issue: Cluster not found <pre><code>[\u2717] Cluster Exists: Cluster fawkes-aks not found in fawkes-rg\n</code></pre> Solution: - Verify cluster name and resource group - Check that cluster is deployed: <code>az aks list -o table</code> - Deploy cluster if needed: <code>./scripts/ignite.sh --provider azure --only-cluster dev</code></p> <p>Issue: kubectl cannot connect <pre><code>[\u2717] kubectl Configuration: kubectl cannot connect to cluster\n</code></pre> Solution: <pre><code>az aks get-credentials \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --overwrite-existing\nkubectl cluster-info\n</code></pre></p> <p>Issue: Metrics not available <pre><code>[\u2717] Cluster Metrics: metrics-server deployed but not returning data\n</code></pre> Solution: - Wait a few minutes for metrics-server to collect data - Check metrics-server pod status: <code>kubectl get pods -n kube-system -l k8s-app=metrics-server</code> - Check metrics-server logs: <code>kubectl logs -n kube-system -l k8s-app=metrics-server</code></p> <p>Issue: Ingress controller not found <pre><code>[\u2717] Ingress Controller: No ingress controller (nginx/traefik) found\n</code></pre> Solution: - Deploy ingress controller (see issue #2 in epic1-local.json) - For nginx: <code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml</code> - Wait for deployment: <code>kubectl wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=120s</code></p> <p>Issue: Nodes over resource limits <pre><code>[\u2717] Resource Limits: 1 node(s) over resource limits\n</code></pre> Solution: - Check node metrics: <code>kubectl top nodes</code> - Scale down resource-intensive workloads - Consider adding more nodes or upgrading node SKUs - For development: This warning can sometimes be ignored if non-critical</p>"},{"location":"runbooks/at-e1-001-validation/#integration-with-cicd","title":"Integration with CI/CD","text":""},{"location":"runbooks/at-e1-001-validation/#github-actions","title":"GitHub Actions","text":"<p>Add to your workflow:</p> <pre><code>- name: Run AT-E1-001 Validation\n  run: |\n    az login --service-principal -u ${{ secrets.AZURE_CLIENT_ID }} -p ${{ secrets.AZURE_CLIENT_SECRET }} --tenant ${{ secrets.AZURE_TENANT_ID }}\n    ./scripts/validate-at-e1-001.sh --resource-group fawkes-rg --cluster-name fawkes-aks\n\n- name: Upload Validation Report\n  if: always()\n  uses: actions/upload-artifact@v3\n  with:\n    name: at-e1-001-report\n    path: reports/at-e1-001-validation-*.json\n</code></pre>"},{"location":"runbooks/at-e1-001-validation/#jenkins","title":"Jenkins","text":"<p>Add to your Jenkinsfile:</p> <pre><code>stage('AT-E1-001 Validation') {\n    steps {\n        withCredentials([azureServicePrincipal('azure-sp')]) {\n            sh '''\n                az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET --tenant $AZURE_TENANT_ID\n                ./scripts/validate-at-e1-001.sh --resource-group fawkes-rg --cluster-name fawkes-aks\n            '''\n        }\n    }\n    post {\n        always {\n            archiveArtifacts artifacts: 'reports/at-e1-001-validation-*.json', allowEmptyArchive: true\n        }\n    }\n}\n</code></pre>"},{"location":"runbooks/at-e1-001-validation/#acceptance-criteria-mapping","title":"Acceptance Criteria Mapping","text":"Criterion Test Name Script Check K8s cluster running (azure aks) <code>check_cluster_exists</code> \u2705 Verifies cluster exists and is in Running state 4 worker nodes healthy and schedulable <code>check_node_count</code>, <code>check_nodes_ready</code>, <code>check_nodes_schedulable</code> \u2705 Counts nodes, checks Ready status, verifies schedulable Cluster metrics available <code>check_metrics_available</code> \u2705 Verifies metrics-server is deployed and returning data StorageClass configured <code>check_storage_class</code> \u2705 Checks for StorageClass and default SC Ingress controller deployed <code>check_ingress_controller</code> \u2705 Looks for nginx-ingress or traefik Cluster resource limits <code>check_resource_limits</code> \u2705 Validates CPU &lt;70%, Memory &lt;70% on all nodes"},{"location":"runbooks/at-e1-001-validation/#related-documentation","title":"Related Documentation","text":"<ul> <li>Azure AKS Setup</li> <li>Azure AKS Validation Checklist</li> <li>BDD Feature: Azure AKS Provisioning</li> <li>InSpec Controls</li> </ul>"},{"location":"runbooks/at-e1-001-validation/#support","title":"Support","text":"<p>For issues or questions: 1. Check the troubleshooting section above 2. Review the Azure AKS validation checklist 3. Open an issue on GitHub with the validation report attached</p>"},{"location":"runbooks/azure-aks-setup/","title":"Azure AKS Setup Guide for Fawkes","text":"<p>Document Purpose: Complete guide for deploying Fawkes platform on Azure Kubernetes Service (AKS) Target Audience: DevOps engineers, Platform engineers, System administrators Estimated Time: 2-3 hours for full deployment Last Updated: December 2024</p>"},{"location":"runbooks/azure-aks-setup/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisites</li> <li>Cost Considerations</li> <li>Architecture Overview</li> <li>Step-by-Step Deployment</li> <li>Access Management</li> <li>Scaling Considerations</li> <li>Backup and Disaster Recovery</li> <li>Troubleshooting</li> <li>Cost Optimization</li> <li>Upgrade Procedures</li> </ol>"},{"location":"runbooks/azure-aks-setup/#prerequisites","title":"Prerequisites","text":""},{"location":"runbooks/azure-aks-setup/#azure-subscription","title":"Azure Subscription","text":"<ul> <li>Active Azure subscription with sufficient quota</li> <li>Owner or Contributor role on the subscription</li> <li>Resource Provider registrations:</li> <li>Microsoft.ContainerService</li> <li>Microsoft.Storage</li> <li>Microsoft.Network</li> <li>Microsoft.KeyVault</li> <li>Microsoft.OperationalInsights</li> </ul>"},{"location":"runbooks/azure-aks-setup/#required-tools","title":"Required Tools","text":"<p>Install the following tools on your local machine:</p> <pre><code># Azure CLI (version 2.50.0 or later)\ncurl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\naz --version\n\n# kubectl (Kubernetes CLI)\naz aks install-cli\n\n# Terraform (1.6.0 or later)\nwget https://releases.hashicorp.com/terraform/1.6.0/terraform_1.6.0_linux_amd64.zip\nunzip terraform_1.6.0_linux_amd64.zip\nsudo mv terraform /usr/local/bin/\nterraform --version\n\n# jq (for JSON processing)\nsudo apt-get install jq\n\n# Helm (optional, for manual operations)\ncurl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#azure-permissions","title":"Azure Permissions","text":"<p>Ensure you have the following permissions:</p> <ul> <li>Create and manage Resource Groups</li> <li>Create and manage AKS clusters</li> <li>Create and manage Virtual Networks</li> <li>Create and manage Azure Container Registry</li> <li>Create and manage Key Vaults</li> <li>Create and manage Storage Accounts</li> <li>Create and manage Log Analytics workspaces</li> <li>Assign Azure RBAC roles</li> </ul>"},{"location":"runbooks/azure-aks-setup/#cost-considerations","title":"Cost Considerations","text":""},{"location":"runbooks/azure-aks-setup/#budget-planning","title":"Budget Planning","text":"<p>Expected monthly costs for the default configuration:</p> Service Configuration Est. Monthly Cost AKS Control Plane Standard tier $0 (Free) System Node Pool 2x Standard_D4s_v3 $280 User Node Pool 2-10x Standard_D4s_v3 (avg 4) $560 Storage (OS Disks) 6x 128GB Premium SSD $118 Container Registry Standard tier $20 Load Balancer Standard tier $18 Public IP Static $4 Log Analytics ~5GB/month $14 Key Vault Standard $1 Storage Account ~50GB LRS $1 Data Transfer ~100GB $8 Total ~$1,024/month"},{"location":"runbooks/azure-aks-setup/#cost-optimization-options","title":"Cost Optimization Options","text":"<p>For development/testing environments, consider:</p> <ol> <li>Reduced VM sizes: Use Standard_D2s_v3 (~$500/month savings)</li> <li>Fewer nodes: Min 2, Max 5 for user pool (~$280/month savings)</li> <li>Basic ACR: Use Basic tier (~$15/month savings)</li> <li>Spot instances: Use Azure Spot VMs for non-critical workloads (up to 90% savings)</li> <li>Azure Reservations: Commit to 1 or 3 years for significant savings</li> </ol> <p>Recommended budget: $300-500/month for dev, $800-1500/month for production</p> <p>Run the cost estimation script: <pre><code>./scripts/azure-cost-estimate.sh\n</code></pre></p>"},{"location":"runbooks/azure-aks-setup/#architecture-overview","title":"Architecture Overview","text":""},{"location":"runbooks/azure-aks-setup/#infrastructure-components","title":"Infrastructure Components","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Azure Subscription                       \u2502\n\u2502                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Resource Group: fawkes-rg                            \u2502  \u2502\n\u2502  \u2502                                                        \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502  \u2502  \u2502  Virtual Network: fawkes-aks-vnet             \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  Address Space: 10.0.0.0/16                   \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502                                                 \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502  AKS Subnet: 10.0.1.0/24                \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502                                          \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502  \u2502  AKS Cluster: fawkes-aks          \u2502  \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502  \u2502  - Control Plane (Managed)        \u2502  \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502  \u2502  - System Pool: 2 nodes           \u2502  \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502  \u2502  - User Pool: 2-10 nodes (auto)   \u2502  \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502  \u2502  - Azure CNI networking           \u2502  \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502  \u2502  - Managed Identity               \u2502  \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502  \u2502                                                        \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502  \u2502  \u2502  Azure Container Registry (ACR)               \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  fawkesacr.azurecr.io                         \u2502   \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502  \u2502                                                        \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502  \u2502  \u2502  Azure Key Vault                              \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  fawkes-kv                                    \u2502   \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502  \u2502                                                        \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502  \u2502  \u2502  Storage Account (Terraform State)            \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  fawkestfstate                                \u2502   \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502  \u2502                                                        \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502  \u2502  \u2502  Log Analytics Workspace                      \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  fawkes-aks-logs                              \u2502   \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502  \u2502                                                        \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502  \u2502  \u2502  Azure Load Balancer + Public IP              \u2502   \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#network-architecture","title":"Network Architecture","text":"<ul> <li>VNet CIDR: 10.0.0.0/16</li> <li>AKS Subnet: 10.0.1.0/24 (for nodes)</li> <li>Service CIDR: 10.1.0.0/16 (for Kubernetes services)</li> <li>DNS Service IP: 10.1.0.10</li> <li>Network Plugin: Azure CNI (Container Networking Interface)</li> <li>Network Policy: Azure Network Policy</li> </ul>"},{"location":"runbooks/azure-aks-setup/#node-pool-strategy","title":"Node Pool Strategy","text":"<p>System Node Pool: - Purpose: Critical system components (kube-system, ArgoCD, monitoring) - VM Size: Standard_D4s_v3 (4 vCPU, 16 GB RAM) - Node Count: 2 (fixed, no auto-scaling) - OS Disk: 128 GB Premium SSD</p> <p>User Node Pool: - Purpose: Application workloads (Backstage, Jenkins, Focalboard, etc.) - VM Size: Standard_D4s_v3 (4 vCPU, 16 GB RAM) - Node Count: 2-10 (auto-scaling enabled) - OS Disk: 128 GB Premium SSD</p>"},{"location":"runbooks/azure-aks-setup/#step-by-step-deployment","title":"Step-by-Step Deployment","text":""},{"location":"runbooks/azure-aks-setup/#phase-1-azure-authentication","title":"Phase 1: Azure Authentication","text":"<pre><code># Login to Azure\naz login\n\n# Set your subscription\naz account set --subscription \"YOUR_SUBSCRIPTION_ID\"\n\n# Verify current subscription\naz account show --output table\n\n# Register required resource providers\naz provider register --namespace Microsoft.ContainerService\naz provider register --namespace Microsoft.Storage\naz provider register --namespace Microsoft.Network\naz provider register --namespace Microsoft.KeyVault\naz provider register --namespace Microsoft.OperationalInsights\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#phase-2-customize-configuration","title":"Phase 2: Customize Configuration","text":"<pre><code># Navigate to infrastructure directory\ncd infra/azure\n\n# Copy example configuration\ncp terraform.tfvars.example terraform.tfvars\n\n# Edit configuration (update globally unique names)\nnano terraform.tfvars\n</code></pre> <p>Important: Update these values to be globally unique: - <code>acr_name</code>: Must be globally unique (lowercase alphanumeric only) - <code>key_vault_name</code>: Must be globally unique (alphanumeric and hyphens) - <code>storage_account_name</code>: Must be globally unique (lowercase alphanumeric only)</p> <p>Example customization: <pre><code>acr_name             = \"fawkesacr20241213\"\nkey_vault_name       = \"fawkes-kv-20241213\"\nstorage_account_name = \"fawkestfstate20241213\"\n</code></pre></p> <p>Production Security Settings:</p> <p>For production environments, update these security-critical settings:</p> <pre><code>environment = \"prod\"\n\n# Key Vault security (production-ready)\nkey_vault_soft_delete_retention_days    = 90      # Longer retention for recovery\nkey_vault_purge_protection_enabled      = true    # Prevent permanent deletion\nkey_vault_network_acls_default_action   = \"Deny\"  # Restrict network access\n\n# Then configure allowed IP ranges or VNets in main.tf:\n# network_acls {\n#   ip_rules = [\"YOUR_OFFICE_IP/32\", \"YOUR_CI_IP/32\"]\n#   virtual_network_subnet_ids = [azurerm_subnet.aks_subnet.id]\n# }\n</code></pre> <p>Note: The default configuration is optimized for development/testing. Production environments should enable additional security controls as shown above.</p>"},{"location":"runbooks/azure-aks-setup/#phase-3-initialize-terraform","title":"Phase 3: Initialize Terraform","text":"<pre><code># Initialize Terraform\nterraform init\n\n# Validate configuration\nterraform validate\n\n# Review planned changes\nterraform plan -out=tfplan\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#phase-4-deploy-infrastructure","title":"Phase 4: Deploy Infrastructure","text":"<pre><code># Apply Terraform configuration\nterraform apply tfplan\n\n# This will create:\n# - Resource Group\n# - Virtual Network and Subnet\n# - AKS Cluster with system and user node pools\n# - Azure Container Registry\n# - Azure Key Vault\n# - Storage Account\n# - Log Analytics Workspace\n# - All necessary IAM role assignments\n\n# Deployment typically takes 10-15 minutes\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#phase-5-configure-kubectl","title":"Phase 5: Configure kubectl","text":"<pre><code># Get AKS credentials\naz aks get-credentials \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --overwrite-existing\n\n# Verify cluster access\nkubectl cluster-info\n\n# Check nodes\nkubectl get nodes\n\n# Expected output: 4 nodes (2 system + 2 user)\n# NAME                                STATUS   ROLE    AGE   VERSION\n# aks-system-12345678-vmss000000     Ready    agent   5m    v1.28.x\n# aks-system-12345678-vmss000001     Ready    agent   5m    v1.28.x\n# aks-user-12345678-vmss000000       Ready    agent   4m    v1.28.x\n# aks-user-12345678-vmss000001       Ready    agent   4m    v1.28.x\n\n# Check system pods\nkubectl get pods -A\n\n# Verify all system pods are running\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#phase-6-verify-azure-integrations","title":"Phase 6: Verify Azure Integrations","text":"<pre><code># Verify ACR integration\naz aks check-acr \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --acr fawkesacr.azurecr.io\n\n# Verify Azure Monitor integration\naz aks show \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --query \"addonProfiles.omsagent.enabled\"\n\n# Should return: true\n\n# View cluster details\naz aks show \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --output table\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#phase-7-deploy-fawkes-platform","title":"Phase 7: Deploy Fawkes Platform","text":"<pre><code># Navigate back to repository root\ncd ../..\n\n# Deploy Fawkes platform components via ignite script\n./scripts/ignite.sh --provider azure --skip-cluster dev\n\n# This will:\n# - Deploy ArgoCD\n# - Deploy platform applications\n# - Configure GitOps sync\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#access-management","title":"Access Management","text":""},{"location":"runbooks/azure-aks-setup/#azure-rbac","title":"Azure RBAC","text":"<p>The cluster is configured with Azure RBAC for Kubernetes authorization:</p> <pre><code># Grant user AKS admin role\naz role assignment create \\\n  --assignee user@example.com \\\n  --role \"Azure Kubernetes Service RBAC Cluster Admin\" \\\n  --scope $(az aks show -g fawkes-rg -n fawkes-aks --query id -o tsv)\n\n# Grant user AKS reader role\naz role assignment create \\\n  --assignee user@example.com \\\n  --role \"Azure Kubernetes Service RBAC Reader\" \\\n  --scope $(az aks show -g fawkes-rg -n fawkes-aks --query id -o tsv)\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#container-registry-access","title":"Container Registry Access","text":"<pre><code># Login to ACR\naz acr login --name fawkesacr\n\n# Grant push permissions to CI/CD service principal\naz role assignment create \\\n  --assignee &lt;service-principal-id&gt; \\\n  --role AcrPush \\\n  --scope $(az acr show -n fawkesacr --query id -o tsv)\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#key-vault-access","title":"Key Vault Access","text":"<pre><code># Grant user access to secrets\naz keyvault set-policy \\\n  --name fawkes-kv \\\n  --upn user@example.com \\\n  --secret-permissions get list set delete\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#scaling-considerations","title":"Scaling Considerations","text":""},{"location":"runbooks/azure-aks-setup/#node-pool-auto-scaling","title":"Node Pool Auto-Scaling","text":"<p>The user node pool automatically scales between 2-10 nodes:</p> <pre><code># Check current node count\nkubectl get nodes -l nodepool-type=user\n\n# View auto-scaler events\nkubectl get events -A | grep cluster-autoscaler\n\n# Manually adjust scaling limits\naz aks nodepool update \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name user \\\n  --min-count 3 \\\n  --max-count 8\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#horizontal-pod-autoscaling","title":"Horizontal Pod Autoscaling","text":"<p>Configure HPA for your applications:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: app-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: my-app\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#vertical-pod-autoscaling","title":"Vertical Pod Autoscaling","text":"<p>Enable VPA addon:</p> <pre><code># Install VPA\nkubectl apply -f https://github.com/kubernetes/autoscaler/releases/download/vertical-pod-autoscaler-0.13.0/vpa-v0.13.0.yaml\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#backup-and-disaster-recovery","title":"Backup and Disaster Recovery","text":""},{"location":"runbooks/azure-aks-setup/#cluster-backups","title":"Cluster Backups","text":"<p>Use Azure Backup for AKS:</p> <pre><code># Enable backup extension\naz aks enable-addons \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --addons azure-backup\n\n# Configure backup policy (via Azure Portal or ARM template)\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#persistent-volume-backups","title":"Persistent Volume Backups","text":"<p>Azure automatically creates volume snapshots. Configure retention:</p> <pre><code>apiVersion: snapshot.storage.k8s.io/v1\nkind: VolumeSnapshotClass\nmetadata:\n  name: default-snapshot-class\ndriver: disk.csi.azure.com\ndeletionPolicy: Retain\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#gitops-state-recovery","title":"GitOps State Recovery","text":"<p>All platform configuration is in Git:</p> <pre><code># Full platform recovery\ngit clone https://github.com/paruff/fawkes.git\ncd fawkes\n./scripts/ignite.sh --provider azure dev\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#disaster-recovery-plan","title":"Disaster Recovery Plan","text":"<ol> <li>Infrastructure: Terraform state in Azure Storage (with versioning)</li> <li>Applications: ArgoCD syncs from Git (declarative)</li> <li>Data: Regular volume snapshots + external database backups</li> <li>Secrets: Azure Key Vault (with soft delete enabled)</li> </ol> <p>RTO: 2-4 hours (new cluster + ArgoCD sync) RPO: 1 hour (snapshot frequency)</p>"},{"location":"runbooks/azure-aks-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"runbooks/azure-aks-setup/#common-issues","title":"Common Issues","text":""},{"location":"runbooks/azure-aks-setup/#issue-terraform-fails-with-name-not-available","title":"Issue: Terraform fails with \"name not available\"","text":"<p>Symptom: ACR, Key Vault, or Storage Account name already taken</p> <p>Solution: Update names in <code>terraform.tfvars</code> to be globally unique: <pre><code>acr_name             = \"fawkesacr$(date +%s)\"\nkey_vault_name       = \"fawkes-kv-$(date +%s)\"\nstorage_account_name = \"tfstate$(date +%s)\"\n</code></pre></p>"},{"location":"runbooks/azure-aks-setup/#issue-nodes-not-joining-cluster","title":"Issue: Nodes not joining cluster","text":"<p>Symptom: <code>kubectl get nodes</code> shows NotReady or missing nodes</p> <p>Solution: <pre><code># Check node pool status\naz aks nodepool list \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --output table\n\n# Check Azure activity logs\naz monitor activity-log list \\\n  --resource-group fawkes-rg \\\n  --offset 1h\n\n# Restart node pool\naz aks nodepool stop \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name user\n\naz aks nodepool start \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name user\n</code></pre></p>"},{"location":"runbooks/azure-aks-setup/#issue-cannot-pull-images-from-acr","title":"Issue: Cannot pull images from ACR","text":"<p>Symptom: Pods stuck in ImagePullBackOff</p> <p>Solution: <pre><code># Verify ACR integration\naz aks check-acr \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --acr fawkesacr.azurecr.io\n\n# Re-attach ACR if needed\naz aks update \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --attach-acr fawkesacr\n</code></pre></p>"},{"location":"runbooks/azure-aks-setup/#issue-high-costs","title":"Issue: High costs","text":"<p>Symptom: Azure bill exceeds budget</p> <p>Solution: <pre><code># Check current costs\naz cost-management query \\\n  --type Usage \\\n  --dataset-filter \"{\\\"and\\\":[{\\\"dimensions\\\":{\\\"name\\\":\\\"ResourceGroup\\\",\\\"operator\\\":\\\"In\\\",\\\"values\\\":[\\\"fawkes-rg\\\"]}}]}\" \\\n  --timeframe MonthToDate\n\n# Scale down user pool\naz aks nodepool scale \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name user \\\n  --node-count 2\n\n# Run cost estimation\n./scripts/azure-cost-estimate.sh\n</code></pre></p>"},{"location":"runbooks/azure-aks-setup/#issue-pods-evicted-due-to-disk-pressure","title":"Issue: Pods evicted due to disk pressure","text":"<p>Symptom: Pods restarting, kubelet reporting disk pressure</p> <p>Solution: <pre><code># Check disk usage on nodes\nkubectl get nodes -o custom-columns=NAME:.metadata.name,DISK:.status.allocatable.ephemeral-storage\n\n# Clean up unused images\nkubectl debug node/aks-user-12345678-vmss000000 -it --image=alpine\n# In debug pod:\n# crictl rmi --prune\n\n# Increase OS disk size (requires recreation)\n# Update terraform.tfvars and re-apply\n</code></pre></p>"},{"location":"runbooks/azure-aks-setup/#diagnostic-commands","title":"Diagnostic Commands","text":"<pre><code># View cluster health\naz aks show \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --query \"{provisioningState:provisioningState,powerState:powerState.code}\"\n\n# View node pool health\naz aks nodepool show \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name user \\\n  --query \"{provisioningState:provisioningState,powerState:powerState.code}\"\n\n# Check Azure Monitor logs\naz monitor log-analytics query \\\n  --workspace &lt;workspace-id&gt; \\\n  --analytics-query \"ContainerLog | where TimeGenerated &gt; ago(1h) | limit 100\"\n\n# Get kubectl diagnostics\nkubectl get events -A --sort-by='.lastTimestamp'\nkubectl top nodes\nkubectl top pods -A\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#cost-optimization","title":"Cost Optimization","text":""},{"location":"runbooks/azure-aks-setup/#development-environment-optimizations","title":"Development Environment Optimizations","text":"<pre><code># terraform.tfvars for dev environment\nsystem_node_pool_vm_size = \"Standard_D2s_v3\"\nsystem_node_pool_count   = 1\n\nuser_node_pool_vm_size   = \"Standard_D2s_v3\"\nuser_node_pool_min_count = 1\nuser_node_pool_max_count = 3\n\nacr_sku = \"Basic\"\nlog_retention_days = 7\n</code></pre> <p>Estimated savings: ~$550/month</p>"},{"location":"runbooks/azure-aks-setup/#auto-shutdown-for-dev-clusters","title":"Auto-Shutdown for Dev Clusters","text":"<pre><code># Stop cluster (nodes only, control plane remains)\naz aks stop \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks\n\n# Start cluster\naz aks start \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks\n\n# Schedule with cron or Azure Automation\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#use-azure-spot-instances","title":"Use Azure Spot Instances","text":"<p>Add a spot node pool for batch workloads:</p> <pre><code>az aks nodepool add \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name spot \\\n  --priority Spot \\\n  --eviction-policy Delete \\\n  --spot-max-price -1 \\\n  --enable-cluster-autoscaler \\\n  --min-count 0 \\\n  --max-count 5 \\\n  --node-vm-size Standard_D4s_v3 \\\n  --node-taints kubernetes.azure.com/scalesetpriority=spot:NoSchedule \\\n  --labels kubernetes.azure.com/scalesetpriority=spot\n</code></pre> <p>Schedule workloads on spot nodes:</p> <pre><code>spec:\n  tolerations:\n  - key: \"kubernetes.azure.com/scalesetpriority\"\n    operator: \"Equal\"\n    value: \"spot\"\n    effect: \"NoSchedule\"\n  nodeSelector:\n    kubernetes.azure.com/scalesetpriority: spot\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#reserved-instances","title":"Reserved Instances","text":"<p>Purchase reserved instances for predictable workloads:</p> <pre><code># View reservation options\naz reservations catalog show \\\n  --subscription-id &lt;subscription-id&gt; \\\n  --reserved-resource-type VirtualMachines \\\n  --location eastus\n</code></pre> <p>Expected savings: 38% (1-year) or 62% (3-year)</p>"},{"location":"runbooks/azure-aks-setup/#upgrade-procedures","title":"Upgrade Procedures","text":""},{"location":"runbooks/azure-aks-setup/#kubernetes-version-upgrade","title":"Kubernetes Version Upgrade","text":"<pre><code># Check available versions\naz aks get-upgrades \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --output table\n\n# Upgrade control plane\naz aks upgrade \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --kubernetes-version 1.29.0\n\n# Upgrade node pools\naz aks nodepool upgrade \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name system \\\n  --kubernetes-version 1.29.0\n\naz aks nodepool upgrade \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name user \\\n  --kubernetes-version 1.29.0\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#terraform-state-upgrade","title":"Terraform State Upgrade","text":"<pre><code># Backup state\naz storage blob download \\\n  --account-name fawkestfstate \\\n  --container-name tfstate \\\n  --name terraform.tfstate \\\n  --file terraform.tfstate.backup\n\n# Update Terraform\nterraform init -upgrade\n\n# Apply changes\nterraform plan\nterraform apply\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#rolling-node-upgrades","title":"Rolling Node Upgrades","text":"<pre><code># Cordon and drain nodes one at a time\nkubectl cordon aks-user-12345678-vmss000000\nkubectl drain aks-user-12345678-vmss000000 --ignore-daemonsets --delete-emptydir-data\n\n# Upgrade via Azure\naz aks nodepool upgrade \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name user \\\n  --node-image-only\n\n# Uncordon when complete\nkubectl uncordon aks-user-12345678-vmss000000\n</code></pre>"},{"location":"runbooks/azure-aks-setup/#additional-resources","title":"Additional Resources","text":"<ul> <li>Azure AKS Documentation</li> <li>Fawkes Architecture</li> <li>Fawkes AWS Deployment Guide</li> <li>Azure Pricing Calculator</li> <li>Terraform AzureRM Provider</li> </ul>"},{"location":"runbooks/azure-aks-setup/#support","title":"Support","text":"<p>For issues or questions:</p> <ol> <li>Check this documentation and troubleshooting section</li> <li>Review Fawkes Troubleshooting Guide</li> <li>Search existing GitHub Issues</li> <li>Open a new issue with the <code>comp-azure</code> label</li> </ol> <p>Document Version: 1.0 Last Review: December 2024 Next Review: March 2025</p>"},{"location":"runbooks/azure-aks-validation-checklist/","title":"Azure AKS Setup Validation Checklist (AT-E1-001)","text":"<p>This checklist validates that the Azure AKS setup meets all acceptance criteria for issue #1.</p>"},{"location":"runbooks/azure-aks-validation-checklist/#pre-deployment-validation","title":"Pre-Deployment Validation","text":""},{"location":"runbooks/azure-aks-validation-checklist/#prerequisites-check","title":"Prerequisites Check","text":"<ul> <li>[ ] Azure CLI installed (<code>az --version</code>)</li> <li>[ ] Terraform installed (<code>terraform --version</code>)</li> <li>[ ] kubectl installed (<code>kubectl version --client</code>)</li> <li>[ ] Authenticated to Azure (<code>az account show</code>)</li> <li>[ ] Correct subscription selected</li> </ul>"},{"location":"runbooks/azure-aks-validation-checklist/#configuration-validation","title":"Configuration Validation","text":"<ul> <li>[ ] Copied <code>terraform.tfvars.example</code> to <code>terraform.tfvars</code></li> <li>[ ] Updated resource names to be globally unique (ACR, Key Vault, Storage Account)</li> <li>[ ] Reviewed and adjusted VM sizes for budget</li> <li>[ ] Reviewed network CIDR ranges (no conflicts)</li> <li>[ ] Set appropriate environment value (dev/stage/prod)</li> <li>[ ] Configured Key Vault security settings for environment</li> </ul>"},{"location":"runbooks/azure-aks-validation-checklist/#terraform-validation","title":"Terraform Validation","text":"<pre><code>cd infra/azure\nterraform init\nterraform validate\nterraform fmt -check\n</code></pre> <ul> <li>[ ] Terraform init succeeds</li> <li>[ ] Terraform validate passes</li> <li>[ ] Terraform formatting is correct</li> </ul>"},{"location":"runbooks/azure-aks-validation-checklist/#deployment-validation","title":"Deployment Validation","text":""},{"location":"runbooks/azure-aks-validation-checklist/#infrastructure-deployment","title":"Infrastructure Deployment","text":"<pre><code># Method 1: Using ignite.sh\n./scripts/ignite.sh --provider azure --only-cluster dev\n\n# Method 2: Direct Terraform\ncd infra/azure\nterraform plan -out=tfplan\nterraform apply tfplan\n</code></pre> <ul> <li>[ ] Deployment completes without errors (10-15 minutes)</li> <li>[ ] Resource Group created</li> <li>[ ] Virtual Network created with correct CIDR</li> <li>[ ] AKS cluster created</li> <li>[ ] System node pool created (2 nodes)</li> <li>[ ] User node pool created (2+ nodes with auto-scaling)</li> <li>[ ] Azure Container Registry created</li> <li>[ ] Azure Key Vault created</li> <li>[ ] Storage Account created</li> <li>[ ] Log Analytics workspace created</li> </ul>"},{"location":"runbooks/azure-aks-validation-checklist/#cluster-access","title":"Cluster Access","text":"<pre><code>az aks get-credentials \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --overwrite-existing\n\nkubectl cluster-info\nkubectl get nodes\n</code></pre> <ul> <li>[ ] kubectl credentials retrieved</li> <li>[ ] Cluster info displays correctly</li> <li>[ ] All nodes visible and in Ready state</li> <li>[ ] At least 4 nodes present (2 system + 2 user minimum)</li> </ul>"},{"location":"runbooks/azure-aks-validation-checklist/#acceptance-criteria-validation-at-e1-001","title":"Acceptance Criteria Validation (AT-E1-001)","text":""},{"location":"runbooks/azure-aks-validation-checklist/#1-aks-cluster-deployed-in-azure","title":"1. AKS cluster deployed in Azure","text":"<p><pre><code>az aks show \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --output table\n</code></pre> - [ ] Cluster exists - [ ] Provisioning state is \"Succeeded\" - [ ] Power state is \"Running\"</p>"},{"location":"runbooks/azure-aks-validation-checklist/#2-3-5-nodes-running-and-schedulable","title":"2. 3-5 nodes running and schedulable","text":"<p><pre><code>kubectl get nodes\nkubectl get nodes -o json | jq '.items | length'\n</code></pre> - [ ] Total node count is 4+ (2 system + 2+ user) - [ ] All nodes show STATUS=Ready - [ ] Nodes are schedulable (not cordoned)</p>"},{"location":"runbooks/azure-aks-validation-checklist/#3-azure-cni-networking-configured","title":"3. Azure CNI networking configured","text":"<p><pre><code>az aks show \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --query \"networkProfile.networkPlugin\" \\\n  --output tsv\n</code></pre> - [ ] Network plugin is \"azure\" - [ ] Network policy is configured (azure or calico) - [ ] Service CIDR is 10.1.0.0/16</p>"},{"location":"runbooks/azure-aks-validation-checklist/#4-system-node-pool-and-user-node-pool-separated","title":"4. System node pool and user node pool separated","text":"<p><pre><code>kubectl get nodes --show-labels | grep nodepool-type\naz aks nodepool list \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --output table\n</code></pre> - [ ] System pool exists with mode=System - [ ] User pool exists with mode=User - [ ] Nodes have appropriate labels (nodepool-type) - [ ] System pool has 2 nodes (fixed) - [ ] User pool has auto-scaling enabled</p>"},{"location":"runbooks/azure-aks-validation-checklist/#5-kubectl-configured-and-working","title":"5. kubectl configured and working","text":"<p><pre><code>kubectl get pods -A\nkubectl get services -A\nkubectl cluster-info\n</code></pre> - [ ] Can list all pods - [ ] Can list all services - [ ] API server is reachable - [ ] System pods are Running</p>"},{"location":"runbooks/azure-aks-validation-checklist/#6-cluster-metrics-available-via-azure-monitor","title":"6. Cluster metrics available via Azure Monitor","text":"<p><pre><code>az aks show \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --query \"addonProfiles.omsagent.enabled\" \\\n  --output tsv\n</code></pre> - [ ] OMS agent addon is enabled - [ ] Log Analytics workspace exists - [ ] Container insights collecting data - [ ] Can view metrics in Azure Portal</p>"},{"location":"runbooks/azure-aks-validation-checklist/#7-azure-ad-integration-configured","title":"7. Azure AD integration configured","text":"<p><pre><code>az aks show \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --query \"aadProfile\" \\\n  --output json\n</code></pre> - [ ] AAD profile exists - [ ] Managed AAD is enabled - [ ] Azure RBAC is enabled - [ ] RBAC is enabled on cluster</p>"},{"location":"runbooks/azure-aks-validation-checklist/#8-cluster-passes-at-e1-001","title":"8. Cluster passes AT-E1-001","text":"<p>Run all validation checks - this is the comprehensive validation.</p>"},{"location":"runbooks/azure-aks-validation-checklist/#resource-integration-validation","title":"Resource Integration Validation","text":""},{"location":"runbooks/azure-aks-validation-checklist/#azure-container-registry-integration","title":"Azure Container Registry Integration","text":"<p><pre><code>az aks check-acr \\\n  --resource-group fawkes-rg \\\n  --name fawkes-aks \\\n  --acr fawkesacr.azurecr.io\n\naz role assignment list \\\n  --scope $(az acr show -n fawkesacr --query id -o tsv) \\\n  --output table\n</code></pre> - [ ] ACR check passes - [ ] AcrPull role assigned to AKS kubelet identity - [ ] Can pull images from ACR</p>"},{"location":"runbooks/azure-aks-validation-checklist/#key-vault-integration","title":"Key Vault Integration","text":"<p><pre><code>az keyvault show --name fawkes-kv --output table\n\naz keyvault show --name fawkes-kv \\\n  --query \"properties.enableSoftDelete\" \\\n  --output tsv\n</code></pre> - [ ] Key Vault exists - [ ] Soft delete is enabled - [ ] Access policies configured for deployer - [ ] Access policies configured for AKS - [ ] Network ACLs configured appropriately</p>"},{"location":"runbooks/azure-aks-validation-checklist/#storage-account","title":"Storage Account","text":"<p><pre><code>az storage account show \\\n  --name fawkestfstate \\\n  --resource-group fawkes-rg \\\n  --output table\n\naz storage container list \\\n  --account-name fawkestfstate \\\n  --output table\n</code></pre> - [ ] Storage account exists - [ ] Container \"tfstate\" exists - [ ] Replication type is correct (LRS/GRS) - [ ] Terraform state is stored there</p>"},{"location":"runbooks/azure-aks-validation-checklist/#log-analytics","title":"Log Analytics","text":"<p><pre><code>az monitor log-analytics workspace show \\\n  --resource-group fawkes-rg \\\n  --workspace-name fawkes-aks-logs \\\n  --output table\n</code></pre> - [ ] Log Analytics workspace exists - [ ] Retention period is configured - [ ] Linked to AKS cluster - [ ] Receiving container logs</p>"},{"location":"runbooks/azure-aks-validation-checklist/#compliance-testing","title":"Compliance Testing","text":""},{"location":"runbooks/azure-aks-validation-checklist/#inspec-tests","title":"InSpec Tests","text":"<pre><code># Install InSpec and Azure plugin if needed\n# curl https://omnitruck.chef.io/install.sh | sudo bash -s -- -P inspec\n# inspec plugin install inspec-azure\n\ncd /path/to/fawkes\ninspec exec infra/azure/inspec/ \\\n  -t azure:// \\\n  --input resource_group=fawkes-rg \\\n  --input cluster_name=fawkes-aks \\\n  --reporter cli json:reports/aks-inspec.json\n</code></pre> <p>Critical controls that must pass: - [ ] aks-cluster-exists: Cluster exists and running - [ ] aks-node-count: Minimum 2+ nodes - [ ] aks-node-pool-separation: System and user pools separated - [ ] aks-azure-cni: Azure CNI configured - [ ] aks-managed-identity: Managed identity enabled - [ ] aks-rbac-enabled: RBAC enabled - [ ] k8s-nodes-ready: All nodes Ready - [ ] k8s-system-pods-running: System pods Running</p>"},{"location":"runbooks/azure-aks-validation-checklist/#bdd-tests","title":"BDD Tests","text":"<p><pre><code># From repository root\npytest tests/bdd/features/azure_aks_provisioning.feature -v\n\n# Or run specific scenarios\npytest tests/bdd/features/azure_aks_provisioning.feature -k \"AT-E1-001\"\n</code></pre> - [ ] All test scenarios pass - [ ] No skipped tests (if authenticated)</p>"},{"location":"runbooks/azure-aks-validation-checklist/#cost-validation","title":"Cost Validation","text":""},{"location":"runbooks/azure-aks-validation-checklist/#cost-estimation","title":"Cost Estimation","text":"<p><pre><code>./scripts/azure-cost-estimate.sh\n</code></pre> - [ ] Script completes successfully - [ ] Cost breakdown displayed - [ ] Total cost within budget expectations - [ ] Optimization suggestions reviewed (if over budget)</p>"},{"location":"runbooks/azure-aks-validation-checklist/#actual-cost-check","title":"Actual Cost Check","text":"<p><pre><code>az consumption usage list \\\n  --start-date $(date -d '1 day ago' +%Y-%m-%d) \\\n  --end-date $(date +%Y-%m-%d) \\\n  --output table\n</code></pre> - [ ] Can view usage data - [ ] Costs align with estimates - [ ] Resource tags present for cost tracking</p>"},{"location":"runbooks/azure-aks-validation-checklist/#operational-validation","title":"Operational Validation","text":""},{"location":"runbooks/azure-aks-validation-checklist/#scaling-tests","title":"Scaling Tests","text":"<p><pre><code># Scale user pool\naz aks nodepool scale \\\n  --resource-group fawkes-rg \\\n  --cluster-name fawkes-aks \\\n  --name user \\\n  --node-count 3\n\nkubectl get nodes\n</code></pre> - [ ] User pool scales up successfully - [ ] New nodes become Ready - [ ] Auto-scaler works within min/max limits</p>"},{"location":"runbooks/azure-aks-validation-checklist/#pod-scheduling","title":"Pod Scheduling","text":"<p><pre><code># Deploy a test workload\nkubectl create deployment nginx --image=nginx --replicas=3\nkubectl get pods -o wide\n</code></pre> - [ ] Pods schedule across nodes - [ ] Pods run successfully - [ ] Can access pod logs</p>"},{"location":"runbooks/azure-aks-validation-checklist/#network-connectivity","title":"Network Connectivity","text":"<p><pre><code># Test pod-to-pod connectivity\nkubectl run test-pod --image=busybox -it --rm -- /bin/sh\n# In pod: nslookup kubernetes.default\n# In pod: wget -O- kubernetes.default\n</code></pre> - [ ] DNS resolution works - [ ] Pod can reach Kubernetes API - [ ] Network policy allows expected traffic</p>"},{"location":"runbooks/azure-aks-validation-checklist/#monitoring","title":"Monitoring","text":"<p><pre><code># Check metrics\nkubectl top nodes\nkubectl top pods -A\n</code></pre> - [ ] Metrics server working - [ ] Node metrics available - [ ] Pod metrics available</p>"},{"location":"runbooks/azure-aks-validation-checklist/#security-validation","title":"Security Validation","text":""},{"location":"runbooks/azure-aks-validation-checklist/#rbac","title":"RBAC","text":"<p><pre><code>kubectl auth can-i list pods --as=system:anonymous\nkubectl auth can-i list pods --as=system:serviceaccount:default:default\n</code></pre> - [ ] Anonymous access properly restricted - [ ] Service account permissions appropriate - [ ] Azure RBAC enforced</p>"},{"location":"runbooks/azure-aks-validation-checklist/#network-security","title":"Network Security","text":"<p><pre><code>kubectl get networkpolicies -A\naz network nsg list --resource-group MC_fawkes-rg_*\n</code></pre> - [ ] Network policies configured (if using) - [ ] NSGs created by AKS - [ ] Only required ports open</p>"},{"location":"runbooks/azure-aks-validation-checklist/#secrets-management","title":"Secrets Management","text":"<p><pre><code>kubectl get secrets -A\naz keyvault secret list --vault-name fawkes-kv\n</code></pre> - [ ] No plaintext secrets in cluster - [ ] Secrets stored in Key Vault - [ ] CSI driver configured (optional)</p>"},{"location":"runbooks/azure-aks-validation-checklist/#documentation-validation","title":"Documentation Validation","text":""},{"location":"runbooks/azure-aks-validation-checklist/#runbook","title":"Runbook","text":"<ul> <li>[ ] Read through <code>docs/runbooks/azure-aks-setup.md</code></li> <li>[ ] All commands work as documented</li> <li>[ ] Architecture diagram matches deployment</li> <li>[ ] Troubleshooting section helpful</li> </ul>"},{"location":"runbooks/azure-aks-validation-checklist/#terraform-documentation","title":"Terraform Documentation","text":"<ul> <li>[ ] All variables documented</li> <li>[ ] Outputs are useful</li> <li>[ ] Examples are clear</li> <li>[ ] Comments explain complex logic</li> </ul>"},{"location":"runbooks/azure-aks-validation-checklist/#cleanup-optional-for-dev-environments","title":"Cleanup (Optional for Dev Environments)","text":"<p>If you need to tear down the environment:</p> <pre><code># Option 1: Terraform destroy\ncd infra/azure\nterraform destroy\n\n# Option 2: Delete resource group\naz group delete --name fawkes-rg --yes --no-wait\n</code></pre> <p>WARNING: This will delete all resources. Ensure you have backups if needed.</p>"},{"location":"runbooks/azure-aks-validation-checklist/#sign-off","title":"Sign-Off","text":"<p>Validated by: __ Date: __ Environment: [ ] Dev [ ] Stage [ ] Prod All critical checks passed: [ ] Yes [ ] No  </p> <p>Notes:</p>"},{"location":"runbooks/azure-aks-validation-checklist/#references","title":"References","text":"<ul> <li>Issue: https://github.com/paruff/fawkes/issues/1</li> <li>PR: https://github.com/paruff/fawkes/pull/[NUMBER]</li> <li>Runbook: docs/runbooks/azure-aks-setup.md</li> <li>InSpec Tests: infra/azure/inspec/</li> <li>BDD Tests: tests/bdd/features/azure_aks_provisioning.feature</li> </ul>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/","title":"AT-E1-002 Implementation Summary","text":""},{"location":"testing/AT-E1-002-IMPLEMENTATION/#overview","title":"Overview","text":"<p>This document summarizes the implementation of AT-E1-002 validation test infrastructure for GitOps with ArgoCD.</p>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#what-was-implemented","title":"What Was Implemented","text":""},{"location":"testing/AT-E1-002-IMPLEMENTATION/#1-validation-script-scriptsvalidate-at-e1-002sh","title":"1. Validation Script (<code>scripts/validate-at-e1-002.sh</code>)","text":"<p>Comprehensive validation script that checks all AT-E1-002 acceptance criteria:</p> <p>\u2705 Prerequisites - Checks kubectl installation - Checks argocd CLI installation (optional)</p> <p>\u2705 Cluster Access - Validates Kubernetes cluster connectivity - Verifies cluster-info access</p> <p>\u2705 ArgoCD Namespace - Checks namespace exists - Validates namespace is Active</p> <p>\u2705 ArgoCD Deployment - Verifies argocd-server deployment - Checks argocd-application-controller - Validates argocd-repo-server - Confirms argocd-redis is running</p> <p>\u2705 ArgoCD Pods - Validates all pods are Running - Checks all pods are Ready - Reports pod count and status</p> <p>\u2705 ArgoCD CRDs - Validates applications.argoproj.io - Checks applicationsets.argoproj.io - Confirms appprojects.argoproj.io</p> <p>\u2705 Git Repository Structure - Checks platform/apps/ directory exists - Validates platform/bootstrap/ directory exists</p> <p>\u2705 App-of-Apps Pattern - Looks for root applications (platform-bootstrap, fawkes-app, fawkes-infra) - Validates at least one Application exists</p> <p>\u2705 Application Sync Status - Checks all applications are Synced - Validates all applications are Healthy - Identifies out-of-sync or unhealthy applications</p> <p>\u2705 Auto-Sync Configuration - Verifies auto-sync is enabled - Checks self-heal is configured</p> <p>\u2705 ArgoCD Ingress - Validates ingress resource exists - Checks ingress host configuration</p> <p>\u2705 Test Reporting - Generates JSON report with timestamp - Includes summary (total, passed, failed, pass rate) - Provides detailed results for each test - Saves to <code>reports/at-e1-002-validation-TIMESTAMP.json</code></p>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#2-e2e-sync-test-script-testse2eargocd-sync-testsh","title":"2. E2E Sync Test Script (<code>tests/e2e/argocd-sync-test.sh</code>)","text":"<p>End-to-end testing for ArgoCD sync operations:</p> <p>\u2705 Features - Tests application sync operations - Supports testing specific application or all applications - Configurable timeout for sync operations - Wait for sync status (Synced) - Wait for health status (Healthy) - Optional hard refresh via argocd CLI - Comprehensive summary reporting</p> <p>\u2705 Options - <code>--namespace</code>: Specify ArgoCD namespace - <code>--app</code>: Test specific application - <code>--timeout</code>: Configure timeout in seconds - <code>--verbose</code>: Enable verbose output</p>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#3-unified-test-runner-testsacceptancerun-testsh","title":"3. Unified Test Runner (<code>tests/acceptance/run-test.sh</code>)","text":"<p>Central test runner for all acceptance tests:</p> <p>\u2705 Features - Supports all AT-E1-XXX test IDs - Implements AT-E1-001 (calls validate-at-e1-001.sh) - Implements AT-E1-002 with multi-step validation:   1. Comprehensive validation (validate-at-e1-002.sh)   2. E2E sync tests (argocd-sync-test.sh)   3. BDD tests (pytest) - Placeholder for AT-E1-003 through AT-E1-012 - Provides help and usage information - Color-coded output</p>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#4-integration-test-structure-testsintegrationargocd","title":"4. Integration Test Structure (<code>tests/integration/argocd/</code>)","text":"<p>Integration test infrastructure for ArgoCD:</p> <p>\u2705 Files Created - <code>README.md</code>: Documentation for integration tests - <code>test-application.yaml</code>: Sample ArgoCD Application for testing - <code>manifests/test-app.yaml</code>: Sample Kubernetes manifests (ConfigMap, Service, Deployment)</p> <p>\u2705 Features - Test Application configured with:   - Auto-sync enabled   - Self-heal enabled   - Prune enabled   - Retry with backoff   - CreateNamespace=true - Sample manifests for testing sync operations</p>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#5-makefile-targets","title":"5. Makefile Targets","text":"<p>Added new targets to <code>Makefile</code>:</p> <p>\u2705 New Targets <pre><code>validate-at-e1-002       # Run AT-E1-002 acceptance test validation\ntest-e2e-argocd          # Run ArgoCD E2E sync tests\n</code></pre></p> <p>\u2705 New Variable <pre><code>ARGO_NAMESPACE ?= fawkes\n</code></pre></p>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#6-documentation","title":"6. Documentation","text":"<p>Comprehensive documentation created:</p> <p>\u2705 Files - <code>tests/acceptance/README.md</code>: Overview of acceptance testing - <code>tests/integration/argocd/README.md</code>: Integration test documentation - <code>docs/testing/at-e1-002-validation-guide.md</code>: Complete validation guide</p> <p>\u2705 Content - Usage instructions for all test scripts - Validation check descriptions - Test report format and viewing - Manual validation commands from issue - Acceptance criteria checklist - Troubleshooting guide - CI/CD integration examples - Dependency information</p>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#usage-examples","title":"Usage Examples","text":""},{"location":"testing/AT-E1-002-IMPLEMENTATION/#run-complete-at-e1-002-validation","title":"Run Complete AT-E1-002 Validation","text":"<pre><code># Using test runner\n./tests/acceptance/run-test.sh AT-E1-002\n\n# Using Makefile\nmake validate-at-e1-002\n</code></pre>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#run-individual-components","title":"Run Individual Components","text":"<pre><code># Validation only\n./scripts/validate-at-e1-002.sh\n\n# E2E sync tests only\n./tests/e2e/argocd-sync-test.sh\n\n# BDD tests only\npytest tests/bdd/test_argocd_bootstrap.py -v -m gitops\n</code></pre>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#with-options","title":"With Options","text":"<pre><code># Custom namespace\n./scripts/validate-at-e1-002.sh --namespace argocd\n\n# Test specific application\n./tests/e2e/argocd-sync-test.sh --app platform-bootstrap --timeout 600\n\n# Verbose output\n./scripts/validate-at-e1-002.sh --verbose\n./tests/e2e/argocd-sync-test.sh --verbose\n</code></pre>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#validation-checklist","title":"Validation Checklist","text":"<p>From Issue #8 acceptance criteria:</p> <ul> <li>\u2705 AT-E1-002 test suite created - Comprehensive validation script implemented</li> <li>\u2705 ArgoCD validation - Checks ArgoCD deployment, pods, CRDs</li> <li>\u2705 Test report generation - JSON reports with timestamp in reports/ directory</li> <li>\u2705 ArgoCD deployment check - Validates all ArgoCD components</li> <li>\u2705 ArgoCD CLI check - Validates CLI installation (optional)</li> <li>\u2705 Git repository structure - Checks platform/apps/ and platform/bootstrap/</li> <li>\u2705 App-of-apps pattern - Validates root applications exist</li> <li>\u2705 Component sync - Checks all applications synced and healthy</li> <li>\u2705 Auto-sync check - Validates auto-sync and self-heal configuration</li> <li>\u2705 Rollback capability - Can be tested via ArgoCD rollback commands</li> <li>\u2705 ArgoCD UI ingress - Validates ingress resource exists</li> </ul>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#test-execution-requirements","title":"Test Execution Requirements","text":"<p>To execute the tests, you need:</p> <ol> <li>Kubernetes cluster (local or cloud)</li> <li>ArgoCD deployed in the cluster</li> <li>kubectl configured with cluster access</li> <li>ArgoCD CLI (optional, for enhanced validation)</li> <li>jq for JSON processing</li> <li>pytest (optional, for BDD tests)</li> </ol>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#files-created","title":"Files Created","text":"<pre><code>scripts/\n  \u2514\u2500\u2500 validate-at-e1-002.sh              # Main validation script\n\ntests/\n  \u251c\u2500\u2500 acceptance/\n  \u2502   \u251c\u2500\u2500 README.md                      # Acceptance testing overview\n  \u2502   \u2514\u2500\u2500 run-test.sh                    # Unified test runner\n  \u251c\u2500\u2500 e2e/\n  \u2502   \u2514\u2500\u2500 argocd-sync-test.sh           # E2E sync tests\n  \u2514\u2500\u2500 integration/\n      \u2514\u2500\u2500 argocd/\n          \u251c\u2500\u2500 README.md                   # Integration test docs\n          \u251c\u2500\u2500 test-application.yaml       # Sample ArgoCD Application\n          \u2514\u2500\u2500 manifests/\n              \u2514\u2500\u2500 test-app.yaml          # Sample K8s manifests\n\ndocs/\n  \u2514\u2500\u2500 testing/\n      \u2514\u2500\u2500 at-e1-002-validation-guide.md # Complete validation guide\n\nMakefile                                 # Updated with new targets\n</code></pre>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#next-steps","title":"Next Steps","text":"<p>To complete AT-E1-002 validation, execute the following when a cluster is available:</p> <ol> <li> <p>Ensure ArgoCD is deployed:    <pre><code>./scripts/ignite.sh local\n</code></pre></p> </li> <li> <p>Run AT-E1-002 validation:    <pre><code>./tests/acceptance/run-test.sh AT-E1-002\n</code></pre></p> </li> <li> <p>Review test report:    <pre><code>cat reports/at-e1-002-validation-*.json | jq .\n</code></pre></p> </li> <li> <p>Verify all acceptance criteria pass:    <pre><code>cat reports/at-e1-002-validation-*.json | jq '.summary'\n</code></pre></p> </li> </ol>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#validation-commands-from-issue","title":"Validation Commands from Issue","text":"<p>The following manual validation commands from the issue are implemented:</p> <p>\u2705 Check all apps are synced <pre><code>argocd app list | grep -c Synced\n</code></pre> Implemented in: <code>check_applications_synced()</code></p> <p>\u2705 Hard refresh platform-bootstrap <pre><code>argocd app get platform-bootstrap --hard-refresh\n</code></pre> Implemented in: E2E sync test</p> <p>\u2705 Check for out-of-sync applications <pre><code>kubectl get applications -n fawkes -o json | \\\n  jq '.items[] | select(.status.sync.status != \"Synced\")' | \\\n  jq -s 'length'\n</code></pre> Implemented in: <code>check_applications_synced()</code> - reports out-of-sync apps</p>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#quality-checks-performed","title":"Quality Checks Performed","text":"<p>\u2705 Bash syntax validation (all scripts pass) \u2705 YAML validation (all manifests valid) \u2705 Makefile target validation (all targets functional) \u2705 Help text verification (all scripts show proper help) \u2705 Shellcheck linting (minor style warnings only)</p>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#dependencies","title":"Dependencies","text":"<p>As specified in Issue #8:</p> <ul> <li>\u2705 Issue #5: Deploy ArgoCD - Validation checks ArgoCD deployment</li> <li>\u2705 Issue #6: Git repo structure - Validation checks platform/apps/ and platform/bootstrap/</li> <li>\u2705 Issue #7: App-of-apps pattern - Validation checks for root applications</li> </ul>"},{"location":"testing/AT-E1-002-IMPLEMENTATION/#summary","title":"Summary","text":"<p>This implementation provides a complete, production-ready test infrastructure for validating AT-E1-002 acceptance criteria. The tests are:</p> <ul> <li>Comprehensive: Cover all acceptance criteria from the issue</li> <li>Modular: Can run individual components or full suite</li> <li>Flexible: Support custom namespaces, timeouts, and verbosity</li> <li>Documented: Extensive documentation and examples</li> <li>Maintainable: Clean code structure with proper error handling</li> <li>Reportable: Generate JSON reports for CI/CD integration</li> <li>Extensible: Easy to add more tests or modify existing ones</li> </ul> <p>The implementation is ready to be executed once a Kubernetes cluster with ArgoCD is available.</p>"},{"location":"testing/at-e1-002-validation-guide/","title":"AT-E1-002 Validation Test Guide","text":""},{"location":"testing/at-e1-002-validation-guide/#overview","title":"Overview","text":"<p>This guide explains how to run and validate AT-E1-002 acceptance tests for GitOps with ArgoCD.</p> <p>Test ID: AT-E1-002 Category: GitOps Description: ArgoCD manages all platform components Priority: P0 - Critical  </p>"},{"location":"testing/at-e1-002-validation-guide/#prerequisites","title":"Prerequisites","text":"<p>Before running AT-E1-002 tests, ensure you have:</p> <ol> <li>Kubernetes cluster - Local (kind, minikube, Docker Desktop) or cloud (AKS, EKS, GKE)</li> <li>kubectl - Configured and connected to your cluster</li> <li>ArgoCD deployed - Via Helm or manifest</li> <li>ArgoCD CLI - Optional but recommended for enhanced validation</li> <li>jq - For JSON processing in validation scripts</li> <li>pytest - For running BDD tests (optional)</li> </ol>"},{"location":"testing/at-e1-002-validation-guide/#quick-start","title":"Quick Start","text":""},{"location":"testing/at-e1-002-validation-guide/#1-run-complete-at-e1-002-validation","title":"1. Run Complete AT-E1-002 Validation","text":"<pre><code># Using the unified test runner\n./tests/acceptance/run-test.sh AT-E1-002\n\n# Or using Makefile\nmake validate-at-e1-002\n</code></pre> <p>This will run: 1. Comprehensive validation checks 2. E2E sync tests 3. BDD tests (if pytest available)</p>"},{"location":"testing/at-e1-002-validation-guide/#2-run-individual-test-components","title":"2. Run Individual Test Components","text":""},{"location":"testing/at-e1-002-validation-guide/#comprehensive-validation-only","title":"Comprehensive Validation Only","text":"<pre><code>./scripts/validate-at-e1-002.sh\n</code></pre> <p>Options: <pre><code># Custom namespace\n./scripts/validate-at-e1-002.sh --namespace argocd\n\n# Verbose output\n./scripts/validate-at-e1-002.sh --verbose\n\n# Custom report location\n./scripts/validate-at-e1-002.sh --report /path/to/report.json\n</code></pre></p>"},{"location":"testing/at-e1-002-validation-guide/#e2e-sync-tests-only","title":"E2E Sync Tests Only","text":"<pre><code>./tests/e2e/argocd-sync-test.sh\n</code></pre> <p>Options: <pre><code># Test specific application\n./tests/e2e/argocd-sync-test.sh --app platform-bootstrap\n\n# Custom timeout\n./tests/e2e/argocd-sync-test.sh --timeout 600\n\n# Verbose output\n./tests/e2e/argocd-sync-test.sh --verbose\n</code></pre></p>"},{"location":"testing/at-e1-002-validation-guide/#bdd-tests-only","title":"BDD Tests Only","text":"<pre><code># All ArgoCD bootstrap tests\npytest tests/bdd/test_argocd_bootstrap.py -v\n\n# All ArgoCD deployment tests\npytest tests/bdd/step_definitions/test_argocd_deployment.py -v\n\n# Tests tagged with @gitops\npytest tests/bdd -v -m gitops\n\n# Tests tagged with @local\npytest tests/bdd -v -m local\n</code></pre>"},{"location":"testing/at-e1-002-validation-guide/#validation-checks","title":"Validation Checks","text":"<p>The AT-E1-002 validation performs the following checks:</p>"},{"location":"testing/at-e1-002-validation-guide/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>\u2705 kubectl is installed and accessible</li> <li>\u2705 argocd CLI is installed (optional)</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#2-cluster-access","title":"2. Cluster Access","text":"<ul> <li>\u2705 Kubernetes cluster is accessible via kubectl</li> <li>\u2705 Cluster info can be retrieved</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#3-argocd-namespace","title":"3. ArgoCD Namespace","text":"<ul> <li>\u2705 ArgoCD namespace exists (default: <code>fawkes</code>)</li> <li>\u2705 Namespace is in Active phase</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#4-argocd-deployment","title":"4. ArgoCD Deployment","text":"<ul> <li>\u2705 argocd-server is deployed</li> <li>\u2705 argocd-application-controller is deployed</li> <li>\u2705 argocd-repo-server is deployed</li> <li>\u2705 argocd-redis is deployed</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#5-argocd-pods","title":"5. ArgoCD Pods","text":"<ul> <li>\u2705 All ArgoCD pods are Running</li> <li>\u2705 All ArgoCD pods are Ready</li> <li>\u2705 No pods in Failed or Pending state</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#6-argocd-crds","title":"6. ArgoCD CRDs","text":"<ul> <li>\u2705 applications.argoproj.io CRD exists</li> <li>\u2705 applicationsets.argoproj.io CRD exists</li> <li>\u2705 appprojects.argoproj.io CRD exists</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#7-git-repository-structure","title":"7. Git Repository Structure","text":"<ul> <li>\u2705 platform/apps/ directory exists</li> <li>\u2705 platform/bootstrap/ directory exists</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#8-app-of-apps-pattern","title":"8. App-of-Apps Pattern","text":"<ul> <li>\u2705 Root Application(s) exist</li> <li>platform-bootstrap</li> <li>fawkes-app</li> <li>fawkes-infra</li> <li>\u2705 At least one Application exists</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#9-application-sync-status","title":"9. Application Sync Status","text":"<ul> <li>\u2705 All applications are Synced</li> <li>\u2705 All applications are Healthy</li> <li>\u2705 No out-of-sync applications</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#10-auto-sync-configuration","title":"10. Auto-Sync Configuration","text":"<ul> <li>\u2705 Auto-sync is enabled on applications</li> <li>\u2705 Self-heal is enabled on applications</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#11-argocd-ingress","title":"11. ArgoCD Ingress","text":"<ul> <li>\u2705 Ingress resource exists for ArgoCD</li> <li>\u2705 Ingress has valid host configuration</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#test-reports","title":"Test Reports","text":""},{"location":"testing/at-e1-002-validation-guide/#json-report-format","title":"JSON Report Format","text":"<p>Test reports are generated in JSON format at: <pre><code>reports/at-e1-002-validation-YYYYMMDD-HHMMSS.json\n</code></pre></p> <p>Example report structure: <pre><code>{\n  \"test_id\": \"AT-E1-002\",\n  \"test_name\": \"GitOps with ArgoCD\",\n  \"timestamp\": \"2025-01-15T10:30:00Z\",\n  \"namespace\": \"fawkes\",\n  \"summary\": {\n    \"total\": 25,\n    \"passed\": 25,\n    \"failed\": 0,\n    \"pass_rate\": \"100.00%\"\n  },\n  \"results\": [\n    {\n      \"name\": \"Prerequisites\",\n      \"status\": \"PASS\",\n      \"message\": \"kubectl is installed\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"testing/at-e1-002-validation-guide/#viewing-reports","title":"Viewing Reports","text":"<pre><code># View latest report\ncat reports/at-e1-002-validation-*.json | jq .\n\n# Check summary only\ncat reports/at-e1-002-validation-*.json | jq '.summary'\n\n# Check failed tests only\ncat reports/at-e1-002-validation-*.json | jq '.results[] | select(.status==\"FAIL\")'\n</code></pre>"},{"location":"testing/at-e1-002-validation-guide/#manual-validation-commands","title":"Manual Validation Commands","text":"<p>From the issue requirements, you can also run these manual validation commands:</p>"},{"location":"testing/at-e1-002-validation-guide/#check-all-apps-are-synced","title":"Check All Apps Are Synced","text":"<pre><code>argocd app list | grep -c Synced\n</code></pre> <p>Expected: Count matches total number of applications</p>"},{"location":"testing/at-e1-002-validation-guide/#hard-refresh-platform-bootstrap","title":"Hard Refresh Platform Bootstrap","text":"<pre><code>argocd app get platform-bootstrap --hard-refresh\n</code></pre> <p>Expected: Application syncs successfully</p>"},{"location":"testing/at-e1-002-validation-guide/#check-for-out-of-sync-applications","title":"Check for Out-of-Sync Applications","text":"<pre><code>kubectl get applications -n fawkes -o json | \\\n  jq '.items[] | select(.status.sync.status != \"Synced\")' | \\\n  jq -s 'length'\n</code></pre> <p>Expected: <code>0</code> (no out-of-sync applications)</p>"},{"location":"testing/at-e1-002-validation-guide/#acceptance-criteria-checklist","title":"Acceptance Criteria Checklist","text":"<p>Based on issue #8, the following acceptance criteria must be met:</p> <ul> <li>[ ] AT-E1-002 test suite passes - All validation scripts pass</li> <li>[ ] ArgoCD managing components - Applications are synced and healthy</li> <li>[ ] Test report generated - JSON report exists in reports/ directory</li> <li>[ ] ArgoCD deployed via Helm - ArgoCD components are running</li> <li>[ ] ArgoCD CLI installed and configured - CLI can interact with server</li> <li>[ ] Git repository structure created - platform/apps/ and platform/bootstrap/ exist</li> <li>[ ] App-of-apps pattern implemented - Root applications manage child applications</li> <li>[ ] All platform components synced from Git - No manual kubectl apply needed</li> <li>[ ] Auto-sync enabled with self-heal - Drift is automatically corrected</li> <li>[ ] Rollback tested successfully - Can revert to previous versions</li> <li>[ ] ArgoCD UI accessible via ingress - UI is available at configured host</li> </ul>"},{"location":"testing/at-e1-002-validation-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"testing/at-e1-002-validation-guide/#no-cluster-access","title":"No Cluster Access","text":"<pre><code>Error: Cannot access Kubernetes cluster\n</code></pre> <p>Solution: Ensure kubectl is configured and pointing to the correct cluster: <pre><code>kubectl cluster-info\nkubectl config current-context\n</code></pre></p>"},{"location":"testing/at-e1-002-validation-guide/#argocd-namespace-not-found","title":"ArgoCD Namespace Not Found","text":"<pre><code>Error: Namespace 'fawkes' does not exist\n</code></pre> <p>Solution: Either: 1. Deploy ArgoCD to the fawkes namespace 2. Use <code>--namespace argocd</code> if ArgoCD is in a different namespace</p>"},{"location":"testing/at-e1-002-validation-guide/#no-applications-found","title":"No Applications Found","text":"<pre><code>Error: No applications found\n</code></pre> <p>Solution: Deploy the app-of-apps pattern: <pre><code>kubectl apply -f platform/bootstrap/app-of-apps.yaml\n</code></pre></p>"},{"location":"testing/at-e1-002-validation-guide/#applications-not-synced","title":"Applications Not Synced","text":"<pre><code>Error: X/Y applications are Synced\n</code></pre> <p>Solution: Check application status and sync: <pre><code>argocd app list\nargocd app sync &lt;app-name&gt;\nargocd app get &lt;app-name&gt;\n</code></pre></p>"},{"location":"testing/at-e1-002-validation-guide/#argocd-cli-not-found","title":"ArgoCD CLI Not Found","text":"<pre><code>Warning: argocd CLI not found\n</code></pre> <p>Note: This is optional. Install from: https://argo-cd.readthedocs.io/en/stable/cli_installation/</p>"},{"location":"testing/at-e1-002-validation-guide/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"testing/at-e1-002-validation-guide/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code>- name: Run AT-E1-002 Validation\n  run: |\n    ./tests/acceptance/run-test.sh AT-E1-002\n\n- name: Upload Test Report\n  uses: actions/upload-artifact@v3\n  if: always()\n  with:\n    name: at-e1-002-report\n    path: reports/at-e1-002-validation-*.json\n</code></pre>"},{"location":"testing/at-e1-002-validation-guide/#jenkins-pipeline-example","title":"Jenkins Pipeline Example","text":"<pre><code>stage('AT-E1-002 Validation') {\n    steps {\n        sh './tests/acceptance/run-test.sh AT-E1-002'\n    }\n    post {\n        always {\n            archiveArtifacts artifacts: 'reports/at-e1-002-validation-*.json'\n        }\n    }\n}\n</code></pre>"},{"location":"testing/at-e1-002-validation-guide/#dependencies","title":"Dependencies","text":"<p>The issue specifies the following dependencies:</p> <ul> <li>Issue #5: Deploy ArgoCD</li> <li>Issue #6: Git repo structure</li> <li>Issue #7: App-of-apps pattern</li> </ul> <p>Ensure these are completed before running AT-E1-002 tests.</p>"},{"location":"testing/at-e1-002-validation-guide/#additional-resources","title":"Additional Resources","text":"<ul> <li>Architecture Documentation</li> <li>Implementation Plan</li> <li>ArgoCD Bootstrap Feature</li> <li>ArgoCD Deployment Feature</li> <li>Week 1 Detailed Tasks</li> </ul>"},{"location":"tools/","title":"Tools Overview","text":"<p>Fawkes integrates with industry-leading open-source tools to implement DORA capabilities effectively.</p>"},{"location":"tools/#continuous-delivery-tools","title":"Continuous Delivery Tools","text":"Tool Purpose Related Patterns Spinnaker (Deprecated) Legacy deployment tool - use ArgoCD instead Continuous Delivery Jenkins Automation server Continuous Delivery"},{"location":"tools/#infrastructure-tools","title":"Infrastructure Tools","text":"Tool Purpose Related Patterns Terraform Infrastructure as Code Infrastructure as Code Kubernetes Container orchestration Infrastructure as Code"},{"location":"tools/#monitoring-tools","title":"Monitoring Tools","text":"Tool Purpose Related Patterns Prometheus Metrics collection Monitoring Grafana Visualization Monitoring"},{"location":"tools/#testing-tools","title":"Testing Tools","text":"Tool Purpose Related Patterns Selenium UI testing Test Automation JUnit Unit testing Test Automation"},{"location":"tools/#collaboration-project-management-tools","title":"Collaboration &amp; Project Management Tools","text":"Tool Purpose Related Patterns Focalboard Project management and Kanban boards N/A <p>View Implementation Guide</p>"},{"location":"tools/focalboard/","title":"Focalboard - Project Management","text":"<p>Focalboard is an open source, self-hosted alternative to Trello, Notion, and Asana. It provides a centralized Kanban board application for the Fawkes platform to manage features, incidents, and stories.</p>"},{"location":"tools/focalboard/#overview","title":"Overview","text":"<p>Focalboard is deployed as part of the Fawkes platform to provide:</p> <ul> <li>Kanban Boards: Visual task management with drag-and-drop cards</li> <li>Multiple Views: Board, table, gallery, and calendar views</li> <li>Real-time Collaboration: Changes are immediately visible to all team members</li> <li>Data Persistence: All data stored in PostgreSQL with high availability</li> </ul>"},{"location":"tools/focalboard/#access","title":"Access","text":"Environment URL Local Dev http://pm.127.0.0.1.nip.io Production <code>https://pm.fawkes.io</code>"},{"location":"tools/focalboard/#quick-start","title":"Quick Start","text":""},{"location":"tools/focalboard/#creating-your-first-board","title":"Creating Your First Board","text":"<ol> <li>Navigate to the Focalboard URL</li> <li>Log in with your platform credentials</li> <li>Click + Add Board to create a new board</li> <li>Choose a template or start from scratch</li> </ol>"},{"location":"tools/focalboard/#board-templates","title":"Board Templates","text":"<p>The platform provides a default template with the following columns:</p> Column Purpose Backlog Items waiting to be prioritized To Do Ready to be worked on In Progress Currently being worked on Review Pending review or approval Done Completed items"},{"location":"tools/focalboard/#working-with-cards","title":"Working with Cards","text":"<ol> <li>Create a Card: Click + New in any column</li> <li>Move a Card: Drag and drop between columns</li> <li>Edit a Card: Click to open and add details</li> <li>Assign Priority: Use the properties panel to set priority</li> <li>Add Comments: Collaborate with team members on cards</li> </ol>"},{"location":"tools/focalboard/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Ingress (nginx)                    \u2502\n\u2502              pm.127.0.0.1.nip.io                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               Focalboard Service                     \u2502\n\u2502                  (ClusterIP)                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Focalboard Deployment                   \u2502\n\u2502         mattermost/focalboard:7.11.4                 \u2502\n\u2502                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Config Vol  \u2502    \u2502    Files PVC (5Gi)          \u2502 \u2502\n\u2502  \u2502 (ConfigMap) \u2502    \u2502    Attachments/Uploads      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         PostgreSQL (CloudNativePG)                   \u2502\n\u2502         db-focalboard-dev cluster                    \u2502\n\u2502         3 replicas for High Availability             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"tools/focalboard/#configuration","title":"Configuration","text":""},{"location":"tools/focalboard/#environment-variables","title":"Environment Variables","text":"<p>The following environment variables are available in <code>env.example</code>:</p> Variable Description Default <code>FOCALBOARD_URL</code> Internal service URL <code>http://focalboard.fawkes.svc:8000</code> <code>FOCALBOARD_EXTERNAL_URL</code> External URL via ingress <code>http://pm.127.0.0.1.nip.io</code> <code>POSTGRESQL_HOST</code> PostgreSQL primary host <code>db-focalboard-dev-rw.fawkes.svc.cluster.local</code> <code>POSTGRESQL_DATABASE</code> Database name <code>focalboard</code> <code>POSTGRESQL_USER</code> Database user <code>focalboard_user</code>"},{"location":"tools/focalboard/#resource-limits","title":"Resource Limits","text":"Resource Request Limit CPU 100m 500m Memory 128Mi 512Mi"},{"location":"tools/focalboard/#storage","title":"Storage","text":"Volume Size Purpose PostgreSQL 10Gi Database storage (per replica) Files PVC 5Gi File attachments and uploads"},{"location":"tools/focalboard/#database","title":"Database","text":"<p>Focalboard uses a dedicated PostgreSQL cluster managed by CloudNativePG:</p> <ul> <li>Cluster Name: <code>db-focalboard-dev</code></li> <li>Instances: 3 (1 primary + 2 replicas)</li> <li>High Availability: Automatic failover within 90 seconds</li> <li>TLS: Encrypted connections required</li> </ul>"},{"location":"tools/focalboard/#connection-details","title":"Connection Details","text":"<pre><code>Host (Read-Write): db-focalboard-dev-rw.fawkes.svc.cluster.local\nHost (Read-Only): db-focalboard-dev-ro.fawkes.svc.cluster.local\nPort: 5432\nDatabase: focalboard\nUsername: focalboard_user\nSSL Mode: require\n</code></pre>"},{"location":"tools/focalboard/#credentials","title":"Credentials","text":"<p>Database credentials are stored in Kubernetes Secrets:</p> <ul> <li>Secret Name: <code>db-focalboard-credentials</code></li> <li>Keys: <code>username</code>, <code>password</code></li> </ul> <p>For production, use External Secrets Operator to pull credentials from your secret manager.</p>"},{"location":"tools/focalboard/#monitoring","title":"Monitoring","text":"<p>Focalboard exposes Prometheus metrics at port 9092:</p> <ul> <li>Endpoint: <code>http://focalboard.fawkes.svc:9092/metrics</code></li> <li>Scrape Interval: 30s</li> </ul>"},{"location":"tools/focalboard/#key-metrics","title":"Key Metrics","text":"Metric Description <code>focalboard_api_request_duration_seconds</code> API request latency <code>focalboard_active_users</code> Number of active users <code>focalboard_boards_total</code> Total number of boards <code>focalboard_cards_total</code> Total number of cards"},{"location":"tools/focalboard/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tools/focalboard/#common-issues","title":"Common Issues","text":""},{"location":"tools/focalboard/#service-not-accessible","title":"Service Not Accessible","text":"<ol> <li> <p>Check if the pod is running:    <pre><code>kubectl get pods -n fawkes -l app=focalboard\n</code></pre></p> </li> <li> <p>Check pod logs:    <pre><code>kubectl logs -n fawkes -l app=focalboard\n</code></pre></p> </li> <li> <p>Verify ingress configuration:    <pre><code>kubectl get ingress -n fawkes focalboard\n</code></pre></p> </li> </ol>"},{"location":"tools/focalboard/#database-connection-failed","title":"Database Connection Failed","text":"<ol> <li> <p>Verify PostgreSQL cluster is healthy:    <pre><code>kubectl get cluster -n fawkes db-focalboard-dev\n</code></pre></p> </li> <li> <p>Check database credentials:    <pre><code>kubectl get secret -n fawkes db-focalboard-credentials\n</code></pre></p> </li> <li> <p>Test database connectivity from the pod:    <pre><code>kubectl exec -n fawkes -it deployment/focalboard -- \\\n  psql \"postgres://focalboard_user@db-focalboard-dev-rw:5432/focalboard?sslmode=require\"\n</code></pre></p> </li> </ol>"},{"location":"tools/focalboard/#pod-restart-loop","title":"Pod Restart Loop","text":"<p>Check for resource constraints: <pre><code>kubectl describe pod -n fawkes -l app=focalboard\n</code></pre></p>"},{"location":"tools/focalboard/#related-resources","title":"Related Resources","text":"<ul> <li>Focalboard GitHub</li> <li>Focalboard Documentation</li> <li>PostgreSQL Deployment</li> <li>CloudNativePG Documentation</li> </ul>"},{"location":"tools/focalboard/#support","title":"Support","text":"<p>For issues with Focalboard on the Fawkes platform:</p> <ol> <li>Check the Troubleshooting Guide</li> <li>Search existing GitHub Issues</li> <li>Open a new issue if needed</li> <li>Contact the Platform Team via Mattermost</li> </ol>"},{"location":"tools/jenkins/","title":"Jenkins","text":"<p>Jenkins is an open-source automation server that enables continuous integration and continuous delivery (CI/CD) for software development projects.</p>"},{"location":"tools/jenkins/#overview","title":"Overview","text":"<p>Jenkins provides robust automation capabilities: - Build Automation - Compile and test code automatically - Deployment Pipeline - Create sophisticated deployment workflows - Plugin Ecosystem - Extend functionality through thousands of plugins</p>"},{"location":"tools/jenkins/#key-features","title":"Key Features","text":"Feature Description  Pipeline as Code Define pipelines using Jenkinsfile  Plugin System Extensive plugin ecosystem  Distributed Builds Scale with master/agent architecture  Security Features Built-in security and authentication"},{"location":"tools/jenkins/#integration-with-fawkes","title":"Integration with Fawkes","text":""},{"location":"tools/jenkins/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker or Kubernetes cluster</li> <li>Helm (for Kubernetes deployment)</li> <li>kubectl configured with cluster access</li> </ul>"},{"location":"tools/jenkins/#installation","title":"Installation","text":"<pre><code># Using Helm\nhelm repo add jenkins https://charts.jenkins.io\nhelm repo update\n\n# Install Jenkins\nhelm install jenkins jenkins/jenkins \\\n  --namespace jenkins \\\n  --create-namespace \\\n  --values jenkins-values.yaml\n</code></pre> <p>Example <code>jenkins-values.yaml</code>: <pre><code>controller:\n  ingress:\n    enabled: true\n    hostName: jenkins.fawkes.local\n  adminPassword: \"your-secure-password\"\n\npersistence:\n  enabled: true\n  size: 10Gi\n\nserviceAccount:\n  create: true\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/jenkins-role\n</code></pre></p>"},{"location":"tools/jenkins/#configuring-jenkins-pipelines","title":"Configuring Jenkins Pipelines","text":""},{"location":"tools/jenkins/#basic-pipeline-example","title":"Basic Pipeline Example","text":"<pre><code>// Jenkinsfile\npipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn clean package'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh 'mvn test'\n            }\n        }\n        stage('Deploy') {\n            steps {\n                sh 'kubectl apply -f k8s/'\n            }\n        }\n    }\n\n    post {\n        always {\n            junit '**/target/surefire-reports/TEST-*.xml'\n        }\n    }\n}\n</code></pre>"},{"location":"tools/jenkins/#advanced-pipeline-with-fawkes-integration","title":"Advanced Pipeline with Fawkes Integration","text":"<pre><code>// Jenkinsfile for Fawkes deployment\npipeline {\n    agent {\n        kubernetes {\n            yaml '''\n                apiVersion: v1\n                kind: Pod\n                spec:\n                  containers:\n                  - name: maven\n                    image: maven:3.8.4-openjdk-11\n                    command:\n                    - cat\n                    tty: true\n                  - name: kubectl\n                    image: bitnami/kubectl\n                    command:\n                    - cat\n                    tty: true\n            '''\n        }\n    }\n\n    stages {\n        stage('Build &amp; Test') {\n            steps {\n                container('maven') {\n                    sh 'mvn clean verify'\n                }\n            }\n        }\n\n        stage('Deploy to Kubernetes') {\n            steps {\n                container('kubectl') {\n                    sh '''\n                        kubectl apply -f k8s/\n                        kubectl rollout status deployment/fawkes-app\n                    '''\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"tools/jenkins/#best-practices","title":"Best Practices","text":"<ol> <li>Pipeline as Code</li> <li>Store Jenkinsfile in version control</li> <li>Use declarative pipeline syntax</li> <li> <p>Keep pipelines simple and modular</p> </li> <li> <p>Security</p> </li> <li>Use credentials management</li> <li>Implement role-based access control</li> <li> <p>Regular security updates</p> </li> <li> <p>Performance</p> </li> <li>Use agent nodes for distribution</li> <li>Clean workspace regularly</li> <li>Optimize build steps</li> </ol>"},{"location":"tools/jenkins/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions:</p> Issue Solution Pipeline fails to start Check Jenkins agent connectivity Build fails Verify build tool configuration Deployment fails Check Kubernetes credentials"},{"location":"tools/jenkins/#monitoring-jenkins","title":"Monitoring Jenkins","text":"<pre><code># Prometheus configuration\n- job_name: 'jenkins'\n  metrics_path: /prometheus\n  static_configs:\n    - targets: ['jenkins.fawkes.local:8080']\n</code></pre>"},{"location":"tools/jenkins/#additional-resources","title":"Additional Resources","text":"<ul> <li>Jenkins Documentation</li> <li>Jenkins GitHub</li> <li>Jenkins Plugins</li> </ul> <p>Configure Jenkins  View Examples </p>"},{"location":"tools/prometheus/","title":"Prometheus","text":"<p>Prometheus is an open-source monitoring and alerting toolkit designed for reliability and scalability in modern cloud environments.</p>"},{"location":"tools/prometheus/#overview","title":"Overview","text":"<p>Prometheus provides essential monitoring capabilities: - Time-Series Database - Store and query metrics data - PromQL - Powerful query language for metrics analysis - Alert Manager - Handle alerts and notifications - Service Discovery - Automatic target discovery</p>"},{"location":"tools/prometheus/#key-features","title":"Key Features","text":"Feature Description  Metrics Collection Pull-based metrics gathering  PromQL Flexible query language  Alerting Configurable alert rules  Service Discovery Auto-discover targets"},{"location":"tools/prometheus/#integration-with-fawkes","title":"Integration with Fawkes","text":""},{"location":"tools/prometheus/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster</li> <li>Helm v3</li> <li>kubectl configured with cluster access</li> </ul>"},{"location":"tools/prometheus/#installation","title":"Installation","text":"<pre><code># Add Prometheus Helm repository\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\n\n# Install Prometheus Stack\nhelm install prometheus prometheus-community/kube-prometheus-stack \\\n  --namespace monitoring \\\n  --create-namespace \\\n  --values prometheus-values.yaml\n</code></pre> <p>Example <code>prometheus-values.yaml</code>: <pre><code>prometheus:\n  prometheusSpec:\n    retention: 15d\n    storageSpec:\n      volumeClaimTemplate:\n        spec:\n          accessModes: [\"ReadWriteOnce\"]\n          resources:\n            requests:\n              storage: 50Gi\n\ngrafana:\n  enabled: true\n  persistence:\n    enabled: true\n    size: 10Gi\n\nalertmanager:\n  config:\n    global:\n      resolve_timeout: 5m\n    route:\n      group_by: ['job']\n      group_wait: 30s\n      group_interval: 5m\n      repeat_interval: 12h\n</code></pre></p>"},{"location":"tools/prometheus/#configuring-prometheus-rules","title":"Configuring Prometheus Rules","text":""},{"location":"tools/prometheus/#basic-recording-rules","title":"Basic Recording Rules","text":"<pre><code>groups:\n- name: fawkes-recording-rules\n  rules:\n  - record: job:http_requests_total:rate5m\n    expr: rate(http_requests_total[5m])\n  - record: job:http_errors_total:rate5m\n    expr: rate(http_errors_total[5m])\n</code></pre>"},{"location":"tools/prometheus/#alert-rules","title":"Alert Rules","text":"<pre><code>groups:\n- name: fawkes-alerts\n  rules:\n  - alert: HighErrorRate\n    expr: job:http_errors_total:rate5m / job:http_requests_total:rate5m &gt; 0.1\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: High error rate detected\n      description: Error rate is above 10% for 5 minutes\n</code></pre>"},{"location":"tools/prometheus/#monitoring-dora-metrics","title":"Monitoring DORA Metrics","text":""},{"location":"tools/prometheus/#deployment-frequency","title":"Deployment Frequency","text":"<pre><code>groups:\n- name: dora-metrics\n  rules:\n  - record: dora:deployment_frequency:count24h\n    expr: count_over_time(deployment_success_total[24h])\n  - record: dora:lead_time_seconds:avg24h\n    expr: avg_over_time(deployment_lead_time_seconds[24h])\n</code></pre>"},{"location":"tools/prometheus/#best-practices","title":"Best Practices","text":"<ol> <li>Data Retention</li> <li>Set appropriate retention periods</li> <li>Use persistent storage</li> <li> <p>Implement data compaction</p> </li> <li> <p>Query Optimization</p> </li> <li>Use recording rules for complex queries</li> <li>Limit the use of high-cardinality labels</li> <li> <p>Cache frequently used queries</p> </li> <li> <p>Alerting</p> </li> <li>Define clear alerting thresholds</li> <li>Implement proper alert routing</li> <li>Avoid alert fatigue</li> </ol>"},{"location":"tools/prometheus/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions:</p> Issue Solution High memory usage Adjust retention period and storage Slow queries Review and optimize PromQL expressions Missing metrics Check service discovery configuration"},{"location":"tools/prometheus/#grafana-dashboard-examples","title":"Grafana Dashboard Examples","text":"<pre><code>{\n  \"dashboard\": {\n    \"id\": null,\n    \"title\": \"Fawkes DORA Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Deployment Frequency\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"dora:deployment_frequency:count24h\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"tools/prometheus/#additional-resources","title":"Additional Resources","text":"<ul> <li>Prometheus Documentation</li> <li>PromQL Examples</li> <li>Grafana Integration</li> </ul> <p>Configure Prometheus  View Dashboards </p>"},{"location":"tools/spinnaker/","title":"Spinnaker (Deprecated)","text":"<p>Deprecated Tool</p> <p>Spinnaker is no longer used in Fawkes. This documentation is retained for historical reference only.</p> <p>Migration Path: Use ArgoCD for GitOps-based continuous delivery.</p> <p>See the migration guide below for transitioning from Spinnaker to ArgoCD.</p>"},{"location":"tools/spinnaker/#migration-from-spinnaker-to-argocd","title":"Migration from Spinnaker to ArgoCD","text":"<p>Fawkes has migrated from Spinnaker to ArgoCD for the following reasons:</p> <ol> <li>GitOps-First: ArgoCD provides native GitOps workflows with Git as the single source of truth</li> <li>Simplicity: Simpler architecture with lower operational overhead</li> <li>Kubernetes-Native: Built specifically for Kubernetes deployments</li> <li>Integration: Better integration with Grafana, Prometheus, and the observability stack</li> <li>Cost: Lower infrastructure and maintenance costs</li> </ol>"},{"location":"tools/spinnaker/#how-to-migrate","title":"How to Migrate","text":""},{"location":"tools/spinnaker/#from-spinnaker-pipelines-to-argocd-applications","title":"From Spinnaker Pipelines to ArgoCD Applications","text":"<p>Spinnaker Pipeline (Old):</p> <pre><code>{\n  \"name\": \"Deploy to Production\",\n  \"stages\": [\n    {\n      \"type\": \"deployManifest\",\n      \"cloudProvider\": \"kubernetes\",\n      \"manifests\": [...]\n    }\n  ]\n}\n</code></pre> <p>ArgoCD Application (New):</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-app-prod\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/your-org/my-app.git\n    targetRevision: main\n    path: k8s/overlays/production\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: production\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n</code></pre>"},{"location":"tools/spinnaker/#progressive-delivery-with-argo-rollouts","title":"Progressive Delivery with Argo Rollouts","text":"<p>For canary and blue-green deployments (previously done in Spinnaker):</p> <p>Argo Rollout:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: my-app\nspec:\n  replicas: 5\n  strategy:\n    canary:\n      steps:\n      - setWeight: 20\n      - pause: {duration: 5m}\n      - setWeight: 40\n      - pause: {duration: 5m}\n      - setWeight: 60\n      - pause: {duration: 5m}\n      - setWeight: 80\n      - pause: {duration: 5m}\n  template:\n    spec:\n      containers:\n      - name: my-app\n        image: my-app:v2.0.0\n</code></pre>"},{"location":"tools/spinnaker/#migration-steps","title":"Migration Steps","text":"<ol> <li>Install ArgoCD (if not already installed)</li> <li>Create ArgoCD Applications for existing Spinnaker pipelines</li> <li>Configure automated sync policies</li> <li>Test deployments in development environment</li> <li>Migrate production workloads incrementally</li> <li>Decommission Spinnaker after full migration</li> </ol>"},{"location":"tools/spinnaker/#resources","title":"Resources","text":"<ul> <li>Onboard Service to ArgoCD - Start here: Step-by-step migration guide</li> <li>Sync ArgoCD Application - Manual and automated sync workflows</li> <li>ArgoCD Documentation - Official ArgoCD docs</li> <li>Argo Rollouts - Progressive delivery</li> </ul>"},{"location":"tools/spinnaker/#historical-documentation-deprecated","title":"Historical Documentation (Deprecated)","text":"<p>The content below is retained for historical reference only and should not be used for new deployments.</p> <p></p> <p>Spinnaker is an open-source continuous delivery platform that helps you release software changes with high velocity and confidence.</p>"},{"location":"tools/spinnaker/#overview","title":"Overview","text":"<p>Spinnaker provides two core sets of features: - Application Management - Deploy and manage cloud resources - Application Deployment - Construct and manage continuous delivery workflows</p>"},{"location":"tools/spinnaker/#key-features","title":"Key Features","text":"Feature Description  Multi-Cloud Deploy to multiple cloud providers  Pipeline Management Create complex deployment workflows  Automated Canary Analysis Automated testing in production  Easy Rollbacks Quick recovery from failed deployments"},{"location":"tools/spinnaker/#integration-with-fawkes","title":"Integration with Fawkes","text":""},{"location":"tools/spinnaker/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster</li> <li>Helm v3</li> <li>kubectl configured with cluster access</li> </ul>"},{"location":"tools/spinnaker/#installation","title":"Installation","text":"<pre><code># Add Spinnaker Helm repository\nhelm repo add spinnaker https://helmcharts.opsmx.com/\nhelm repo update\n\n# Install Spinnaker\nhelm install spinnaker spinnaker/spinnaker \\\n  --namespace spinnaker \\\n  --create-namespace \\\n  --values values.yaml\n</code></pre> <p>Example <code>values.yaml</code>: <pre><code>spinnakerConfig:\n  profiles:\n    clouddriver:\n      kubernetes:\n        enabled: true\n        accounts:\n        - name: fawkes-cluster\n          requiredGroupMembership: []\n          providerVersion: V2\n          permissions: {}\n          dockerRegistries: []\n          configureImagePullSecrets: true\n          cacheThreads: 1\n          namespaces: []\n          omitNamespaces: []\n          kinds: []\n          omitKinds: []\n          customResources: []\n</code></pre></p>"},{"location":"tools/spinnaker/#using-spinnaker-with-fawkes","title":"Using Spinnaker with Fawkes","text":""},{"location":"tools/spinnaker/#creating-a-deployment-pipeline","title":"Creating a Deployment Pipeline","text":"<ol> <li>Navigate to Spinnaker UI</li> <li>Create a new application:</li> <li>Name: <code>fawkes-app</code></li> <li>Owner Email: <code>team@fawkes.io</code></li> <li> <p>Cloud Providers: <code>Kubernetes V2</code></p> </li> <li> <p>Create a deployment pipeline:    <pre><code>{\n  \"name\": \"Deploy to Production\",\n  \"stages\": [\n    {\n      \"type\": \"deployManifest\",\n      \"name\": \"Deploy Application\",\n      \"cloudProvider\": \"kubernetes\",\n      \"account\": \"fawkes-cluster\",\n      \"source\": \"text\",\n      \"manifests\": [\n        {\n          \"apiVersion\": \"apps/v1\",\n          \"kind\": \"Deployment\",\n          \"metadata\": {\n            \"name\": \"fawkes-app\"\n          },\n          \"spec\": {\n            \"replicas\": 3\n          }\n        }\n      ]\n    }\n  ]\n}\n</code></pre></p> </li> </ol>"},{"location":"tools/spinnaker/#best-practices","title":"Best Practices","text":"<ol> <li>Pipeline Templates</li> <li>Use pipeline templates for consistency</li> <li>Version control your templates</li> <li> <p>Share common deployment patterns</p> </li> <li> <p>Security</p> </li> <li>Enable RBAC</li> <li>Use service accounts</li> <li> <p>Implement least privilege access</p> </li> <li> <p>Monitoring</p> </li> <li>Configure pipeline notifications</li> <li>Monitor pipeline executions</li> <li>Set up alerting for failures</li> </ol>"},{"location":"tools/spinnaker/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions:</p> Issue Solution Pipeline fails to start Check Spinnaker service account permissions Manifest deployment fails Verify Kubernetes cluster connectivity Images not found Confirm container registry configuration"},{"location":"tools/spinnaker/#additional-resources","title":"Additional Resources","text":"<ul> <li>Spinnaker Documentation</li> <li>GitHub Repository</li> <li>Community Slack</li> </ul> <p>Configure Spinnaker  View Examples </p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Tutorials are learning-oriented experiences. They guide you through a series of steps to complete a project or learn a new concept. Unlike how-to guides, tutorials focus on learning, not accomplishing a specific task.</p>"},{"location":"tutorials/#what-youll-find-here","title":"What You'll Find Here","text":"<p>Tutorials in Fawkes are designed to:</p> <ul> <li>Take you by the hand through a complete learning experience</li> <li>Help you build understanding through practical exercises</li> <li>Introduce concepts in a logical, incremental order</li> <li>Provide a safe environment to learn and experiment</li> </ul>"},{"location":"tutorials/#getting-started-tutorials","title":"Getting Started Tutorials","text":"<p>These tutorials help you get hands-on experience with the Fawkes platform. Complete them in order for the best learning experience.</p> Tutorial Duration What You'll Learn Status 1. Deploy Your First Service 30 min Deploy an application to Fawkes platform, achieve Time to First Success (TTFS) \u2705 Available 2. Add Distributed Tracing 25 min Instrument with OpenTelemetry and view traces in Grafana Tempo \u2705 Available 3. Consume Vault Secrets 30 min Implement compliant secret management with HashiCorp Vault \u2705 Available 4. Migrate to Buildpacks 25 min Replace Dockerfiles with Cloud Native Buildpacks for automated security \u2705 Available 5. Create a Golden Path Template 35 min Build a Backstage template to enable platform self-service \u2705 Available 6. Measure DORA Metrics 30 min Analyze your service performance with DORA metrics in DevLake \u2705 Available <p>Start Here for Time to First Success!</p> <p>Begin with Tutorial 1: Deploy Your First Service to get your first application running on Fawkes in under 30 minutes.</p>"},{"location":"tutorials/#tutorial-learning-path","title":"Tutorial Learning Path","text":"<pre><code>graph LR\n    A[1. Deploy First Service] --&gt; B[2. Add Tracing]\n    B --&gt; C[3. Vault Secrets]\n    C --&gt; D[4. Buildpacks]\n    D --&gt; E[5. Golden Path]\n    E --&gt; F[6. DORA Metrics]\n\n    style A fill:#4CAF50\n    style B fill:#4CAF50\n    style C fill:#4CAF50\n    style D fill:#4CAF50\n    style E fill:#4CAF50\n    style F fill:#4CAF50</code></pre>"},{"location":"tutorials/#tutorial-design-principles","title":"Tutorial Design Principles","text":"<p>These tutorials follow the Di\u00e1taxis framework for documentation:</p> <ul> <li>Learning-oriented: Designed to help you learn by doing</li> <li>Concrete and specific: Clear, numbered steps with expected outcomes</li> <li>Safe to explore: Use isolated environments and reversible actions</li> <li>Incremental: Each tutorial builds on the previous one</li> </ul> <p>Complement with the Dojo</p> <p>After completing these tutorials, continue your learning journey with the Dojo belt progression system for deeper platform engineering expertise.</p>"},{"location":"tutorials/#dojo-learning-path","title":"Dojo Learning Path","text":"<p>The Fawkes Dojo provides structured, belt-based learning:</p> Belt Level Focus Area Duration Start Here \ud83e\udd4b White Belt Platform Fundamentals 8 hours Module 1: What is IDP \ud83d\udfe1 Yellow Belt CI/CD Mastery 8 hours Module 5: CI Fundamentals \ud83d\udfe2 Green Belt GitOps &amp; Deployment 8 hours Module 9: GitOps with ArgoCD \ud83d\udfe4 Brown Belt Observability &amp; SRE 8 hours Module 13: Observability \u26ab Black Belt Platform Architecture 8 hours Module 17: Platform as Product"},{"location":"tutorials/#how-tutorials-differ-from-how-to-guides","title":"How Tutorials Differ from How-To Guides","text":"Tutorials How-To Guides Learning-oriented Task-oriented Designed for beginners Designed for practitioners Focus on understanding Focus on accomplishing Complete learning experience Solve specific problems <p>Start White Belt  View How-To Guides </p>"},{"location":"tutorials/1-deploy-first-service/","title":"Deploy Your First Service","text":"<p>Time to Complete: 30 minutes Goal: Deploy a simple web service to the Fawkes platform and see it running, secured, and visible in Backstage.</p>"},{"location":"tutorials/1-deploy-first-service/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this tutorial, you will have:</p> <ol> <li>\u2705 Deployed a simple \"Hello Fawkes\" web service</li> <li>\u2705 Accessed your service through a secure ingress endpoint</li> <li>\u2705 Verified your service appears in the Backstage service catalog</li> <li>\u2705 Understood the basic Fawkes deployment workflow</li> </ol>"},{"location":"tutorials/1-deploy-first-service/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Access to the Fawkes platform (ask your platform team for credentials)</li> <li>[ ] <code>kubectl</code> installed and configured to access the Fawkes cluster</li> <li>[ ] <code>git</code> installed on your workstation</li> <li>[ ] A GitHub account (for source code repository)</li> <li>[ ] Basic understanding of Kubernetes concepts (pods, deployments, services)</li> </ul> <p>New to Kubernetes?</p> <p>If you're unfamiliar with Kubernetes, don't worry! Follow along step-by-step. This tutorial is designed to work even if you don't understand every detail yet.</p>"},{"location":"tutorials/1-deploy-first-service/#step-1-verify-platform-access","title":"Step 1: Verify Platform Access","text":"<p>First, let's confirm you can connect to the Fawkes cluster.</p> <ol> <li>Check your kubectl context:    <pre><code>kubectl config current-context\n</code></pre></li> </ol> <p>You should see a context name containing \"fawkes\" or your cluster name.</p> <ol> <li>Verify you can list namespaces:    <pre><code>kubectl get namespaces\n</code></pre></li> </ol> <p>You should see core Fawkes namespaces like <code>fawkes-platform</code>, <code>argocd</code>, <code>vault</code>, etc.</p> <ol> <li>Check your assigned namespace:    <pre><code>kubectl get namespace my-first-app\n</code></pre></li> </ol> <p>If this returns an error, create the namespace:    <pre><code>kubectl create namespace my-first-app\n</code></pre></p> <p>Checkpoint</p> <p>You should now have access to the Fawkes cluster and a namespace for your application.</p>"},{"location":"tutorials/1-deploy-first-service/#step-2-create-your-application-repository","title":"Step 2: Create Your Application Repository","text":"<p>We'll start with a simple Node.js application to demonstrate the deployment workflow.</p> <ol> <li> <p>Create a new directory for your application:    <pre><code>mkdir hello-fawkes\ncd hello-fawkes\n</code></pre></p> </li> <li> <p>Initialize a git repository:    <pre><code>git init\n</code></pre></p> </li> <li> <p>Create a simple Node.js application.</p> </li> </ol> <p>Create <code>package.json</code>:    <pre><code>{\n  \"name\": \"hello-fawkes\",\n  \"version\": \"1.0.0\",\n  \"description\": \"My first Fawkes service\",\n  \"main\": \"server.js\",\n  \"scripts\": {\n    \"start\": \"node server.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\"\n  }\n}\n</code></pre></p> <ol> <li> <p>Create <code>server.js</code>:    <pre><code>const express = require('express');\nconst app = express();\nconst PORT = process.env.PORT || 8080;\n\napp.get('/', (req, res) =&gt; {\n  res.json({\n    message: 'Hello from Fawkes!',\n    timestamp: new Date().toISOString(),\n    version: '1.0.0'\n  });\n});\n\napp.get('/health', (req, res) =&gt; {\n  res.json({ status: 'healthy' });\n});\n\napp.listen(PORT, '0.0.0.0', () =&gt; {\n  console.log(`Server running on port ${PORT}`);\n});\n</code></pre></p> </li> <li> <p>Commit your code:    <pre><code>git add .\ngit commit -m \"Initial hello-fawkes service\"\n</code></pre></p> </li> <li> <p>Push to GitHub (create a repository first at github.com):    <pre><code>git remote add origin https://github.com/YOUR-USERNAME/hello-fawkes.git\ngit branch -M main\ngit push -u origin main\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>You now have a simple web service ready to deploy, stored in a Git repository.</p>"},{"location":"tutorials/1-deploy-first-service/#step-3-create-kubernetes-manifests","title":"Step 3: Create Kubernetes Manifests","text":"<p>Fawkes uses GitOps, which means your deployment configuration lives in Git alongside your code.</p> <ol> <li> <p>Create a <code>k8s/</code> directory in your project:    <pre><code>mkdir -p k8s\n</code></pre></p> </li> <li> <p>Create <code>k8s/deployment.yaml</code>:    <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-fawkes\n  namespace: my-first-app\n  labels:\n    app: hello-fawkes\n    version: v1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-fawkes\n  template:\n    metadata:\n      labels:\n        app: hello-fawkes\n        version: v1\n    spec:\n      containers:\n      - name: hello-fawkes\n        image: YOUR-USERNAME/hello-fawkes:v1.0.0\n        ports:\n        - containerPort: 8080\n          name: http\n        env:\n        - name: PORT\n          value: \"8080\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"200m\"\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 1000\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n</code></pre></p> </li> <li> <p>Create <code>k8s/service.yaml</code>:    <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: hello-fawkes\n  namespace: my-first-app\n  labels:\n    app: hello-fawkes\nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\n    name: http\n  selector:\n    app: hello-fawkes\n</code></pre></p> </li> <li> <p>Create <code>k8s/ingress.yaml</code>:    <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: hello-fawkes\n  namespace: my-first-app\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - hello-fawkes.127.0.0.1.nip.io\n    secretName: hello-fawkes-tls\n  rules:\n  - host: hello-fawkes.127.0.0.1.nip.io\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: hello-fawkes\n            port:\n              number: 80\n</code></pre></p> </li> </ol> <p>Why runAsNonRoot?</p> <p>Notice the <code>securityContext</code> settings? Fawkes enforces security best practices. Running as non-root prevents privilege escalation attacks. Learn more about Zero Trust Security.</p> <ol> <li>Commit the manifests:    <pre><code>git add k8s/\ngit commit -m \"Add Kubernetes manifests\"\ngit push\n</code></pre></li> </ol> <p>Checkpoint</p> <p>Your application now has Kubernetes deployment manifests that follow Fawkes security policies.</p>"},{"location":"tutorials/1-deploy-first-service/#step-4-build-and-push-container-image","title":"Step 4: Build and Push Container Image","text":"<p>Since we're not using Cloud Native Buildpacks in this first tutorial (that's Tutorial 4!), we'll use a simple Dockerfile.</p> <ol> <li> <p>Create a <code>Dockerfile</code>:    <pre><code>FROM node:18-alpine\n\n# Create app directory\nWORKDIR /app\n\n# Install dependencies\nCOPY package*.json ./\nRUN npm ci --only=production\n\n# Copy app source\nCOPY server.js ./\n\n# Create non-root user\nRUN addgroup -g 1000 appuser &amp;&amp; \\\n    adduser -D -u 1000 -G appuser appuser &amp;&amp; \\\n    chown -R appuser:appuser /app\n\nUSER appuser\n\nEXPOSE 8080\n\nCMD [\"npm\", \"start\"]\n</code></pre></p> </li> <li> <p>Build the container image:    <pre><code>docker build -t YOUR-USERNAME/hello-fawkes:v1.0.0 .\n</code></pre></p> </li> <li> <p>Push to a container registry (Docker Hub, GitHub Container Registry, etc.):    <pre><code>docker login\ndocker push YOUR-USERNAME/hello-fawkes:v1.0.0\n</code></pre></p> </li> <li> <p>Update the image reference in <code>k8s/deployment.yaml</code> if needed.</p> </li> </ol> <p>Checkpoint</p> <p>Your container image is now available in a registry and ready to be deployed.</p>"},{"location":"tutorials/1-deploy-first-service/#step-5-deploy-with-argocd-gitops-way","title":"Step 5: Deploy with ArgoCD (GitOps Way)","text":"<p>Fawkes uses ArgoCD for GitOps-based deployments. This is the preferred method.</p> <ol> <li> <p>Create an ArgoCD Application manifest <code>argocd-app.yaml</code>:    <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: hello-fawkes\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/YOUR-USERNAME/hello-fawkes.git\n    targetRevision: main\n    path: k8s\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-first-app\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n    syncOptions:\n    - CreateNamespace=true\n</code></pre></p> </li> <li> <p>Apply the ArgoCD Application:    <pre><code>kubectl apply -f argocd-app.yaml\n</code></pre></p> </li> <li> <p>Watch ArgoCD sync your application:    <pre><code>kubectl get applications -n argocd hello-fawkes -w\n</code></pre></p> </li> </ol> <p>Wait until <code>STATUS</code> shows <code>Synced</code> and <code>HEALTH</code> shows <code>Healthy</code>.</p> <p>Alternative: Direct kubectl Apply</p> <p>If ArgoCD isn't available, you can deploy directly: <pre><code>kubectl apply -f k8s/\n</code></pre></p> <p>Checkpoint</p> <p>ArgoCD is now managing your application deployment. Any changes you push to Git will automatically sync!</p>"},{"location":"tutorials/1-deploy-first-service/#step-6-verify-your-deployment","title":"Step 6: Verify Your Deployment","text":"<p>Let's confirm everything is working.</p> <ol> <li>Check pod status:    <pre><code>kubectl get pods -n my-first-app\n</code></pre></li> </ol> <p>You should see 2 pods running (we specified <code>replicas: 2</code>):    <pre><code>NAME                            READY   STATUS    RESTARTS   AGE\nhello-fawkes-xxxxxxxxx-xxxxx    1/1     Running   0          2m\nhello-fawkes-xxxxxxxxx-xxxxx    1/1     Running   0          2m\n</code></pre></p> <ol> <li> <p>Check the service:    <pre><code>kubectl get service -n my-first-app\n</code></pre></p> </li> <li> <p>Check the ingress:    <pre><code>kubectl get ingress -n my-first-app\n</code></pre></p> </li> </ol> <p>Note the <code>ADDRESS</code> field - this is your ingress IP.</p> <ol> <li>Test the endpoint locally first:    <pre><code>kubectl port-forward -n my-first-app svc/hello-fawkes 8080:80\n</code></pre></li> </ol> <p>In another terminal:    <pre><code>curl http://localhost:8080\n</code></pre></p> <p>You should see:    <pre><code>{\n  \"message\": \"Hello from Fawkes!\",\n  \"timestamp\": \"2025-12-06T12:00:00.000Z\",\n  \"version\": \"1.0.0\"\n}\n</code></pre></p> <ol> <li>Test via ingress (in your browser or with curl):    <pre><code>curl https://hello-fawkes.127.0.0.1.nip.io\n</code></pre></li> </ol> <p>Checkpoint</p> <p>Your service is running, accessible via HTTPS, and responding to requests! \ud83c\udf89</p>"},{"location":"tutorials/1-deploy-first-service/#step-7-register-in-backstage-catalog","title":"Step 7: Register in Backstage Catalog","text":"<p>To make your service visible in the Fawkes developer portal, register it in Backstage.</p> <ol> <li> <p>Create a <code>catalog-info.yaml</code> file in your repository root:    <pre><code>apiVersion: backstage.io/v1alpha1\nkind: Component\nmetadata:\n  name: hello-fawkes\n  description: My first service on Fawkes\n  annotations:\n    github.com/project-slug: YOUR-USERNAME/hello-fawkes\n    argocd/app-name: hello-fawkes\nspec:\n  type: service\n  lifecycle: experimental\n  owner: team-platform\n  system: tutorials\n</code></pre></p> </li> <li> <p>Commit and push:    <pre><code>git add catalog-info.yaml\ngit commit -m \"Add Backstage catalog info\"\ngit push\n</code></pre></p> </li> <li> <p>Register the component in Backstage:</p> </li> <li>Navigate to the Backstage UI (typically <code>https://backstage.fawkes.yourdomain.com</code>)</li> <li>Click Create \u2192 Register Existing Component</li> <li>Enter your repository URL: <code>https://github.com/YOUR-USERNAME/hello-fawkes</code></li> <li> <p>Click Analyze \u2192 Import</p> </li> <li> <p>View your service in the catalog:</p> </li> <li>Go to Catalog \u2192 All</li> <li>Search for \"hello-fawkes\"</li> <li>Click on your component to see details</li> </ol> <p>Checkpoint</p> <p>Your service is now registered in the Backstage service catalog, making it discoverable to your entire team!</p>"},{"location":"tutorials/1-deploy-first-service/#step-8-celebrate-your-first-success","title":"Step 8: Celebrate Your First Success! \ud83c\udf89","text":"<p>Congratulations! You've successfully:</p> <ul> <li>\u2705 Created a cloud-native web service</li> <li>\u2705 Deployed it using GitOps principles</li> <li>\u2705 Made it accessible via secure HTTPS ingress</li> <li>\u2705 Registered it in the developer portal</li> <li>\u2705 Followed Fawkes security best practices</li> </ul>"},{"location":"tutorials/1-deploy-first-service/#whats-next","title":"What's Next?","text":"<p>Now that you have a running service, you can:</p> <ol> <li>Add Distributed Tracing - Learn how to instrument your service with OpenTelemetry and view traces in Grafana Tempo</li> <li>Consume Vault Secrets - Secure your application by using HashiCorp Vault for secrets management</li> <li>Explore DORA Metrics - See how your deployment is contributing to your team's DORA metrics</li> </ol>"},{"location":"tutorials/1-deploy-first-service/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/1-deploy-first-service/#pods-not-starting","title":"Pods Not Starting","text":"<pre><code># Check pod status\nkubectl describe pod -n my-first-app -l app=hello-fawkes\n\n# Check logs\nkubectl logs -n my-first-app -l app=hello-fawkes\n</code></pre> <p>Common issues: - ImagePullBackOff: Check your image name and registry credentials - CrashLoopBackOff: Check application logs for startup errors - Pending: Check resource quotas and node capacity</p>"},{"location":"tutorials/1-deploy-first-service/#ingress-not-accessible","title":"Ingress Not Accessible","text":"<pre><code># Verify ingress controller is running\nkubectl get pods -n ingress-nginx\n\n# Check ingress events\nkubectl describe ingress -n my-first-app hello-fawkes\n</code></pre>"},{"location":"tutorials/1-deploy-first-service/#argocd-not-syncing","title":"ArgoCD Not Syncing","text":"<pre><code># Check ArgoCD application status\nkubectl get application -n argocd hello-fawkes -o yaml\n\n# View sync errors\nkubectl describe application -n argocd hello-fawkes\n</code></pre>"},{"location":"tutorials/1-deploy-first-service/#learn-more","title":"Learn More","text":"<ul> <li>GitOps Strategy Explanation - Understand why Fawkes uses GitOps</li> <li>Zero Trust Security Model - Learn about the security context settings we used</li> <li>How to Configure Ingress with TLS - Advanced ingress configuration</li> </ul>"},{"location":"tutorials/1-deploy-first-service/#feedback","title":"Feedback","text":"<p>This tutorial is designed to get you to success in under 30 minutes. Did you make it? Was anything confusing? Let us know in the Fawkes Community Mattermost or open an issue.</p>"},{"location":"tutorials/2-add-tracing-tempo/","title":"Add Distributed Tracing with Tempo","text":"<p>Time to Complete: 25 minutes Goal: Add OpenTelemetry instrumentation to your service and view distributed traces in Grafana Tempo.</p>"},{"location":"tutorials/2-add-tracing-tempo/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this tutorial, you will have:</p> <ol> <li>\u2705 Instrumented your application with OpenTelemetry</li> <li>\u2705 Configured trace export to Grafana Tempo</li> <li>\u2705 Generated traces by making requests to your service</li> <li>\u2705 Viewed and analyzed traces in the Grafana UI</li> </ol>"},{"location":"tutorials/2-add-tracing-tempo/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Completed Tutorial 1: Deploy Your First Service</li> <li>[ ] Your <code>hello-fawkes</code> service running and accessible</li> <li>[ ] Access to Grafana (typically at <code>https://grafana.127.0.0.1.nip.io</code>)</li> <li>[ ] Basic understanding of distributed tracing concepts (helpful but not required)</li> </ul> <p>What is Distributed Tracing?</p> <p>Distributed tracing tracks requests as they flow through multiple services. Each request gets a unique trace ID, and each service operation creates a \"span\". This helps you debug performance issues and understand system behavior. Learn more about Unified Telemetry.</p>"},{"location":"tutorials/2-add-tracing-tempo/#step-1-install-opentelemetry-dependencies","title":"Step 1: Install OpenTelemetry Dependencies","text":"<p>We'll add OpenTelemetry instrumentation to the Node.js application we created in Tutorial 1.</p> <ol> <li> <p>Navigate to your <code>hello-fawkes</code> directory:    <pre><code>cd hello-fawkes\n</code></pre></p> </li> <li> <p>Install OpenTelemetry packages:    <pre><code>npm install --save \\\n  @opentelemetry/api \\\n  @opentelemetry/sdk-node \\\n  @opentelemetry/auto-instrumentations-node \\\n  @opentelemetry/exporter-trace-otlp-http\n</code></pre></p> </li> <li> <p>Update <code>package.json</code> to save the dependencies:    <pre><code>git add package.json package-lock.json\ngit commit -m \"Add OpenTelemetry dependencies\"\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>OpenTelemetry dependencies are installed and ready to use.</p>"},{"location":"tutorials/2-add-tracing-tempo/#step-2-create-opentelemetry-configuration","title":"Step 2: Create OpenTelemetry Configuration","text":"<ol> <li> <p>Create a new file <code>tracing.js</code> in your project root:    <pre><code>const { NodeSDK } = require('@opentelemetry/sdk-node');\nconst { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');\nconst { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-http');\nconst { Resource } = require('@opentelemetry/resources');\nconst { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');\n\n// Configure the trace exporter\nconst traceExporter = new OTLPTraceExporter({\n  url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT || 'http://tempo.fawkes-platform.svc.cluster.local:4318/v1/traces',\n});\n\n// Create resource with service information\nconst resource = new Resource({\n  [SemanticResourceAttributes.SERVICE_NAME]: process.env.OTEL_SERVICE_NAME || 'hello-fawkes',\n  [SemanticResourceAttributes.SERVICE_VERSION]: process.env.SERVICE_VERSION || '1.0.0',\n  [SemanticResourceAttributes.DEPLOYMENT_ENVIRONMENT]: process.env.ENVIRONMENT || 'development',\n});\n\n// Initialize the SDK\nconst sdk = new NodeSDK({\n  resource: resource,\n  traceExporter: traceExporter,\n  instrumentations: [\n    getNodeAutoInstrumentations({\n      // Customize instrumentation\n      '@opentelemetry/instrumentation-fs': {\n        enabled: false, // Disable file system instrumentation for cleaner traces\n      },\n    }),\n  ],\n});\n\n// Start the SDK\nsdk.start();\n\n// Graceful shutdown\nprocess.on('SIGTERM', () =&gt; {\n  sdk.shutdown()\n    .then(() =&gt; console.log('Tracing terminated'))\n    .catch((error) =&gt; console.log('Error terminating tracing', error))\n    .finally(() =&gt; process.exit(0));\n});\n\nconsole.log('OpenTelemetry tracing initialized');\n</code></pre></p> </li> <li> <p>Update <code>server.js</code> to load tracing first:    <pre><code>// Load tracing before anything else\nrequire('./tracing');\n\nconst express = require('express');\nconst app = express();\nconst PORT = process.env.PORT || 8080;\n\napp.get('/', (req, res) =&gt; {\n  res.json({\n    message: 'Hello from Fawkes!',\n    timestamp: new Date().toISOString(),\n    version: '1.0.0',\n    tracing: 'enabled'\n  });\n});\n\napp.get('/health', (req, res) =&gt; {\n  res.json({ status: 'healthy' });\n});\n\n// Add a new endpoint to simulate a traced operation\napp.get('/api/data', async (req, res) =&gt; {\n  // Simulate some work\n  await new Promise(resolve =&gt; setTimeout(resolve, 100));\n\n  res.json({\n    data: [\n      { id: 1, name: 'Item 1' },\n      { id: 2, name: 'Item 2' },\n      { id: 3, name: 'Item 3' }\n    ],\n    traceId: req.headers['x-trace-id'] || 'auto-generated'\n  });\n});\n\napp.listen(PORT, '0.0.0.0', () =&gt; {\n  console.log(`Server running on port ${PORT}`);\n});\n</code></pre></p> </li> <li> <p>Commit the changes:    <pre><code>git add tracing.js server.js\ngit commit -m \"Add OpenTelemetry instrumentation\"\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>Your application is now instrumented with OpenTelemetry!</p>"},{"location":"tutorials/2-add-tracing-tempo/#step-3-update-kubernetes-deployment","title":"Step 3: Update Kubernetes Deployment","text":"<p>We need to configure environment variables for the OpenTelemetry exporter.</p> <ol> <li> <p>Update <code>k8s/deployment.yaml</code> to add environment variables:    <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-fawkes\n  namespace: my-first-app\n  labels:\n    app: hello-fawkes\n    version: v2\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-fawkes\n  template:\n    metadata:\n      labels:\n        app: hello-fawkes\n        version: v2\n    spec:\n      containers:\n      - name: hello-fawkes\n        image: YOUR-USERNAME/hello-fawkes:v2.0.0  # Update version\n        ports:\n        - containerPort: 8080\n          name: http\n        env:\n        - name: PORT\n          value: \"8080\"\n        - name: OTEL_SERVICE_NAME\n          value: \"hello-fawkes\"\n        - name: SERVICE_VERSION\n          value: \"2.0.0\"\n        - name: ENVIRONMENT\n          value: \"development\"\n        - name: OTEL_EXPORTER_OTLP_ENDPOINT\n          value: \"http://tempo.fawkes-platform.svc.cluster.local:4318/v1/traces\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        resources:\n          requests:\n            memory: \"128Mi\"  # Increased for tracing overhead\n            cpu: \"100m\"\n          limits:\n            memory: \"256Mi\"  # Increased for tracing overhead\n            cpu: \"200m\"\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 1000\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n</code></pre></p> </li> <li> <p>Commit the updated manifest:    <pre><code>git add k8s/deployment.yaml\ngit commit -m \"Configure OpenTelemetry environment variables\"\n</code></pre></p> </li> </ol> <p>Why These Environment Variables?</p> <ul> <li><code>OTEL_SERVICE_NAME</code>: Identifies your service in traces</li> <li><code>OTEL_EXPORTER_OTLP_ENDPOINT</code>: Where to send traces (Tempo endpoint)</li> <li><code>ENVIRONMENT</code>: Helps filter traces by environment (dev/staging/prod)</li> </ul> <p>Checkpoint</p> <p>Deployment is configured to export traces to Tempo.</p>"},{"location":"tutorials/2-add-tracing-tempo/#step-4-build-and-deploy-updated-application","title":"Step 4: Build and Deploy Updated Application","text":"<ol> <li> <p>Build the new version of your container:    <pre><code>docker build -t YOUR-USERNAME/hello-fawkes:v2.0.0 .\n</code></pre></p> </li> <li> <p>Push the image:    <pre><code>docker push YOUR-USERNAME/hello-fawkes:v2.0.0\n</code></pre></p> </li> <li> <p>Push your code changes to Git:    <pre><code>git push\n</code></pre></p> </li> <li> <p>If using ArgoCD, it will automatically sync. If not, apply manually:    <pre><code>kubectl apply -f k8s/deployment.yaml\n</code></pre></p> </li> <li> <p>Watch the rollout:    <pre><code>kubectl rollout status deployment/hello-fawkes -n my-first-app\n</code></pre></p> </li> <li> <p>Verify the new pods are running:    <pre><code>kubectl get pods -n my-first-app\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>Your updated application with tracing is deployed and running!</p>"},{"location":"tutorials/2-add-tracing-tempo/#step-5-generate-traces","title":"Step 5: Generate Traces","text":"<p>Now let's create some traces by making requests to our service.</p> <ol> <li> <p>Make some requests to generate traces:    <pre><code># Make multiple requests\nfor i in {1..10}; do\n  curl https://hello-fawkes.127.0.0.1.nip.io/\n  sleep 1\ndone\n</code></pre></p> </li> <li> <p>Make requests to the new <code>/api/data</code> endpoint:    <pre><code># Generate traces with the data endpoint\nfor i in {1..10}; do\n  curl https://hello-fawkes.127.0.0.1.nip.io/api/data\n  sleep 1\ndone\n</code></pre></p> </li> <li> <p>Mix in some health check requests:    <pre><code>curl https://hello-fawkes.127.0.0.1.nip.io/health\n</code></pre></p> </li> </ol> <p>Generate Realistic Traffic</p> <p>The more varied your requests, the more interesting your traces will be. Try different endpoints and patterns.</p> <p>Checkpoint</p> <p>You've generated trace data that should now be visible in Grafana Tempo!</p>"},{"location":"tutorials/2-add-tracing-tempo/#step-6-view-traces-in-grafana","title":"Step 6: View Traces in Grafana","text":"<p>Now for the exciting part - seeing your traces visualized!</p> <ol> <li> <p>Open Grafana in your browser:    <pre><code>https://grafana.127.0.0.1.nip.io\n</code></pre></p> </li> <li> <p>Log in with your Grafana credentials (ask your platform team if you don't have them).</p> </li> <li> <p>Navigate to Explore (compass icon in left sidebar).</p> </li> <li> <p>Select Tempo as the data source from the dropdown at the top.</p> </li> <li> <p>In the query builder:</p> </li> <li>Select Search tab</li> <li>Service Name: <code>hello-fawkes</code></li> <li> <p>Click Run query</p> </li> <li> <p>You should see a list of traces! Click on one to expand it.</p> </li> <li> <p>In the trace view, you'll see:</p> </li> <li>Timeline: Visual representation of span durations</li> <li>Span details: Operation names, durations, tags</li> <li>Service map: Shows service dependencies (even for a single service)</li> </ol> <p>Understanding the Trace View</p> <p>Each horizontal bar is a \"span\" representing an operation. Nested spans show parent-child relationships. Longer bars indicate slower operations.</p> <p>Checkpoint</p> <p>You're viewing distributed traces in Grafana Tempo! \ud83c\udf89</p>"},{"location":"tutorials/2-add-tracing-tempo/#step-7-analyze-a-trace","title":"Step 7: Analyze a Trace","text":"<p>Let's understand what you're seeing in the trace view.</p> <ol> <li> <p>Pick a trace for the <code>/api/data</code> endpoint.</p> </li> <li> <p>Expand the spans to see the hierarchy:    <pre><code>GET /api/data (root span)\n\u251c\u2500 Express middleware\n\u251c\u2500 Route handler\n\u2514\u2500 HTTP response\n</code></pre></p> </li> <li> <p>Look at the span details:</p> </li> <li>Duration: How long this operation took</li> <li>Tags: Metadata like HTTP method, status code, URL</li> <li> <p>Logs: Any events recorded during this span</p> </li> <li> <p>Compare traces:</p> </li> <li>Click on multiple traces to see timing variations</li> <li>Look for patterns in slow requests</li> </ol> <p>What Makes a Good Trace?</p> <p>A well-instrumented trace shows you exactly where time is spent. You should be able to answer: \"Which operation is slow?\" without looking at code.</p>"},{"location":"tutorials/2-add-tracing-tempo/#step-8-create-a-grafana-dashboard-optional","title":"Step 8: Create a Grafana Dashboard (Optional)","text":"<p>For ongoing monitoring, create a dashboard to visualize trace metrics.</p> <ol> <li> <p>In Grafana, go to Dashboards \u2192 New \u2192 New Dashboard.</p> </li> <li> <p>Click Add visualization.</p> </li> <li> <p>Select Tempo as the data source.</p> </li> <li> <p>Create a panel showing request rate:</p> </li> <li>Query: Use TraceQL: <code>{ service.name=\"hello-fawkes\" }</code></li> <li> <p>Visualization: Time series</p> </li> <li> <p>Add another panel for duration percentiles:</p> </li> <li> <p>This shows p50, p95, p99 latencies over time</p> </li> <li> <p>Save the dashboard as \"Hello Fawkes - Tracing\".</p> </li> </ol> <p>Checkpoint</p> <p>You now have a dashboard to monitor your service's trace data continuously!</p>"},{"location":"tutorials/2-add-tracing-tempo/#what-youve-accomplished","title":"What You've Accomplished","text":"<p>Congratulations! You've successfully:</p> <ul> <li>\u2705 Instrumented a Node.js application with OpenTelemetry</li> <li>\u2705 Configured trace export to Grafana Tempo</li> <li>\u2705 Deployed the instrumented application to Fawkes</li> <li>\u2705 Generated and viewed distributed traces</li> <li>\u2705 Analyzed trace data to understand application behavior</li> </ul>"},{"location":"tutorials/2-add-tracing-tempo/#whats-next","title":"What's Next?","text":"<p>Continue your Fawkes journey:</p> <ol> <li>Consume Vault Secrets - Secure your application configuration</li> <li>Measure DORA Metrics - See how tracing contributes to observability metrics</li> <li>How to Trace Requests with Tempo - Advanced tracing techniques</li> </ol>"},{"location":"tutorials/2-add-tracing-tempo/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/2-add-tracing-tempo/#no-traces-appearing-in-grafana","title":"No Traces Appearing in Grafana","text":"<ol> <li> <p>Check that Tempo is running:    <pre><code>kubectl get pods -n fawkes-platform -l app=tempo\n</code></pre></p> </li> <li> <p>Verify your application can reach Tempo:    <pre><code>kubectl exec -n my-first-app deployment/hello-fawkes -- \\\n  wget -O- http://tempo.fawkes-platform.svc.cluster.local:4318/v1/traces\n</code></pre></p> </li> <li> <p>Check application logs for tracing errors:    <pre><code>kubectl logs -n my-first-app -l app=hello-fawkes | grep -i otel\n</code></pre></p> </li> </ol>"},{"location":"tutorials/2-add-tracing-tempo/#traces-appear-but-are-incomplete","title":"Traces Appear but Are Incomplete","text":"<ul> <li>Ensure <code>tracing.js</code> is loaded before other modules in <code>server.js</code></li> <li>Check that auto-instrumentation is enabled for Express</li> <li>Verify resource limits aren't too restrictive</li> </ul>"},{"location":"tutorials/2-add-tracing-tempo/#high-memory-usage-after-adding-tracing","title":"High Memory Usage After Adding Tracing","text":"<ul> <li>Tracing adds ~20-30MB overhead per container</li> <li>Adjust resource limits if needed</li> <li>Consider sampling: only trace a percentage of requests in production</li> </ul>"},{"location":"tutorials/2-add-tracing-tempo/#learn-more","title":"Learn More","text":"<ul> <li>Unified Telemetry Explanation - How metrics, logs, and traces work together</li> <li>How to Trace Requests with Tempo - Advanced tracing patterns</li> <li>OpenTelemetry Documentation - Official OpenTelemetry docs</li> </ul>"},{"location":"tutorials/2-add-tracing-tempo/#feedback","title":"Feedback","text":"<p>How was this tutorial? Did you successfully view your traces? Share your experience in the Fawkes Community Mattermost!</p>"},{"location":"tutorials/3-consume-vault-secret/","title":"Consume Vault Secrets","text":"<p>Time to Complete: 30 minutes Goal: Replace hardcoded configuration with secrets managed by HashiCorp Vault, following the Fawkes security best practices.</p>"},{"location":"tutorials/3-consume-vault-secret/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this tutorial, you will have:</p> <ol> <li>\u2705 Stored a secret in HashiCorp Vault</li> <li>\u2705 Configured your application to authenticate with Vault using Kubernetes Service Account</li> <li>\u2705 Retrieved secrets at runtime using the Vault Agent pattern</li> <li>\u2705 Rotated a secret and verified your application picks up the new value</li> </ol>"},{"location":"tutorials/3-consume-vault-secret/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Completed Tutorial 1: Deploy Your First Service</li> <li>[ ] Your <code>hello-fawkes</code> service running and accessible</li> <li>[ ] Access to HashiCorp Vault (typically at <code>https://vault.127.0.0.1.nip.io</code>)</li> <li>[ ] <code>vault</code> CLI installed on your workstation</li> <li>[ ] Basic understanding of Kubernetes secrets (helpful but not required)</li> </ul> <p>Why Vault?</p> <p>Storing secrets in code, environment variables, or ConfigMaps is insecure. Vault provides centralized secret management with audit logs, access control, and rotation capabilities. Learn more about Zero Trust Security.</p>"},{"location":"tutorials/3-consume-vault-secret/#step-1-authenticate-to-vault","title":"Step 1: Authenticate to Vault","text":"<p>First, let's verify you can access Vault.</p> <ol> <li> <p>Set the Vault address:    <pre><code>export VAULT_ADDR=\"https://vault.127.0.0.1.nip.io\"\n</code></pre></p> </li> <li> <p>Log in to Vault (use the token provided by your platform team):    <pre><code>vault login\n</code></pre></p> </li> </ol> <p>Enter your token when prompted.</p> <ol> <li>Verify authentication:    <pre><code>vault token lookup\n</code></pre></li> </ol> <p>You should see details about your token, including policies and permissions.</p> <p>Vault Token Management</p> <p>In production, individual users don't use root tokens. Instead, applications authenticate using Kubernetes Service Accounts. We'll set that up later in this tutorial.</p> <p>Checkpoint</p> <p>You can authenticate to Vault and are ready to create secrets.</p>"},{"location":"tutorials/3-consume-vault-secret/#step-2-create-a-secret-in-vault","title":"Step 2: Create a Secret in Vault","text":"<p>Let's create a database connection secret for our application.</p> <ol> <li>Enable the KV v2 secrets engine if not already enabled:    <pre><code>vault secrets enable -path=secret kv-v2\n</code></pre></li> </ol> <p>If it's already enabled, you'll see an error - that's okay!</p> <ol> <li> <p>Create a secret for your application:    <pre><code>vault kv put secret/hello-fawkes/database \\\n  host=\"postgres.database.svc.cluster.local\" \\\n  port=\"5432\" \\\n  username=\"hello_fawkes_user\" \\\n  password=\"SuperSecretPassword123!\"\n</code></pre></p> </li> <li> <p>Verify the secret was created:    <pre><code>vault kv get secret/hello-fawkes/database\n</code></pre></p> </li> </ol> <p>You should see your secret values:    <pre><code>====== Data ======\nKey         Value\n---         -----\nhost        postgres.database.svc.cluster.local\nport        5432\nusername    hello_fawkes_user\npassword    SuperSecretPassword123!\n</code></pre></p> <ol> <li>Create another secret for API keys:    <pre><code>vault kv put secret/hello-fawkes/api \\\n  api_key=\"fawkes-api-key-12345\" \\\n  api_secret=\"fawkes-secret-67890\"\n</code></pre></li> </ol> <p>Checkpoint</p> <p>Your secrets are stored in Vault and can be accessed programmatically.</p>"},{"location":"tutorials/3-consume-vault-secret/#step-3-configure-vault-kubernetes-authentication","title":"Step 3: Configure Vault Kubernetes Authentication","text":"<p>For your application to access Vault, we need to set up Kubernetes authentication.</p> <ol> <li> <p>Enable Kubernetes auth method (if not already enabled):    <pre><code>vault auth enable kubernetes\n</code></pre></p> </li> <li> <p>Configure the Kubernetes auth method:    <pre><code>vault write auth/kubernetes/config \\\n  kubernetes_host=\"https://kubernetes.default.svc:443\"\n</code></pre></p> </li> <li> <p>Create a policy that allows reading your secrets:</p> </li> </ol> <p>Create a file <code>hello-fawkes-policy.hcl</code>:    <pre><code># Allow reading secrets for hello-fawkes\npath \"secret/data/hello-fawkes/*\" {\n  capabilities = [\"read\", \"list\"]\n}\n\n# Allow reading secret metadata\npath \"secret/metadata/hello-fawkes/*\" {\n  capabilities = [\"read\", \"list\"]\n}\n</code></pre></p> <ol> <li> <p>Upload the policy to Vault:    <pre><code>vault policy write hello-fawkes hello-fawkes-policy.hcl\n</code></pre></p> </li> <li> <p>Create a Vault role that maps to your Kubernetes service account:    <pre><code>vault write auth/kubernetes/role/hello-fawkes \\\n  bound_service_account_names=hello-fawkes \\\n  bound_service_account_namespaces=my-first-app \\\n  policies=hello-fawkes \\\n  ttl=24h\n</code></pre></p> </li> </ol> <p>What Did We Just Do?</p> <p>We created a Vault role that trusts the <code>hello-fawkes</code> ServiceAccount in the <code>my-first-app</code> namespace. This allows pods using that ServiceAccount to authenticate to Vault and read secrets according to the <code>hello-fawkes</code> policy.</p> <p>Checkpoint</p> <p>Kubernetes authentication is configured, allowing your application to securely access Vault.</p>"},{"location":"tutorials/3-consume-vault-secret/#step-4-create-a-kubernetes-service-account","title":"Step 4: Create a Kubernetes Service Account","text":"<p>Your application needs a ServiceAccount to authenticate with Vault.</p> <ol> <li> <p>Create <code>k8s/serviceaccount.yaml</code>:    <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: hello-fawkes\n  namespace: my-first-app\n</code></pre></p> </li> <li> <p>Update <code>k8s/deployment.yaml</code> to use the ServiceAccount:    <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-fawkes\n  namespace: my-first-app\n  labels:\n    app: hello-fawkes\n    version: v3\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-fawkes\n  template:\n    metadata:\n      labels:\n        app: hello-fawkes\n        version: v3\n    spec:\n      serviceAccountName: hello-fawkes  # Add this line\n      containers:\n      - name: hello-fawkes\n        image: YOUR-USERNAME/hello-fawkes:v3.0.0\n        # ... rest of container spec\n</code></pre></p> </li> <li> <p>Apply the ServiceAccount:    <pre><code>kubectl apply -f k8s/serviceaccount.yaml\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>Your application now has a ServiceAccount that can authenticate with Vault.</p>"},{"location":"tutorials/3-consume-vault-secret/#step-5-update-application-to-use-vault","title":"Step 5: Update Application to Use Vault","text":"<p>Now let's modify our application to fetch secrets from Vault at runtime.</p> <ol> <li> <p>Install the Vault client library:    <pre><code>npm install --save node-vault\n</code></pre></p> </li> <li> <p>Create a new file <code>vault-client.js</code>:    <pre><code>const vault = require('node-vault');\nconst fs = require('fs');\n\n// Read the service account token\nconst getK8sToken = () =&gt; {\n  try {\n    return fs.readFileSync('/var/run/secrets/kubernetes.io/serviceaccount/token', 'utf8');\n  } catch (error) {\n    console.error('Failed to read Kubernetes token:', error);\n    return null;\n  }\n};\n\n// Initialize Vault client\nconst initVaultClient = async () =&gt; {\n  const vaultClient = vault({\n    apiVersion: 'v1',\n    endpoint: process.env.VAULT_ADDR || 'http://vault.fawkes-platform.svc.cluster.local:8200',\n  });\n\n  // Authenticate using Kubernetes service account\n  const k8sToken = getK8sToken();\n  if (!k8sToken) {\n    throw new Error('No Kubernetes token available');\n  }\n\n  try {\n    const result = await vaultClient.kubernetesLogin({\n      role: 'hello-fawkes',\n      jwt: k8sToken,\n    });\n\n    console.log('Successfully authenticated to Vault');\n\n    // Set the client token for future requests\n    vaultClient.token = result.auth.client_token;\n\n    return vaultClient;\n  } catch (error) {\n    console.error('Vault authentication failed:', error);\n    throw error;\n  }\n};\n\n// Get a secret from Vault\nconst getSecret = async (vaultClient, path) =&gt; {\n  try {\n    const secret = await vaultClient.read(`secret/data/${path}`);\n    return secret.data.data; // KV v2 nests data twice\n  } catch (error) {\n    console.error(`Failed to read secret ${path}:`, error);\n    throw error;\n  }\n};\n\nmodule.exports = {\n  initVaultClient,\n  getSecret,\n};\n</code></pre></p> </li> <li> <p>Update <code>server.js</code> to use Vault secrets:    <pre><code>// Load tracing first\nrequire('./tracing');\n\nconst express = require('express');\nconst { initVaultClient, getSecret } = require('./vault-client');\n\nconst app = express();\nconst PORT = process.env.PORT || 8080;\n\n// Store Vault client and secrets\nlet vaultClient;\nlet secrets = {\n  database: null,\n  api: null,\n};\n\n// Initialize Vault and load secrets\nconst initializeSecrets = async () =&gt; {\n  try {\n    vaultClient = await initVaultClient();\n\n    // Load database secrets\n    secrets.database = await getSecret(vaultClient, 'hello-fawkes/database');\n    console.log('Database secrets loaded');\n\n    // Load API secrets\n    secrets.api = await getSecret(vaultClient, 'hello-fawkes/api');\n    console.log('API secrets loaded');\n\n    return true;\n  } catch (error) {\n    console.error('Failed to initialize secrets:', error);\n    return false;\n  }\n};\n\napp.get('/', (req, res) =&gt; {\n  res.json({\n    message: 'Hello from Fawkes!',\n    timestamp: new Date().toISOString(),\n    version: '3.0.0',\n    tracing: 'enabled',\n    secrets: 'managed by Vault'\n  });\n});\n\napp.get('/health', (req, res) =&gt; {\n  const healthy = secrets.database !== null &amp;&amp; secrets.api !== null;\n  res.status(healthy ? 200 : 503).json({ \n    status: healthy ? 'healthy' : 'unhealthy',\n    secretsLoaded: healthy\n  });\n});\n\n// Endpoint that uses database secrets\napp.get('/api/data', async (req, res) =&gt; {\n  if (!secrets.database) {\n    return res.status(503).json({ error: 'Database secrets not loaded' });\n  }\n\n  // In a real app, you'd use these to connect to the database\n  const dbConfig = {\n    host: secrets.database.host,\n    port: secrets.database.port,\n    username: secrets.database.username,\n    // Never log passwords!\n  };\n\n  res.json({\n    message: 'Database connection configured',\n    host: dbConfig.host,\n    port: dbConfig.port,\n    user: dbConfig.username,\n  });\n});\n\n// Endpoint to trigger secret refresh\napp.post('/api/refresh-secrets', async (req, res) =&gt; {\n  console.log('Refreshing secrets from Vault...');\n  const success = await initializeSecrets();\n  res.json({ \n    success,\n    message: success ? 'Secrets refreshed' : 'Failed to refresh secrets'\n  });\n});\n\n// Start server after loading secrets\n(async () =&gt; {\n  const secretsLoaded = await initializeSecrets();\n\n  if (!secretsLoaded) {\n    console.error('Failed to load secrets. Server will start but may not function correctly.');\n  }\n\n  app.listen(PORT, '0.0.0.0', () =&gt; {\n    console.log(`Server running on port ${PORT}`);\n  });\n})();\n</code></pre></p> </li> <li> <p>Commit the changes:    <pre><code>git add vault-client.js server.js package.json package-lock.json\ngit commit -m \"Add Vault secret management\"\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>Your application now fetches secrets from Vault instead of using hardcoded values!</p>"},{"location":"tutorials/3-consume-vault-secret/#step-6-update-deployment-configuration","title":"Step 6: Update Deployment Configuration","text":"<p>Add environment variables for Vault connectivity.</p> <ol> <li> <p>Update <code>k8s/deployment.yaml</code>:    <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-fawkes\n  namespace: my-first-app\n  labels:\n    app: hello-fawkes\n    version: v3\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-fawkes\n  template:\n    metadata:\n      labels:\n        app: hello-fawkes\n        version: v3\n    spec:\n      serviceAccountName: hello-fawkes\n      containers:\n      - name: hello-fawkes\n        image: YOUR-USERNAME/hello-fawkes:v3.0.0\n        ports:\n        - containerPort: 8080\n          name: http\n        env:\n        - name: PORT\n          value: \"8080\"\n        - name: VAULT_ADDR\n          value: \"http://vault.fawkes-platform.svc.cluster.local:8200\"\n        - name: OTEL_SERVICE_NAME\n          value: \"hello-fawkes\"\n        - name: SERVICE_VERSION\n          value: \"3.0.0\"\n        - name: ENVIRONMENT\n          value: \"development\"\n        - name: OTEL_EXPORTER_OTLP_ENDPOINT\n          value: \"http://tempo.fawkes-platform.svc.cluster.local:4318/v1/traces\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 15\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        resources:\n          requests:\n            memory: \"128Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"256Mi\"\n            cpu: \"200m\"\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 1000\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n</code></pre></p> </li> <li> <p>Commit the changes:    <pre><code>git add k8s/\ngit commit -m \"Configure Vault integration in deployment\"\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>Deployment is configured to connect to Vault using the ServiceAccount.</p>"},{"location":"tutorials/3-consume-vault-secret/#step-7-deploy-and-verify","title":"Step 7: Deploy and Verify","text":"<p>Let's deploy the updated application and verify it can read secrets from Vault.</p> <ol> <li> <p>Build and push the new version:    <pre><code>docker build -t YOUR-USERNAME/hello-fawkes:v3.0.0 .\ndocker push YOUR-USERNAME/hello-fawkes:v3.0.0\n</code></pre></p> </li> <li> <p>Push to Git (ArgoCD will auto-sync):    <pre><code>git push\n</code></pre></p> </li> <li> <p>Watch the deployment:    <pre><code>kubectl rollout status deployment/hello-fawkes -n my-first-app\n</code></pre></p> </li> <li> <p>Check that secrets loaded successfully:    <pre><code>kubectl logs -n my-first-app -l app=hello-fawkes | grep -i vault\n</code></pre></p> </li> </ol> <p>You should see:    <pre><code>Successfully authenticated to Vault\nDatabase secrets loaded\nAPI secrets loaded\n</code></pre></p> <ol> <li>Test the health endpoint:    <pre><code>curl https://hello-fawkes.127.0.0.1.nip.io/health\n</code></pre></li> </ol> <p>Should return:    <pre><code>{\n  \"status\": \"healthy\",\n  \"secretsLoaded\": true\n}\n</code></pre></p> <ol> <li>Test the data endpoint that uses secrets:    <pre><code>curl https://hello-fawkes.127.0.0.1.nip.io/api/data\n</code></pre></li> </ol> <p>Should return database configuration from Vault:    <pre><code>{\n  \"message\": \"Database connection configured\",\n  \"host\": \"postgres.database.svc.cluster.local\",\n  \"port\": \"5432\",\n  \"user\": \"hello_fawkes_user\"\n}\n</code></pre></p> <p>Checkpoint</p> <p>Your application is running and successfully retrieving secrets from Vault! \ud83c\udf89</p>"},{"location":"tutorials/3-consume-vault-secret/#step-8-rotate-a-secret","title":"Step 8: Rotate a Secret","text":"<p>Let's verify that secret rotation works by updating a secret in Vault and refreshing it in the application.</p> <ol> <li> <p>Update the database password in Vault:    <pre><code>vault kv put secret/hello-fawkes/database \\\n  host=\"postgres.database.svc.cluster.local\" \\\n  port=\"5432\" \\\n  username=\"hello_fawkes_user\" \\\n  password=\"NewRotatedPassword456!\"\n</code></pre></p> </li> <li> <p>Verify the secret was updated:    <pre><code>vault kv get secret/hello-fawkes/database\n</code></pre></p> </li> <li> <p>Trigger secret refresh in your application:    <pre><code>curl -X POST https://hello-fawkes.127.0.0.1.nip.io/api/refresh-secrets\n</code></pre></p> </li> </ol> <p>Should return:    <pre><code>{\n  \"success\": true,\n  \"message\": \"Secrets refreshed\"\n}\n</code></pre></p> <ol> <li>Check the logs to verify the new secret was loaded:    <pre><code>kubectl logs -n my-first-app -l app=hello-fawkes --tail=20\n</code></pre></li> </ol> <p>You should see:    <pre><code>Refreshing secrets from Vault...\nDatabase secrets loaded\nAPI secrets loaded\n</code></pre></p> <p>Production Secret Rotation</p> <p>In production, you'd automate secret rotation using: - Vault's automatic rotation features - A sidecar that refreshes secrets periodically - Or External Secrets Operator for full automation</p> <p>See How to Rotate Vault Secrets for advanced patterns.</p> <p>Checkpoint</p> <p>You've successfully rotated a secret and verified your application picked up the new value!</p>"},{"location":"tutorials/3-consume-vault-secret/#what-youve-accomplished","title":"What You've Accomplished","text":"<p>Congratulations! You've successfully:</p> <ul> <li>\u2705 Created and stored secrets in HashiCorp Vault</li> <li>\u2705 Configured Kubernetes authentication for Vault</li> <li>\u2705 Updated your application to fetch secrets at runtime</li> <li>\u2705 Deployed with proper ServiceAccount permissions</li> <li>\u2705 Rotated a secret and verified the update</li> </ul>"},{"location":"tutorials/3-consume-vault-secret/#best-practices-youve-learned","title":"Best Practices You've Learned","text":"<ol> <li>Never hardcode secrets - Always use a secret management system</li> <li>Use Kubernetes ServiceAccounts - Avoid using root tokens in applications</li> <li>Implement least privilege - Create specific policies for each application</li> <li>Enable audit logging - Vault logs all secret access</li> <li>Plan for rotation - Design applications to handle secret updates gracefully</li> </ol>"},{"location":"tutorials/3-consume-vault-secret/#whats-next","title":"What's Next?","text":"<p>Continue securing and enhancing your application:</p> <ol> <li>Buildpack Migration - Automate secure container builds</li> <li>Measure DORA Metrics - Track your security improvements</li> <li>Zero Trust Security Model - Understand the full security architecture</li> </ol>"},{"location":"tutorials/3-consume-vault-secret/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/3-consume-vault-secret/#application-cant-authenticate-to-vault","title":"Application Can't Authenticate to Vault","text":"<pre><code># Check ServiceAccount exists\nkubectl get serviceaccount hello-fawkes -n my-first-app\n\n# Verify Vault role exists\nvault read auth/kubernetes/role/hello-fawkes\n\n# Check pod has ServiceAccount token mounted\nkubectl exec -n my-first-app deployment/hello-fawkes -- \\\n  ls -la /var/run/secrets/kubernetes.io/serviceaccount/\n</code></pre>"},{"location":"tutorials/3-consume-vault-secret/#secrets-not-loading","title":"Secrets Not Loading","text":"<pre><code># Test Vault policy\nvault token create -policy=hello-fawkes\n\n# Check application logs\nkubectl logs -n my-first-app -l app=hello-fawkes\n\n# Verify secrets exist\nvault kv get secret/hello-fawkes/database\n</code></pre>"},{"location":"tutorials/3-consume-vault-secret/#permission-denied-errors","title":"Permission Denied Errors","text":"<ul> <li>Verify the policy allows <code>read</code> on <code>secret/data/hello-fawkes/*</code></li> <li>Check that the role is bound to the correct ServiceAccount and namespace</li> <li>Ensure the Vault token hasn't expired</li> </ul>"},{"location":"tutorials/3-consume-vault-secret/#learn-more","title":"Learn More","text":"<ul> <li>Zero Trust Security Model - Defense in depth with Vault, Kyverno, and Ingress</li> <li>How to Rotate Vault Secrets - Advanced rotation patterns</li> <li>Vault Documentation - Official HashiCorp Vault docs</li> </ul>"},{"location":"tutorials/3-consume-vault-secret/#feedback","title":"Feedback","text":"<p>How was your experience with Vault integration? Share your thoughts in the Fawkes Community Mattermost!</p>"},{"location":"tutorials/4-buildpack-migration/","title":"Migrate to Cloud Native Buildpacks","text":"<p>Time to Complete: 25 minutes Goal: Replace your Dockerfile with Cloud Native Buildpacks (CNB) for automated, secure, and maintainable container builds.</p>"},{"location":"tutorials/4-buildpack-migration/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this tutorial, you will have:</p> <ol> <li>\u2705 Understood the benefits of Cloud Native Buildpacks over Dockerfiles</li> <li>\u2705 Removed your Dockerfile and configured Buildpacks</li> <li>\u2705 Built a container image using Buildpacks</li> <li>\u2705 Deployed the Buildpack-built image to Fawkes</li> <li>\u2705 Verified automatic base image updates (rebasing)</li> </ol>"},{"location":"tutorials/4-buildpack-migration/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Completed Tutorial 1: Deploy Your First Service</li> <li>[ ] Your <code>hello-fawkes</code> service with a Dockerfile</li> <li>[ ] Docker or Podman installed locally</li> <li>[ ] <code>pack</code> CLI installed (installation guide)</li> <li>[ ] Basic understanding of Docker and container images</li> </ul> <p>Why Buildpacks?</p> <p>Dockerfiles give you control, but with control comes responsibility. Who updates base images when CVEs are discovered? Who ensures all teams follow security best practices? Buildpacks automate these concerns. Learn the philosophy.</p>"},{"location":"tutorials/4-buildpack-migration/#step-1-understand-your-current-dockerfile","title":"Step 1: Understand Your Current Dockerfile","text":"<p>Let's review what your Dockerfile is doing and how Buildpacks will replace it.</p> <ol> <li> <p>View your current <code>Dockerfile</code>:    <pre><code>FROM node:18-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci --only=production\n\nCOPY server.js ./\nCOPY tracing.js ./\nCOPY vault-client.js ./\n\nRUN addgroup -g 1000 appuser &amp;&amp; \\\n    adduser -D -u 1000 -G appuser appuser &amp;&amp; \\\n    chown -R appuser:appuser /app\n\nUSER appuser\n\nEXPOSE 8080\n\nCMD [\"npm\", \"start\"]\n</code></pre></p> </li> <li> <p>Identify what the Dockerfile is doing:</p> </li> <li>\u2705 Choosing a base image (node:18-alpine)</li> <li>\u2705 Installing dependencies (npm ci)</li> <li>\u2705 Copying application code</li> <li>\u2705 Creating a non-root user</li> <li> <p>\u2705 Setting the start command</p> </li> <li> <p>Problems with this approach:</p> </li> <li>Manual updates: When Node.js 18 reaches EOL, you must update it</li> <li>CVE lag: Security patches require rebuilding every image</li> <li>Inconsistency: Different teams use different base images</li> <li>No caching: Every team implements their own layer caching</li> </ol> <p>Buildpacks Automate All of This</p> <p>Buildpacks detect your application type, choose appropriate base images, install dependencies, and configure security - all automatically.</p> <p>Checkpoint</p> <p>You understand what your Dockerfile does and why Buildpacks are an improvement.</p>"},{"location":"tutorials/4-buildpack-migration/#step-2-install-pack-cli","title":"Step 2: Install Pack CLI","text":"<p>Pack is the CLI for working with Cloud Native Buildpacks.</p> <ol> <li>Install Pack (choose your platform):</li> </ol> <p>macOS (Homebrew): <pre><code>brew install buildpacks/tap/pack\n</code></pre></p> <p>Linux: <pre><code>sudo add-apt-repository ppa:cncf-buildpacks/pack-cli\nsudo apt-get update\nsudo apt-get install pack-cli\n</code></pre></p> <p>Windows (Chocolatey): <pre><code>choco install pack\n</code></pre></p> <ol> <li> <p>Verify installation:    <pre><code>pack --version\n</code></pre></p> </li> <li> <p>Set a default builder (we'll use Paketo):    <pre><code>pack config default-builder paketobuildpacks/builder:base\n</code></pre></p> </li> </ol> <p>What's a Builder?</p> <p>A builder is a container image that contains buildpacks and knows how to build your application. Paketo Buildpacks is a CNCF project that provides enterprise-grade buildpacks for multiple languages.</p> <p>Checkpoint</p> <p>Pack CLI is installed and configured with a default builder.</p>"},{"location":"tutorials/4-buildpack-migration/#step-3-prepare-for-buildpacks","title":"Step 3: Prepare for Buildpacks","text":"<p>Buildpacks work best when your application follows conventions. Let's ensure your app is ready.</p> <ol> <li> <p>Verify your <code>package.json</code> has a start script:    <pre><code>{\n  \"name\": \"hello-fawkes\",\n  \"version\": \"3.0.0\",\n  \"scripts\": {\n    \"start\": \"node server.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"node-vault\": \"^0.10.2\",\n    \"@opentelemetry/api\": \"^1.4.1\",\n    \"@opentelemetry/sdk-node\": \"^0.41.0\",\n    \"@opentelemetry/auto-instrumentations-node\": \"^0.39.1\",\n    \"@opentelemetry/exporter-trace-otlp-http\": \"^0.41.0\"\n  }\n}\n</code></pre></p> </li> <li> <p>Ensure you have a <code>package-lock.json</code>:    <pre><code>npm install\n</code></pre></p> </li> <li> <p>Optional: Create a <code>.packignore</code> file to exclude files from the build:    <pre><code>.git/\n.gitignore\n*.md\nDockerfile\nk8s/\nnode_modules/\n</code></pre></p> </li> <li> <p>Commit these changes:    <pre><code>git add .packignore package.json package-lock.json\ngit commit -m \"Prepare for Buildpacks migration\"\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>Your application follows Buildpacks conventions and is ready to build.</p>"},{"location":"tutorials/4-buildpack-migration/#step-4-build-with-buildpacks","title":"Step 4: Build with Buildpacks","text":"<p>Now for the exciting part - building your first Buildpack image!</p> <ol> <li> <p>Build your application with Pack:    <pre><code>pack build YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack \\\n  --builder paketobuildpacks/builder:base \\\n  --env BP_NODE_VERSION=18\n</code></pre></p> </li> <li> <p>Watch the build process:</p> </li> <li>Buildpacks will detect that you're using Node.js</li> <li>It will install the correct Node.js version</li> <li>It will run <code>npm ci</code> to install dependencies</li> <li>It will configure the start command</li> <li> <p>It will create a secure, minimal container image</p> </li> <li> <p>Inspect the build output:    <pre><code>===&gt; DETECTING\n[detector] 6 of 24 buildpacks participating\n[detector] paketo-buildpacks/ca-certificates   3.6.3\n[detector] paketo-buildpacks/node-engine        2.0.0\n[detector] paketo-buildpacks/npm-install        1.2.3\n[detector] paketo-buildpacks/node-run-script    1.0.5\n[detector] paketo-buildpacks/node-start         1.0.5\n[detector] paketo-buildpacks/procfile           5.6.3\n\n===&gt; BUILDING\n[builder] Running npm ci...\n[builder] Installing node_modules...\n\n===&gt; EXPORTING\n[exporter] Adding layer 'paketo-buildpacks/node-engine:node'\n[exporter] Adding layer 'paketo-buildpacks/npm-install:modules'\n</code></pre></p> </li> <li> <p>Verify the image was created:    <pre><code>docker images | grep hello-fawkes\n</code></pre></p> </li> </ol> <p>Build Time</p> <p>The first build may take a few minutes as it downloads base images and buildpacks. Subsequent builds are much faster thanks to layer caching.</p> <p>Checkpoint</p> <p>You've built a container image using Cloud Native Buildpacks!</p>"},{"location":"tutorials/4-buildpack-migration/#step-5-compare-image-sizes","title":"Step 5: Compare Image Sizes","text":"<p>Let's see how the Buildpack image compares to your Dockerfile image.</p> <ol> <li> <p>Check Dockerfile image size:    <pre><code>docker images YOUR-USERNAME/hello-fawkes:v3.0.0\n</code></pre></p> </li> <li> <p>Check Buildpack image size:    <pre><code>docker images YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n</code></pre></p> </li> <li> <p>Compare the layers:    <pre><code># Dockerfile image\ndocker history YOUR-USERNAME/hello-fawkes:v3.0.0\n\n# Buildpack image\ndocker history YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n</code></pre></p> </li> </ol> <p>Image Size Differences</p> <p>Buildpack images may be larger than Alpine-based Dockerfile images because they use Ubuntu Bionic for better compatibility. However, they're more secure and maintainable. The trade-off is worth it for most applications.</p> <p>Checkpoint</p> <p>You understand the characteristics of your Buildpack-built image.</p>"},{"location":"tutorials/4-buildpack-migration/#step-6-test-the-buildpack-image-locally","title":"Step 6: Test the Buildpack Image Locally","text":"<p>Before deploying, let's verify the image works correctly.</p> <ol> <li> <p>Run the container locally:    <pre><code>docker run -d --name hello-fawkes-test \\\n  -p 8080:8080 \\\n  -e PORT=8080 \\\n  -e VAULT_ADDR=http://vault.fawkes-platform.svc.cluster.local:8200 \\\n  YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n</code></pre></p> </li> <li> <p>Test the endpoint:    <pre><code>curl http://localhost:8080/\n</code></pre></p> </li> </ol> <p>Should return:    <pre><code>{\n  \"message\": \"Hello from Fawkes!\",\n  \"timestamp\": \"2025-12-06T12:00:00.000Z\",\n  \"version\": \"3.0.0\",\n  \"tracing\": \"enabled\",\n  \"secrets\": \"managed by Vault\"\n}\n</code></pre></p> <ol> <li>Check the running user (should be non-root):    <pre><code>docker exec hello-fawkes-test whoami\n</code></pre></li> </ol> <p>Should output: <code>cnb</code> (Buildpacks default non-root user)</p> <ol> <li>Stop and remove the test container:    <pre><code>docker stop hello-fawkes-test\ndocker rm hello-fawkes-test\n</code></pre></li> </ol> <p>Checkpoint</p> <p>The Buildpack image works correctly and follows security best practices!</p>"},{"location":"tutorials/4-buildpack-migration/#step-7-deploy-buildpack-image-to-fawkes","title":"Step 7: Deploy Buildpack Image to Fawkes","text":"<p>Now let's deploy the Buildpack-built image to your cluster.</p> <ol> <li> <p>Push the image to your registry:    <pre><code>docker push YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n</code></pre></p> </li> <li> <p>Update <code>k8s/deployment.yaml</code> to use the new image:    <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-fawkes\n  namespace: my-first-app\n  labels:\n    app: hello-fawkes\n    version: v4\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-fawkes\n  template:\n    metadata:\n      labels:\n        app: hello-fawkes\n        version: v4\n      annotations:\n        buildpack.io/builder: \"paketobuildpacks/builder:base\"\n    spec:\n      serviceAccountName: hello-fawkes\n      containers:\n      - name: hello-fawkes\n        image: YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n        # Rest of spec remains the same\n</code></pre></p> </li> <li> <p>Commit and push:    <pre><code>git add k8s/deployment.yaml\ngit commit -m \"Deploy Buildpack-built image\"\ngit push\n</code></pre></p> </li> <li> <p>Watch the rollout:    <pre><code>kubectl rollout status deployment/hello-fawkes -n my-first-app\n</code></pre></p> </li> <li> <p>Verify the new pods are running:    <pre><code>kubectl get pods -n my-first-app\n</code></pre></p> </li> <li> <p>Test the deployed service:    <pre><code>curl https://hello-fawkes.127.0.0.1.nip.io/\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>Your service is now running with a Buildpack-built image on Fawkes!</p>"},{"location":"tutorials/4-buildpack-migration/#step-8-understand-rebasing","title":"Step 8: Understand Rebasing","text":"<p>One of the key benefits of Buildpacks is \"rebasing\" - updating base images without rebuilding.</p> <ol> <li>Check the current base image:    <pre><code>pack inspect YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n</code></pre></li> </ol> <p>Note the \"Run Image\" section.</p> <ol> <li> <p>Rebase to the latest base image (simulating a security update):    <pre><code>pack rebase YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n</code></pre></p> </li> <li> <p>Compare the speed:</p> </li> <li>Rebuild: 2-5 minutes (downloads dependencies, runs build)</li> <li> <p>Rebase: 5-10 seconds (only updates base layers)</p> </li> <li> <p>Push the rebased image:    <pre><code>docker push YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n</code></pre></p> </li> <li> <p>Trigger a rollout in Kubernetes:    <pre><code>kubectl rollout restart deployment/hello-fawkes -n my-first-app\n</code></pre></p> </li> </ol> <p>Rebasing in Production</p> <p>In a mature platform, rebasing is automated: - CI/CD pipeline runs <code>pack rebase</code> nightly - Images get security updates without code changes - ArgoCD deploys updated images automatically</p> <p>This is how you patch 100 microservices in minutes, not weeks.</p> <p>Checkpoint</p> <p>You've rebased your image and understand the power of this feature!</p>"},{"location":"tutorials/4-buildpack-migration/#step-9-remove-the-dockerfile","title":"Step 9: Remove the Dockerfile","text":"<p>Now that you're using Buildpacks, the Dockerfile is obsolete.</p> <ol> <li> <p>Remove the Dockerfile:    <pre><code>rm Dockerfile\n</code></pre></p> </li> <li> <p>Optional: Add a <code>project.toml</code> for Buildpack configuration:    <pre><code>[_]\nschema-version = \"0.2\"\n\n[[io.buildpacks.build.env]]\nname = \"BP_NODE_VERSION\"\nvalue = \"18\"\n\n[[io.buildpacks.build.env]]\nname = \"BP_NPM_INSTALL_ARGS\"\nvalue = \"--production\"\n</code></pre></p> </li> <li> <p>Update your CI/CD pipeline to use <code>pack build</code> instead of <code>docker build</code>.</p> </li> </ol> <p>Example Jenkins pipeline snippet:    <pre><code>stage('Build Image') {\n  steps {\n    sh '''\n      pack build ${IMAGE_NAME}:${VERSION} \\\n        --builder paketobuildpacks/builder:base \\\n        --publish\n    '''\n  }\n}\n</code></pre></p> <ol> <li>Commit the changes:    <pre><code>git add Dockerfile project.toml\ngit commit -m \"Remove Dockerfile, migrate to Buildpacks\"\ngit push\n</code></pre></li> </ol> <p>Checkpoint</p> <p>You've fully migrated from Dockerfiles to Cloud Native Buildpacks!</p>"},{"location":"tutorials/4-buildpack-migration/#what-youve-accomplished","title":"What You've Accomplished","text":"<p>Congratulations! You've successfully:</p> <ul> <li>\u2705 Understood the benefits of Buildpacks over Dockerfiles</li> <li>\u2705 Built a container image using Cloud Native Buildpacks</li> <li>\u2705 Deployed a Buildpack-built image to Fawkes</li> <li>\u2705 Learned about rebasing for fast security updates</li> <li>\u2705 Migrated away from manual Dockerfile maintenance</li> </ul>"},{"location":"tutorials/4-buildpack-migration/#benefits-youve-gained","title":"Benefits You've Gained","text":"<ol> <li>Automated Security - Base images update automatically</li> <li>Consistency - All Node.js apps use the same buildpack</li> <li>Best Practices - Non-root user, minimal layers, optimal caching</li> <li>Fast Patching - Rebase 100 images in minutes</li> <li>Less Maintenance - No Dockerfiles to update across teams</li> </ol>"},{"location":"tutorials/4-buildpack-migration/#whats-next","title":"What's Next?","text":"<p>Continue your Fawkes journey:</p> <ol> <li>Create Golden Path Template - Make Buildpacks the default for new services</li> <li>Measure DORA Metrics - Track deployment frequency improvements</li> <li>Buildpacks Philosophy - Deep dive into the trade-offs</li> </ol>"},{"location":"tutorials/4-buildpack-migration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/4-buildpack-migration/#pack-build-fails-to-detect-buildpack","title":"Pack Build Fails to Detect Buildpack","text":"<pre><code># Ensure package.json is in the root directory\nls -la package.json\n\n# Try specifying the buildpack explicitly\npack build myimage --buildpack paketo-buildpacks/nodejs\n</code></pre>"},{"location":"tutorials/4-buildpack-migration/#image-larger-than-expected","title":"Image Larger Than Expected","text":"<ul> <li>Buildpacks use Ubuntu, not Alpine</li> <li>Includes build tools for maximum compatibility</li> <li>Trade-off: Larger size for better security and maintainability</li> <li>Consider multi-stage builds if size is critical</li> </ul>"},{"location":"tutorials/4-buildpack-migration/#application-wont-start","title":"Application Won't Start","text":"<pre><code># Check the buildpack-detected start command\npack inspect YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n\n# Verify your package.json \"start\" script\ncat package.json | grep -A2 scripts\n\n# Test locally first\ndocker run -it YOUR-USERNAME/hello-fawkes:v4.0.0-buildpack\n</code></pre>"},{"location":"tutorials/4-buildpack-migration/#need-to-customize-build-process","title":"Need to Customize Build Process","text":"<ul> <li>Use <code>project.toml</code> for buildpack configuration</li> <li>Set environment variables: <code>--env BP_NODE_VERSION=18</code></li> <li>Add build-time arguments: <code>--env BP_BUILD_ARGS=\"--verbose\"</code></li> <li>See Paketo Node.js Buildpack docs</li> </ul>"},{"location":"tutorials/4-buildpack-migration/#learn-more","title":"Learn More","text":"<ul> <li>Buildpacks Philosophy - Understand the security vs. control trade-off</li> <li>Cloud Native Buildpacks Documentation - Official CNB docs</li> <li>Paketo Buildpacks - Enterprise-grade buildpacks for Java, Node.js, Go, Python, and more</li> </ul>"},{"location":"tutorials/4-buildpack-migration/#feedback","title":"Feedback","text":"<p>How was your experience migrating to Buildpacks? Did you encounter any issues? Share your feedback in the Fawkes Community Mattermost!</p>"},{"location":"tutorials/5-create-golden-path-template/","title":"Create a Golden Path Template","text":"<p>Time to Complete: 35 minutes Goal: Create a Backstage software template that encodes best practices and enables self-service application creation.</p>"},{"location":"tutorials/5-create-golden-path-template/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this tutorial, you will have:</p> <ol> <li>\u2705 Created a custom Backstage software template</li> <li>\u2705 Encoded Fawkes best practices (Buildpacks, Vault, Tracing) in the template</li> <li>\u2705 Published the template to your Backstage catalog</li> <li>\u2705 Used the template to scaffold a new service</li> <li>\u2705 Understood how templates enable platform self-service</li> </ol>"},{"location":"tutorials/5-create-golden-path-template/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Completed tutorials 1-4 (understanding of Fawkes workflows)</li> <li>[ ] Access to Backstage UI (typically at <code>https://backstage.fawkes.yourdomain.com</code>)</li> <li>[ ] A GitHub account with permission to create repositories</li> <li>[ ] <code>cookiecutter</code> installed (<code>pip install cookiecutter</code> or <code>brew install cookiecutter</code>)</li> <li>[ ] Understanding of YAML and basic templating</li> </ul> <p>What is a Golden Path?</p> <p>A \"Golden Path\" is a supported, opinionated, well-documented way to build and deploy software. It reduces cognitive load by providing sensible defaults while still allowing customization when needed.</p>"},{"location":"tutorials/5-create-golden-path-template/#step-1-understand-backstage-templates","title":"Step 1: Understand Backstage Templates","text":"<p>Backstage templates use a declarative format to scaffold new projects.</p> <ol> <li> <p>Navigate to Backstage and click Create.</p> </li> <li> <p>Browse the existing templates:</p> </li> <li>What information do they collect?</li> <li>What files do they generate?</li> <li> <p>How do they integrate with the platform?</p> </li> <li> <p>Key components of a template:</p> </li> <li>Parameters: Questions to ask the user (service name, owner, etc.)</li> <li>Steps: Actions to perform (fetch skeleton, publish to GitHub)</li> <li>Output: Links to the created resources</li> </ol> <p>Template Philosophy</p> <p>Templates should make it easy to do the right thing and hard to do the wrong thing. Embed security, observability, and compliance by default.</p> <p>Checkpoint</p> <p>You understand what Backstage templates do and how they work.</p>"},{"location":"tutorials/5-create-golden-path-template/#step-2-create-template-repository-structure","title":"Step 2: Create Template Repository Structure","text":"<p>Let's create a template for Node.js services that includes all Fawkes best practices.</p> <ol> <li> <p>Create a new directory for your template:    <pre><code>mkdir fawkes-nodejs-template\ncd fawkes-nodejs-template\n</code></pre></p> </li> <li> <p>Create the directory structure:    <pre><code>mkdir -p skeleton\nmkdir -p skeleton/k8s\nmkdir -p skeleton/.github/workflows\n</code></pre></p> </li> <li> <p>Initialize a git repository:    <pre><code>git init\n</code></pre></p> </li> <li> <p>Create a <code>template.yaml</code> at the root:    <pre><code>apiVersion: scaffolder.backstage.io/v1beta3\nkind: Template\nmetadata:\n  name: fawkes-nodejs-service\n  title: Fawkes Node.js Service\n  description: Create a production-ready Node.js service with Buildpacks, Vault, and Tracing\n  tags:\n    - nodejs\n    - fawkes\n    - recommended\nspec:\n  owner: group:platform-team\n  type: service\n\n  parameters:\n    - title: Service Information\n      required:\n        - component_id\n        - owner\n      properties:\n        component_id:\n          title: Name\n          type: string\n          description: Unique name for this service (lowercase, hyphens only)\n          pattern: '^[a-z0-9-]+$'\n          ui:autofocus: true\n        description:\n          title: Description\n          type: string\n          description: What does this service do?\n        owner:\n          title: Owner\n          type: string\n          description: Team responsible for this service\n          ui:field: OwnerPicker\n          ui:options:\n            catalogFilter:\n              kind: Group\n\n    - title: Configuration\n      required:\n        - port\n      properties:\n        port:\n          title: HTTP Port\n          type: number\n          default: 8080\n          description: Port the service listens on\n        enable_tracing:\n          title: Enable Distributed Tracing\n          type: boolean\n          default: true\n          description: Instrument with OpenTelemetry\n        enable_vault:\n          title: Enable Vault Secrets\n          type: boolean\n          default: true\n          description: Use HashiCorp Vault for secrets\n\n    - title: Repository\n      required:\n        - repoUrl\n      properties:\n        repoUrl:\n          title: Repository Location\n          type: string\n          ui:field: RepoUrlPicker\n          ui:options:\n            allowedHosts:\n              - github.com\n\n  steps:\n    - id: fetch\n      name: Fetch Skeleton\n      action: fetch:template\n      input:\n        url: ./skeleton\n        values:\n          component_id: ${{ parameters.component_id }}\n          description: ${{ parameters.description }}\n          owner: ${{ parameters.owner }}\n          port: ${{ parameters.port }}\n          enable_tracing: ${{ parameters.enable_tracing }}\n          enable_vault: ${{ parameters.enable_vault }}\n\n    - id: publish\n      name: Publish to GitHub\n      action: publish:github\n      input:\n        allowedHosts:\n          - github.com\n        description: ${{ parameters.description }}\n        repoUrl: ${{ parameters.repoUrl }}\n        defaultBranch: main\n\n    - id: register\n      name: Register Component\n      action: catalog:register\n      input:\n        repoContentsUrl: ${{ steps.publish.output.repoContentsUrl }}\n        catalogInfoPath: '/catalog-info.yaml'\n\n    - id: create-argocd-app\n      name: Create ArgoCD Application\n      action: fawkes:create-argocd-app\n      input:\n        name: ${{ parameters.component_id }}\n        namespace: ${{ parameters.component_id }}\n        repoUrl: ${{ steps.publish.output.remoteUrl }}\n\n  output:\n    links:\n      - title: Repository\n        url: ${{ steps.publish.output.remoteUrl }}\n      - title: View in Catalog\n        icon: catalog\n        entityRef: ${{ steps.register.output.entityRef }}\n      - title: ArgoCD\n        url: https://argocd.fawkes.yourdomain.com/applications/${{ parameters.component_id }}\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>Template metadata and parameters are defined.</p>"},{"location":"tutorials/5-create-golden-path-template/#step-3-create-skeleton-files","title":"Step 3: Create Skeleton Files","text":"<p>Now let's create the actual files that will be generated.</p> <ol> <li> <p>Create <code>skeleton/catalog-info.yaml</code>:    <pre><code>apiVersion: backstage.io/v1alpha1\nkind: Component\nmetadata:\n  name: ${{ values.component_id }}\n  description: ${{ values.description }}\n  annotations:\n    github.com/project-slug: ${{ values.repoUrl | parseRepoUrl | pick('owner') }}/${{ values.component_id }}\n    argocd/app-name: ${{ values.component_id }}\n  tags:\n    - nodejs\n    - fawkes\nspec:\n  type: service\n  lifecycle: experimental\n  owner: ${{ values.owner }}\n  system: fawkes-platform\n</code></pre></p> </li> <li> <p>Create <code>skeleton/package.json</code>:    <pre><code>{\n  \"name\": \"${{ values.component_id }}\",\n  \"version\": \"1.0.0\",\n  \"description\": \"${{ values.description }}\",\n  \"main\": \"server.js\",\n  \"scripts\": {\n    \"start\": \"node server.js\",\n    \"test\": \"echo 'No tests yet' &amp;&amp; exit 0\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\"{% if values.enable_tracing %},\n    \"@opentelemetry/api\": \"^1.4.1\",\n    \"@opentelemetry/sdk-node\": \"^0.41.0\",\n    \"@opentelemetry/auto-instrumentations-node\": \"^0.39.1\",\n    \"@opentelemetry/exporter-trace-otlp-http\": \"^0.41.0\"{% endif %}{% if values.enable_vault %},\n    \"node-vault\": \"^0.10.2\"{% endif %}\n  }\n}\n</code></pre></p> </li> <li> <p>Create <code>skeleton/server.js</code>:    <pre><code>{% if values.enable_tracing %}// Load tracing before anything else\nrequire('./tracing');\n{% endif %}\nconst express = require('express');\n{% if values.enable_vault %}const { initVaultClient, getSecret } = require('./vault-client');\n{% endif %}\nconst app = express();\nconst PORT = process.env.PORT || ${{ values.port }};\n\n{% if values.enable_vault %}// Store Vault client and secrets\nlet vaultClient;\nlet secrets = {};\n\n// Initialize Vault and load secrets\nconst initializeSecrets = async () =&gt; {\n  try {\n    vaultClient = await initVaultClient();\n    console.log('Vault initialized');\n    // Add your secret paths here\n    // secrets.mySecret = await getSecret(vaultClient, '${{ values.component_id }}/config');\n    return true;\n  } catch (error) {\n    console.error('Failed to initialize secrets:', error);\n    return false;\n  }\n};\n{% endif %}\napp.get('/', (req, res) =&gt; {\n  res.json({\n    service: '${{ values.component_id }}',\n    description: '${{ values.description }}',\n    version: '1.0.0',\n    timestamp: new Date().toISOString()\n  });\n});\n\napp.get('/health', (req, res) =&gt; {\n  res.json({ status: 'healthy' });\n});\n\n// Start server\n(async () =&gt; {\n  {% if values.enable_vault %}const secretsLoaded = await initializeSecrets();\n  if (!secretsLoaded) {\n    console.warn('Secrets not loaded, but starting anyway...');\n  }\n  {% endif %}\n  app.listen(PORT, '0.0.0.0', () =&gt; {\n    console.log(`${{ values.component_id }} listening on port ${PORT}`);\n  });\n})();\n</code></pre></p> </li> <li> <p>If tracing is enabled, create <code>skeleton/tracing.js</code>:    <pre><code>{% if values.enable_tracing %}const { NodeSDK } = require('@opentelemetry/sdk-node');\nconst { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');\nconst { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-http');\nconst { Resource } = require('@opentelemetry/resources');\nconst { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');\n\nconst traceExporter = new OTLPTraceExporter({\n  url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT || 'http://tempo.fawkes-platform.svc.cluster.local:4318/v1/traces',\n});\n\nconst resource = new Resource({\n  [SemanticResourceAttributes.SERVICE_NAME]: '${{ values.component_id }}',\n  [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',\n});\n\nconst sdk = new NodeSDK({\n  resource,\n  traceExporter,\n  instrumentations: [getNodeAutoInstrumentations()],\n});\n\nsdk.start();\nconsole.log('OpenTelemetry tracing initialized');\n{% endif %}\n</code></pre></p> </li> <li> <p>If Vault is enabled, create <code>skeleton/vault-client.js</code>:    <pre><code>{% if values.enable_vault %}const vault = require('node-vault');\nconst fs = require('fs');\n\nconst getK8sToken = () =&gt; {\n  try {\n    return fs.readFileSync('/var/run/secrets/kubernetes.io/serviceaccount/token', 'utf8');\n  } catch (error) {\n    console.error('Failed to read Kubernetes token:', error);\n    return null;\n  }\n};\n\nconst initVaultClient = async () =&gt; {\n  const vaultClient = vault({\n    apiVersion: 'v1',\n    endpoint: process.env.VAULT_ADDR || 'http://vault.fawkes-platform.svc.cluster.local:8200',\n  });\n\n  const k8sToken = getK8sToken();\n  if (!k8sToken) {\n    throw new Error('No Kubernetes token available');\n  }\n\n  const result = await vaultClient.kubernetesLogin({\n    role: '${{ values.component_id }}',\n    jwt: k8sToken,\n  });\n\n  vaultClient.token = result.auth.client_token;\n  return vaultClient;\n};\n\nconst getSecret = async (vaultClient, path) =&gt; {\n  const secret = await vaultClient.read(`secret/data/${path}`);\n  return secret.data.data;\n};\n\nmodule.exports = { initVaultClient, getSecret };\n{% endif %}\n</code></pre></p> </li> </ol> <p>Checkpoint</p> <p>Skeleton application files are created with conditional features.</p>"},{"location":"tutorials/5-create-golden-path-template/#step-4-create-kubernetes-manifests","title":"Step 4: Create Kubernetes Manifests","text":"<ol> <li> <p>Create <code>skeleton/k8s/deployment.yaml</code>:    <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ${{ values.component_id }}\n  namespace: ${{ values.component_id }}\n  labels:\n    app: ${{ values.component_id }}\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ${{ values.component_id }}\n  template:\n    metadata:\n      labels:\n        app: ${{ values.component_id }}\n      annotations:\n        buildpack.io/builder: \"paketobuildpacks/builder:base\"\n    spec:\n      {% if values.enable_vault %}serviceAccountName: ${{ values.component_id }}\n      {% endif %}containers:\n      - name: ${{ values.component_id }}\n        image: REPLACE_WITH_YOUR_IMAGE\n        ports:\n        - containerPort: ${{ values.port }}\n          name: http\n        env:\n        - name: PORT\n          value: \"${{ values.port }}\"\n        {% if values.enable_vault %}- name: VAULT_ADDR\n          value: \"http://vault.fawkes-platform.svc.cluster.local:8200\"\n        {% endif %}{% if values.enable_tracing %}- name: OTEL_SERVICE_NAME\n          value: \"${{ values.component_id }}\"\n        - name: OTEL_EXPORTER_OTLP_ENDPOINT\n          value: \"http://tempo.fawkes-platform.svc.cluster.local:4318/v1/traces\"\n        {% endif %}livenessProbe:\n          httpGet:\n            path: /health\n            port: ${{ values.port }}\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: ${{ values.port }}\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        resources:\n          requests:\n            memory: \"128Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"256Mi\"\n            cpu: \"200m\"\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 1000\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n</code></pre></p> </li> <li> <p>Create other Kubernetes manifests (service, ingress, serviceaccount if needed).</p> </li> <li> <p>Create <code>skeleton/README.md</code>:    <pre><code># ${{ values.component_id }}\n\n${{ values.description }}\n\n## Quick Start\n\n```bash\nnpm install\nnpm start\n</code></pre></p> </li> </ol> <p>## Building with Buildpacks</p> <pre><code>pack build ${{ values.component_id }}:latest --builder paketobuildpacks/builder:base\n</code></pre> <p>## Deployment</p> <p>This service is deployed using ArgoCD. Push to <code>main</code> branch to trigger deployment.</p> <p>## Features</p> <ul> <li>\u2705 Express.js REST API    {% if values.enable_tracing %}- \u2705 OpenTelemetry distributed tracing    {% endif %}{% if values.enable_vault %}- \u2705 HashiCorp Vault secret management    {% endif %}- \u2705 Cloud Native Buildpacks</li> <li>\u2705 Kubernetes-ready with health checks</li> <li>\u2705 Security best practices (non-root, read-only filesystem)</li> </ul> <p>## Owner</p> <p>Team: ${{ values.owner }}    ```</p> <p>Checkpoint</p> <p>Complete skeleton with Kubernetes manifests and README.</p>"},{"location":"tutorials/5-create-golden-path-template/#step-5-publish-the-template","title":"Step 5: Publish the Template","text":"<ol> <li> <p>Commit all files:    <pre><code>git add .\ngit commit -m \"Initial Fawkes Node.js template\"\n</code></pre></p> </li> <li> <p>Create a GitHub repository:</p> </li> <li>Go to github.com</li> <li>Create a new repository: <code>fawkes-nodejs-template</code></li> <li> <p>Push your code:      <pre><code>git remote add origin https://github.com/YOUR-ORG/fawkes-nodejs-template.git\ngit branch -M main\ngit push -u origin main\n</code></pre></p> </li> <li> <p>Register the template in Backstage:</p> </li> <li>Navigate to Backstage UI</li> <li>Click Create \u2192 Register Existing Component</li> <li>Enter: <code>https://github.com/YOUR-ORG/fawkes-nodejs-template/blob/main/template.yaml</code></li> <li>Click Analyze \u2192 Import</li> </ol> <p>Checkpoint</p> <p>Your template is published and available in Backstage!</p>"},{"location":"tutorials/5-create-golden-path-template/#step-6-use-your-template","title":"Step 6: Use Your Template","text":"<p>Let's create a new service using your template.</p> <ol> <li> <p>In Backstage, click Create.</p> </li> <li> <p>Find and select Fawkes Node.js Service.</p> </li> <li> <p>Fill in the form:</p> </li> <li>Name: <code>my-awesome-service</code></li> <li>Description: <code>A service created from the Golden Path template</code></li> <li>Owner: Select your team</li> <li>Enable Tracing: \u2705 Yes</li> <li>Enable Vault: \u2705 Yes</li> <li> <p>Repository: Choose location</p> </li> <li> <p>Click Create.</p> </li> <li> <p>Watch Backstage:</p> </li> <li>Fetch the skeleton</li> <li>Substitute variables</li> <li>Create GitHub repository</li> <li>Register in catalog</li> <li> <p>Create ArgoCD application</p> </li> <li> <p>Navigate to the newly created repository and service in the catalog!</p> </li> </ol> <p>Checkpoint</p> <p>You've used your Golden Path template to create a production-ready service in minutes!</p>"},{"location":"tutorials/5-create-golden-path-template/#what-youve-accomplished","title":"What You've Accomplished","text":"<p>Congratulations! You've successfully:</p> <ul> <li>\u2705 Created a Backstage software template</li> <li>\u2705 Encoded Fawkes best practices (Buildpacks, Vault, Tracing)</li> <li>\u2705 Published the template to Backstage</li> <li>\u2705 Used the template to scaffold a new service</li> <li>\u2705 Enabled self-service platform adoption</li> </ul>"},{"location":"tutorials/5-create-golden-path-template/#impact-of-golden-paths","title":"Impact of Golden Paths","text":"<p>By creating this template, you've:</p> <ol> <li>Reduced Onboarding Time - New services in minutes, not days</li> <li>Enforced Best Practices - Security, observability by default</li> <li>Improved Consistency - All services follow the same patterns</li> <li>Enabled Self-Service - Developers don't need platform expertise</li> <li>Accelerated DORA Metrics - Faster deployment frequency</li> </ol>"},{"location":"tutorials/5-create-golden-path-template/#whats-next","title":"What's Next?","text":"<ol> <li>Measure DORA Metrics - See the impact of your Golden Path</li> <li>Extend the Template - Add database setup, message queues, etc.</li> <li>Create More Templates - Python, Java, Go, Frontend, etc.</li> </ol>"},{"location":"tutorials/5-create-golden-path-template/#learn-more","title":"Learn More","text":"<ul> <li>Backstage Template Documentation - Official Backstage docs</li> <li>Golden Path Usage Guide - How to use Fawkes Golden Paths</li> </ul>"},{"location":"tutorials/5-create-golden-path-template/#feedback","title":"Feedback","text":"<p>Share your Golden Path template with the community! Post in Fawkes Community Mattermost!</p>"},{"location":"tutorials/6-measure-dora-metrics/","title":"Measure DORA Metrics","text":"<p>Time to Complete: 30 minutes Goal: Understand how your service contributes to team DORA metrics and use data to drive improvements.</p>"},{"location":"tutorials/6-measure-dora-metrics/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this tutorial, you will have:</p> <ol> <li>\u2705 Understood the four key DORA metrics</li> <li>\u2705 Configured your service for DORA metric collection</li> <li>\u2705 Viewed your service's metrics in Apache DevLake dashboards</li> <li>\u2705 Analyzed trends and identified improvement opportunities</li> <li>\u2705 Understood how Fawkes automates DORA data collection</li> </ol>"},{"location":"tutorials/6-measure-dora-metrics/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>[ ] Completed Tutorial 1: Deploy Your First Service</li> <li>[ ] Your <code>hello-fawkes</code> service deployed and operational</li> <li>[ ] Access to Grafana (typically at <code>https://grafana.127.0.0.1.nip.io</code>)</li> <li>[ ] Access to DevLake (typically at <code>https://devlake.127.0.0.1.nip.io</code>)</li> <li>[ ] At least a few deployments of your service (from previous tutorials)</li> </ul> <p>What are DORA Metrics?</p> <p>DORA (DevOps Research and Assessment) identified four key metrics that predict software delivery performance: 1. Deployment Frequency - How often you deploy to production 2. Lead Time for Changes - Time from commit to production 3. Change Failure Rate - % of deployments causing failures 4. Time to Restore Service - Time to recover from failures</p> <p>Learn more about DORA capabilities.</p>"},{"location":"tutorials/6-measure-dora-metrics/#step-1-understand-dora-metrics","title":"Step 1: Understand DORA Metrics","text":"<p>Let's review what each metric measures and why it matters.</p>"},{"location":"tutorials/6-measure-dora-metrics/#deployment-frequency","title":"Deployment Frequency","text":"<p>Definition: How often an organization successfully releases to production.</p> <p>Elite Performance: Multiple deploys per day Industry Average: Between once per week and once per month</p> <p>Why it matters:  - High frequency = smaller changes - Smaller changes = lower risk - Lower risk = faster feedback</p>"},{"location":"tutorials/6-measure-dora-metrics/#lead-time-for-changes","title":"Lead Time for Changes","text":"<p>Definition: Time from code committed to code successfully running in production.</p> <p>Elite Performance: Less than one hour Industry Average: Between one week and one month</p> <p>Why it matters: - Short lead time = fast feedback - Fast feedback = rapid iteration - Rapid iteration = better products</p>"},{"location":"tutorials/6-measure-dora-metrics/#change-failure-rate","title":"Change Failure Rate","text":"<p>Definition: Percentage of changes that result in a failure in production.</p> <p>Elite Performance: 0-15% Industry Average: 31-45%</p> <p>Why it matters: - Low failure rate = stable releases - Stable releases = customer trust - Customer trust = business success</p>"},{"location":"tutorials/6-measure-dora-metrics/#time-to-restore-service","title":"Time to Restore Service","text":"<p>Definition: Time it takes to recover from a failure in production.</p> <p>Elite Performance: Less than one hour Industry Average: Less than one day</p> <p>Why it matters: - Fast recovery = minimized impact - Minimized impact = satisfied customers - Satisfied customers = retained revenue</p> <p>Checkpoint</p> <p>You understand what DORA metrics are and why they matter.</p>"},{"location":"tutorials/6-measure-dora-metrics/#step-2-access-devlake-dashboard","title":"Step 2: Access DevLake Dashboard","text":"<p>Apache DevLake is Fawkes' data platform for DORA metrics.</p> <ol> <li> <p>Navigate to DevLake in your browser:    <pre><code>https://devlake.127.0.0.1.nip.io\n</code></pre></p> </li> <li> <p>Log in with your credentials (ask your platform team if you don't have them).</p> </li> <li> <p>You should see the main dashboard with:</p> </li> <li>Projects list</li> <li>DORA metrics overview</li> <li> <p>Trend graphs</p> </li> <li> <p>Navigate to Dashboards \u2192 DORA Dashboard.</p> </li> <li> <p>Use the filters to select your service:</p> </li> <li>Project: <code>my-first-app</code></li> <li>Repository: <code>hello-fawkes</code></li> <li>Time Range: Last 30 days</li> </ol> <p>No Data Yet?</p> <p>If this is your first deployment, you may not see much data yet. That's okay! We'll generate more data in this tutorial.</p> <p>Checkpoint</p> <p>You can access the DevLake DORA dashboard and filter by your service.</p>"},{"location":"tutorials/6-measure-dora-metrics/#step-3-configure-data-collection","title":"Step 3: Configure Data Collection","text":"<p>Fawkes automatically collects most DORA data, but let's verify the configuration.</p> <ol> <li>Check that your ArgoCD application has DORA annotations.</li> </ol> <p>View <code>argocd-app.yaml</code>:    <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: hello-fawkes\n  namespace: argocd\n  annotations:\n    # DORA metric annotations\n    dora/team: \"platform-team\"\n    dora/service: \"hello-fawkes\"\n    notifications.argoproj.io/subscribe.on-deployed.devlake: \"webhook\"\nspec:\n  # ... rest of spec\n</code></pre></p> <ol> <li> <p>If annotations are missing, add them:    <pre><code>kubectl annotate application hello-fawkes -n argocd \\\n  dora/team=platform-team \\\n  dora/service=hello-fawkes \\\n  notifications.argoproj.io/subscribe.on-deployed.devlake=webhook\n</code></pre></p> </li> <li> <p>Verify ArgoCD notifications are configured:    <pre><code>kubectl get configmap argocd-notifications-cm -n argocd -o yaml\n</code></pre></p> </li> </ol> <p>Should include a DevLake webhook trigger.</p> <ol> <li>Check that your GitHub repository is connected:</li> <li>In DevLake UI, go to Data Connections</li> <li>Verify <code>hello-fawkes</code> repository is listed</li> <li>If not, add it following the platform team's instructions</li> </ol> <p>Checkpoint</p> <p>Your service is configured for automatic DORA data collection.</p>"},{"location":"tutorials/6-measure-dora-metrics/#step-4-generate-deployment-data","title":"Step 4: Generate Deployment Data","text":"<p>Let's create some deployments to populate the metrics.</p> <ol> <li> <p>Make a small code change to <code>server.js</code>:    <pre><code>app.get('/', (req, res) =&gt; {\n  res.json({\n    message: 'Hello from Fawkes!',\n    timestamp: new Date().toISOString(),\n    version: '4.0.0',  // Bump version\n    tracing: 'enabled',\n    secrets: 'managed by Vault',\n    dora: 'tracking enabled'  // New field\n  });\n});\n</code></pre></p> </li> <li> <p>Commit and push:    <pre><code>git add server.js\ngit commit -m \"Add DORA tracking indicator\"\ngit push\n</code></pre></p> </li> <li> <p>This triggers:</p> </li> <li>Git webhook to DevLake (Lead Time starts)</li> <li>ArgoCD sync (Deployment happens)</li> <li> <p>Deployment notification to DevLake (Deployment Frequency recorded)</p> </li> <li> <p>Wait for ArgoCD to sync (check in ArgoCD UI or CLI):    <pre><code>kubectl get application hello-fawkes -n argocd -w\n</code></pre></p> </li> <li> <p>Make a few more changes to generate more data points:    <pre><code># Change 2\ngit commit --allow-empty -m \"Trigger deployment 2\"\ngit push\n\n# Wait 5 minutes\n\n# Change 3\ngit commit --allow-empty -m \"Trigger deployment 3\"\ngit push\n</code></pre></p> </li> </ol> <p>Why Multiple Deployments?</p> <p>DORA metrics are trends, not single data points. The more deployments you have, the more meaningful the metrics become.</p> <p>Checkpoint</p> <p>You've generated deployment data for DORA analysis.</p>"},{"location":"tutorials/6-measure-dora-metrics/#step-5-view-deployment-frequency","title":"Step 5: View Deployment Frequency","text":"<p>Let's analyze how often you're deploying.</p> <ol> <li> <p>In DevLake, navigate to DORA Dashboard \u2192 Deployment Frequency.</p> </li> <li> <p>You should see:</p> </li> <li>A timeline graph showing deployments over time</li> <li>Total deployments in the selected period</li> <li>Average deployments per day/week</li> <li> <p>Trend: Increasing, Stable, or Decreasing</p> </li> <li> <p>Filter by your service (<code>hello-fawkes</code>).</p> </li> <li> <p>Compare to team average and industry benchmarks.</p> </li> <li> <p>Example insights:</p> </li> <li>\"We deployed 3 times this week\"</li> <li>\"Our average is 0.6 deployments per day\"</li> <li>\"We're at 'Medium' performance tier (weekly deploys)\"</li> <li>\"Goal: Reach 'High' tier (daily deploys)\"</li> </ol> <p>Interpreting the Data</p> <ul> <li>Elite: On-demand (multiple per day)</li> <li>High: Between once per day and once per week</li> <li>Medium: Between once per week and once per month</li> <li>Low: Less than once per month</li> </ul> <p>Checkpoint</p> <p>You can view and interpret your deployment frequency metrics.</p>"},{"location":"tutorials/6-measure-dora-metrics/#step-6-analyze-lead-time-for-changes","title":"Step 6: Analyze Lead Time for Changes","text":"<p>Now let's see how long it takes from commit to production.</p> <ol> <li> <p>In DevLake, navigate to DORA Dashboard \u2192 Lead Time for Changes.</p> </li> <li> <p>The dashboard shows:</p> </li> <li>Median lead time (p50)</li> <li>95th percentile lead time (p95)</li> <li> <p>Breakdown by stage:</p> <ul> <li>Code commit to PR creation</li> <li>PR creation to approval</li> <li>PR approval to merge</li> <li>Merge to deployment</li> </ul> </li> <li> <p>Click on a specific deployment to see its journey:    <pre><code>Commit: 2025-12-06 10:00:00\n\u251c\u2500 PR Created: +5 minutes\n\u251c\u2500 PR Approved: +10 minutes\n\u251c\u2500 PR Merged: +2 minutes\n\u2514\u2500 Deployed: +3 minutes\n\nTotal Lead Time: 20 minutes \u2705 Elite\n</code></pre></p> </li> <li> <p>Identify bottlenecks:</p> </li> <li>If \"PR approval\" takes hours \u2192 Need faster reviews</li> <li>If \"Merge to deploy\" is slow \u2192 Optimize CI/CD pipeline</li> <li>If \"Commit to PR\" is long \u2192 Smaller changesets</li> </ol> <p>Lead Time Stages</p> <p>Fawkes tracks each stage separately so you can identify exactly where delays occur.</p> <p>Checkpoint</p> <p>You understand your lead time and where time is spent.</p>"},{"location":"tutorials/6-measure-dora-metrics/#step-7-monitor-change-failure-rate","title":"Step 7: Monitor Change Failure Rate","text":"<p>Let's see how often deployments cause problems.</p> <ol> <li> <p>In DevLake, navigate to DORA Dashboard \u2192 Change Failure Rate.</p> </li> <li> <p>The dashboard shows:</p> </li> <li>Percentage of failed deployments</li> <li>Failed vs. successful deployments over time</li> <li> <p>Correlation with deployment frequency</p> </li> <li> <p>What counts as a \"failure\"?</p> </li> <li>Deployment rollback</li> <li>Hotfix deployed within 24 hours</li> <li>Production incident tagged to a deployment</li> <li> <p>Pod crash loops after deployment</p> </li> <li> <p>Example analysis:</p> </li> <li>\"3 deployments, 0 failures = 0% failure rate \u2705 Elite\"</li> <li> <p>Or: \"10 deployments, 3 failures = 30% failure rate \u26a0\ufe0f Medium\"</p> </li> <li> <p>If you have failures, click to see details:</p> </li> <li>Which commit caused the failure?</li> <li>What was the error?</li> <li>How long until it was fixed?</li> </ol> <p>Improving Change Failure Rate</p> <ul> <li>Increase test coverage</li> <li>Add canary deployments</li> <li>Implement feature flags</li> <li>Improve staging environment parity</li> </ul> <p>Checkpoint</p> <p>You can track how often your deployments fail.</p>"},{"location":"tutorials/6-measure-dora-metrics/#step-8-measure-time-to-restore-service","title":"Step 8: Measure Time to Restore Service","text":"<p>Finally, let's look at recovery time when failures do occur.</p> <ol> <li> <p>In DevLake, navigate to DORA Dashboard \u2192 Mean Time to Restore.</p> </li> <li> <p>The dashboard shows:</p> </li> <li>Average time from incident detection to resolution</li> <li>Trend over time</li> <li> <p>Incidents by severity</p> </li> <li> <p>What counts as an \"incident\"?</p> </li> <li>Service downtime (health check failures)</li> <li>Error rate spike</li> <li>Performance degradation</li> <li> <p>Manual incident creation in PagerDuty/Mattermost</p> </li> <li> <p>Example incident timeline:    <pre><code>Incident Detected: 2025-12-06 14:00:00 (Automated alert)\n\u251c\u2500 Team Notified: +1 minute (Mattermost alert)\n\u251c\u2500 Diagnosis Started: +5 minutes (Engineer joined)\n\u251c\u2500 Fix Identified: +10 minutes (Found bad config)\n\u251c\u2500 Rollback Initiated: +2 minutes (ArgoCD rollback)\n\u2514\u2500 Service Restored: +3 minutes (Health checks pass)\n\nTotal MTTR: 21 minutes \u2705 Elite\n</code></pre></p> </li> <li> <p>If you don't have incidents yet (great!), you can simulate one:    <pre><code># Break the service temporarily\nkubectl scale deployment hello-fawkes -n my-first-app --replicas=0\n\n# Wait 2 minutes for alert\n\n# Restore service\nkubectl scale deployment hello-fawkes -n my-first-app --replicas=2\n</code></pre></p> </li> </ol> <p>Simulated Incidents</p> <p>Only simulate incidents in development/staging. Never in production!</p> <p>Checkpoint</p> <p>You can measure how quickly your team recovers from incidents.</p>"},{"location":"tutorials/6-measure-dora-metrics/#step-9-create-a-dora-improvement-plan","title":"Step 9: Create a DORA Improvement Plan","text":"<p>Based on your metrics, create an action plan.</p> <ol> <li>In DevLake or Grafana, export your current DORA metrics:</li> <li>Deployment Frequency: X per week</li> <li>Lead Time: X minutes</li> <li>Change Failure Rate: X%</li> <li> <p>MTTR: X minutes</p> </li> <li> <p>Identify your current performance tier:</p> </li> <li> <p>Elite, High, Medium, or Low for each metric</p> </li> <li> <p>Choose one metric to improve first:</p> </li> <li>Pick the one farthest from Elite</li> <li> <p>Or the one with the biggest business impact</p> </li> <li> <p>Set a SMART goal:</p> </li> <li>Specific: Increase deployment frequency</li> <li>Measurable: From 3/week to 1/day</li> <li>Achievable: By automating tests</li> <li>Relevant: Faster feedback to customers</li> <li> <p>Time-bound: Within 30 days</p> </li> <li> <p>Track progress:</p> </li> <li>Review DORA dashboard weekly</li> <li>Adjust tactics based on data</li> <li>Celebrate improvements!</li> </ol> <p>Checkpoint</p> <p>You have a data-driven plan to improve your DORA metrics.</p>"},{"location":"tutorials/6-measure-dora-metrics/#what-youve-accomplished","title":"What You've Accomplished","text":"<p>Congratulations! You've successfully:</p> <ul> <li>\u2705 Understood the four key DORA metrics</li> <li>\u2705 Configured your service for metric collection</li> <li>\u2705 Viewed metrics in DevLake dashboards</li> <li>\u2705 Analyzed deployment frequency, lead time, failure rate, and MTTR</li> <li>\u2705 Created an improvement plan based on data</li> </ul>"},{"location":"tutorials/6-measure-dora-metrics/#key-insights","title":"Key Insights","text":"<p>Through this tutorial, you've learned:</p> <ol> <li>DORA metrics are objective - No more arguing about \"good\" or \"bad\" deployment practices</li> <li>Fawkes automates collection - No manual tracking or surveys needed</li> <li>Trends matter more than absolutes - Focus on improving, not perfection</li> <li>All four metrics work together - Optimizing one at the expense of others doesn't work</li> <li>Elite performance is achievable - With the right platform and practices</li> </ol>"},{"location":"tutorials/6-measure-dora-metrics/#whats-next","title":"What's Next?","text":"<p>Continue your Fawkes journey:</p> <ol> <li>Review all tutorials - Ensure you've completed 1-6</li> <li>Join the Dojo - Progress through belt levels for deeper learning</li> <li>Share your metrics - Discuss with your team and set collective goals</li> <li>Contribute back - Share your DORA improvement story with the community</li> </ol>"},{"location":"tutorials/6-measure-dora-metrics/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/6-measure-dora-metrics/#no-data-in-devlake","title":"No Data in DevLake","text":"<pre><code># Check DevLake is running\nkubectl get pods -n fawkes-platform -l app=devlake\n\n# Verify GitHub connection\n# In DevLake UI: Data Connections \u2192 GitHub\n\n# Check ArgoCD notifications\nkubectl logs -n argocd -l app.kubernetes.io/name=argocd-notifications-controller\n</code></pre>"},{"location":"tutorials/6-measure-dora-metrics/#metrics-seem-wrong","title":"Metrics Seem Wrong","text":"<ul> <li>Verify time zone settings in DevLake</li> <li>Check that repository is correctly tagged</li> <li>Ensure ArgoCD sync policies are correct</li> <li>Review incident tagging criteria</li> </ul>"},{"location":"tutorials/6-measure-dora-metrics/#cant-see-my-service","title":"Can't See My Service","text":"<ul> <li>Confirm ArgoCD application has DORA annotations</li> <li>Verify repository is connected in DevLake</li> <li>Check that commits are being detected</li> <li>Wait 5-10 minutes for data pipeline to process</li> </ul>"},{"location":"tutorials/6-measure-dora-metrics/#learn-more","title":"Learn More","text":"<ul> <li>DORA Capabilities - All 24 capabilities that drive DORA metrics</li> <li>How to View DORA Metrics - Advanced DevLake usage</li> <li>Accelerate Book - The research behind DORA metrics</li> <li>State of DevOps Report - Annual DORA research</li> </ul>"},{"location":"tutorials/6-measure-dora-metrics/#feedback","title":"Feedback","text":"<p>What did you learn from your DORA metrics? What surprised you? Share your insights in the Fawkes Community Mattermost!</p>"},{"location":"tutorials/6-measure-dora-metrics/#youve-completed-all-six-tutorials","title":"\ud83c\udf89 You've Completed All Six Tutorials!","text":"<p>Congratulations on completing the entire Fawkes tutorial series! You now have:</p> <ul> <li>\u2705 Deployed a service to Fawkes</li> <li>\u2705 Added distributed tracing</li> <li>\u2705 Implemented Vault secret management</li> <li>\u2705 Migrated to Cloud Native Buildpacks</li> <li>\u2705 Created a Golden Path template</li> <li>\u2705 Measured and analyzed DORA metrics</li> </ul>"},{"location":"tutorials/6-measure-dora-metrics/#next-steps","title":"Next Steps","text":"<ol> <li>Join the Dojo - Start your White Belt journey</li> <li>Explore How-To Guides - Solve specific problems</li> <li>Read Explanations - Deepen your understanding</li> <li>Contribute - Help improve Fawkes</li> </ol>"},{"location":"tutorials/6-measure-dora-metrics/#share-your-success","title":"Share Your Success","text":"<ul> <li>Post your achievement in Mattermost</li> <li>Write a blog post about your experience</li> <li>Help others complete the tutorials</li> <li>Contribute improvements to the docs</li> </ul> <p>Thank you for learning with Fawkes! \ud83d\ude80</p>"}]}